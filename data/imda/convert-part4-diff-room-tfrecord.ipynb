{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbf1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'mesolitica-tpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff0dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.7/site-packages/malaya_boilerplate/frozen_graph.py:25: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  'Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0'\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import malaya_speech\n",
    "from malaya_speech.utils import subword\n",
    "import numpy as np\n",
    "import mp\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a0a6fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "489837"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singlish = glob('part4-diff-room/wav/*.wav')\n",
    "len(singlish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8347a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords = subword.load('transducer-singlish.subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23aea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "vocabs = [\" \", \"a\", \"e\", \"n\", \"i\", \"t\", \"o\", \"u\", \"s\", \"k\", \"r\", \"l\", \"h\", \"d\", \"m\", \"g\", \"y\", \"b\", \"p\", \"w\", \"c\", \"f\", \"j\", \"v\", \"z\", \"0\", \"1\", \"x\", \"2\", \"q\", \"5\", \"3\", \"4\", \"6\", \"9\", \"8\", \"7\"]\n",
    "\n",
    "def preprocessing_text(string):\n",
    "    \n",
    "    string = unicodedata.normalize('NFC', string.lower())\n",
    "    string = string.replace('\\'', '')\n",
    "    string = ''.join([c if c in vocabs else ' ' for c in string])\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = (\n",
    "        ''.join(''.join(s)[:2] for _, s in itertools.groupby(string))\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8edad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_after_mandarin(word):\n",
    "    if '<mandarin>' in word:\n",
    "        w = word.split('>')[1].split(':')[1]\n",
    "        return w.split('</')[0]\n",
    "    else:\n",
    "        return word\n",
    "    \n",
    "def get_before_mandarin(word):\n",
    "    if '</mandarin>' in word:\n",
    "        return word.split('</')[0]\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def replace_paralinguistic(string, replaces = ['(ppb)', '(ppc)', '(ppl)', '(ppo)', '<UNK>', '<MANDARIN>']):\n",
    "    for r in replaces:\n",
    "        string = string.replace(r, ' ')\n",
    "    string = string.split()\n",
    "    string = [get_after_mandarin(w) for w in string]\n",
    "    string = [get_before_mandarin(w) for w in string]\n",
    "    string = [w for w in string if w[0] not in '<[(' and w[-1] not in '>])']\n",
    "    return ' '.join(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f89c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(files):\n",
    "    files, index = files\n",
    "    results = []\n",
    "    for i in tqdm(files):\n",
    "        try:\n",
    "            p = i.replace('/wav','/text')\n",
    "            with open(f'{p}.txt') as fopen:\n",
    "                text = fopen.read()\n",
    "            if len(text) < 2:\n",
    "                continue\n",
    "            if text[0] == '<' and text[-1] == '>':\n",
    "                continue\n",
    "            text = replace_paralinguistic(text)\n",
    "            text = preprocessing_text(text)\n",
    "            if len(text):\n",
    "                results.append((i, text))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9cc477e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 943.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('part4-diff-room/wav/sur_0755_2510_phnd_cs-tml-0-230.wav', 'doubt irukku'),\n",
       " ('part4-diff-room/wav/sur_1183_3366_phnd_cs-chn-0-433.wav', 'so'),\n",
       " ('part4-diff-room/wav/sur_0983_2967_phnd_cs-chn-0-1354.wav',\n",
       "  'like like ni ming tian yao qu club then ni today need to go like testing'),\n",
       " ('part4-diff-room/wav/sur_0010_1020_phnd_cs-chn-0-146.wav',\n",
       "  'you need to turn off your phone vibrations dude')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop((singlish[:10], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1253042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40819/40819 [03:08<00:00, 216.96it/s] \n",
      "100%|██████████| 40819/40819 [03:07<00:00, 217.49it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 163.71it/s].40it/s]\n",
      "100%|██████████| 40819/40819 [03:08<00:00, 216.65it/s]\n",
      "100%|██████████| 40819/40819 [03:08<00:00, 217.00it/s]\n",
      "100%|██████████| 40819/40819 [03:09<00:00, 215.94it/s]\n",
      "100%|██████████| 40819/40819 [03:08<00:00, 216.17it/s]\n",
      "100%|██████████| 40819/40819 [03:10<00:00, 214.58it/s] \n",
      "100%|██████████| 40819/40819 [03:10<00:00, 214.61it/s] \n",
      "100%|██████████| 40819/40819 [03:10<00:00, 214.41it/s] \n",
      "100%|██████████| 40819/40819 [03:10<00:00, 213.80it/s] \n",
      "100%|██████████| 40819/40819 [03:11<00:00, 213.44it/s] \n",
      "100%|██████████| 40819/40819 [03:11<00:00, 213.37it/s] \n"
     ]
    }
   ],
   "source": [
    "singlishs = mp.multiprocessing(singlish, loop, cores = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83357343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188242"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(singlishs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae880a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "\n",
    "def to_example(dictionary):\n",
    "    \"\"\"Helper: build tf.Example from (string -> int/float/str list) dictionary.\"\"\"\n",
    "    features = {}\n",
    "    for (k, v) in six.iteritems(dictionary):\n",
    "        if not v:\n",
    "            raise ValueError('Empty generated field: %s' % str((k, v)))\n",
    "        # Subtly in PY2 vs PY3, map is not scriptable in py3. As a result,\n",
    "        # map objects will fail with TypeError, unless converted to a list.\n",
    "        if six.PY3 and isinstance(v, map):\n",
    "            v = list(v)\n",
    "        if isinstance(v[0], six.integer_types) or np.issubdtype(\n",
    "            type(v[0]), np.integer\n",
    "        ):\n",
    "            features[k] = tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=v)\n",
    "            )\n",
    "        elif isinstance(v[0], float):\n",
    "            features[k] = tf.train.Feature(\n",
    "                float_list=tf.train.FloatList(value=v)\n",
    "            )\n",
    "        elif isinstance(v[0], six.string_types):\n",
    "            if not six.PY2:  # Convert in python 3.\n",
    "                v = [bytes(x, 'utf-8') for x in v]\n",
    "            features[k] = tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=v)\n",
    "            )\n",
    "        elif isinstance(v[0], bytes):\n",
    "            features[k] = tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=v)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Value for %s is not a recognized type; v: %s type: %s'\n",
    "                % (k, str(v[0]), str(type(v[0])))\n",
    "            )\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b4400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "maxlen = 18\n",
    "minlen_text = 1\n",
    "global_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ff52da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(files):\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket('mesolitica-tpu-general')\n",
    "    files, index = files\n",
    "    output_file = f'{index}-{global_count}.tfrecord'\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "    for s in tqdm(files):\n",
    "        try:\n",
    "            if len(s[1]) < minlen_text:\n",
    "                continue\n",
    "            y, _ = malaya_speech.load(s[0])\n",
    "            if (len(y) / sr) > maxlen:\n",
    "                continue\n",
    "            t = subword.encode(subwords, s[1], add_blank=False)\n",
    "            example = to_example({'waveforms': y.tolist(), \n",
    "                                  'targets': t, \n",
    "                                  'targets_length': [len(t)]})\n",
    "            writer.write(example.SerializeToString())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    writer.close()\n",
    "    blob = bucket.blob(f'imda/part4-diff-room/{output_file}')\n",
    "    blob.upload_from_filename(output_file)\n",
    "    os.system(f'rm {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9045b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 33.39it/s]\n"
     ]
    }
   ],
   "source": [
    "loop((singlishs[:10], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28377eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 58/4166 [00:02<02:28, 27.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1211/4166 [01:00<02:41, 18.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1264/4166 [01:00<02:24, 20.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4166/4166 [03:19<00:00, 20.89it/s]\n",
      "100%|██████████| 4166/4166 [03:19<00:00, 20.83it/s]\n",
      "100%|██████████| 4166/4166 [03:21<00:00, 20.68it/s]\n",
      "100%|██████████| 4166/4166 [03:23<00:00, 20.49it/s]\n",
      "100%|██████████| 4166/4166 [03:23<00:00, 20.47it/s]\n",
      "100%|██████████| 4166/4166 [03:26<00:00, 20.21it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 28.54it/s]\n",
      "  8%|▊         | 352/4166 [00:14<02:08, 29.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3198/4166 [02:14<00:41, 23.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4079/4166 [02:50<00:03, 27.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4166/4166 [02:52<00:00, 24.14it/s]\n",
      "100%|██████████| 4166/4166 [02:53<00:00, 23.99it/s]\n",
      "100%|██████████| 4166/4166 [02:54<00:00, 23.93it/s]\n",
      "100%|██████████| 4166/4166 [02:54<00:00, 23.88it/s]\n",
      "100%|██████████| 4166/4166 [02:54<00:00, 23.88it/s]\n",
      "100%|██████████| 4166/4166 [02:56<00:00, 23.66it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 58.06it/s]\n",
      "100%|██████████| 4166/4166 [02:50<00:00, 24.39it/s]\n",
      "100%|██████████| 4166/4166 [02:52<00:00, 24.17it/s]\n",
      "100%|██████████| 4166/4166 [02:56<00:00, 23.64it/s]\n",
      "100%|██████████| 4166/4166 [02:56<00:00, 23.61it/s]\n",
      "100%|██████████| 4166/4166 [02:56<00:00, 23.59it/s]\n",
      "100%|██████████| 4166/4166 [02:57<00:00, 23.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 53.25it/s]\n",
      "  1%|          | 24/4166 [00:01<03:56, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 1941/4166 [01:24<01:32, 24.16it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 4166/4166 [02:57<00:00, 23.44it/s]\n",
      "100%|██████████| 4166/4166 [02:58<00:00, 23.39it/s]\n",
      "100%|██████████| 4166/4166 [02:58<00:00, 23.37it/s]\n",
      "100%|██████████| 4166/4166 [02:59<00:00, 23.27it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 54.93it/s]\n",
      " 12%|█▏        | 501/4166 [00:22<02:03, 29.79it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 27%|██▋       | 1104/4166 [00:46<02:11, 23.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2406/4166 [01:38<01:38, 17.90it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 19%|█▉        | 787/4166 [00:33<02:46, 20.30it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 61%|██████    | 2522/4166 [01:42<00:49, 33.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2617/4166 [01:49<01:09, 22.21it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 54%|█████▍    | 1198/2207 [00:50<00:41, 24.21it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 2207/2207 [01:27<00:00, 25.21it/s]\n",
      "100%|██████████| 2207/2207 [01:29<00:00, 24.68it/s]\n",
      "100%|██████████| 2207/2207 [01:29<00:00, 24.60it/s]\n",
      "100%|██████████| 2207/2207 [01:30<00:00, 24.36it/s]\n",
      "100%|██████████| 2207/2207 [01:30<00:00, 24.32it/s]\n",
      "100%|██████████| 2207/2207 [01:30<00:00, 24.31it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 25000\n",
    "for i in range(0, len(singlishs), batch_size):\n",
    "    batch = singlishs[i: i + batch_size]\n",
    "    mp.multiprocessing(batch, loop, cores = 6, returned = False)\n",
    "    global_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e83ba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.utils import tf_featurization\n",
    "\n",
    "config = malaya_speech.config.transducer_featurizer_config\n",
    "featurizer = tf_featurization.STTFeaturizer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ecc4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "\n",
    "def preprocess_inputs(example):\n",
    "    s = featurizer.vectorize(example['waveforms'])\n",
    "    mel_fbanks = tf.reshape(s, (-1, n_mels))\n",
    "    example['inputs'] = mel_fbanks\n",
    "    return example\n",
    "\n",
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.compat.v1.VarLenFeature(tf.float32),\n",
    "        'targets': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'targets_length': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.compat.v1.parse_single_example(\n",
    "        serialized_example, features = data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "        \n",
    "    features = preprocess_inputs(features)\n",
    "\n",
    "    keys = list(features.keys())\n",
    "    for k in keys:\n",
    "        if k not in ['waveforms', 'inputs', 'targets', 'targets_length']:\n",
    "            features.pop(k, None)\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_dataset(files, batch_size = 2, shuffle_size = 32, thread_count = 24):\n",
    "    def get():\n",
    "        dataset = tf.data.TFRecordDataset(files)\n",
    "        dataset = dataset.shuffle(shuffle_size)\n",
    "        dataset = dataset.map(parse, num_parallel_calls = thread_count)\n",
    "        dataset = dataset.repeat()\n",
    "        return dataset\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f80dd5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.io.gfile.glob('gs://mesolitica-tpu-general/imda/part4-diff-room/*.tfrecord')\n",
    "d = get_dataset(files)()\n",
    "d = d.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76ad1873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'targets': array([ 99, 795,  31, 795,  78,   2,  59, 405,  22,   1, 795, 214, 556,\n",
       "         19,  38, 795,  31, 795,   7, 362, 243, 248]),\n",
       " 'targets_length': array([22]),\n",
       " 'waveforms': array([0.00248065, 0.00290834, 0.00205295, ..., 0.00521791, 0.00560284,\n",
       "        0.00577392], dtype=float32),\n",
       " 'inputs': array([[-1.9488629 , -2.057597  , -2.8818624 , ..., -0.86949223,\n",
       "         -0.9249324 , -0.78570694],\n",
       "        [-2.5919015 , -2.1173923 , -1.8380868 , ..., -0.72417307,\n",
       "         -0.86280835, -0.73799723],\n",
       "        [-2.0038202 , -1.5480981 , -1.2718482 , ..., -0.7812969 ,\n",
       "         -0.66750306, -0.75536823],\n",
       "        ...,\n",
       "        [-0.986085  , -0.83058625, -0.6588496 , ..., -0.52381754,\n",
       "         -0.6392593 , -0.6377021 ],\n",
       "        [-1.1207328 , -1.1697851 , -1.3221172 , ..., -0.74652433,\n",
       "         -0.5505037 , -0.7463927 ],\n",
       "        [-1.3293318 , -1.395412  , -1.6278265 , ..., -0.81956124,\n",
       "         -0.5398238 , -0.776421  ]], dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334b4c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
