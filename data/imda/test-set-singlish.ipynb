{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/husein/t5/prepare/mesolitica-tpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/speech/manglish/test-wav.tgz\n",
    "# !tar -zxf test-wav.tgz\n",
    "# !rm test-wav.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13189"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "wavs = glob('test-wav/*.WAV')\n",
    "len(wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_filename</th>\n",
       "      <th>wav_filesize</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221930043.WAV</td>\n",
       "      <td>219052</td>\n",
       "      <td>b r sreenivasan ho see beng and sai hua kuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221930091.WAV</td>\n",
       "      <td>172204</td>\n",
       "      <td>p c show kiki and kinohimitsu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221931702.WAV</td>\n",
       "      <td>149804</td>\n",
       "      <td>wantan mee is a traditional local cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221930052.WAV</td>\n",
       "      <td>195276</td>\n",
       "      <td>antonia recently opened a new hainanese curry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221931492.WAV</td>\n",
       "      <td>155372</td>\n",
       "      <td>three two seven four nine six three zero</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wav_filename  wav_filesize  \\\n",
       "0  221930043.WAV        219052   \n",
       "1  221930091.WAV        172204   \n",
       "2  221931702.WAV        149804   \n",
       "3  221930052.WAV        195276   \n",
       "4  221931492.WAV        155372   \n",
       "\n",
       "                                          transcript  \n",
       "0       b r sreenivasan ho see beng and sai hua kuan  \n",
       "1                      p c show kiki and kinohimitsu  \n",
       "2          wantan mee is a traditional local cuisine  \n",
       "3  antonia recently opened a new hainanese curry ...  \n",
       "4           three two seven four nine six three zero  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('test-wav/notes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = []\n",
    "for a in audios:\n",
    "    testset.append((os.path.join('test-wav', a[0]), a[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import json\n",
    "\n",
    "subwords = malaya_speech.subword.load('transducer-singlish.subword')\n",
    "\n",
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.compat.v1.VarLenFeature(tf.float32),\n",
    "        'targets': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'targets_length': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.compat.v1.parse_single_example(\n",
    "        serialized_example, features=data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "\n",
    "    return features\n",
    "\n",
    "def get_dataset(files, shuffle_size=32, num_cpu_threads=4,\n",
    "                thread_count=24, is_training=False):\n",
    "    def get():\n",
    "        if is_training:\n",
    "            d = tf.data.Dataset.from_tensor_slices(tf.constant(files))\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=len(files))\n",
    "            cycle_length = min(num_cpu_threads, len(files))\n",
    "            d = d.apply(\n",
    "                tf.contrib.data.parallel_interleave(\n",
    "                    tf.data.TFRecordDataset,\n",
    "                    sloppy=is_training,\n",
    "                    cycle_length=cycle_length))\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "        else:\n",
    "            d = tf.data.TFRecordDataset(files)\n",
    "        d = d.map(parse, num_parallel_calls=thread_count)\n",
    "        return d\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-570e93e45039>:5: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext:0' shape=(?,) dtype=int64>,\n",
       " 'targets_length': <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int64>,\n",
       " 'waveforms': <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=float32>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('imda-tfrecords.json') as fopen:\n",
    "    imda_tfrecord = json.load(fopen)\n",
    "    \n",
    "dev_dataset = get_dataset(imda_tfrecord['test'], is_training=False)()\n",
    "features = dev_dataset.make_one_shot_iterator().get_next()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('rm -rf testset-imda')\n",
    "os.system('mkdir testset-imda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function soundfile.write(file, data, samplerate, subtype=None, endian=None, format=None, closefd=True)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "sf.write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "maxsize = 2000\n",
    "\n",
    "index = 0\n",
    "while True:\n",
    "    try:\n",
    "        r = sess.run(features)\n",
    "        f = f'testset-imda/{index}.wav'\n",
    "        sf.write(f, r['waveforms'], 16000)\n",
    "        t = malaya_speech.subword.decode(subwords, r['targets'])\n",
    "        testset.append((f, t))\n",
    "        index += 1\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        if index >= maxsize:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15189"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test-set-imda.json', 'w') as fopen:\n",
    "    json.dump(testset, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zcf testset-imda.tar.gz testset-imda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_application_key_id = os.environ['b2_application_key_id']\n",
    "b2_application_key = os.environ['b2_application_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from b2sdk.v1 import *\n",
    "info = InMemoryAccountInfo()\n",
    "b2_api = B2Api(info)\n",
    "application_key_id = b2_application_key_id\n",
    "application_key = b2_application_key\n",
    "b2_api.authorize_account(\"production\", application_key_id, application_key)\n",
    "file_info = {'how': 'good-file'}\n",
    "b2_bucket = b2_api.get_bucket_by_name('malay-dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPutname = f'speech/manglish/testset-imda.tar.gz'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file='testset-imda.tar.gz',\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPutname = f'speech/manglish/test-set-imda.json'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file='test-set-imda.json',\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
