{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/husein/t5/prepare/mesolitica-tpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = tf.io.gfile.glob('gs://mesolitica-tpu-general/imda/*/*.tfrecord')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'part1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0].split('gs://mesolitica-tpu-general/imda/')[1].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "parts = defaultdict(list)\n",
    "for f in files:\n",
    "    part = f.split('gs://mesolitica-tpu-general/imda/')[1].split('/')[0]\n",
    "    parts[part].append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['part1', 'part2', 'part3', 'part4-diff-room', 'part4-same-room', 'part5-debate', 'part6-call-centre-1', 'part6-call-centre-2'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 974)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = []\n",
    "train_set = []\n",
    "for part in parts.keys():\n",
    "    if len(parts[part]) >= 100:\n",
    "        choice = random.choice(parts[part])\n",
    "        train = list(set(parts[part]) - set([choice]))\n",
    "        train_set.extend(train)\n",
    "        test_set.append(choice)\n",
    "    else:\n",
    "        train_set.extend(parts[part])\n",
    "len(test_set), len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://mesolitica-tpu-general/imda/part1/0-29.tfrecord',\n",
       " 'gs://mesolitica-tpu-general/imda/part2/5-30.tfrecord',\n",
       " 'gs://mesolitica-tpu-general/imda/part3/4-16.tfrecord',\n",
       " 'gs://mesolitica-tpu-general/imda/part4-same-room/3-2.tfrecord']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('imda-tfrecords.json', 'w') as fopen:\n",
    "    json.dump({'train': train_set, 'test': test_set}, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:41: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:44: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import malaya_speech.train as train\n",
    "import malaya_speech.config\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.augmentation.spectrogram as mask_augmentation\n",
    "import malaya_speech.augmentation.waveform as augmentation\n",
    "import malaya_speech\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature=True\n",
    ")\n",
    "n_mels = featurizer.num_feature_bins\n",
    "\n",
    "def mel_augmentation(features):\n",
    "\n",
    "    features = mask_augmentation.warp_time_pil(features)\n",
    "    features = mask_augmentation.mask_frequency(features, width_freq_mask=12)\n",
    "    features = mask_augmentation.mask_time(\n",
    "        features, width_time_mask=int(features.shape[0] * 0.05)\n",
    "    )\n",
    "    return features\n",
    "\n",
    "\n",
    "def preprocess_inputs(example):\n",
    "    s = featurizer.vectorize(example['waveforms'])\n",
    "    s = tf.reshape(s, (-1, n_mels))\n",
    "    s = tf.compat.v1.numpy_function(mel_augmentation, [s], tf.float32)\n",
    "    mel_fbanks = tf.reshape(s, (-1, n_mels))\n",
    "    length = tf.cast(tf.shape(mel_fbanks)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['inputs'] = mel_fbanks\n",
    "    example['inputs_length'] = length\n",
    "    example['targets'] = tf.cast(example['targets'], tf.int32)\n",
    "    example['targets_length'] = tf.cast(example['targets_length'], tf.int32)\n",
    "    return example\n",
    "\n",
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.compat.v1.VarLenFeature(tf.float32),\n",
    "        'targets': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'targets_length': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.compat.v1.parse_single_example(\n",
    "        serialized_example, features=data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "\n",
    "    features = preprocess_inputs(features)\n",
    "\n",
    "    keys = list(features.keys())\n",
    "    for k in keys:\n",
    "        if k not in ['inputs', 'inputs_length', 'targets', 'targets_length']:\n",
    "            features.pop(k, None)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(files, batch_size=20, shuffle_size=32, num_cpu_threads=4,\n",
    "                thread_count=24, is_training=True):\n",
    "    def get():\n",
    "        if is_training:\n",
    "            d = tf.data.Dataset.from_tensor_slices(tf.constant(files))\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=len(files))\n",
    "            cycle_length = min(num_cpu_threads, len(files))\n",
    "            d = d.apply(\n",
    "                tf.contrib.data.parallel_interleave(\n",
    "                    tf.data.TFRecordDataset,\n",
    "                    sloppy=is_training,\n",
    "                    cycle_length=cycle_length))\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "        else:\n",
    "            d = tf.data.TFRecordDataset(files)\n",
    "            d = d.repeat()\n",
    "        d = d.map(parse, num_parallel_calls=thread_count)\n",
    "        d = d.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes={\n",
    "                'inputs': tf.TensorShape([None, n_mels]),\n",
    "                'inputs_length': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "                'targets_length': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values={\n",
    "                'inputs': tf.constant(0, dtype=tf.float32),\n",
    "                'inputs_length': tf.constant(0, dtype=tf.int32),\n",
    "                'targets': tf.constant(0, dtype=tf.int32),\n",
    "                'targets_length': tf.constant(0, dtype=tf.int32),\n",
    "            },\n",
    "        )\n",
    "        return d\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext_1:2' shape=(?, ?) dtype=int32>,\n",
       " 'targets_length': <tf.Tensor 'IteratorGetNext_1:3' shape=(?, ?) dtype=int32>,\n",
       " 'inputs': <tf.Tensor 'IteratorGetNext_1:0' shape=(?, ?, 80) dtype=float32>,\n",
       " 'inputs_length': <tf.Tensor 'IteratorGetNext_1:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_dataset(train_set, batch_size = 2)().make_one_shot_iterator().get_next()\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'targets': array([[ 66,  14,   3,  20,   5,  20,   5,   7, 272,  11, 378, 147, 148,\n",
       "           0,   0,   0,   0,   0,   0],\n",
       "        [103,  12, 795,  20, 114,  14,   3,  67, 136,  71, 795,  52,  21,\n",
       "          34,  16,  87,  62, 382, 875]], dtype=int32),\n",
       " 'targets_length': array([[13],\n",
       "        [19]], dtype=int32),\n",
       " 'inputs': array([[[-0.38590848, -0.85252655, -0.6197265 , ..., -2.2818308 ,\n",
       "          -2.0294595 , -2.3721614 ],\n",
       "         [-0.59135187, -1.0706898 , -0.7697544 , ..., -2.206452  ,\n",
       "          -2.0517805 , -1.6242082 ],\n",
       "         [-0.46245736, -0.9674944 , -0.719194  , ..., -1.5186559 ,\n",
       "          -1.6715912 , -2.067461  ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [-2.3213513 , -1.7293038 , -1.5346535 , ..., -0.7339674 ,\n",
       "          -0.5391779 , -0.7925337 ],\n",
       "         [-1.2983541 , -1.8814013 , -1.864261  , ..., -0.65046775,\n",
       "          -0.9367179 , -0.7629068 ],\n",
       "         [-3.1445928 , -1.8663467 , -1.6802825 , ..., -1.0523847 ,\n",
       "          -0.77213913, -0.53679425]]], dtype=float32),\n",
       " 'inputs_length': array([[192],\n",
       "        [309]], dtype=int32)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext_2:2' shape=(?, ?) dtype=int32>,\n",
       " 'targets_length': <tf.Tensor 'IteratorGetNext_2:3' shape=(?, ?) dtype=int32>,\n",
       " 'inputs': <tf.Tensor 'IteratorGetNext_2:0' shape=(?, ?, 80) dtype=float32>,\n",
       " 'inputs_length': <tf.Tensor 'IteratorGetNext_2:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = get_dataset(test_set, batch_size = 2, is_training=False)().make_one_shot_iterator().get_next()\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'targets': array([[111, 161,   2, 112,   1, 795, 592,   3, 102, 235, 795, 544, 663,\n",
       "           3, 103,   7, 272,  11, 271, 533,  48,  12, 795,  58, 795,  12,\n",
       "          22, 516,  17,  54, 300, 795,  34,  31, 226,   0,   0],\n",
       "        [ 59, 225, 135,  41, 795, 397, 213, 365,   2,   7,  92, 352, 218,\n",
       "         594,  25,  26, 795,  76,   1,  22,  75,  29, 795,   1, 795, 551,\n",
       "         164, 795, 237,   9, 200,  15, 534,   1,  22, 330,  81]],\n",
       "       dtype=int32), 'targets_length': array([[35],\n",
       "        [37]], dtype=int32), 'inputs': array([[[ 6.23412669e-01,  2.11047888e-01,  1.18641414e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.73207760e+00],\n",
       "         [ 7.89191663e-01,  1.65041089e-01, -4.14103091e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.46829021e+00],\n",
       "         [ 6.07244968e-01, -2.01284041e-04, -3.59744161e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.21086931e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 1.06527758e+00,  5.23685694e-01,  1.03925347e-01, ...,\n",
       "           0.00000000e+00,  0.00000000e+00, -1.49223351e+00]],\n",
       " \n",
       "        [[-1.92814350e-01, -6.56559289e-01, -5.23674488e-01, ...,\n",
       "          -1.54342556e+00, -1.60949194e+00, -1.46003234e+00],\n",
       "         [ 2.94934541e-01, -5.39069712e-01, -1.50340629e+00, ...,\n",
       "          -1.25976026e+00, -1.30834830e+00, -1.26130772e+00],\n",
       "         [-6.54452384e-01, -1.48488295e+00, -2.16398263e+00, ...,\n",
       "          -1.31364286e+00, -1.27572417e+00, -1.47943211e+00],\n",
       "         ...,\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "           0.00000000e+00,  0.00000000e+00,  0.00000000e+00]]],\n",
       "       dtype=float32), 'inputs_length': array([[683],\n",
       "        [646]], dtype=int32)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
