{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_wav(vid_path, sr = 16000, mode='eval'):\n",
    "    wav, sr_ret = librosa.load(vid_path, sr=sr)\n",
    "    assert sr_ret == sr\n",
    "    if mode == 'train':\n",
    "        extended_wav = np.append(wav, wav)\n",
    "        if np.random.random() < 0.3:\n",
    "            extended_wav = extended_wav[::-1]\n",
    "        return extended_wav\n",
    "    else:\n",
    "        extended_wav = np.append(wav, wav[::-1])\n",
    "        return extended_wav\n",
    "\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=1024):\n",
    "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length)\n",
    "    return linear.T\n",
    "\n",
    "\n",
    "def load_data(wav, win_length=400, sr=16000, hop_length=160, n_fft=512, spec_len=120, mode='train'):\n",
    "    # wav = load_wav(path, sr=sr, mode=mode)\n",
    "    linear_spect = lin_spectogram_from_wav(wav, hop_length, win_length, n_fft)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    mag_T = mag.T\n",
    "    freq, time = mag_T.shape\n",
    "    if mode == 'train':\n",
    "        if time < spec_len:\n",
    "            spec_mag = np.pad(mag_T, ((0, 0), (0, spec_len - time)), 'constant')\n",
    "        else:\n",
    "            spec_mag = mag_T\n",
    "    else:\n",
    "        spec_mag = mag_T\n",
    "    mu = np.mean(spec_mag, 0, keepdims=True)\n",
    "    std = np.std(spec_mag, 0, keepdims=True)\n",
    "    return (spec_mag - mu) / (std + 1e-5)\n",
    "\n",
    "def padding_sequence_nd(\n",
    "    seq, maxlen = None, padding: str = 'post', pad_val = 0.0, dim: int = 1\n",
    "):\n",
    "    if padding not in ['post', 'pre']:\n",
    "        raise ValueError('padding only supported [`post`, `pre`]')\n",
    "\n",
    "    if not maxlen:\n",
    "        maxlen = max([np.shape(s)[dim] for s in seq])\n",
    "\n",
    "    padded_seqs = []\n",
    "    for s in seq:\n",
    "        npad = [[0, 0] for _ in range(len(s.shape))]\n",
    "        if padding == 'pre':\n",
    "            padding = 0\n",
    "        if padding == 'post':\n",
    "            padding = 1\n",
    "        npad[dim][padding] = maxlen - s.shape[dim]\n",
    "        padded_seqs.append(\n",
    "            np.pad(\n",
    "                s,\n",
    "                pad_width = npad,\n",
    "                mode = 'constant',\n",
    "                constant_values = pad_val,\n",
    "            )\n",
    "        )\n",
    "    return np.array(padded_seqs)\n",
    "\n",
    "def add_noise(samples, noise, random_sample = True, factor = 0.1):\n",
    "    y_noise = samples.copy()\n",
    "    if len(y_noise) > len(noise):\n",
    "        noise = np.tile(noise, int(np.ceil(len(y_noise) / len(noise))))\n",
    "    else:\n",
    "        if random_sample:\n",
    "            noise = noise[np.random.randint(0, len(noise) - len(y_noise) + 1) :]\n",
    "    return y_noise + noise[: len(y_noise)] * factor\n",
    "\n",
    "def frames(\n",
    "    audio,\n",
    "    frame_duration_ms: int = 30,\n",
    "    sample_rate: int = 16000,\n",
    "):\n",
    "\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0))\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = float(n) / sample_rate\n",
    "    results = []\n",
    "    while offset + n < len(audio):\n",
    "        results.append(audio[offset : offset + n])\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('indices.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "\n",
    "files = data['files']\n",
    "speakers = data['speakers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(file):\n",
    "    return file.split('/')[-1].split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5368"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_speakers = sorted(list(speakers.keys()))\n",
    "unique_speakers.index(get_id(files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../noise/noise.pkl', 'rb') as fopen:\n",
    "    noises = pickle.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import itertools\n",
    "\n",
    "cycle_files = itertools.cycle(files)\n",
    "batch_size = 32\n",
    "\n",
    "def generate(partition = 100, batch_size = batch_size, sample_rate = 16000, max_length = 5):\n",
    "    while True:\n",
    "        batch_files = [next(cycle_files) for _ in range(partition)]\n",
    "        X, Y = [], []\n",
    "        for file in batch_files:\n",
    "            y = unique_speakers.index(get_id(file))\n",
    "            w = load_wav(file)\n",
    "            if len(w) / sample_rate > max_length:\n",
    "                X.append(w[:sample_rate * max_length])\n",
    "                Y.append(y)\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                f = frames(w, random.randint(500, max_length * 1000))\n",
    "                X.extend(f)\n",
    "                Y.extend([y] * len(f))\n",
    "        \n",
    "        for k in range(len(X)):\n",
    "            if random.randint(0, 1):\n",
    "                for _ in range(random.randint(1, 5)):\n",
    "                    x = add_noise(X[k], random.choice(noises), random.uniform(0.1, 0.6))\n",
    "                    X.append(x)\n",
    "                    Y.append(Y[k])\n",
    "        \n",
    "\n",
    "        actual_X, actual_Y = [], []\n",
    "\n",
    "        for k in range(len(X)):\n",
    "            try:\n",
    "                actual_X.append(load_data(X[k]))\n",
    "                actual_Y.append(Y[k])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        X, Y = shuffle(actual_X, actual_Y)\n",
    "        \n",
    "        for k in range(len(X)):\n",
    "            yield {'inputs': np.expand_dims(X[k], -1), 'targets': [Y[k]]}\n",
    "\n",
    "#         for k in range(0, (len(X) // batch_size) * batch_size, batch_size):\n",
    "#             batch_x = X[k: k + batch_size]\n",
    "#             batch_y = Y[k: k + batch_size]\n",
    "            \n",
    "#             yield {'inputs': padding_sequence_nd(batch_x), 'targets': batch_y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(example):\n",
    "    print(example)\n",
    "    return example\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generate, {'inputs': tf.float32, 'targets': tf.int32},\n",
    "                                        output_shapes={'inputs': tf.TensorShape([257, None, 1]), \n",
    "                                                       'targets': tf.TensorShape([1])})\n",
    "dataset = dataset.padded_batch(\n",
    "    batch_size,\n",
    "    padded_shapes = {\n",
    "        'inputs': tf.TensorShape([257, None, 1]),\n",
    "        'targets': tf.TensorShape([None]),\n",
    "    },\n",
    "    padding_values = {\n",
    "        'inputs': tf.constant(0, dtype = tf.float32),\n",
    "        'targets': tf.constant(0, dtype = tf.int32),\n",
    "    },\n",
    ")\n",
    "iterator = dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': <tf.Tensor 'IteratorGetNext_2:0' shape=(?, 257, ?, 1) dtype=float32>,\n",
       " 'targets': <tf.Tensor 'IteratorGetNext_2:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 257, 501, 1), (32, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sess.run(iterator)\n",
    "r['inputs'].shape, r['targets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4622],\n",
       "       [ 178],\n",
       "       [2491],\n",
       "       [  71],\n",
       "       [5550],\n",
       "       [ 178],\n",
       "       [2302],\n",
       "       [3193],\n",
       "       [3193],\n",
       "       [4712],\n",
       "       [5507],\n",
       "       [5386],\n",
       "       [2491],\n",
       "       [5487],\n",
       "       [5606],\n",
       "       [5419],\n",
       "       [4661],\n",
       "       [4114],\n",
       "       [1728],\n",
       "       [5536],\n",
       "       [5507],\n",
       "       [4565],\n",
       "       [2639],\n",
       "       [4622],\n",
       "       [3750],\n",
       "       [5982],\n",
       "       [5789],\n",
       "       [5386],\n",
       "       [4545],\n",
       "       [ 178],\n",
       "       [3754],\n",
       "       [5507]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
