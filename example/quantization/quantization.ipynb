{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "increased-pantyhose",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-porter",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [malaya-speech/example/quantization](https://github.com/huseinzol05/malaya-speech/tree/master/example/quantization).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-retailer",
   "metadata": {},
   "source": [
    "We provided Quantized model for all Malaya-Speech models, example, gender detection models,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gothic-empty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:last accuracy during training session before early stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>Quantized Size (MB)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vggvox-v2</th>\n",
       "      <td>31.1</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0.9756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep-speaker</th>\n",
       "      <td>96.9</td>\n",
       "      <td>24.40</td>\n",
       "      <td>0.9455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Size (MB)  Quantized Size (MB)  Accuracy\n",
       "vggvox-v2          31.1                 7.92    0.9756\n",
       "deep-speaker       96.9                24.40    0.9455"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import malaya_speech\n",
    "\n",
    "malaya_speech.gender.available_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-bracelet",
   "metadata": {},
   "source": [
    "Usually quantized model able to compress 4x of original size. This quantized model will convert all possible floating constants to quantized constants, and only stored mean, standard deviation of floating constants and quantized constants.\n",
    "\n",
    "Again, quantized model is not necessary faster, because tensorflow will cast back to FP32 during feed-forward for certain operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-youth",
   "metadata": {},
   "source": [
    "### Use quantized model\n",
    "\n",
    "Simply pass `quantized` parameter become `True`, default is `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "better-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Load quantized model will cause accuracy drop.\n",
      "INFO:root:running gender/vggvox-v2-quantized using device /device:CPU:0\n",
      "INFO:root:running gender/vggvox-v2 using device /device:CPU:0\n"
     ]
    }
   ],
   "source": [
    "quantized_vggvox_v2 = malaya_speech.gender.deep_model(model = 'vggvox-v2', quantized = True)\n",
    "vggvox_v2 = malaya_speech.gender.deep_model(model = 'vggvox-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imposed-uganda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 16000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = malaya_speech.load('speech/video/The-Singaporean-White-Boy.wav')\n",
    "y = y[:int(sr * 0.5)]\n",
    "len(y), sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dietary-lottery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 171 ms, sys: 32.5 ms, total: 203 ms\n",
      "Wall time: 51.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['not a gender']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vggvox_v2.predict([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "trying-capability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 147 ms, sys: 34.7 ms, total: 182 ms\n",
      "Wall time: 48.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['not a gender']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "quantized_vggvox_v2.predict([y])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
