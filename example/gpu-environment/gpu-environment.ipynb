{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "This tutorial is available as an IPython notebook at [malaya-speech/example/gpu-environment](https://github.com/huseinzol05/malaya-speech/tree/master/example/gpu-environment).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.55 s, sys: 2.71 s, total: 8.26 s\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import malaya_speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Malaya-Speech is GPU\n",
    "\n",
    "Make sure install malaya-speech-gpu to utilize full gpu functions in Malaya-Speech,\n",
    "\n",
    "```bash\n",
    "pip install malaya-speech-gpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya_speech.check_malaya_speech_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List available GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1', '/device:GPU:2', '/device:GPU:3']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya_speech.__gpu__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `Malaya-Speech` will not set max cap for GPU memory, to put a cap, override `gpu_limit` parameter in any load model API. `gpu_limit` should 0 < `gpu_limit` < 1. If `gpu_limit` = 0.3, it means the model will not use more than 30% of GPU memory.\n",
    "\n",
    "`malaya_speech.vad.deep_model(gpu_limit = 0.3)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Models to N gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allocate a model to another GPU, use gpu parameter, default is 0.\n",
    "\n",
    "```python\n",
    "malaya_speech.emotion.deep_model(gpu_limit = 0.5, gpu = 0)\n",
    "malaya_speech.language_detection.deep_model(gpu_limit = 0.5, gpu = 1)\n",
    "malaya_speech.noise_reduction.deep_model(gpu_limit = 0.5, gpu = 2)\n",
    "malaya_speech.vad.deep_model(gpu_limit = 0.5, gpu = 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `Malaya-Speech` will not consumed all available GPU memory, but slowly grow based on batch size. This growth only towards positive (use more GPU memory) dynamically, but will not reduce GPU memory if feed small batch size.\n",
    "2. Use `malaya_speech.clear_session` to clear session from unused models but this will not free GPU memory.\n",
    "3. Even if you installed `Malaya-Speech` CPU version, it will always to load the models in GPU 0 first, if failed, it will load it in CPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
