{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech.train as train\n",
    "import malaya_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[106, 103, 110, 110, 113, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = malaya_speech.char.encode('hello')\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello<EOS>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya_speech.char.decode(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "672"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "files = glob('../speech-bahasa/LibriSpeech/*/*/*/*.trans.txt')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31159, 31159)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audios, texts = [], []\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    p = os.path.split(file)[0]\n",
    "    with open(file) as fopen:\n",
    "        d = list(filter(None, fopen.read().split('\\n')))\n",
    "    \n",
    "    for row in d:\n",
    "        splitted = row.split()\n",
    "        s = os.path.join(p, splitted[0] + '.flac')\n",
    "        text = ' '.join(splitted[1:])\n",
    "        if not os.path.exists(s):\n",
    "            print(s, 'not exist')\n",
    "            continue\n",
    "        \n",
    "        audios.append(s)\n",
    "        texts.append(text)\n",
    "\n",
    "    \n",
    "len(audios), len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "_, audios, _, texts = train_test_split(audios, texts, test_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generator():\n",
    "    for i in tqdm(range(len(audios))):\n",
    "        wav_data, sr = malaya_speech.load(audios[i])\n",
    "\n",
    "        yield {\n",
    "            'waveforms': wav_data.tolist(),\n",
    "            'waveform_lens': [len(wav_data)],\n",
    "            'targets': malaya_speech.char.encode(texts[i]),\n",
    "            'raw_transcript': [texts[i]],\n",
    "        }\n",
    "        \n",
    "generator = generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.system('rm training/data/*')\n",
    "DATA_DIR = os.path.expanduser('training/data')\n",
    "tf.gfile.MakeDirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shards = [{'split': 'train', 'shards': 99}, {'split': 'dev', 'shards': 1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/prepare_data.py:89: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/prepare_data.py:199: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/prepare_data.py:205: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:Generating case 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [06:25<00:00, 25.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/prepare_data.py:218: The name tf.gfile.Rename is deprecated. Please use tf.io.gfile.rename instead.\n",
      "\n",
      "INFO:tensorflow:Generated 10000 Examples\n",
      "INFO:tensorflow:Shuffling data...\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/prepare_data.py:26: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/prepare_data.py:57: The name tf.gfile.Remove is deprecated. Please use tf.io.gfile.remove instead.\n",
      "\n",
      "INFO:tensorflow:Data shuffled.\n"
     ]
    }
   ],
   "source": [
    "train.prepare_dataset(generator, DATA_DIR, shards, prefix = 'librispeech')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
