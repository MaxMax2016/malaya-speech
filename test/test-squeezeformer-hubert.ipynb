{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run test-mfcc-kmean.ipynb first to get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "from malaya_speech.train.model import hubert, bert, fastspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encoder_subsampling': {'type': 'conv2d',\n",
       "  'filters': 196,\n",
       "  'kernel_size': 3,\n",
       "  'strides': 2},\n",
       " 'encoder_dmodel': 196,\n",
       " 'encoder_num_blocks': 18,\n",
       " 'encoder_head_size': 49,\n",
       " 'encoder_num_heads': 4,\n",
       " 'encoder_mha_type': 'relmha',\n",
       " 'encoder_kernel_size': 31,\n",
       " 'encoder_fc_factor': 1.0,\n",
       " 'encoder_dropout': 0.1,\n",
       " 'encoder_time_reduce_idx': [8],\n",
       " 'encoder_time_recover_idx': [17],\n",
       " 'encoder_conv_use_glu': False,\n",
       " 'encoder_ds_subsample': True,\n",
       " 'encoder_no_post_ln': True,\n",
       " 'encoder_adaptive_scale': True,\n",
       " 'encoder_fixed_arch': ['M', 's', 'C', 's']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya_speech.config.squeezeformer_s_encoder_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/squeezeformer/encoder.py:499: The name tf.keras.initializers.RandomUniform is deprecated. Please use tf.compat.v1.keras.initializers.RandomUniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n",
      "['M', 's', 'C', 's']\n"
     ]
    }
   ],
   "source": [
    "from malaya_speech.train.model.squeezeformer.model import Model as ConformerModel\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.encoder = ConformerModel(**self.config)\n",
    "\n",
    "    def __call__(self, x, input_mask, training = True):\n",
    "        print(input_mask)\n",
    "        input_lengths = tf.reduce_sum(tf.cast(input_mask, tf.int32), axis = 1)\n",
    "        return self.encoder(x, input_lengths)\n",
    "    \n",
    "config_conformer = malaya_speech.config.squeezeformer_s_encoder_config\n",
    "config_conformer['encoder_subsampling']['type'] = 'none'\n",
    "config_conformer['encoder_dropout'] = 0.0\n",
    "encoder = Encoder(config_conformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/hubert/model.py:59: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = hubert.HuBERTConfig()\n",
    "model = hubert.Model(cfg, encoder, ['pad', 'eos', 'unk'] + [str(i) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, (None, None))\n",
    "Y = tf.placeholder(tf.int32, (None, None))\n",
    "X_len = tf.placeholder(tf.int32, (None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/hubert/masking.py:10: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Tensor(\"hubert/LogicalNot:0\", shape=(?, ?), dtype=bool)\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/hubert/model.py:155: calling cosine_distance (from tensorflow.python.ops.losses.losses_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logit_m_list': <tf.Tensor 'hubert/transpose:0' shape=(?, 104) dtype=float32>,\n",
       " 'logit_u_list': <tf.Tensor 'hubert/transpose_1:0' shape=(?, 104) dtype=float32>,\n",
       " 'padding_mask': <tf.Tensor 'hubert/LogicalNot:0' shape=(?, ?) dtype=bool>,\n",
       " 'features_pen': <tf.Tensor 'hubert/Mean:0' shape=() dtype=float32>,\n",
       " 'x': <tf.Tensor 'hubert/conformer/conformer_encoder/conformer_encoder_block_17/conformer_encoder_block_17_layer3/conformer_encoder_block_17_layer3_ln/batchnorm/add_1:0' shape=(?, ?, 196) dtype=float32>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = model(X, padding_mask = X_len, target_list = Y)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_m = tf.zeros((tf.shape(r['logit_m_list'])[0],),dtype=tf.int32)\n",
    "target_u = tf.zeros((tf.shape(r['logit_u_list'])[0],),dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = tf.cast(tf.shape(target_m)[0], tf.float32)\n",
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = target_m, logits = r['logit_m_list'])\n",
    "entropy_m = tf.reduce_sum(entropy) / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = tf.cast(tf.shape(target_u)[0], tf.float32)\n",
    "entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = target_u, logits = r['logit_u_list'])\n",
    "entropy_u = tf.reduce_sum(entropy) / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = entropy_m * 0.95 + entropy_u * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456, 90)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = np.load('out.npy', mmap_mode=\"r\")\n",
    "leng_path = 'out.len'\n",
    "with open(leng_path, \"r\") as f:\n",
    "    lengs = [int(line.rstrip()) for line in f]\n",
    "    offsets = [0] + np.cumsum(lengs[:-1]).tolist()\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = hubert.kmeans.ApplyKmeans_TF('kmean.km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "for offset, leng in zip(offsets, lengs):\n",
    "    x = feat[offset: offset + leng]\n",
    "    y = kmean(x) + 3\n",
    "    ys.append(y)\n",
    "    xs.append(x)\n",
    "len(ys), len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90090, 56298)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = malaya_speech.load('../speech/example-speaker/husein-zolkepli.wav', sr = 16000)\n",
    "y1, sr = malaya_speech.load('../speech/example-speaker/shafiqah-idayu.wav', sr = 16000)\n",
    "len(y), len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 90090)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = malaya_speech.padding.sequence_1d([y, y1])\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 281)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_ = malaya_speech.padding.sequence_1d(ys)\n",
    "Y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = sess.run([r, loss, optimizer], feed_dict = {X: X_, X_len: [len(y), len(y1)], Y: Y_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.69257, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
