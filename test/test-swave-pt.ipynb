{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "earned-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southeast-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import malaya_speech.augmentation.waveform as augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electoral-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "british-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interpreted-intermediate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5, shape=(1, 178, 128), dtype=float32, numpy=\n",
       "array([[[-0.6716616 , -0.94313586, -1.983692  , ..., -0.8577411 ,\n",
       "         -0.09423348, -0.3860373 ],\n",
       "        [-0.46310467,  0.23541881, -2.483333  , ..., -1.1263511 ,\n",
       "         -0.8384689 ,  1.3011782 ],\n",
       "        [ 1.5427862 , -0.31271583,  0.30277067, ...,  0.6110602 ,\n",
       "          0.07288417,  0.8147117 ],\n",
       "        ...,\n",
       "        [-0.973642  , -1.4052933 , -1.6098809 , ...,  0.04782953,\n",
       "         -0.1449026 ,  0.55369186],\n",
       "        [ 1.8318324 ,  0.45195335, -0.08632987, ...,  0.79892737,\n",
       "          1.3192973 ,  0.16247705],\n",
       "        [-0.61873925, -0.52677757, -0.06590458, ..., -0.70629084,\n",
       "         -1.096342  ,  0.54372966]]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape = (1, 178, 128))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "global-dress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10, shape=(1, 178), dtype=int64, numpy=\n",
       "array([[128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
       "        128, 128, 128, 128, 128, 128, 128, 128, 128]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.count_nonzero(x, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "limited-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sr = 8000\n",
    "speakers_size = 4\n",
    "\n",
    "def read_wav(f):\n",
    "    return malaya_speech.load(f, sr = sr)\n",
    "\n",
    "def random_sampling(s, length):\n",
    "    return augmentation.random_sampling(s, sr = sr, length = length)\n",
    "\n",
    "def combine_speakers(files, n = 5, limit = 4):\n",
    "    w_samples = random.sample(files, n)\n",
    "    w_samples = [\n",
    "        random_sampling(\n",
    "            read_wav(f)[0],\n",
    "            length = min(\n",
    "                random.randint(10000 // n, 20000 // n), 10000\n",
    "            ),\n",
    "        )\n",
    "        for f in w_samples\n",
    "    ]\n",
    "    y = [w_samples[0]]\n",
    "    left = w_samples[0].copy() * random.uniform(0.5, 1.0)\n",
    "    start, end = [], []\n",
    "    start.append(0)\n",
    "    end.append(len(left))\n",
    "\n",
    "    combined = None\n",
    "\n",
    "    for i in range(1, n):\n",
    "        right = w_samples[i].copy() * random.uniform(0.5, 1.0)\n",
    "        overlap = random.uniform(0.1, 0.9)\n",
    "        print(i, overlap, len(right))\n",
    "        len_overlap = int(overlap * len(right))\n",
    "        minus = len(left) - len_overlap\n",
    "        padded_right = np.pad(right, (minus, 0))\n",
    "        start.append(minus)\n",
    "        end.append(len(padded_right))\n",
    "        left = np.pad(left, (0, len(padded_right) - len(left)))\n",
    "\n",
    "        left = left + padded_right\n",
    "\n",
    "        if i >= (limit - 1):\n",
    "            if combined is None:\n",
    "                combined = padded_right\n",
    "            else:\n",
    "                combined = np.pad(\n",
    "                    combined, (0, len(padded_right) - len(combined))\n",
    "                )\n",
    "                combined += padded_right\n",
    "\n",
    "        else:\n",
    "            y.append(padded_right)\n",
    "\n",
    "    if combined is not None:\n",
    "        y.append(combined)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if len(y[i]) != len(left):\n",
    "            y[i] = np.pad(y[i], (0, len(left) - len(y[i])))\n",
    "            y[i] = y[i] / np.max(np.abs(y[i]))\n",
    "\n",
    "    left = left / np.max(np.abs(left))\n",
    "    \n",
    "    while len(y) < limit:\n",
    "        y.append(np.zeros((len(left))))\n",
    "        start.append(0)\n",
    "        end.append(0)\n",
    "        \n",
    "    return left, y, start[:limit], end[:limit]\n",
    "\n",
    "# y, _ = malaya_speech.load('../speech/example-speaker/husein-zolkepli.wav')\n",
    "# y = np.expand_dims(y, 0).astype(np.float32)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "square-theory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "wavs = glob('../speech/example-speaker/*.wav')\n",
    "len(wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "international-crawford",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5802090710500968 14224\n",
      "2 0.3371547201584426 14152\n",
      "3 0.18621705475614123 15640\n",
      "4 0.30573009227454906 19024\n",
      "5 0.3378238329582478 19672\n",
      "6 0.21772350976926572 15408\n",
      "7 0.7706967253518235 13712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10.418375, 4, [0, 5580, 15033, 26273], [13832, 19804, 29185, 41913])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, y, start, end = combine_speakers(wavs, random.randint(1, len(wavs)))\n",
    "len(left) / sr, len(y), start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sensitive-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Audio(left[start[0]: end[0]], rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "preceding-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "left = np.array([left.astype(np.float32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "foster-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pt = torch.from_numpy(left)\n",
    "y_tf = tf.convert_to_tensor(left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "qualified-russell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 257)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 128\n",
    "L = 8\n",
    "H = 128\n",
    "R = 6\n",
    "C = speakers_size\n",
    "input_normalize = False\n",
    "sample_rate = 8000\n",
    "segment = 4\n",
    "context_len = 2 * sr / 1000\n",
    "context = int(sr * context_len / 1000)\n",
    "layer = R\n",
    "filter_dim = context * 2 + 1\n",
    "num_spk = C\n",
    "segment_size = int(np.sqrt(2 * sr * segment / (L/2)))\n",
    "segment_size, filter_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "judicial-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder_PT(nn.Module):\n",
    "    def __init__(self, L, N):\n",
    "        super(Encoder_PT, self).__init__()\n",
    "        self.L, self.N = L, N\n",
    "        # setting 50% overlap\n",
    "        self.conv = nn.Conv1d(\n",
    "            1, N, kernel_size=L, stride=L // 2, bias=False)\n",
    "\n",
    "    def forward(self, mixture):\n",
    "        mixture = torch.unsqueeze(mixture, 1)\n",
    "        mixture_w = F.relu(self.conv(mixture))\n",
    "        return mixture_w\n",
    "    \n",
    "class MulCatBlock_PT(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, dropout=0, bidirectional=False):\n",
    "        super(MulCatBlock_PT, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_direction = int(bidirectional) + 1\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, 1, dropout=dropout,\n",
    "                           batch_first=True, bidirectional=bidirectional)\n",
    "        self.rnn_proj = nn.Linear(hidden_size * self.num_direction, input_size)\n",
    "\n",
    "        self.gate_rnn = nn.LSTM(input_size, hidden_size, num_layers=1,\n",
    "                                batch_first=True, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.gate_rnn_proj = nn.Linear(\n",
    "            hidden_size * self.num_direction, input_size)\n",
    "\n",
    "        self.block_projection = nn.Linear(input_size * 2, input_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = input\n",
    "        # run rnn module\n",
    "        rnn_output, _ = self.rnn(output)\n",
    "        rnn_output = self.rnn_proj(rnn_output.contiguous(\n",
    "        ).view(-1, rnn_output.shape[2])).view(output.shape).contiguous()\n",
    "        # run gate rnn module\n",
    "        gate_rnn_output, _ = self.gate_rnn(output)\n",
    "        gate_rnn_output = self.gate_rnn_proj(gate_rnn_output.contiguous(\n",
    "        ).view(-1, gate_rnn_output.shape[2])).view(output.shape).contiguous()\n",
    "        # apply gated rnn\n",
    "        gated_output = torch.mul(rnn_output, gate_rnn_output)\n",
    "        gated_output = torch.cat([gated_output, output], 2)\n",
    "        gated_output = self.block_projection(\n",
    "            gated_output.contiguous().view(-1, gated_output.shape[2])).view(output.shape)\n",
    "        return gated_output\n",
    "        \n",
    "class ByPass_PT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ByPass_PT, self).__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "\n",
    "class DPMulCat_PT(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_spk,\n",
    "                 dropout=0, num_layers=1, bidirectional=True, input_normalize=False):\n",
    "        super(DPMulCat_PT, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_norm = input_normalize\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.rows_grnn = nn.ModuleList([])\n",
    "        self.cols_grnn = nn.ModuleList([])\n",
    "        self.rows_normalization = nn.ModuleList([])\n",
    "        self.cols_normalization = nn.ModuleList([])\n",
    "\n",
    "        # create the dual path pipeline\n",
    "        for i in range(num_layers):\n",
    "            self.rows_grnn.append(MulCatBlock_PT(\n",
    "                input_size, hidden_size, dropout, bidirectional=bidirectional))\n",
    "            self.cols_grnn.append(MulCatBlock_PT(\n",
    "                input_size, hidden_size, dropout, bidirectional=bidirectional))\n",
    "            if self.in_norm:\n",
    "                self.rows_normalization.append(\n",
    "                    nn.GroupNorm(1, input_size, eps=1e-8))\n",
    "                self.cols_normalization.append(\n",
    "                    nn.GroupNorm(1, input_size, eps=1e-8))\n",
    "            else:\n",
    "                # used to disable normalization\n",
    "                self.rows_normalization.append(ByPass_PT())\n",
    "                self.cols_normalization.append(ByPass_PT())\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.PReLU(), nn.Conv2d(input_size, output_size * num_spk, 1))\n",
    "\n",
    "    def forward(self, input):\n",
    "        batch_size, _, d1, d2 = input.shape\n",
    "        output = input\n",
    "        output_all = []\n",
    "        for i in range(self.num_layers):\n",
    "            row_input = output.permute(0, 3, 2, 1).contiguous().view(batch_size * d2, d1, -1)\n",
    "            \n",
    "            row_output = self.rows_grnn[i](row_input)\n",
    "            row_output = row_output.view(\n",
    "                batch_size, d2, d1, -1).permute(0, 3, 2, 1).contiguous()\n",
    "            row_output = self.rows_normalization[i](row_output)\n",
    "            # apply a skip connection\n",
    "            output = output + row_output\n",
    "            \n",
    "            print(i, row_input.shape, row_output.shape, output.shape)\n",
    "\n",
    "            col_input = output.permute(0, 2, 3, 1).contiguous().view(\n",
    "                batch_size * d1, d2, -1)\n",
    "            col_output = self.cols_grnn[i](col_input)\n",
    "            col_output = col_output.view(\n",
    "                batch_size, d1, d2, -1).permute(0, 3, 1, 2).contiguous()\n",
    "            col_output = self.cols_normalization[i](col_output).contiguous()\n",
    "            # apply a skip connection\n",
    "            output = output + col_output\n",
    "            \n",
    "            print(i, col_input.shape, col_output.shape, output.shape)\n",
    "\n",
    "            output_i = self.output(output)\n",
    "            output_all.append(output_i)\n",
    "        return output_all\n",
    "\n",
    "        \n",
    "class Separator_PT(nn.Module):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim, output_dim, num_spk=2,\n",
    "                 layer=4, segment_size=100, input_normalize=False, bidirectional=True):\n",
    "        super(Separator_PT, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.layer = layer\n",
    "        self.segment_size = segment_size\n",
    "        self.num_spk = num_spk\n",
    "        self.input_normalize = input_normalize\n",
    "\n",
    "        self.rnn_model = DPMulCat_PT(self.feature_dim, self.hidden_dim,\n",
    "                                  self.feature_dim, self.num_spk, num_layers=layer, bidirectional=bidirectional, input_normalize=input_normalize)\n",
    "\n",
    "    # ======================================= #\n",
    "    # The following code block was borrowed and modified from https://github.com/yluo42/TAC\n",
    "    # ================ BEGIN ================ #\n",
    "    def pad_segment(self, input, segment_size):\n",
    "        # input is the features: (B, N, T)\n",
    "        batch_size, dim, seq_len = input.shape\n",
    "        segment_stride = segment_size // 2\n",
    "        rest = segment_size - (segment_stride + seq_len %\n",
    "                               segment_size) % segment_size\n",
    "        if rest > 0:\n",
    "            pad = Variable(torch.zeros(batch_size, dim, rest)\n",
    "                           ).type(input.type())\n",
    "            input = torch.cat([input, pad], 2)\n",
    "\n",
    "        pad_aux = Variable(torch.zeros(\n",
    "            batch_size, dim, segment_stride)).type(input.type())\n",
    "        input = torch.cat([pad_aux, input, pad_aux], 2)\n",
    "        return input, rest\n",
    "\n",
    "    def create_chuncks(self, input, segment_size):\n",
    "        # split the feature into chunks of segment size\n",
    "        # input is the features: (B, N, T)\n",
    "\n",
    "        input, rest = self.pad_segment(input, segment_size)\n",
    "        batch_size, dim, seq_len = input.shape\n",
    "        segment_stride = segment_size // 2\n",
    "\n",
    "        segments1 = input[:, :, :-segment_stride].contiguous().view(batch_size,\n",
    "                                                                    dim, -1, segment_size)\n",
    "        segments2 = input[:, :, segment_stride:].contiguous().view(\n",
    "            batch_size, dim, -1, segment_size)\n",
    "        segments = torch.cat([segments1, segments2], 3).view(\n",
    "            batch_size, dim, -1, segment_size).transpose(2, 3)\n",
    "        return segments.contiguous(), rest\n",
    "\n",
    "    def merge_chuncks(self, input, rest):\n",
    "\n",
    "        batch_size, dim, segment_size, _ = input.shape\n",
    "        segment_stride = segment_size // 2\n",
    "        input = input.transpose(2, 3).contiguous().view(\n",
    "            batch_size, dim, -1, segment_size*2)  # B, N, K, L\n",
    "\n",
    "        input1 = input[:, :, :, :segment_size].contiguous().view(\n",
    "            batch_size, dim, -1)[:, :, segment_stride:]\n",
    "        input2 = input[:, :, :, segment_size:].contiguous().view(\n",
    "            batch_size, dim, -1)[:, :, :-segment_stride]\n",
    "\n",
    "        output = input1 + input2\n",
    "        if rest > 0:\n",
    "            output = output[:, :, :-rest]\n",
    "        return output.contiguous()\n",
    "    \n",
    "    def forward(self, input):\n",
    "        # create chunks\n",
    "        enc_segments, enc_rest = self.create_chuncks(\n",
    "            input, self.segment_size)\n",
    "        output_all = self.rnn_model(enc_segments)\n",
    "        \n",
    "        output_all_wav = []\n",
    "        for ii in range(len(output_all)):\n",
    "            output_ii = self.merge_chuncks(\n",
    "                output_all[ii], enc_rest)\n",
    "            print(ii, output_all[ii].shape)\n",
    "            output_all_wav.append(output_ii)\n",
    "        return output_all_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "legendary-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_pt = Encoder_PT(L, N)\n",
    "# separator_pt = Separator_PT(filter_dim + N, N, H,\n",
    "#                       filter_dim, num_spk, layer, segment_size, input_normalize)\n",
    "# e_pt = encoder_pt(y_pt)\n",
    "# o_pt = separator_pt(e_pt)\n",
    "# # l.shape, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "close-couple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i.shape for i in o_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "historic-initial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_list(x):\n",
    "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
    "    static = x.shape.as_list()\n",
    "    dynamic = tf.shape(x)\n",
    "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, L, N, **kwargs):\n",
    "        super(Encoder, self).__init__(name = 'Encoder', **kwargs)\n",
    "        self.conv = tf.keras.layers.Conv1D(N, kernel_size=L, strides=L // 2, use_bias=False)\n",
    "    \n",
    "    def call(self, mixture):\n",
    "        mixture = tf.expand_dims(mixture, -1)\n",
    "        mixture_w = tf.nn.relu(self.conv(mixture))\n",
    "        return mixture_w\n",
    "    \n",
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, L, **kwargs):\n",
    "        super(Decoder, self).__init__(name = 'Decoder', **kwargs)\n",
    "        self.L = L\n",
    "\n",
    "    def call(self, est_source):\n",
    "        # torch.Size([1, 256, 22521])\n",
    "        # pt (1, 2, 128, 22521), tf (1, 22521, 2, 128)\n",
    "        est_source = tf.transpose(est_source, (0, 1, 3, 2))\n",
    "        est_source = tf.compat.v1.layers.average_pooling2d(est_source, 1, (1,8),\n",
    "                                     padding = 'SAME')\n",
    "        est_source = tf.signal.overlap_and_add(tf.transpose(est_source, (0, 3, 1, 2)), self.L // 2)\n",
    "\n",
    "        return est_source\n",
    "    \n",
    "class MulCatBlock(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, dropout=0, bidirectional=False, **kwargs):\n",
    "        super(MulCatBlock, self).__init__(name = 'MulCatBlock', **kwargs)\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_direction = int(bidirectional) + 1\n",
    "        \n",
    "        if bidirectional:\n",
    "            self.rnn = tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.LSTM(hidden_size, return_sequences = True)\n",
    "            )\n",
    "            self.gate_rnn = tf.keras.layers.Bidirectional(\n",
    "                tf.keras.layers.LSTM(hidden_size, return_sequences = True)\n",
    "            )\n",
    "        else:\n",
    "            self.rnn = tf.keras.layers.LSTM(hidden_size, return_sequences = True)\n",
    "            self.gate_rnn = tf.keras.layers.LSTM(hidden_size, return_sequences = True)\n",
    "        \n",
    "        self.rnn_proj = tf.keras.layers.Dense(input_size)\n",
    "        self.gate_rnn_proj = tf.keras.layers.Dense(input_size)\n",
    "        self.block_projection = tf.keras.layers.Dense(input_size)\n",
    "    \n",
    "    def call(self, input):\n",
    "        output = input\n",
    "        rnn_output = self.rnn(output)\n",
    "        rnn_output = self.rnn_proj(rnn_output)\n",
    "        gate_rnn_output = self.gate_rnn(output)\n",
    "        gate_rnn_output = self.gate_rnn_proj(gate_rnn_output)\n",
    "        gated_output = tf.multiply(rnn_output, gate_rnn_output)\n",
    "        gated_output = tf.concat([gated_output, output], 2)\n",
    "        gated_output = self.block_projection(gated_output)\n",
    "        return gated_output\n",
    "    \n",
    "class GroupNorm(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DPMulCat, self).__init__(name = 'GroupNorm', **kwargs)\n",
    "    \n",
    "    def call(self, input):\n",
    "        return tf.contrib.layers.group_norm(x_tf, groups = 1, epsilon = 1e-8)\n",
    "    \n",
    "class ByPass(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ByPass, self).__init__(name = 'ByPass', **kwargs)\n",
    "\n",
    "    def call(self, input):\n",
    "        return input\n",
    "        \n",
    "class DPMulCat(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_spk,\n",
    "                 dropout=0, num_layers=1, bidirectional=True, input_normalize=False, **kwargs):\n",
    "        super(DPMulCat, self).__init__(name = 'DPMulCat', **kwargs)\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.in_norm = input_normalize\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rows_grnn = []\n",
    "        self.cols_grnn = []\n",
    "        self.rows_normalization = []\n",
    "        self.cols_normalization = []\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            self.rows_grnn.append(MulCatBlock(\n",
    "                input_size, hidden_size, dropout, bidirectional=bidirectional))\n",
    "            self.cols_grnn.append(MulCatBlock(\n",
    "                input_size, hidden_size, dropout, bidirectional=bidirectional))\n",
    "            if self.in_norm:\n",
    "                self.rows_normalization.append(GroupNorm())\n",
    "                self.cols_normalization.append(GroupNorm())\n",
    "            else:\n",
    "                # used to disable normalization\n",
    "                self.rows_normalization.append(ByPass())\n",
    "                self.cols_normalization.append(ByPass())\n",
    "                \n",
    "        self.outputs = tf.keras.Sequential()     \n",
    "        self.outputs.add(tf.keras.layers.PReLU())\n",
    "        self.outputs.add(tf.keras.layers.Conv2D(output_size * num_spk, 1, padding = 'SAME'))\n",
    "    \n",
    "    def call(self, input):\n",
    "        # original, [b, d3, d1, d2]\n",
    "        input = tf.transpose(input, (0, 2, 1, 3))\n",
    "        batch_size, d3, d1, d2 = shape_list(input)\n",
    "        output = input\n",
    "        output_all = []\n",
    "        for i in range(self.num_layers):\n",
    "            row_input = tf.transpose(output, [0, 3, 2, 1])\n",
    "            row_input = tf.reshape(row_input, (batch_size * d2, d1, d3))\n",
    "            row_output = self.rows_grnn[i](row_input)\n",
    "            row_output = tf.reshape(row_output, (batch_size, d2, d1, d3))\n",
    "            row_output = tf.transpose(row_output, (0, 3, 2, 1))\n",
    "            row_output = self.rows_normalization[i](row_output)\n",
    "            output = output + row_output\n",
    "            \n",
    "            print(i, row_input.shape, row_output.shape, output.shape)\n",
    "            \n",
    "            col_input = tf.transpose(output, [0, 2, 3, 1])\n",
    "            col_input = tf.reshape(col_input, (batch_size * d1, d2, d3))\n",
    "            col_output = self.cols_grnn[i](col_input)\n",
    "            col_output = tf.reshape(col_output, (batch_size, d1, d2, d3))\n",
    "            col_output = tf.transpose(col_output, (0, 3, 1, 2))\n",
    "            col_output = self.cols_normalization[i](col_output)\n",
    "            \n",
    "            output = output + col_output\n",
    "            \n",
    "            print(i, col_input.shape, col_output.shape, output.shape)\n",
    "            \n",
    "            # torch.Size([1, 128, 126, 360]\n",
    "            output_i = self.outputs(tf.transpose(output, [0, 2, 3, 1]))\n",
    "            output_all.append(output_i)\n",
    "        return output_all\n",
    "    \n",
    "class Separator(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, feature_dim, hidden_dim, output_dim, num_spk=2,\n",
    "                 layer=4, segment_size=100, input_normalize=False, bidirectional=True, **kwargs):\n",
    "        super(Separator, self).__init__(name = 'Separator', **kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.feature_dim = feature_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.layer = layer\n",
    "        self.segment_size = segment_size\n",
    "        self.num_spk = num_spk\n",
    "        self.input_normalize = input_normalize\n",
    "        \n",
    "        self.rnn_model = DPMulCat(self.feature_dim, self.hidden_dim,\n",
    "                                  self.feature_dim, self.num_spk, num_layers=layer, \n",
    "                                  bidirectional=bidirectional, input_normalize=input_normalize)\n",
    "    \n",
    "    def pad_segment(self, input, segment_size):\n",
    "        # input is the features: (B, N, T)\n",
    "        \n",
    "        batch_size, seq_len, dim = shape_list(input)\n",
    "        segment_stride = segment_size // 2\n",
    "        rest = segment_size - (segment_stride + seq_len %\n",
    "                               segment_size) % segment_size\n",
    "        if rest > 0:\n",
    "            pad = tf.Variable(tf.zeros(shape=(batch_size, rest, dim)))\n",
    "            input = tf.concat([input, pad], 1)\n",
    "\n",
    "        pad_aux = tf.Variable(tf.zeros(shape=(batch_size, segment_stride, dim)))\n",
    "        input = tf.concat([pad_aux, input, pad_aux], 1)\n",
    "        return input, rest\n",
    "    \n",
    "    def create_chuncks(self, input, segment_size):\n",
    "\n",
    "        input, rest = self.pad_segment(input, segment_size)\n",
    "        batch_size, seq_len, dim = shape_list(input)\n",
    "        segment_stride = segment_size // 2\n",
    "        segments1 = tf.reshape(input[:, :-segment_stride], (batch_size, -1, dim, segment_size))\n",
    "        segments2 = tf.reshape(input[:, segment_stride:], (batch_size, -1, dim, segment_size))\n",
    "        segments = tf.concat([segments1, segments2], axis = 3)\n",
    "        segments = tf.reshape(segments, (batch_size, -1, dim, segment_size))\n",
    "        segments = tf.transpose(segments, perm = [0, 3, 2, 1])\n",
    "        return segments, rest\n",
    "    \n",
    "    def merge_chuncks(self, input, rest):\n",
    "        # original, [b, dim, segment_size, _]\n",
    "        # torch.Size([1, 256, 126, 360])\n",
    "        # (1, 126, 360, 256)\n",
    "        input = tf.transpose(input, perm = [0, 3, 1, 2])\n",
    "        batch_size, dim, segment_size, _ = shape_list(input)\n",
    "        segment_stride = segment_size // 2\n",
    "        # original, [b, dim, _, segment_size]\n",
    "        input = tf.transpose(input, perm = [0, 1, 3, 2])\n",
    "        input = tf.reshape(input, (batch_size, dim, -1, segment_size * 2))\n",
    "        \n",
    "        input1 = tf.reshape(input[:, :, :, :segment_size], (batch_size, dim, -1))[:, :, segment_stride:]\n",
    "        input2 = tf.reshape(input[:, :, :, segment_size:], (batch_size, dim, -1))[:, :, :-segment_stride]\n",
    "        \n",
    "        output = input1 + input2\n",
    "        if rest > 0:\n",
    "            output = output[:, :, :-rest]\n",
    "            \n",
    "        return tf.transpose(output, perm = [0, 2, 1])\n",
    "        \n",
    "    def call(self, input):\n",
    "        # create chunks\n",
    "        enc_segments, enc_rest = self.create_chuncks(\n",
    "            input, self.segment_size)\n",
    "        output_all = self.rnn_model(enc_segments)\n",
    "        output_all_wav = []\n",
    "        for ii in range(len(output_all)):\n",
    "            print(ii, output_all[ii].shape)\n",
    "            output_ii = self.merge_chuncks(\n",
    "                output_all[ii], enc_rest)\n",
    "            output_all_wav.append(output_ii)\n",
    "        return output_all_wav\n",
    "    \n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        N = 128,\n",
    "        L = 8,\n",
    "        H = 128,\n",
    "        R = 6,\n",
    "        C = 2,\n",
    "        input_normalize = False,\n",
    "        sample_rate = 8000,\n",
    "        segment = 4,\n",
    "        context_len = 2 * sr / 1000,\n",
    "        context = int(sr * context_len / 1000),\n",
    "        layer = R,\n",
    "        filter_dim = context * 2 + 1,\n",
    "        num_spk = C,\n",
    "        segment_size = int(np.sqrt(2 * sr * segment / (L / 2))),\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Model, self).__init__(name = 'swave', **kwargs)\n",
    "        self.C = C\n",
    "        self.N = N\n",
    "        self.encoder = Encoder(L, N)\n",
    "        self.separator = Separator(\n",
    "            filter_dim + N,\n",
    "            N,\n",
    "            H,\n",
    "            filter_dim,\n",
    "            num_spk,\n",
    "            layer,\n",
    "            segment_size,\n",
    "            input_normalize,\n",
    "        )\n",
    "        self.decoder = Decoder(L)\n",
    "\n",
    "    def call(self, mixture):\n",
    "        mixture_w = self.encoder(mixture)\n",
    "        output_all = self.separator(mixture_w)\n",
    "        T_mix = tf.shape(mixture)[1]\n",
    "        batch_size = tf.shape(mixture)[0]\n",
    "        T_mix_w = tf.shape(mixture_w)[1]\n",
    "        # generate wav after each RNN block and optimize the loss\n",
    "        outputs = []\n",
    "        for ii in range(len(output_all)):\n",
    "            output_ii = tf.reshape(\n",
    "                output_all[ii], (batch_size, T_mix_w, self.C, self.N)\n",
    "            )\n",
    "            output_ii = self.decoder(output_ii)\n",
    "            output_ii = tf.cond(\n",
    "                tf.shape(output_ii)[2] >= T_mix,\n",
    "                lambda: output_ii[:, :, :T_mix],\n",
    "                lambda: tf.pad(\n",
    "                    output_ii,\n",
    "                    [[0, 0], [0, 0], [0, T_mix - tf.shape(output_ii)[2]]],\n",
    "                ),\n",
    "            )\n",
    "            outputs.append(output_ii)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "formed-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(C = speakers_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "utility-algorithm",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (332, 126, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "0 (126, 332, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "1 (332, 126, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "1 (126, 332, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "2 (332, 126, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "2 (126, 332, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "3 (332, 126, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "3 (126, 332, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "4 (332, 126, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "4 (126, 332, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "5 (332, 126, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "5 (126, 332, 128) (1, 128, 126, 332) (1, 128, 126, 332)\n",
      "0 (1, 126, 332, 512)\n",
      "1 (1, 126, 332, 512)\n",
      "2 (1, 126, 332, 512)\n",
      "3 (1, 126, 332, 512)\n",
      "4 (1, 126, 332, 512)\n",
      "5 (1, 126, 332, 512)\n",
      "WARNING:tensorflow:From <ipython-input-18-849ef4ab4d2a>:27: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.AveragePooling2D instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/layers/pooling.py:238: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "outputs = model(y_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cultural-heavy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1), Dimension(4), Dimension(83347)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "tough-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "\n",
    "def log10(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(10, dtype=numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "def cal_si_snr_with_pit(source, estimate_source, source_lengths, C):\n",
    "    B, _, T = shape_list(source)\n",
    "    mask = tf.cast(tf.sequence_mask(source_lengths, tf.reduce_max(source_lengths)), source.dtype)\n",
    "    print(mask)\n",
    "    estimate_source *= mask\n",
    "    \n",
    "    num_samples = tf.cast(tf.reshape(source_lengths, (-1, 1, 1)), tf.float32)\n",
    "    mean_target = tf.reduce_sum(source, axis = 2, keepdims = True) / num_samples\n",
    "    mean_estimate = tf.reduce_sum(estimate_source, axis = 2, keepdims = True) / num_samples\n",
    "    zero_mean_target = source - mean_target\n",
    "    zero_mean_estimate = estimate_source - mean_estimate\n",
    "    zero_mean_target *= mask\n",
    "    zero_mean_estimate *= mask\n",
    "    \n",
    "    s_target = tf.expand_dims(zero_mean_target, 1)\n",
    "    s_estimate = tf.expand_dims(zero_mean_estimate, 2)\n",
    "    return s_estimate * s_target\n",
    "    \n",
    "    pair_wise_dot = tf.reduce_sum(s_estimate * s_target,\n",
    "                              axis=3, keepdims=True)\n",
    "    s_target_energy = tf.reduce_sum(\n",
    "        s_target ** 2, axis=3, keepdims=True) + EPS\n",
    "    pair_wise_proj = pair_wise_dot * s_target / s_target_energy\n",
    "    e_noise = s_estimate - pair_wise_proj\n",
    "    pair_wise_si_snr = tf.reduce_sum(\n",
    "        pair_wise_proj ** 2, axis=3) / (tf.reduce_sum(e_noise ** 2, axis=3) + EPS)\n",
    "    pair_wise_si_snr = 10.0 * log10(pair_wise_si_snr + EPS)\n",
    "    pair_wise_si_snr = tf.transpose(pair_wise_si_snr, perm = [0, 2, 1])\n",
    "    \n",
    "    return pair_wise_si_snr\n",
    "                                 \n",
    "    perms = tf.convert_to_tensor(np.array(list(permutations(range(C)))))\n",
    "    perms = tf.cast(perms, tf.int32)\n",
    "    index = tf.expand_dims(perms, 2)\n",
    "    ones = tf.ones(tf.reduce_prod(tf.shape(index)))\n",
    "    perms_one_hot = tf.zeros((tf.shape(perms)[0], tf.shape(perms)[1], C))\n",
    "    \n",
    "    indices = index\n",
    "    tensor = perms_one_hot\n",
    "    original_tensor = tensor\n",
    "    indices = tf.reshape(indices, shape=[-1, tf.shape(indices)[-1]])\n",
    "    indices_add = tf.expand_dims(tf.range(0, tf.shape(indices)[0], 1)*(tf.shape(tensor)[-1]), axis=-1)\n",
    "    indices += indices_add\n",
    "    tensor = tf.reshape(perms_one_hot, shape=[-1])\n",
    "    indices = tf.reshape(indices, shape=[-1, 1])\n",
    "    updates = tf.reshape(ones, shape=[-1])\n",
    "    scatter = tf.tensor_scatter_nd_update(tensor, indices, updates)\n",
    "    perms_one_hot = tf.reshape(scatter, \n",
    "                          shape=[tf.shape(original_tensor)[0], tf.shape(original_tensor)[1], -1])\n",
    "    \n",
    "    snr_set = tf.einsum('bij,pij->bp', pair_wise_si_snr, perms_one_hot)\n",
    "    max_snr_idx = tf.argmax(snr_set, axis=1)\n",
    "    max_snr = tf.reduce_max(snr_set, axis=1, keepdims=True)\n",
    "    max_snr /= C\n",
    "    \n",
    "    return max_snr, perms, max_snr_idx, snr_set / C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "overhead-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = torch.from_numpy(np.expand_dims(y, 0))\n",
    "# estimated_source = torch.from_numpy(outputs[0].numpy())\n",
    "# source_lengths = torch.from_numpy(np.array([len(left[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "significant-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal_si_snr_with_pit_pt(source, estimated_source, source_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "initial-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tf = tf.convert_to_tensor(np.expand_dims(y, 0).astype(np.float32))\n",
    "source_lengths_tf = tf.convert_to_tensor(np.array([len(left[0])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "outdoor-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 1. 1. ... 1. 1. 1.]], shape=(1, 83347), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=934173, shape=(1, 4, 4, 83347), dtype=float32, numpy=\n",
       "array([[[[ 1.57583490e-05,  2.24255673e-05,  5.07647314e-07, ...,\n",
       "          -1.97981525e-08,  5.17372598e-08,  4.21800195e-08],\n",
       "         [-2.95857134e-08, -5.94604685e-08, -3.74996567e-08, ...,\n",
       "          -3.79336491e-08,  9.91296076e-08,  8.08177489e-08],\n",
       "         [-8.87883189e-08, -1.78444068e-07, -1.12538494e-07, ...,\n",
       "          -1.13840933e-07,  2.97493301e-07,  2.42538420e-07],\n",
       "         [ 4.47851605e-08,  9.00078518e-08,  5.67648364e-08, ...,\n",
       "           2.70396754e-06, -1.47081300e-05, -5.71218015e-06]],\n",
       "\n",
       "        [[-6.09359777e-05, -1.99023580e-05, -1.01570595e-06, ...,\n",
       "           5.36101901e-08,  7.48650706e-08,  2.41571385e-08],\n",
       "         [ 1.14405019e-07,  5.27702824e-08,  7.50296962e-08, ...,\n",
       "           1.02718182e-07,  1.43442946e-07,  4.62855532e-08],\n",
       "         [ 3.43335643e-07,  1.58366461e-07,  2.25168165e-07, ...,\n",
       "           3.08262798e-07,  4.30480014e-07,  1.38905449e-07],\n",
       "         [-1.73179771e-07, -7.98806354e-08, -1.13575659e-07, ...,\n",
       "          -7.32190620e-06, -2.12830200e-05, -3.27145244e-06]],\n",
       "\n",
       "        [[ 8.60347354e-05,  7.85461234e-05,  2.85820647e-06, ...,\n",
       "          -5.64698475e-08, -4.88082783e-08, -7.72115456e-08],\n",
       "         [-1.61526998e-07, -2.08261810e-07, -2.11134292e-07, ...,\n",
       "          -1.08197341e-07, -9.35176274e-08, -1.47938849e-07],\n",
       "         [-4.84751240e-07, -6.25004930e-07, -6.33625405e-07, ...,\n",
       "          -3.24706036e-07, -2.80651420e-07, -4.43972453e-07],\n",
       "         [ 2.44510346e-07,  3.15254795e-07,  3.19603004e-07, ...,\n",
       "           7.71246869e-06,  1.38754649e-05,  1.04562841e-05]],\n",
       "\n",
       "        [[ 2.69048614e-04,  1.91080137e-04,  6.33315130e-06, ...,\n",
       "          -2.53222993e-07, -1.81356810e-07, -2.43640642e-07],\n",
       "         [-5.05128753e-07, -5.06641129e-07, -4.67826766e-07, ...,\n",
       "          -4.85180237e-07, -3.47483223e-07, -4.66820268e-07],\n",
       "         [-1.51591860e-06, -1.52045732e-06, -1.40397333e-06, ...,\n",
       "          -1.45605202e-06, -1.04281594e-06, -1.40095278e-06],\n",
       "         [ 7.64634990e-07,  7.66924359e-07,  7.08169352e-07, ...,\n",
       "           3.45843764e-05,  5.15570355e-05,  3.29947507e-05]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_si_snr_with_pit(source_tf, outputs[0], source_lengths_tf, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "interested-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = source_lengths.view(-1, 1, 1).float()\n",
    "num_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "south-dancing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[80695.]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = source_lengths.view(-1, 1, 1).float()\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.math.logical_not(tf.sequence_mask(start, 105299))\n",
    "e = tf.sequence_mask(end, 105299)\n",
    "tf.math.logical_and(s, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "civil-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=913901, shape=(1, 4, 80695), dtype=float32, numpy=\n",
       "array([[[ 0.01009563,  0.00609156, -0.00160525, ..., -0.01258242,\n",
       "         -0.0039157 , -0.0223956 ],\n",
       "        [-0.06504403, -0.00103295, -0.03156273, ..., -0.00795869,\n",
       "          0.00436507, -0.00990242],\n",
       "        [ 0.00923771,  0.00564549, -0.00792148, ..., -0.00024877,\n",
       "         -0.0082346 , -0.01020905],\n",
       "        [-0.01299534,  0.01603856,  0.00078306, ...,  0.00634084,\n",
       "          0.00328981,  0.0002893 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.cast(tf.sequence_mask([80695], 80695), outputs[0].dtype)\n",
    "outputs[0] * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-length",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1, 3],[2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sequence_mask([1,2,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-horizontal",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = tf.sequence_mask(np.concatenate([s, e]).T)\n",
    "r = tf.cast(r, tf.int32).numpy()\n",
    "# r = tf.reduce_sum(r, axis = 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.sequence_mask([[     0], [44368]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 torch.Size([360, 126, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 0 torch.Size([126, 360, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 1 torch.Size([360, 126, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 1 torch.Size([126, 360, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 2 torch.Size([360, 126, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 2 torch.Size([126, 360, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 3 torch.Size([360, 126, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 3 torch.Size([126, 360, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 4 torch.Size([360, 126, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 4 torch.Size([126, 360, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 5 torch.Size([360, 126, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])\n",
    "# 5 torch.Size([126, 360, 128]) torch.Size([1, 128, 126, 360]) torch.Size([1, 128, 126, 360])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 torch.Size([1, 256, 126, 360])\n",
    "# 1 torch.Size([1, 256, 126, 360])\n",
    "# 2 torch.Size([1, 256, 126, 360])\n",
    "# 3 torch.Size([1, 256, 126, 360])\n",
    "# 4 torch.Size([1, 256, 126, 360])\n",
    "# 5 torch.Size([1, 256, 126, 360])\n",
    "\n",
    "# [torch.Size([1, 256, 22521]),\n",
    "#  torch.Size([1, 256, 22521]),\n",
    "#  torch.Size([1, 256, 22521]),\n",
    "#  torch.Size([1, 256, 22521]),\n",
    "#  torch.Size([1, 256, 22521]),\n",
    "#  torch.Size([1, 256, 22521])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.pad(output_ii, (0, 90199 - T_est)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0, 90099 - T_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [F.pad(output_ii, (0, 90199 - T_est)), F.pad(output_ii, (0, 90199 - T_est))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(p).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.pad(outputs[0], [[0,0], [0,0], [0,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.shape(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "unique-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.randn(10, 2, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "limiting-pilot",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_targets = torch.randn(10, 2, 32000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "governmental-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targets.unsqueeze(1)\n",
    "est_targets = est_targets.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "focused-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 2, 32000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "illegal-reality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 1, 32000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "developing-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_loss = (targets - est_targets) ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "plain-breathing",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_over = list(range(3, pw_loss.ndim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "amber-cream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pw_loss.mean(dim=mean_over).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-norwegian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
