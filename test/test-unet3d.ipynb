{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:38: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import malaya_speech.train\n",
    "from malaya_speech.train.model import unet\n",
    "from malaya_speech.utils import tf_featurization\n",
    "from tensorflow.keras.layers import Multiply\n",
    "import IPython.display as ipd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations\n",
    "import numpy as np\n",
    "\n",
    "reduce_time = 0.02307655849224936\n",
    "EPS = 1e-8\n",
    "\n",
    "def get_stft(X):\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    stft_X = tf.TensorArray(\n",
    "        dtype = tf.complex64,\n",
    "        size = batch_size,\n",
    "        dynamic_size = False,\n",
    "        infer_shape = False,\n",
    "    )\n",
    "    D_X = tf.TensorArray(\n",
    "        dtype = tf.float32,\n",
    "        size = batch_size,\n",
    "        dynamic_size = False,\n",
    "        infer_shape = False,\n",
    "    )\n",
    "\n",
    "    init_state = (0, stft_X, D_X)\n",
    "\n",
    "    def condition(i, stft, D):\n",
    "        return i < batch_size\n",
    "\n",
    "    def body(i, stft, D):\n",
    "        stft_x, D_x = tf_featurization.get_stft(X[i])\n",
    "        return i + 1, stft.write(i, stft_x), D.write(i, D_x)\n",
    "\n",
    "    _, stft_X, D_X = tf.while_loop(condition, body, init_state)\n",
    "    stft_X = stft_X.stack()\n",
    "    stft_X.set_shape((None, None, 2049, 1))\n",
    "    D_X = D_X.stack()\n",
    "    D_X.set_shape((None, None, 512, 1024, 1))\n",
    "    return stft_X, D_X\n",
    "\n",
    "def log10(x):\n",
    "    numerator = tf.log(x)\n",
    "    denominator = tf.log(tf.constant(10, dtype = numerator.dtype))\n",
    "    return numerator / denominator\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, size = 4):\n",
    "        self.X = tf.placeholder(tf.float32, (None, None))\n",
    "        self.Y = tf.placeholder(tf.float32, (None, size, None))\n",
    "        self.length = tf.placeholder(tf.float32, (None,))\n",
    "        self.lengths = tf.cast(self.length / reduce_time, tf.int32)\n",
    "        \n",
    "        stft_X, D_X = get_stft(self.X)\n",
    "        \n",
    "        self.stft = []\n",
    "        for i in range(size):\n",
    "            self.stft.append(get_stft(self.Y[:, i]))\n",
    "            \n",
    "        self.outputs = []\n",
    "        for i in range(size):\n",
    "            with tf.variable_scope(f'model_{i}'):\n",
    "                output = unet.Model3D(\n",
    "                    D_X, dropout = 0.0, training = True\n",
    "                ).logits\n",
    "                self.outputs.append(output)\n",
    "        \n",
    "        batch_size = tf.shape(self.outputs[0])[0]\n",
    "        fft_size = self.outputs[0].shape[3]\n",
    "        \n",
    "        labels = [i[1] for i in self.stft]\n",
    "        labels = tf.concat(labels, axis = 4)\n",
    "        labels = tf.reshape(labels, [batch_size, -1, fft_size, size])\n",
    "        labels = tf.transpose(labels, perm = [0, 3, 1, 2])\n",
    "        \n",
    "        concatenated = tf.concat(self.outputs, axis = 4)\n",
    "        concatenated = tf.reshape(concatenated, [batch_size, -1, fft_size, size])\n",
    "        concatenated = tf.transpose(concatenated, perm = [0, 3, 1, 2])\n",
    "        \n",
    "        mask = tf.cast(\n",
    "            tf.sequence_mask(self.lengths, tf.shape(concatenated)[2]),\n",
    "            concatenated.dtype,\n",
    "        )\n",
    "        mask = tf.expand_dims(mask, 1)\n",
    "        mask = tf.expand_dims(mask, -1)\n",
    "        \n",
    "        labels = labels * mask\n",
    "        concatenated = concatenated * mask\n",
    "        \n",
    "        # https://github.com/asteroid-team/asteroid/blob/master/asteroid/losses/mse.py\n",
    "        targets = tf.expand_dims(labels, 1)\n",
    "        est_targets = tf.expand_dims(concatenated, 2)\n",
    "        pw_loss = tf.abs(targets - est_targets)\n",
    "        pair_wise_abs = tf.reduce_mean(pw_loss, axis = [3, 4])\n",
    "        \n",
    "        perms = tf.convert_to_tensor(np.array(list(permutations(range(size)))))\n",
    "        perms = tf.cast(perms, tf.int32)\n",
    "        index = tf.expand_dims(perms, 2)\n",
    "        ones = tf.ones(tf.reduce_prod(tf.shape(index)))\n",
    "        perms_one_hot = tf.zeros((tf.shape(perms)[0], tf.shape(perms)[1], size))\n",
    "\n",
    "        indices = index\n",
    "        tensor = perms_one_hot\n",
    "        original_tensor = tensor\n",
    "        indices = tf.reshape(indices, shape = [-1, tf.shape(indices)[-1]])\n",
    "        indices_add = tf.expand_dims(\n",
    "            tf.range(0, tf.shape(indices)[0], 1) * (tf.shape(tensor)[-1]), axis = -1\n",
    "        )\n",
    "        indices += indices_add\n",
    "        tensor = tf.reshape(perms_one_hot, shape = [-1])\n",
    "        indices = tf.reshape(indices, shape = [-1, 1])\n",
    "        updates = tf.reshape(ones, shape = [-1])\n",
    "        scatter = tf.tensor_scatter_nd_update(tensor, indices, updates)\n",
    "        perms_one_hot = tf.reshape(\n",
    "            scatter,\n",
    "            shape = [\n",
    "                tf.shape(original_tensor)[0],\n",
    "                tf.shape(original_tensor)[1],\n",
    "                -1,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        abs_set = tf.einsum('bij,pij->bp', pair_wise_abs, perms_one_hot)\n",
    "        min_abs = tf.reduce_min(abs_set, axis = 1, keepdims = True)\n",
    "        min_abs /= size\n",
    "        self.loss = tf.reduce_mean(min_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "model = Model()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 3.0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, _ = malaya_speech.load('../speech/example-speaker/husein-zolkepli.wav', sr = 44100)\n",
    "y1, _ = malaya_speech.load('../speech/example-speaker/shafiqah-idayu.wav', sr = 44100)\n",
    "y = y[:sr * 3]\n",
    "y1 = y1[:sr * 3]\n",
    "len(y) / sr, len(y1) / sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.394099"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(model.loss, feed_dict = {model.X: [y, y],\n",
    "                                  model.Y: [[y1, y, y1, y], [y1] * 4],\n",
    "                                  model.length: [len(y) / sr, len(y) / sr]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stft[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = sess.run(model.outputs, feed_dict = {model.X: y_})\n",
    "# [o.shape for o in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(model.loss, feed_dict = {model.X: y_, model.Y: [y, noise]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# istft = sess.run(model.istft, feed_dict = {model.X: y_})\n",
    "# [s.shape for s in istft]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(istft[0], rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(istft[1], rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(y_, rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess, 'test/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
