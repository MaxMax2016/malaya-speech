{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stopped-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "blind-visibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "important-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blind-adams",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:41: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:44: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "from malaya_speech.train.model import wav2vec2, bert, fastspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "egyptian-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from malaya_speech.train.model.fastvc.model import Decoder\n",
    "\n",
    "# config = malaya_speech.config.fastspeech_config\n",
    "# dim = 768\n",
    "# config['encoder_hidden_size'] = dim\n",
    "# config['encoder_num_hidden_layers'] = 4\n",
    "# config['encoder_num_attention_heads'] = 12\n",
    "# config['encoder_intermediate_size'] = dim * config['encoder_num_hidden_layers']\n",
    "# config = fastspeech.Config(vocab_size = 1, **config)\n",
    "# encoder = Decoder(config.encoder_self_attention_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broke-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Encoder:\n",
    "#     def __init__(self, config):\n",
    "#         self.config = config\n",
    "#         self.model = None\n",
    "#     def __call__(self, x, input_mask, training = True):\n",
    "#         if self.model is None:\n",
    "#             input_mask = tf.logical_not(input_mask)\n",
    "#             self.model = bert.BertModel(config = self.config, is_training = training,\n",
    "#                                   input_ids = x, input_mask = input_mask)\n",
    "#         return self.model.sequence_output\n",
    "    \n",
    "# encoder = Encoder(config = bert.BertConfig())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sunrise-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.train.model.conformer.model import Model as ConformerModel\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.encoder = ConformerModel(**self.config)\n",
    "\n",
    "    def __call__(self, x, input_mask, training = True):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "config_conformer = malaya_speech.config.conformer_base_encoder_config\n",
    "config_conformer['subsampling']['type'] = 'none'\n",
    "config_conformer['dropout'] = 0.0\n",
    "encoder = Encoder(config_conformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "complex-antique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/wav2vec2/layer.py:190: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = wav2vec2.Wav2Vec2Config()\n",
    "model = wav2vec2.Model(cfg, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "affected-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, (None, None))\n",
    "X_len = tf.placeholder(tf.int32, (None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "looking-technique",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/wav2vec2/masking.py:10: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/wav2vec2/layer.py:37: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Tensor(\"wav2vec2/dense_3/BiasAdd:0\", shape=(?, ?, 256), dtype=float32) Tensor(\"wav2vec2/dense_2/BiasAdd:0\", shape=(?, ?, 256), dtype=float32) Tensor(\"wav2vec2/transpose:0\", shape=(100, ?, ?, 256), dtype=float32)\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/wav2vec2/model.py:237: calling cosine_distance (from tensorflow.python.ops.losses.losses_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "Tensor(\"wav2vec2/strided_slice_11:0\", shape=(101, ?, ?), dtype=float32) Tensor(\"wav2vec2/All:0\", shape=(100, ?, ?), dtype=bool)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': <tf.Tensor 'wav2vec2/concat_1:0' shape=(101, ?, ?) dtype=float32>,\n",
       " 'padding_mask': <tf.Tensor 'wav2vec2/LogicalNot:0' shape=(?, ?) dtype=bool>,\n",
       " 'features_pen': <tf.Tensor 'wav2vec2/Mean:0' shape=() dtype=float32>,\n",
       " 'prob_perplexity': <tf.Tensor 'wav2vec2/GumbelVectorQuantizer/Sum_3:0' shape=() dtype=float32>,\n",
       " 'code_perplexity': <tf.Tensor 'wav2vec2/GumbelVectorQuantizer/Sum_1:0' shape=() dtype=float32>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, num_vars, curr_temp = model(X, padding_mask = X_len)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "several-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Reshape:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'zeros:0' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = r['x']\n",
    "logits = tf.transpose(logits, [2, 1, 0])\n",
    "logits = tf.reshape(logits, (-1, tf.shape(logits)[-1]))\n",
    "target = tf.zeros(shape = (tf.shape(r['x'])[1] * tf.shape(r['x'])[2]), dtype = tf.int32)\n",
    "logits, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "completed-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = target, logits = logits)\n",
    "loss = tf.reduce_sum(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "legendary-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_losses = []\n",
    "\n",
    "if 'prob_perplexity' in r:\n",
    "    extra_losses.append(\n",
    "        (num_vars - r[\"prob_perplexity\"])\n",
    "        / num_vars\n",
    "    )\n",
    "\n",
    "if \"features_pen\" in r:\n",
    "    extra_losses.append(r[\"features_pen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "transparent-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = tf.cast(tf.shape(target)[0], tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "difficult-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = [0.1, 10]\n",
    "for p, coef in zip(extra_losses, loss_weights):\n",
    "    if coef != 0 and p is not None:\n",
    "        p = coef * p * sample_size\n",
    "        loss += p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "close-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "educational-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "challenging-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.518625"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = malaya_speech.load('../speech/example-speaker/shafiqah-idayu.wav')\n",
    "len(y) / sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "round-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.normal(size = (16000 * 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "spare-setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37 s, sys: 13.2 s, total: 50.2 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "o = sess.run([r, logits, target, loss, optimizer], feed_dict = {X: [y, y], X_len: [len(y), len(y)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "figured-today",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5618.202"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "employed-spice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/model.ckpt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'test/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "square-cornell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 711752\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    77B Apr 27 08:14 checkpoint\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff   326M Apr 27 08:14 model.ckpt.data-00000-of-00001\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    72K Apr 27 08:14 model.ckpt.index\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    19M Apr 27 08:14 model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh test\n",
    "!rm -rf test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-reservation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
