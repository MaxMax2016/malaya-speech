{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "from malaya_speech.train.model import vits, melgan, hifigan\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from malaya_speech.train.loss import calculate_3d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mel', 'text_ids', 'len_mel', 'len_text_ids', 'stop_token_target', 'f0', 'len_f0', 'energy', 'len_energy', 'g'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset-mel.pkl', 'rb') as fopen:\n",
    "    data, d = pickle.load(fopen)\n",
    "    \n",
    "with open('dataset-mel-wav.pkl', 'rb') as fopen:\n",
    "    wav = pickle.load(fopen)\n",
    "    \n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 104448)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav['wav'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = vits.Config(mel = 80, vocabs = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vits.Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(104448)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.convert_to_tensor([data['text_ids'][0],data['text_ids'][0]])\n",
    "i_lengths = tf.convert_to_tensor([data['len_text_ids'][0,0], data['len_text_ids'][0,0]])\n",
    "mel_outputs = tf.convert_to_tensor([data['mel'].astype(np.float32)[0],data['mel'].astype(np.float32)[0]])\n",
    "mel_lengths = tf.convert_to_tensor([408,408])\n",
    "wavs = tf.convert_to_tensor([wav['wav'].astype(np.float32)] * 2)[:,0]\n",
    "wavs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = tf.placeholder(tf.int32, [None, None])\n",
    "# i_lengths = tf.placeholder(tf.int32, [None])\n",
    "# mel_outputs = tf.placeholder(tf.float32, [None, None, 80])\n",
    "# mel_lengths = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hifigan_config = malaya_speech.config.hifigan_config\n",
    "generator = hifigan.Generator(\n",
    "    hifigan.GeneratorConfig(**hifigan_config['hifigan_generator_params']),\n",
    "    name='hifigan_generator',\n",
    ")\n",
    "multiperiod_discriminator = hifigan.MultiPeriodDiscriminator(\n",
    "    hifigan.DiscriminatorConfig(\n",
    "        **hifigan_config['hifigan_discriminator_params']\n",
    "    ),\n",
    "    name='hifigan_multiperiod_discriminator',\n",
    ")\n",
    "multiscale_discriminator = melgan.MultiScaleDiscriminator(\n",
    "    melgan.DiscriminatorConfig(\n",
    "        **hifigan_config['melgan_discriminator_params'],\n",
    "        name='melgan_multiscale_discriminator',\n",
    "    )\n",
    ")\n",
    "discriminator = hifigan.Discriminator(\n",
    "    multiperiod_discriminator, multiscale_discriminator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, attn, latent, z_slice, ids_slice = model.compute_loss(text = i, textlen = i_lengths, mel = mel_outputs, mellen = mel_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kl': <tf.Tensor: id=66044, shape=(), dtype=float32, numpy=1256.746>,\n",
       " 'durloss': <tf.Tensor: id=66138, shape=(), dtype=float32, numpy=0.13915735>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(8192), Dimension(1)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = generator(z_slice, training = True)\n",
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(32), Dimension(80)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=69392, shape=(2, 32, 80), dtype=float32, numpy=\n",
       "array([[[-0.2805809 ,  0.62709516,  1.2112881 , ...,  0.01505315,\n",
       "         -0.41925836, -0.82422316],\n",
       "        [-0.24844494,  0.69540465,  1.2325964 , ..., -0.2543169 ,\n",
       "         -0.9362055 , -0.97167784],\n",
       "        [-0.409442  ,  0.7712348 ,  1.2470031 , ..., -0.62703884,\n",
       "         -0.8012669 , -0.5956461 ],\n",
       "        ...,\n",
       "        [ 0.8821723 ,  0.94003916,  0.5176595 , ..., -1.0322577 ,\n",
       "         -1.2004273 , -1.1929351 ],\n",
       "        [ 0.87541205,  0.7640229 , -0.00418954, ..., -1.2069349 ,\n",
       "         -1.1324048 , -1.3753017 ],\n",
       "        [ 0.8312827 ,  0.72150886, -0.05245129, ..., -1.354502  ,\n",
       "         -1.1004343 , -1.4508146 ]],\n",
       "\n",
       "       [[ 0.12655376,  0.07635016, -0.4597771 , ..., -0.9492999 ,\n",
       "         -1.1483208 , -1.2437546 ],\n",
       "        [-0.17899442, -0.08848351, -0.6270338 , ..., -1.3663133 ,\n",
       "         -1.4980968 , -1.6064864 ],\n",
       "        [-0.2239177 , -0.22869256, -0.68688244, ..., -1.4690951 ,\n",
       "         -1.5015829 , -1.6740974 ],\n",
       "        ...,\n",
       "        [ 0.87573767, -0.48764956, -0.73492616, ...,  0.6009203 ,\n",
       "          0.6436237 ,  0.29061928],\n",
       "        [ 0.78394866, -0.46579516, -0.84323454, ...,  0.43640742,\n",
       "          0.5382323 ,  0.3014518 ],\n",
       "        [ 0.48419422, -0.49280313, -0.7773516 , ...,  0.36862957,\n",
       "          0.3437703 ,  0.04270842]]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel = vits.slice_segments(mel_outputs, ids_slice, model.segment_size // model.hop_size, np.log(1e-2))\n",
    "mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2), Dimension(8192), Dimension(1)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = vits.slice_segments(tf.expand_dims(wavs, -1), ids_slice * model.hop_size, model.segment_size)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(2), Dimension(8192), Dimension(1)]),\n",
       " TensorShape([Dimension(2), Dimension(8192), Dimension(1)]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = discriminator(y)\n",
    "# p_hat = discriminator(y_hat)\n",
    "\n",
    "# real_loss = 0.0\n",
    "# fake_loss = 0.0\n",
    "# for i in range(len(p)):\n",
    "#     real_loss += calculate_3d_loss(\n",
    "#         tf.ones_like(p[i][-1]), p[i][-1], loss_fn=mse_loss\n",
    "#     )\n",
    "#     fake_loss += calculate_3d_loss(\n",
    "#         tf.zeros_like(p_hat[i][-1]), p_hat[i][-1], loss_fn=mse_loss\n",
    "#     )\n",
    "# real_loss /= i + 1\n",
    "# fake_loss /= i + 1\n",
    "# dis_loss = real_loss + fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "\n",
    "# p = discriminator(y)\n",
    "# p_hat = discriminator(y_hat)\n",
    "\n",
    "# adv_loss = 0.0\n",
    "# for i in range(len(p_hat)):\n",
    "#     adv_loss += calculate_3d_loss(\n",
    "#         tf.ones_like(p_hat[i][-1]), p_hat[i][-1], loss_fn=mse_loss\n",
    "#     )\n",
    "# adv_loss /= i + 1\n",
    "\n",
    "# fm_loss = 0.0\n",
    "# for i in range(len(p_hat)):\n",
    "#     for j in range(len(p_hat[i]) - 1):\n",
    "#         fm_loss += calculate_3d_loss(\n",
    "#             p[i][j], p_hat[i][j], loss_fn=mae_loss\n",
    "#         )\n",
    "\n",
    "# fm_loss /= (i + 1) * (j + 1)\n",
    "# adv_loss += 1.0 * fm_loss\n",
    "# generator_loss = 1.0 * adv_loss\n",
    "\n",
    "mel_loss = calculate_3d_loss(mel, mel_hat, loss_fn=mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_, mellen_, attn_out = model(inputs = i, lengths = i_lengths)\n",
    "mel_, mellen_, attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = tf.train.AdamOptimizer(learning_rate = 1e-6, beta1 = 0.9, \n",
    "#                                    beta2 = 0.98, epsilon = 1e-9).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate = 1e-4, beta1 = 0.9, \n",
    "                                   beta2 = 0.98, epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        losses, attn, latent, mel_hat, ids_slice = model.compute_loss(text = i, textlen = i_lengths, mel = mel_outputs, mellen = mel_lengths)\n",
    "        mel = vits.slice_segments(mel_outputs, ids_slice, model.segment_size // model.hop_size, np.log(1e-2))\n",
    "        mel_loss = calculate_3d_loss(mel, mel_hat, loss_fn=mae_loss)\n",
    "        loss = losses['nll'] + losses['durloss'] + mel_loss\n",
    "    print(k, losses)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_, mellen_, attn_out = model(inputs = i, lengths = i_lengths)\n",
    "mel_, mellen_, attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# o = sess.run([loss, losses, attn], feed_dict = {i: [data['text_ids'][0],data['text_ids'][0]],\n",
    "#                                                i_lengths: [data['len_text_ids'][0,0], data['len_text_ids'][0,0]],\n",
    "#                                                mel_outputs: [data['mel'].astype(np.float32)[0],data['mel'].astype(np.float32)[0]],\n",
    "#                                                mel_lengths: [408, 408]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = sess.run([mel, mellen, attn_out], feed_dict = {i: [data['text_ids'][0],data['text_ids'][0]],\n",
    "#                                                i_lengths: [data['len_text_ids'][0,0], data['len_text_ids'][0,0]],\n",
    "#                                         mel_outputs: [data['mel'].astype(np.float32)[0],data['mel'].astype(np.float32)[0]],\n",
    "#                                                mel_lengths: [408, 408]})\n",
    "# o[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for k in range(50):\n",
    "#     o = sess.run([loss, losses, optimizer], feed_dict = {i: [data['text_ids'][0],data['text_ids'][0]],\n",
    "#                                                i_lengths: [data['len_text_ids'][0,0], data['len_text_ids'][0,0]],\n",
    "#                                                mel_outputs: [data['mel'].astype(np.float32)[0],data['mel'].astype(np.float32)[0]],\n",
    "#                                                mel_lengths: [408, 408]})\n",
    "#     print(k, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = sess.run([mel, mellen, attn_out], feed_dict = {i: [data['text_ids'][0],data['text_ids'][0]],\n",
    "#                                                i_lengths: [data['len_text_ids'][0,0], data['len_text_ids'][0,0]],\n",
    "#                                         mel_outputs: [data['mel'].astype(np.float32)[0],data['mel'].astype(np.float32)[0]],\n",
    "#                                                mel_lengths: [408, 408]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_outputs_ = np.reshape(mel_[0], [-1, 80])\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_title(f'Predicted Mel-before-Spectrogram')\n",
    "im = ax1.imshow(np.rot90(mel_outputs_), aspect='auto', interpolation='none')\n",
    "fig.colorbar(mappable=im, shrink=0.65, orientation='horizontal', ax=ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title('Alignment steps')\n",
    "im = ax.imshow(\n",
    "    o[-1][0],\n",
    "    aspect='auto',\n",
    "    origin='lower',\n",
    "    interpolation='none')\n",
    "fig.colorbar(im, ax=ax)\n",
    "xlabel = 'Decoder timestep'\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel('Encoder timestep')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'test/model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
