{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gross-amplifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exterior-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "existing-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intensive-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:38: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "disturbed-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malaya-speech-model/v1/vocab/malaya-speech.tokenizer.subwords\n",
    "# !wget https://f000.backblazeb2.com/file/malaya-speech-model/pretrained/asr-small-conformer-output.tar.gz\n",
    "# !tar -zxf asr-small-conformer-output.tar.gz\n",
    "# !ls asr-small-conformer-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surgical-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow-datasets==3.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "proper-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords = malaya_speech.subword.load('transducer.tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sticky-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fatty-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    '../speech/record/savewav_2020-11-26_22-36-06_294832.wav',\n",
    "    '../speech/record/savewav_2020-11-26_22-40-56_929661.wav',\n",
    "    '../speech/record/675.wav',\n",
    "    '../speech/record/664.wav',\n",
    "    '../speech/example-speaker/husein-zolkepli.wav',\n",
    "    '../speech/example-speaker/mas-aisyah.wav',\n",
    "    '../speech/example-speaker/khalil-nooh.wav',\n",
    "    '../speech/example-speaker/shafiqah-idayu.wav',\n",
    "    '../speech/khutbah/wadi-annuar.wav',\n",
    "]\n",
    "\n",
    "ys = [malaya_speech.load(f)[0] for f in files[:1]]\n",
    "padded, lens = malaya_speech.padding.sequence_1d(ys, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "representative-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(padded.astype(np.float32))\n",
    "X_len = tf.convert_to_tensor(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "respiratory-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "# X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unique-jesus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=350, shape=(1, 598, 80, 1), dtype=float32, numpy=\n",
       " array([[[[-2.2115872 ],\n",
       "          [-1.5766288 ],\n",
       "          [-1.4163095 ],\n",
       "          ...,\n",
       "          [-0.8240542 ],\n",
       "          [-0.5252634 ],\n",
       "          [-0.50458676]],\n",
       " \n",
       "         [[-1.2302203 ],\n",
       "          [-1.4857259 ],\n",
       "          [-1.383363  ],\n",
       "          ...,\n",
       "          [-1.0011699 ],\n",
       "          [-0.9600155 ],\n",
       "          [-0.8101736 ]],\n",
       " \n",
       "         [[-1.6328442 ],\n",
       "          [-2.1661863 ],\n",
       "          [-2.1120117 ],\n",
       "          ...,\n",
       "          [-0.9762852 ],\n",
       "          [-0.9798523 ],\n",
       "          [-0.9050785 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-1.2225453 ],\n",
       "          [-1.4474126 ],\n",
       "          [-1.342642  ],\n",
       "          ...,\n",
       "          [-0.60859317],\n",
       "          [-0.5357948 ],\n",
       "          [-1.0666174 ]],\n",
       " \n",
       "         [[-1.8612145 ],\n",
       "          [-2.130672  ],\n",
       "          [-2.0027483 ],\n",
       "          ...,\n",
       "          [-0.59845954],\n",
       "          [-0.7141181 ],\n",
       "          [-0.49980083]],\n",
       " \n",
       "         [[-0.70888734],\n",
       "          [-1.2011607 ],\n",
       "          [-1.154966  ],\n",
       "          ...,\n",
       "          [-1.0014057 ],\n",
       "          [-0.8354665 ],\n",
       "          [-0.36788353]]]], dtype=float32)>,\n",
       " <tf.Tensor: id=348, shape=(1,), dtype=int32, numpy=array([598], dtype=int32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "features = tf.TensorArray(dtype = tf.float32, size = batch_size, dynamic_size = True, infer_shape = False)\n",
    "features_len = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "\n",
    "init_state = (0, features, features_len)\n",
    "\n",
    "def condition(i, features, features_len):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, features, features_len):\n",
    "    f = featurizer(X[i, :X_len[i]])\n",
    "    f_len = tf.shape(f)[0]\n",
    "    return i + 1, features.write(i, f), features_len.write(i, f_len)\n",
    "\n",
    "_, features, features_len = tf.while_loop(condition, body, init_state)\n",
    "features_len = features_len.stack()\n",
    "padded_features = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_lens = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "maxlen = tf.reduce_max(features_len)\n",
    "\n",
    "init_state = (0, padded_features, padded_lens)\n",
    "\n",
    "def condition(i, padded_features, padded_lens):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, padded_features, padded_lens):\n",
    "    f = features.read(i)\n",
    "    len_f = tf.shape(f)[0]\n",
    "    f = tf.pad(f, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    return i + 1, padded_features.write(i, f), padded_lens.write(i, len_f)\n",
    "\n",
    "_, padded_features, padded_lens = tf.while_loop(condition, body, init_state)\n",
    "padded_features = padded_features.stack()\n",
    "padded_lens = padded_lens.stack()\n",
    "padded_lens.set_shape((None))\n",
    "padded_features.set_shape((None, None, 80))\n",
    "padded_features = tf.expand_dims(padded_features, -1)\n",
    "padded_features, padded_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mexican-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = tf.identity(padded_features, name = 'padded_features')\n",
    "padded_lens = tf.identity(padded_lens, name = 'padded_lens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rising-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.conformer_small_encoder_config\n",
    "conformer_model = conformer.Model(**config)\n",
    "decoder_config = malaya_speech.config.conformer_small_decoder_config\n",
    "transducer_model = transducer.rnn.Model(\n",
    "    conformer_model, vocabulary_size = subwords.vocab_size, **decoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proper-atmosphere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transducer_model.encoder.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "important-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
    "# z = tf.zeros((tf.shape(p)[0], 1),dtype=tf.int32)\n",
    "# c = tf.concat([z, p], axis = 1)\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "black-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=365, shape=(1, 6), dtype=int32, numpy=array([[0, 2, 2, 2, 2, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = tf.constant([[2,2,2,2,2]])\n",
    "z = tf.zeros((tf.shape(p)[0], 1),dtype=tf.int32)\n",
    "c = tf.concat([z, p], axis = 1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "united-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = tf.constant([6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "stuffed-drama",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/transducer/layer.py:37: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12615, shape=(1, 150, 6, 1019), dtype=float32, numpy=\n",
       "array([[[[-0.21974955,  0.5226778 ,  0.02030805, ...,  0.04838037,\n",
       "          -0.44045997, -0.5315165 ],\n",
       "         [-0.22635975,  0.5210593 ,  0.17396489, ...,  0.18695638,\n",
       "          -0.5194685 , -0.52632284],\n",
       "         [-0.23254883,  0.49548236,  0.24859768, ...,  0.24871068,\n",
       "          -0.5706615 , -0.5231326 ],\n",
       "         [-0.2396116 ,  0.46431023,  0.28361756, ...,  0.26548967,\n",
       "          -0.597591  , -0.5188615 ],\n",
       "         [-0.24655414,  0.43456012,  0.29953557, ...,  0.26119354,\n",
       "          -0.6105197 , -0.51496816],\n",
       "         [-0.2524442 ,  0.4082055 ,  0.30604976, ...,  0.24828719,\n",
       "          -0.6168091 , -0.51176333]],\n",
       "\n",
       "        [[-0.06653558,  0.6587397 , -0.12961435, ...,  0.06785958,\n",
       "          -0.3941598 , -0.5885802 ],\n",
       "         [-0.06261308,  0.65313065,  0.03283359, ...,  0.19708693,\n",
       "          -0.47041103, -0.5877011 ],\n",
       "         [-0.06166597,  0.619279  ,  0.1207882 , ...,  0.2516792 ,\n",
       "          -0.5219394 , -0.5794502 ],\n",
       "         [-0.06517343,  0.58159566,  0.16501826, ...,  0.2639284 ,\n",
       "          -0.5505631 , -0.5694775 ],\n",
       "         [-0.07082037,  0.5473239 ,  0.18653348, ...,  0.2567597 ,\n",
       "          -0.56555486, -0.5610482 ],\n",
       "         [-0.07669839,  0.5178481 ,  0.19647028, ...,  0.2419517 ,\n",
       "          -0.5737989 , -0.5546588 ]],\n",
       "\n",
       "        [[-0.10202614,  0.6551102 , -0.01935777, ..., -0.02518733,\n",
       "          -0.48366156, -0.49618083],\n",
       "         [-0.09631573,  0.64541525,  0.12498678, ...,  0.10426337,\n",
       "          -0.55544007, -0.5034586 ],\n",
       "         [-0.0943218 ,  0.6089976 ,  0.19799641, ...,  0.16440605,\n",
       "          -0.6060499 , -0.5051912 ],\n",
       "         [-0.09574114,  0.5716913 ,  0.23205987, ...,  0.1829045 ,\n",
       "          -0.63360333, -0.5040273 ],\n",
       "         [-0.09869955,  0.53925806,  0.24664012, ...,  0.18095577,\n",
       "          -0.6471063 , -0.50252724],\n",
       "         [-0.10178585,  0.512099  ,  0.25166175, ...,  0.17022148,\n",
       "          -0.6538348 , -0.50131315]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1536158 ,  0.5810604 ,  0.04596284, ...,  0.18762635,\n",
       "          -0.5140366 , -0.45953745],\n",
       "         [-0.15434548,  0.56628305,  0.21717402, ...,  0.30931783,\n",
       "          -0.58889276, -0.44703126],\n",
       "         [-0.1502409 ,  0.5329293 ,  0.30515057, ...,  0.3559326 ,\n",
       "          -0.6361358 , -0.439192  ],\n",
       "         [-0.1502158 ,  0.49696496,  0.34650904, ...,  0.36183158,\n",
       "          -0.65973157, -0.43115672],\n",
       "         [-0.15359269,  0.46373355,  0.36473098, ...,  0.34979603,\n",
       "          -0.6701365 , -0.4241326 ],\n",
       "         [-0.15820473,  0.43473202,  0.3716807 , ...,  0.33131996,\n",
       "          -0.67449987, -0.41855577]],\n",
       "\n",
       "        [[-0.1442796 ,  0.55680096,  0.03062764, ...,  0.20859438,\n",
       "          -0.51752925, -0.49603954],\n",
       "         [-0.14165933,  0.5482303 ,  0.19610523, ...,  0.3294191 ,\n",
       "          -0.58719295, -0.485727  ],\n",
       "         [-0.13564369,  0.5195116 ,  0.28104904, ...,  0.3747677 ,\n",
       "          -0.630471  , -0.4779117 ],\n",
       "         [-0.1348101 ,  0.48579064,  0.32076058, ...,  0.37916702,\n",
       "          -0.65218043, -0.4689896 ],\n",
       "         [-0.13794872,  0.45331413,  0.3379783 , ...,  0.3657006 ,\n",
       "          -0.66189146, -0.46077707],\n",
       "         [-0.1425701 ,  0.42430213,  0.34427017, ...,  0.345976  ,\n",
       "          -0.66610825, -0.4540575 ]],\n",
       "\n",
       "        [[-0.27547598,  0.6606127 , -0.11956947, ...,  0.2562333 ,\n",
       "          -0.42161003, -0.538662  ],\n",
       "         [-0.2694951 ,  0.6464211 ,  0.05098857, ...,  0.37185904,\n",
       "          -0.5061829 , -0.5317428 ],\n",
       "         [-0.26328167,  0.61038965,  0.1442745 , ...,  0.4151458 ,\n",
       "          -0.5605751 , -0.52369905],\n",
       "         [-0.26325566,  0.5714545 ,  0.19183797, ...,  0.419402  ,\n",
       "          -0.58912873, -0.5132673 ],\n",
       "         [-0.26682055,  0.535838  ,  0.21554902, ...,  0.40688676,\n",
       "          -0.60307395, -0.5036376 ],\n",
       "         [-0.27140114,  0.50498587,  0.22701402, ...,  0.38861087,\n",
       "          -0.61008084, -0.49586838]]]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = transducer_model([padded_features, c, l], training = False)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "automated-compiler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py:1249: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.NameBasedSaverStatus at 0x152d83fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transducer_model.load_weights('asr-small-conformer-output/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "coated-queensland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=351, shape=(1, 598, 80, 1), dtype=float32, numpy=\n",
       "array([[[[-2.2115872 ],\n",
       "         [-1.5766288 ],\n",
       "         [-1.4163095 ],\n",
       "         ...,\n",
       "         [-0.8240542 ],\n",
       "         [-0.5252634 ],\n",
       "         [-0.50458676]],\n",
       "\n",
       "        [[-1.2302203 ],\n",
       "         [-1.4857259 ],\n",
       "         [-1.383363  ],\n",
       "         ...,\n",
       "         [-1.0011699 ],\n",
       "         [-0.9600155 ],\n",
       "         [-0.8101736 ]],\n",
       "\n",
       "        [[-1.6328442 ],\n",
       "         [-2.1661863 ],\n",
       "         [-2.1120117 ],\n",
       "         ...,\n",
       "         [-0.9762852 ],\n",
       "         [-0.9798523 ],\n",
       "         [-0.9050785 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.2225453 ],\n",
       "         [-1.4474126 ],\n",
       "         [-1.342642  ],\n",
       "         ...,\n",
       "         [-0.60859317],\n",
       "         [-0.5357948 ],\n",
       "         [-1.0666174 ]],\n",
       "\n",
       "        [[-1.8612145 ],\n",
       "         [-2.130672  ],\n",
       "         [-2.0027483 ],\n",
       "         ...,\n",
       "         [-0.59845954],\n",
       "         [-0.7141181 ],\n",
       "         [-0.49980083]],\n",
       "\n",
       "        [[-0.70888734],\n",
       "         [-1.2011607 ],\n",
       "         [-1.154966  ],\n",
       "         ...,\n",
       "         [-1.0014057 ],\n",
       "         [-0.8354665 ],\n",
       "         [-0.36788353]]]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "gorgeous-agreement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21342, shape=(150, 144), dtype=float32, numpy=\n",
       "array([[-0.6797897 ,  0.26061982,  1.2461013 , ..., -0.47316766,\n",
       "         0.51813114,  0.78770745],\n",
       "       [-0.903607  ,  0.37088263,  0.91624343, ..., -0.60682523,\n",
       "         0.4082876 ,  0.84890574],\n",
       "       [-0.48814595,  0.11114161,  0.03709664, ..., -0.44080445,\n",
       "         0.17693707,  0.12082277],\n",
       "       ...,\n",
       "       [ 0.82666403, -0.5946571 , -0.3874987 , ..., -0.6909609 ,\n",
       "        -0.3609525 , -0.8450332 ],\n",
       "       [ 0.49660668, -0.70961297, -0.8074534 , ..., -0.76029015,\n",
       "        -0.43788105, -0.37397334],\n",
       "       [ 0.34774616, -1.1404285 , -0.6966349 , ..., -0.5111091 ,\n",
       "        -0.36480278, -0.25822282]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = transducer_model.encoder_inference(padded_features[0])\n",
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "broke-writer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21342, shape=(150, 144), dtype=float32, numpy=\n",
       "array([[-0.6797897 ,  0.26061982,  1.2461013 , ..., -0.47316766,\n",
       "         0.51813114,  0.78770745],\n",
       "       [-0.903607  ,  0.37088263,  0.91624343, ..., -0.60682523,\n",
       "         0.4082876 ,  0.84890574],\n",
       "       [-0.48814595,  0.11114161,  0.03709664, ..., -0.44080445,\n",
       "         0.17693707,  0.12082277],\n",
       "       ...,\n",
       "       [ 0.82666403, -0.5946571 , -0.3874987 , ..., -0.6909609 ,\n",
       "        -0.3609525 , -0.8450332 ],\n",
       "       [ 0.49660668, -0.70961297, -0.8074534 , ..., -0.76029015,\n",
       "        -0.43788105, -0.37397334],\n",
       "       [ 0.34774616, -1.1404285 , -0.6966349 , ..., -0.5111091 ,\n",
       "        -0.36480278, -0.25822282]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vulnerable-tribute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypothesis(index=<tf.Tensor: id=63217, shape=(), dtype=int32, numpy=870>, prediction=<tf.Tensor: id=63222, shape=(150,), dtype=int32, numpy=\n",
       "array([  0, 596, 206,   0,   0,   0, 795,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 514,   0,   0,   0,   0,   0, 795,   0,\n",
       "        30,   0,   0,   0,   0, 795,   0,   0,   0, 266,   0,   0,   0,\n",
       "         0,   0,   0,   0, 175,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        30,   0,   0, 795,   0,  17,   0,   0,   0, 421,   0,   0,   0,\n",
       "       795, 204,   0,   0,   0,   0,  27,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 405,   0,   0,\n",
       "         0,  54,   0,   0,  30,   0,   0,   0,   0, 795,   0,   0,   0,\n",
       "         0, 136,   0,   0,   0,   0,   0,   0,   0,   0, 870,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0], dtype=int32)>, states=<tf.Tensor: id=63218, shape=(1, 2, 1, 320), dtype=float32, numpy=\n",
       "array([[[[ 5.60698450e-01,  2.32693739e-02, -1.38049498e-01,\n",
       "           2.77668238e-01, -9.28736944e-03,  5.67813158e-01,\n",
       "          -1.20832194e-02,  9.41104665e-02,  6.25789985e-02,\n",
       "           1.61799323e-02, -1.25140637e-01,  8.92624483e-02,\n",
       "           5.69487214e-02,  2.42520757e-02, -8.97588059e-02,\n",
       "           1.71416745e-01,  3.55067730e-01, -6.61696121e-02,\n",
       "          -1.48847282e-01, -3.25950414e-01, -5.81640601e-01,\n",
       "          -3.48649174e-01,  4.06244516e-01, -9.19005200e-02,\n",
       "          -4.79568169e-02,  1.39089659e-01,  1.11615531e-01,\n",
       "          -7.76370615e-03, -3.28745604e-01, -4.95600253e-02,\n",
       "          -3.18764746e-02,  2.47987662e-03, -2.87413299e-02,\n",
       "          -1.26749382e-03,  5.12747606e-03, -7.91574940e-02,\n",
       "           3.54620367e-02, -1.59279287e-01, -1.30000383e-01,\n",
       "          -1.84685051e-01,  8.09972286e-02, -0.00000000e+00,\n",
       "          -3.99230272e-02,  5.17459214e-02, -3.50258946e-01,\n",
       "          -3.80047351e-01, -2.75959820e-02, -1.44913346e-01,\n",
       "           3.70448492e-02,  9.52316344e-01,  3.83078665e-01,\n",
       "          -6.29706532e-02,  3.25228304e-01,  2.85224229e-01,\n",
       "           1.32521197e-01,  1.11165754e-01,  1.58601135e-01,\n",
       "           1.04184203e-01,  3.02274942e-01,  4.18956071e-01,\n",
       "           4.71594036e-02,  3.88173312e-02, -2.28948280e-01,\n",
       "          -4.34954534e-04, -7.28165358e-03, -2.84159929e-02,\n",
       "           2.61230897e-02, -6.98262379e-02, -1.54413491e-01,\n",
       "           0.00000000e+00,  7.05048591e-02, -3.76328304e-02,\n",
       "           8.81545153e-03,  1.31286666e-01, -3.30560863e-01,\n",
       "           1.69387758e-01, -3.81281488e-02, -4.47381616e-01,\n",
       "          -1.06457248e-02,  1.97155312e-01,  1.47604316e-01,\n",
       "           1.59698948e-01, -2.39014715e-01,  4.84950989e-02,\n",
       "           0.00000000e+00, -1.22270666e-01,  9.99633148e-02,\n",
       "           1.19609468e-01,  1.30527228e-01, -1.15142567e-02,\n",
       "          -2.60987524e-02,  1.07105300e-02,  1.45410709e-02,\n",
       "          -3.86863112e-01,  5.74477911e-01,  9.54663102e-03,\n",
       "          -1.16428345e-01,  4.30750027e-02, -3.64597768e-01,\n",
       "           2.54886538e-01,  2.98134327e-01,  2.18634326e-02,\n",
       "          -1.80479199e-01,  2.21802548e-01, -3.86850424e-02,\n",
       "          -1.47479326e-02, -2.20150091e-02,  5.53529151e-02,\n",
       "          -1.53098451e-02,  3.78328025e-01, -4.41159084e-02,\n",
       "          -4.56619151e-02,  4.25933599e-01,  2.97686011e-01,\n",
       "          -2.28365526e-01,  3.45781803e-01, -1.92847960e-02,\n",
       "           5.49950562e-02,  3.20878059e-01,  2.76475679e-02,\n",
       "          -8.91766101e-02, -1.20579854e-01,  0.00000000e+00,\n",
       "          -6.59268256e-03, -6.46416917e-02,  3.80719490e-02,\n",
       "          -8.82566813e-03, -1.82490841e-01, -4.66998927e-02,\n",
       "          -1.01242080e-01,  1.12543195e-01,  1.24470647e-02,\n",
       "          -2.41014380e-02, -3.40784080e-02, -3.05641741e-01,\n",
       "          -6.97433650e-02, -1.47204503e-01,  2.33275279e-01,\n",
       "           5.25813699e-02, -9.31078047e-02,  8.37108642e-02,\n",
       "          -1.38476908e-01,  1.27359014e-02, -1.26001472e-02,\n",
       "          -7.64967203e-02, -3.55848260e-02,  6.90695122e-02,\n",
       "          -4.49241847e-01,  1.97930813e-01,  1.21676803e-01,\n",
       "           0.00000000e+00,  9.07697901e-03, -2.52215087e-01,\n",
       "          -1.03503935e-01, -4.41258341e-01, -1.93274021e-02,\n",
       "          -9.35879871e-02,  1.57910854e-01, -3.03989053e-02,\n",
       "           2.23390460e-01,  2.98455339e-02, -1.73201952e-02,\n",
       "          -3.25066112e-02, -9.72222723e-03,  1.37606069e-01,\n",
       "           7.08938539e-02,  2.16368258e-01, -2.57339209e-01,\n",
       "          -8.12847167e-02,  8.99750516e-02,  5.43860793e-02,\n",
       "          -1.45266771e-01,  3.55448797e-02, -1.60646178e-02,\n",
       "          -2.80377716e-01, -3.08095008e-01,  6.88932538e-02,\n",
       "           4.30454053e-02,  7.54690096e-02,  1.57685086e-01,\n",
       "           4.87075523e-02,  3.55253875e-01,  3.14330608e-02,\n",
       "           2.71876976e-02, -1.97296720e-02,  5.02502248e-02,\n",
       "           2.92052422e-03,  1.62226200e-01,  2.42035285e-01,\n",
       "           7.35615864e-02,  6.71305135e-02, -6.37195930e-02,\n",
       "           2.66025960e-01,  5.52162826e-01, -7.18435124e-02,\n",
       "           2.04323307e-01,  4.27011661e-02, -9.52793192e-03,\n",
       "           2.20601082e-01, -1.33051127e-01, -3.32162231e-02,\n",
       "           4.23027873e-01,  1.38892392e-02,  2.53780186e-02,\n",
       "           1.43826604e-01,  4.42563668e-02, -1.13448858e-01,\n",
       "           8.65180418e-03, -4.81704287e-02, -1.39117733e-01,\n",
       "           8.09576421e-04, -6.13587163e-02,  2.52100796e-01,\n",
       "           8.07788447e-02,  1.42995998e-01, -2.13003963e-01,\n",
       "           2.24554554e-01,  4.07764822e-01, -2.31140614e-01,\n",
       "           4.11002315e-04,  6.45676553e-02,  1.11496776e-01,\n",
       "           1.34241179e-01,  2.75950819e-01, -3.49900305e-01,\n",
       "           3.42460752e-01,  3.54797468e-02, -8.66627842e-02,\n",
       "          -5.54297715e-02,  3.16547871e-01, -2.32073385e-02,\n",
       "          -1.24530848e-02, -1.62761793e-01,  8.88445139e-01,\n",
       "           7.79547379e-04,  1.95031986e-01, -1.80716272e-02,\n",
       "           1.16859470e-02,  5.94129205e-01,  2.75305003e-01,\n",
       "          -7.57758915e-02,  0.00000000e+00, -4.07356769e-01,\n",
       "          -7.53440522e-03,  2.83309072e-01, -7.23107755e-02,\n",
       "           1.53017536e-01,  2.44965956e-01,  1.11829981e-01,\n",
       "          -2.15448499e-01, -1.73697010e-01,  1.77256614e-01,\n",
       "          -9.60940272e-02,  1.16375059e-01,  1.54218571e-02,\n",
       "           8.82470459e-02,  0.00000000e+00,  2.23221555e-01,\n",
       "           5.58853783e-02, -6.18938245e-02, -1.35796696e-01,\n",
       "          -1.28676966e-01, -2.51894712e-01,  4.76990819e-01,\n",
       "           6.96439818e-02,  4.25969511e-02, -5.98878553e-03,\n",
       "           1.80337336e-02,  1.38421403e-03, -5.44631202e-03,\n",
       "           8.14880151e-03,  5.38636595e-02, -7.59310275e-02,\n",
       "          -2.64502376e-01, -1.47103844e-02,  2.74058372e-01,\n",
       "          -2.02301279e-01,  2.16082662e-01,  0.00000000e+00,\n",
       "           2.19128071e-03, -5.03110923e-02, -2.74535902e-02,\n",
       "          -1.60043448e-01, -1.83049515e-01, -3.02167237e-01,\n",
       "           6.86152950e-02, -8.55383128e-02, -0.00000000e+00,\n",
       "          -9.55981836e-02,  4.46916938e-01,  2.37721384e-01,\n",
       "           7.70271361e-01, -1.52611926e-01,  1.23079285e-01,\n",
       "          -1.82748437e-02,  4.22291547e-01,  1.58356838e-02,\n",
       "          -2.10270643e-01, -4.48203236e-02,  4.10598554e-02,\n",
       "          -8.77235606e-02, -1.15069607e-02, -1.51741039e-02,\n",
       "           1.11550473e-01, -5.42211812e-03, -5.97595843e-03,\n",
       "           7.37400129e-02, -9.36825052e-02,  1.34525821e-01,\n",
       "          -9.23431590e-02,  3.35204422e-01,  4.32393588e-02,\n",
       "          -3.71118672e-02,  3.81819993e-01,  5.61994389e-02,\n",
       "           2.04013716e-02,  0.00000000e+00,  2.17942804e-01,\n",
       "           2.81293280e-02,  2.28252653e-02]],\n",
       "\n",
       "        [[ 6.33851290e-01,  1.23663679e-01, -2.12985843e-01,\n",
       "           6.89370275e-01, -1.08143948e-01,  8.62349212e-01,\n",
       "          -8.23743641e-02,  9.43898037e-02,  3.63299161e-01,\n",
       "           5.95062040e-02, -2.12947875e-01,  1.41670063e-01,\n",
       "           1.19055636e-01,  7.95968771e-02, -4.11120683e-01,\n",
       "           3.40564877e-01,  5.46922147e-01, -9.92762893e-02,\n",
       "          -5.35751283e-01, -4.08631057e-01, -7.26700604e-01,\n",
       "          -5.59869349e-01,  7.87211955e-01, -1.98807478e-01,\n",
       "          -4.79936376e-02,  3.56237292e-01,  2.46621341e-01,\n",
       "          -2.41971552e-01, -3.41421217e-01, -1.27794936e-01,\n",
       "          -3.65555435e-01,  1.86632518e-02, -5.66620529e-02,\n",
       "          -1.94157939e-03,  3.47411692e-01, -1.68727636e-01,\n",
       "           2.09990427e-01, -2.08784550e-01, -3.02598953e-01,\n",
       "          -3.71177554e-01,  2.27840140e-01, -8.39556009e-02,\n",
       "          -1.72613412e-01,  6.56818002e-02, -4.56733316e-01,\n",
       "          -4.32509422e-01, -1.21329628e-01, -2.74786234e-01,\n",
       "           1.93030864e-01,  1.85609245e+00,  5.44522166e-01,\n",
       "          -2.30668247e-01,  4.14625257e-01,  4.52055067e-01,\n",
       "           3.98467958e-01,  5.37468195e-01,  2.63205707e-01,\n",
       "           2.02357844e-01,  6.55587256e-01,  7.02264190e-01,\n",
       "           4.71944138e-02,  1.46107331e-01, -4.86680210e-01,\n",
       "          -1.54725614e-03, -1.62133984e-02, -5.89300618e-02,\n",
       "           1.32512212e-01, -3.81298006e-01, -3.15627217e-01,\n",
       "           2.20631421e-01,  4.99058992e-01, -5.51471114e-02,\n",
       "           2.78965235e-02,  3.69915992e-01, -4.40242082e-01,\n",
       "           3.61319602e-01, -9.97119918e-02, -6.12319589e-01,\n",
       "          -3.26549150e-02,  3.62121552e-01,  2.45491594e-01,\n",
       "           3.08522820e-01, -5.46631873e-01,  9.44578946e-02,\n",
       "           1.06151804e-01, -2.84701884e-01,  3.29358131e-01,\n",
       "           2.56089896e-01,  3.64982098e-01, -3.05842087e-02,\n",
       "          -9.03811231e-02,  5.31123988e-02,  5.14340848e-02,\n",
       "          -4.08105791e-01,  8.73767853e-01,  1.98672377e-02,\n",
       "          -3.36038262e-01,  1.08363762e-01, -5.72456002e-01,\n",
       "           3.55791181e-01,  4.67574745e-01,  5.92405736e-01,\n",
       "          -3.29101533e-01,  5.55127323e-01, -9.19669867e-02,\n",
       "          -5.42140119e-02, -2.20185705e-02,  1.72284052e-01,\n",
       "          -1.04107842e-01,  6.30756378e-01, -2.67646432e-01,\n",
       "          -1.36835128e-01,  5.49298227e-01,  6.40088320e-01,\n",
       "          -5.18159628e-01,  4.97147441e-01, -7.30403066e-02,\n",
       "           1.11975126e-01,  6.90977871e-01,  4.38789189e-01,\n",
       "          -1.73305511e-01, -1.21779501e-01,  4.50829536e-01,\n",
       "          -2.41448916e-02, -9.54820961e-02,  1.05439693e-01,\n",
       "          -1.89597026e-01, -1.84558153e-01, -1.12798765e-01,\n",
       "          -1.01590142e-01,  3.38862449e-01,  1.58888549e-02,\n",
       "          -6.03790954e-02, -5.60978949e-02, -5.10278881e-01,\n",
       "          -1.33808181e-01, -4.57963705e-01,  4.73757982e-01,\n",
       "           9.06915963e-02, -2.52157450e-01,  2.84645885e-01,\n",
       "          -3.54939818e-01,  2.38579884e-02, -1.57643743e-02,\n",
       "          -2.20099479e-01, -1.13702983e-01,  6.91796690e-02,\n",
       "          -4.83750015e-01,  3.40438694e-01,  4.40020978e-01,\n",
       "           4.05226499e-01,  3.64780992e-01, -3.44209760e-01,\n",
       "          -2.26957709e-01, -7.37131596e-01, -1.01203345e-01,\n",
       "          -3.15896332e-01,  2.32476979e-01, -4.42621149e-02,\n",
       "           5.64093173e-01,  2.38337696e-01, -1.42249301e-01,\n",
       "          -4.46453542e-02, -2.56939977e-02,  1.61635116e-01,\n",
       "           2.40421295e-01,  3.15946341e-01, -3.35197240e-01,\n",
       "          -1.94712773e-01,  1.27029523e-01,  1.64347261e-01,\n",
       "          -2.91782141e-01,  1.04881987e-01, -4.38013747e-02,\n",
       "          -4.06717241e-01, -4.09686923e-01,  4.19314474e-01,\n",
       "           2.13840872e-01,  2.05443725e-01,  5.32492638e-01,\n",
       "           1.96206301e-01,  4.48051542e-01,  2.33547702e-01,\n",
       "           4.20635603e-02, -1.97322350e-02,  4.47759122e-01,\n",
       "           7.52992555e-03,  2.76631027e-01,  3.92107934e-01,\n",
       "           1.80947185e-01,  8.25022310e-02, -9.48077887e-02,\n",
       "           5.37218809e-01,  8.61986876e-01, -9.90856588e-02,\n",
       "           4.96406317e-01,  4.80997145e-01, -3.10351551e-02,\n",
       "           5.07466555e-01, -2.39873141e-01, -3.33027333e-01,\n",
       "           7.15119839e-01,  3.06983858e-01,  6.31407201e-02,\n",
       "           3.36373359e-01,  1.50622457e-01, -1.53664172e-01,\n",
       "           2.68315319e-02, -1.14498891e-01, -3.24677557e-01,\n",
       "           3.86330575e-01, -2.25628972e-01,  3.59604478e-01,\n",
       "           3.37647259e-01,  2.69629598e-01, -4.04523849e-01,\n",
       "           6.06509149e-01,  4.92179513e-01, -3.77190739e-01,\n",
       "           5.63258901e-02,  3.87226790e-01,  1.76117167e-01,\n",
       "           5.04246652e-01,  4.20012593e-01, -3.65330189e-01,\n",
       "           6.33285642e-01,  5.53728528e-02, -1.60631135e-01,\n",
       "          -3.44643533e-01,  5.69837093e-01, -1.05571516e-01,\n",
       "          -1.45183563e-01, -4.14359301e-01,  3.31804371e+00,\n",
       "           2.71743536e-03,  2.44526595e-01, -5.82752824e-02,\n",
       "           1.09341621e-01,  7.62328088e-01,  5.82368016e-01,\n",
       "          -1.98224604e-01,  6.45190775e-01, -4.63302672e-01,\n",
       "          -2.09827125e-02,  3.15966994e-01, -1.20601311e-01,\n",
       "           3.35712522e-01,  6.76086068e-01,  1.19289815e-01,\n",
       "          -3.43686491e-01, -4.88326788e-01,  2.79046834e-01,\n",
       "          -1.59326747e-01,  2.22511649e-01,  9.51871872e-02,\n",
       "           3.57829094e-01,  3.82256627e-01,  4.61006790e-01,\n",
       "           2.24404559e-01, -2.35530123e-01, -5.35907269e-01,\n",
       "          -2.99700558e-01, -4.31880385e-01,  5.19991100e-01,\n",
       "           2.03557909e-01,  2.74401277e-01, -1.53238671e-02,\n",
       "           3.15228105e-02,  1.39147788e-03, -2.90097803e-01,\n",
       "           1.48399457e-01,  1.12455621e-01, -1.84636861e-01,\n",
       "          -4.03204381e-01, -2.88693309e-02,  3.94043446e-01,\n",
       "          -3.91967952e-01,  4.28352535e-01,  2.15857387e-01,\n",
       "           7.01646693e-03, -2.70453006e-01, -1.51847273e-01,\n",
       "          -4.40483123e-01, -2.04997450e-01, -6.26972139e-01,\n",
       "           2.31525868e-01, -3.80310327e-01, -2.19188407e-01,\n",
       "          -2.68952936e-01,  4.91578311e-01,  5.45370519e-01,\n",
       "           1.40577126e+00, -2.69102752e-01,  3.48921239e-01,\n",
       "          -6.96798787e-02,  7.70993829e-01,  9.03905258e-02,\n",
       "          -3.35634023e-01, -6.22015446e-02,  1.41418993e-01,\n",
       "          -1.36243433e-01, -7.97617733e-02, -4.61657085e-02,\n",
       "           4.36771929e-01, -1.51146147e-02, -8.84507895e-02,\n",
       "           2.16432944e-01, -1.76269874e-01,  1.86260670e-01,\n",
       "          -9.26069915e-02,  6.45115614e-01,  8.36302489e-02,\n",
       "          -1.03775054e-01,  4.41736400e-01,  9.44788009e-02,\n",
       "           9.89985764e-02,  9.59595218e-02,  5.78283846e-01,\n",
       "           5.03366329e-02,  9.96421427e-02]]]], dtype=float32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = transducer_model._perform_greedy(encoded, tf.shape(encoded)[0],\n",
    "                                tf.constant(0, dtype = tf.int32),\n",
    "                                transducer_model.predict_net.get_initial_state())\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "satellite-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = g.prediction\n",
    "minus_one = -1 * tf.ones_like(indices, dtype=tf.int32)\n",
    "blank_like = 0 * tf.ones_like(indices, dtype=tf.int32)\n",
    "indices = tf.where(indices == minus_one, blank_like, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "recovered-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = tf.cast(tf.shape(X[0])[0], dtype=tf.float32)\n",
    "total_time_reduction_factor = featurizer.frame_step\n",
    "stime = tf.range(0, num_samples, delta=total_time_reduction_factor, dtype=tf.float32)\n",
    "stime /= tf.cast(featurizer.sample_rate, dtype=tf.float32)\n",
    "etime = tf.range(total_time_reduction_factor, num_samples, delta=total_time_reduction_factor, dtype=tf.float32)\n",
    "etime /= tf.cast(featurizer.sample_rate, dtype=tf.float32)\n",
    "non_blank = tf.where(tf.not_equal(indices, 0))\n",
    "non_blank_transcript = tf.gather_nd(indices, non_blank)\n",
    "non_blank_stime = tf.gather_nd(tf.repeat(tf.expand_dims(stime, axis=-1), tf.shape(indices)[-1], axis=-1), non_blank)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cathedral-polls",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helo nama saya bersin saya tak suka mandi ketat saya masak'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malaya_speech.subword.decode(subwords, non_blank_transcript.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "meaning-repeat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('he', 'lo')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subwords._id_to_subword(596 - 1), subwords._id_to_subword(206 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "economic-amendment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=63350, shape=(22,), dtype=int32, numpy=\n",
       "array([596, 206, 795, 514, 795,  30, 795, 266, 175,  30, 795,  17, 421,\n",
       "       795, 204,  27, 405,  54,  30, 795, 136, 870], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_blank_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "mineral-steal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=63292, shape=(22,), dtype=float32, numpy=\n",
       "array([0.01, 0.02, 0.06, 0.18, 0.24, 0.26, 0.31, 0.35, 0.43, 0.65, 0.68,\n",
       "       0.7 , 0.74, 0.78, 0.79, 0.84, 1.14, 1.18, 1.21, 1.26, 1.31, 1.4 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_blank_stime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "about-korea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=110056, shape=(1, 598), dtype=int32, numpy=\n",
       "array([[  0, 596, 206,   0,   0,   0, 795,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 514,   0,   0,   0,   0,   0, 795,   0,\n",
       "         30,   0,   0,   0,   0, 795,   0,   0,   0, 266,   0,   0,   0,\n",
       "          0,   0,   0,   0, 175,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         30,   0,   0, 795,   0,  17,   0,   0,   0, 421,   0,   0,   0,\n",
       "        795, 204,   0,   0,   0,   0,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 405,   0,   0,\n",
       "          0,  54,   0,   0,  30,   0,   0,   0,   0, 795,   0,   0,   0,\n",
       "          0, 136,   0,   0,   0,   0,   0,   0,   0,   0, 870,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = transducer_model.greedy_decoder(padded_features, padded_lens, training = False)\n",
    "decoded = tf.identity(decoded, name = 'greedy_decoder')\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beam_width = tf.placeholder(tf.int32, None, name = 'beam_width')\n",
    "# decoded_beam = transducer_model.beam_decoder(padded_features, padded_lens, \n",
    "#                                              beam_width = beam_width, training = False)\n",
    "# decoded_beam = tf.identity(decoded_beam, name = 'beam_decoder')\n",
    "# decoded_beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = transducer_model.encoder(padded_features, training = False)\n",
    "encoded = tf.identity(encoded, name = 'encoded')\n",
    "encoded_placeholder = tf.placeholder(tf.float32, [config['dmodel']], name = 'encoded_placeholder')\n",
    "predicted_placeholder = tf.placeholder(tf.int32, None, name = 'predicted_placeholder')\n",
    "t = transducer_model.predict_net.get_initial_state().shape\n",
    "states_placeholder = tf.placeholder(tf.float32, [int(i) for i in t], name = 'states_placeholder')\n",
    "\n",
    "ytu, new_states = transducer_model.decoder_inference(\n",
    "    encoded=encoded_placeholder,\n",
    "    predicted=predicted_placeholder,\n",
    "    states=states_placeholder,\n",
    "    training = True\n",
    ")\n",
    "\n",
    "ytu = tf.identity(ytu, name = 'ytu')\n",
    "new_states = tf.identity(new_states, name = 'new_states')\n",
    "ytu, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = transducer_model.predict_net.get_initial_state()\n",
    "initial_states = tf.identity(initial_states, name = 'initial_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-nashville",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'asr-small-conformer-output/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-switzerland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-scott",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sess.run([non_blank_transcript, non_blank_stime, non_blank_etime], feed_dict = {X: padded, X_len: lens})\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "r[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BeamHypothesis = collections.namedtuple(\n",
    "    'BeamHypothesis', ('score', 'prediction', 'states')\n",
    ")\n",
    "\n",
    "\n",
    "def transducer(\n",
    "    enc,\n",
    "    total,\n",
    "    initial_states,\n",
    "    encoded_placeholder,\n",
    "    predicted_placeholder,\n",
    "    states_placeholder,\n",
    "    ytu,\n",
    "    new_states,\n",
    "    sess,\n",
    "    beam_width = 10,\n",
    "    norm_score = True,\n",
    "):\n",
    "    kept_hyps = [\n",
    "        BeamHypothesis(score = 0.0, prediction = [0], states = initial_states)\n",
    "    ]\n",
    "    B = kept_hyps\n",
    "    for i in range(total):\n",
    "        A = B\n",
    "        B = []\n",
    "        while True:\n",
    "            y_hat = max(A, key = lambda x: x.score)\n",
    "            A.remove(y_hat)\n",
    "            ytu_, new_states_ = sess.run(\n",
    "                [ytu, new_states],\n",
    "                feed_dict = {\n",
    "                    encoded_placeholder: enc[i],\n",
    "                    predicted_placeholder: y_hat.prediction[-1],\n",
    "                    states_placeholder: y_hat.states,\n",
    "                },\n",
    "            )\n",
    "            for k in range(ytu_.shape[0]):\n",
    "                beam_hyp = BeamHypothesis(\n",
    "                    score = (y_hat.score + float(ytu_[k])),\n",
    "                    prediction = y_hat.prediction,\n",
    "                    states = y_hat.states,\n",
    "                )\n",
    "                if k == 0:\n",
    "                    B.append(beam_hyp)\n",
    "                else:\n",
    "                    beam_hyp = BeamHypothesis(\n",
    "                        score = beam_hyp.score,\n",
    "                        prediction = (beam_hyp.prediction + [int(k)]),\n",
    "                        states = new_states_,\n",
    "                    )\n",
    "                    A.append(beam_hyp)\n",
    "            if len(B) > beam_width:\n",
    "                break\n",
    "    if norm_score:\n",
    "        kept_hyps = sorted(\n",
    "            B, key = lambda x: x.score / len(x.prediction), reverse = True\n",
    "        )[:beam_width]\n",
    "    else:\n",
    "        kept_hyps = sorted(B, key = lambda x: x.score, reverse = True)[\n",
    "            :beam_width\n",
    "        ]\n",
    "    return kept_hyps[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "r = sess.run(decoded, feed_dict = {X: padded, X_len: lens})\n",
    "for row in r:\n",
    "    print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-twist",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "encoded_, padded_lens_  = sess.run([encoded, padded_lens], feed_dict = {X: padded, X_len: lens})\n",
    "padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor\n",
    "s = sess.run(initial_states)\n",
    "\n",
    "for i in range(len(encoded_)):\n",
    "    r = transducer(\n",
    "        enc = encoded_[i],\n",
    "        total = padded_lens_[i],\n",
    "        initial_states = s,\n",
    "        encoded_placeholder = encoded_placeholder,\n",
    "        predicted_placeholder = predicted_placeholder,\n",
    "        states_placeholder = states_placeholder,\n",
    "        ytu = ytu,\n",
    "        new_states = new_states,\n",
    "        sess = sess,\n",
    "        beam_width = 1,\n",
    "    )\n",
    "\n",
    "    print(malaya_speech.subword.decode(subwords, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'output/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'gather' in n.op.lower()\n",
    "        or 'placeholder' in n.name\n",
    "        or 'encoded' in n.name\n",
    "        or 'decoder' in n.name\n",
    "        or 'ytu' in n.name\n",
    "        or 'new_states' in n.name\n",
    "        or 'padded_' in n.name\n",
    "        or 'initial_states' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "        and 'ReadVariableOp' not in n.name\n",
    "        and 'Gather' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_graph('output', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "                \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "    'encoded_placeholder',\n",
    "    'predicted_placeholder',\n",
    "    'states_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'greedy_decoder',\n",
    "    'encoded',\n",
    "    'ytu',\n",
    "    'new_states',\n",
    "    'padded_features',\n",
    "    'padded_lens',\n",
    "    'initial_states'\n",
    "]\n",
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-johns",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run(outputs['greedy_decoder'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                          inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in r:\n",
    "    print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_, padded_lens_, s  = test_sess.run([outputs['encoded'], outputs['padded_lens'], outputs['initial_states']], \n",
    "                                        feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                     inputs['X_len_placeholder']: lens})\n",
    "\n",
    "padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "r = transducer(\n",
    "    enc = encoded_[i],\n",
    "    total = padded_lens_[i],\n",
    "    initial_states = s,\n",
    "    encoded_placeholder = inputs['encoded_placeholder'],\n",
    "    predicted_placeholder = inputs['predicted_placeholder'],\n",
    "    states_placeholder = inputs['states_placeholder'],\n",
    "    ytu = outputs['ytu'],\n",
    "    new_states = outputs['new_states'],\n",
    "    sess = test_sess,\n",
    "    beam_width = 1,\n",
    ")\n",
    "\n",
    "malaya_speech.subword.decode(subwords, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-monkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "pb = 'output/frozen_model.pb'\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.FastGFile(pb, 'rb') as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                           input_nodes,\n",
    "                                           output_nodes, transforms)\n",
    "    \n",
    "with tf.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "    f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output/frozen_model.pb.quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}\n",
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run(outputs['greedy_decoder'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                          inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in r:\n",
    "    print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_, padded_lens_, s  = test_sess.run([outputs['encoded'], outputs['padded_lens'], outputs['initial_states']], \n",
    "                                        feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                     inputs['X_len_placeholder']: lens})\n",
    "\n",
    "padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "r = transducer(\n",
    "    enc = encoded_[i],\n",
    "    total = padded_lens_[i],\n",
    "    initial_states = s,\n",
    "    encoded_placeholder = inputs['encoded_placeholder'],\n",
    "    predicted_placeholder = inputs['predicted_placeholder'],\n",
    "    states_placeholder = inputs['states_placeholder'],\n",
    "    ytu = outputs['ytu'],\n",
    "    new_states = outputs['new_states'],\n",
    "    sess = test_sess,\n",
    "    beam_width = 1,\n",
    ")\n",
    "\n",
    "malaya_speech.subword.decode(subwords, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf output asr-small-conformer-output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
