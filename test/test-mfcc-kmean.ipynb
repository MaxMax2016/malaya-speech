{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twenty-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install npy-append-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "genetic-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solid-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "royal-passenger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:41: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:44: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "import tensorflow as tf\n",
    "from npy_append_array import NpyAppendArray\n",
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "from malaya_speech.train.model import hubert\n",
    "\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "physical-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.transducer_featurizer_config\n",
    "config['feature_type'] = 'mfcc'\n",
    "config['num_feature_bins'] = 30\n",
    "config['stride_ms'] = 20\n",
    "featurizer = malaya_speech.utils.tf_featurization.STTFeaturizer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appropriate-mauritius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90090, 56298)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = malaya_speech.load('../speech/example-speaker/husein-zolkepli.wav', sr = 16000)\n",
    "y1, sr = malaya_speech.load('../speech/example-speaker/shafiqah-idayu.wav', sr = 16000)\n",
    "len(y), len(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tested-template",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_1:0' shape=(?, 30) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.placeholder(tf.float32, [None])\n",
    "v = featurizer.vectorize(i)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "variable-individual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_3:0' shape=(?, 30) dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deltas = malaya_speech.utils.tf_featurization.deltas(v)\n",
    "deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "delayed-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice_4:0' shape=(?, 30) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddeltas = malaya_speech.utils.tf_featurization.deltas(deltas)\n",
    "ddeltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eleven-chart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(?, 90) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concated = tf.concat([v, deltas, ddeltas], axis = 1)\n",
    "concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comic-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "confidential-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm out.npy\n",
    "feat_f = NpyAppendArray('out.npy')\n",
    "leng_path = 'out.len'\n",
    "leng_f = open(leng_path, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "existing-graduate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 90)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 281\n",
    "v1 = sess.run(concated, feed_dict = {i: y})\n",
    "feat_f.append(v1)\n",
    "leng_f.write(f\"{len(v1)}\\n\")\n",
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "available-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 90)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 175\n",
    "v1 = sess.run(concated, feed_dict = {i: y1})\n",
    "feat_f.append(v1)\n",
    "leng_f.write(f\"{len(v1)}\\n\")\n",
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "treated-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "leng_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handled-slide",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(456, 90)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = np.load('out.npy', mmap_mode=\"r\")\n",
    "with open(leng_path, \"r\") as f:\n",
    "    lengs = [int(line.rstrip()) for line in f]\n",
    "    offsets = [0] + np.cumsum(lengs[:-1]).tolist()\n",
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "elementary-egyptian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 281], [281, 175])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets, lengs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "solid-bleeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init 1/20 with method: k-means++\n",
      "Inertia for init 1/20: 188.207199\n",
      "Init 2/20 with method: k-means++\n",
      "Inertia for init 2/20: 197.536896\n",
      "Init 3/20 with method: k-means++\n",
      "Inertia for init 3/20: 195.492920\n",
      "Init 4/20 with method: k-means++\n",
      "Inertia for init 4/20: 200.351501\n",
      "Init 5/20 with method: k-means++\n",
      "Inertia for init 5/20: 179.846130\n",
      "Init 6/20 with method: k-means++\n",
      "Inertia for init 6/20: 192.046005\n",
      "Init 7/20 with method: k-means++\n",
      "Inertia for init 7/20: 183.870071\n",
      "Init 8/20 with method: k-means++\n",
      "Inertia for init 8/20: 190.811417\n",
      "Init 9/20 with method: k-means++\n",
      "Inertia for init 9/20: 207.396988\n",
      "Init 10/20 with method: k-means++\n",
      "Inertia for init 10/20: 185.271866\n",
      "Init 11/20 with method: k-means++\n",
      "Inertia for init 11/20: 200.053375\n",
      "Init 12/20 with method: k-means++\n",
      "Inertia for init 12/20: 207.223862\n",
      "Init 13/20 with method: k-means++\n",
      "Inertia for init 13/20: 187.891174\n",
      "Init 14/20 with method: k-means++\n",
      "Inertia for init 14/20: 195.406738\n",
      "Init 15/20 with method: k-means++\n",
      "Inertia for init 15/20: 191.814484\n",
      "Init 16/20 with method: k-means++\n",
      "Inertia for init 16/20: 187.858414\n",
      "Init 17/20 with method: k-means++\n",
      "Inertia for init 17/20: 193.366699\n",
      "Init 18/20 with method: k-means++\n",
      "Inertia for init 18/20: 193.603821\n",
      "Init 19/20 with method: k-means++\n",
      "Inertia for init 19/20: 190.872253\n",
      "Init 20/20 with method: k-means++\n",
      "Inertia for init 20/20: 195.363251\n",
      "Minibatch iteration 1/100: mean batch inertia: 0.639115, ewa inertia: 0.639115 \n",
      "Minibatch iteration 2/100: mean batch inertia: 0.538611, ewa inertia: 0.538611 \n",
      "Minibatch iteration 3/100: mean batch inertia: 0.528902, ewa inertia: 0.528902 \n",
      "Minibatch iteration 4/100: mean batch inertia: 0.527991, ewa inertia: 0.527991 \n",
      "Minibatch iteration 5/100: mean batch inertia: 0.524807, ewa inertia: 0.524807 \n",
      "Minibatch iteration 6/100: mean batch inertia: 0.531614, ewa inertia: 0.531614 \n",
      "Minibatch iteration 7/100: mean batch inertia: 0.520536, ewa inertia: 0.520536 \n",
      "Minibatch iteration 8/100: mean batch inertia: 0.527608, ewa inertia: 0.527608 \n",
      "Minibatch iteration 9/100: mean batch inertia: 0.524158, ewa inertia: 0.524158 \n",
      "Minibatch iteration 10/100: mean batch inertia: 0.514084, ewa inertia: 0.514084 \n",
      "Minibatch iteration 11/100: mean batch inertia: 0.520008, ewa inertia: 0.520008 \n",
      "Minibatch iteration 12/100: mean batch inertia: 0.527244, ewa inertia: 0.527244 \n",
      "Minibatch iteration 13/100: mean batch inertia: 0.523140, ewa inertia: 0.523140 \n",
      "Minibatch iteration 14/100: mean batch inertia: 0.519368, ewa inertia: 0.519368 \n",
      "Minibatch iteration 15/100: mean batch inertia: 0.526020, ewa inertia: 0.526020 \n",
      "Minibatch iteration 16/100: mean batch inertia: 0.522034, ewa inertia: 0.522034 \n",
      "Minibatch iteration 17/100: mean batch inertia: 0.523408, ewa inertia: 0.523408 \n",
      "Minibatch iteration 18/100: mean batch inertia: 0.525264, ewa inertia: 0.525264 \n",
      "Minibatch iteration 19/100: mean batch inertia: 0.523893, ewa inertia: 0.523893 \n",
      "Minibatch iteration 20/100: mean batch inertia: 0.526638, ewa inertia: 0.526638 \n",
      "Minibatch iteration 21/100: mean batch inertia: 0.525056, ewa inertia: 0.525056 \n",
      "Minibatch iteration 22/100: mean batch inertia: 0.520798, ewa inertia: 0.520798 \n",
      "Minibatch iteration 23/100: mean batch inertia: 0.520696, ewa inertia: 0.520696 \n",
      "Minibatch iteration 24/100: mean batch inertia: 0.528842, ewa inertia: 0.528842 \n",
      "Minibatch iteration 25/100: mean batch inertia: 0.530783, ewa inertia: 0.530783 \n",
      "Minibatch iteration 26/100: mean batch inertia: 0.517783, ewa inertia: 0.517783 \n",
      "Minibatch iteration 27/100: mean batch inertia: 0.517660, ewa inertia: 0.517660 \n",
      "Minibatch iteration 28/100: mean batch inertia: 0.526546, ewa inertia: 0.526546 \n",
      "Minibatch iteration 29/100: mean batch inertia: 0.518630, ewa inertia: 0.518630 \n",
      "Minibatch iteration 30/100: mean batch inertia: 0.519028, ewa inertia: 0.519028 \n",
      "Minibatch iteration 31/100: mean batch inertia: 0.525127, ewa inertia: 0.525127 \n",
      "Minibatch iteration 32/100: mean batch inertia: 0.524028, ewa inertia: 0.524028 \n",
      "Minibatch iteration 33/100: mean batch inertia: 0.521738, ewa inertia: 0.521738 \n",
      "Minibatch iteration 34/100: mean batch inertia: 0.526015, ewa inertia: 0.526015 \n",
      "Minibatch iteration 35/100: mean batch inertia: 0.519491, ewa inertia: 0.519491 \n",
      "Minibatch iteration 36/100: mean batch inertia: 0.527915, ewa inertia: 0.527915 \n",
      "Minibatch iteration 37/100: mean batch inertia: 0.519117, ewa inertia: 0.519117 \n",
      "Minibatch iteration 38/100: mean batch inertia: 0.521698, ewa inertia: 0.521698 \n",
      "Minibatch iteration 39/100: mean batch inertia: 0.523174, ewa inertia: 0.523174 \n",
      "Minibatch iteration 40/100: mean batch inertia: 0.528567, ewa inertia: 0.528567 \n",
      "Minibatch iteration 41/100: mean batch inertia: 0.518995, ewa inertia: 0.518995 \n",
      "Minibatch iteration 42/100: mean batch inertia: 0.520995, ewa inertia: 0.520995 \n",
      "Minibatch iteration 43/100: mean batch inertia: 0.524048, ewa inertia: 0.524048 \n",
      "Minibatch iteration 44/100: mean batch inertia: 0.522219, ewa inertia: 0.522219 \n",
      "Minibatch iteration 45/100: mean batch inertia: 0.525467, ewa inertia: 0.525467 \n",
      "Minibatch iteration 46/100: mean batch inertia: 0.518454, ewa inertia: 0.518454 \n",
      "Minibatch iteration 47/100: mean batch inertia: 0.520221, ewa inertia: 0.520221 \n",
      "Minibatch iteration 48/100: mean batch inertia: 0.525472, ewa inertia: 0.525472 \n",
      "Minibatch iteration 49/100: mean batch inertia: 0.526671, ewa inertia: 0.526671 \n",
      "Minibatch iteration 50/100: mean batch inertia: 0.516158, ewa inertia: 0.516158 \n",
      "Minibatch iteration 51/100: mean batch inertia: 0.529723, ewa inertia: 0.529723 \n",
      "Minibatch iteration 52/100: mean batch inertia: 0.522791, ewa inertia: 0.522791 \n",
      "Minibatch iteration 53/100: mean batch inertia: 0.519129, ewa inertia: 0.519129 \n",
      "Minibatch iteration 54/100: mean batch inertia: 0.523710, ewa inertia: 0.523710 \n",
      "Minibatch iteration 55/100: mean batch inertia: 0.526590, ewa inertia: 0.526590 \n",
      "Minibatch iteration 56/100: mean batch inertia: 0.524360, ewa inertia: 0.524360 \n",
      "Minibatch iteration 57/100: mean batch inertia: 0.526166, ewa inertia: 0.526166 \n",
      "Minibatch iteration 58/100: mean batch inertia: 0.520436, ewa inertia: 0.520436 \n",
      "Minibatch iteration 59/100: mean batch inertia: 0.524899, ewa inertia: 0.524899 \n",
      "Minibatch iteration 60/100: mean batch inertia: 0.519977, ewa inertia: 0.519977 \n",
      "Minibatch iteration 61/100: mean batch inertia: 0.522763, ewa inertia: 0.522763 \n",
      "Minibatch iteration 62/100: mean batch inertia: 0.518328, ewa inertia: 0.518328 \n",
      "Minibatch iteration 63/100: mean batch inertia: 0.524049, ewa inertia: 0.524049 \n",
      "Minibatch iteration 64/100: mean batch inertia: 0.524461, ewa inertia: 0.524461 \n",
      "Minibatch iteration 65/100: mean batch inertia: 0.525974, ewa inertia: 0.525974 \n",
      "Minibatch iteration 66/100: mean batch inertia: 0.519224, ewa inertia: 0.519224 \n",
      "Minibatch iteration 67/100: mean batch inertia: 0.521730, ewa inertia: 0.521730 \n",
      "Minibatch iteration 68/100: mean batch inertia: 0.520495, ewa inertia: 0.520495 \n",
      "Minibatch iteration 69/100: mean batch inertia: 0.524379, ewa inertia: 0.524379 \n",
      "Minibatch iteration 70/100: mean batch inertia: 0.527046, ewa inertia: 0.527046 \n",
      "Minibatch iteration 71/100: mean batch inertia: 0.517496, ewa inertia: 0.517496 \n",
      "Minibatch iteration 72/100: mean batch inertia: 0.524470, ewa inertia: 0.524470 \n",
      "Minibatch iteration 73/100: mean batch inertia: 0.520647, ewa inertia: 0.520647 \n",
      "Minibatch iteration 74/100: mean batch inertia: 0.524143, ewa inertia: 0.524143 \n",
      "Minibatch iteration 75/100: mean batch inertia: 0.520683, ewa inertia: 0.520683 \n",
      "Minibatch iteration 76/100: mean batch inertia: 0.524018, ewa inertia: 0.524018 \n",
      "Minibatch iteration 77/100: mean batch inertia: 0.519570, ewa inertia: 0.519570 \n",
      "Minibatch iteration 78/100: mean batch inertia: 0.525801, ewa inertia: 0.525801 \n",
      "Minibatch iteration 79/100: mean batch inertia: 0.525227, ewa inertia: 0.525227 \n",
      "Minibatch iteration 80/100: mean batch inertia: 0.519427, ewa inertia: 0.519427 \n",
      "Minibatch iteration 81/100: mean batch inertia: 0.520012, ewa inertia: 0.520012 \n",
      "Minibatch iteration 82/100: mean batch inertia: 0.523497, ewa inertia: 0.523497 \n",
      "Minibatch iteration 83/100: mean batch inertia: 0.524657, ewa inertia: 0.524657 \n",
      "Minibatch iteration 84/100: mean batch inertia: 0.523507, ewa inertia: 0.523507 \n",
      "Minibatch iteration 85/100: mean batch inertia: 0.526257, ewa inertia: 0.526257 \n",
      "Minibatch iteration 86/100: mean batch inertia: 0.521582, ewa inertia: 0.521582 \n",
      "Minibatch iteration 87/100: mean batch inertia: 0.516091, ewa inertia: 0.516091 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch iteration 88/100: mean batch inertia: 0.522143, ewa inertia: 0.522143 \n",
      "Minibatch iteration 89/100: mean batch inertia: 0.518121, ewa inertia: 0.518121 \n",
      "Minibatch iteration 90/100: mean batch inertia: 0.524661, ewa inertia: 0.524661 \n",
      "Minibatch iteration 91/100: mean batch inertia: 0.523175, ewa inertia: 0.523175 \n",
      "Minibatch iteration 92/100: mean batch inertia: 0.519629, ewa inertia: 0.519629 \n",
      "Minibatch iteration 93/100: mean batch inertia: 0.514391, ewa inertia: 0.514391 \n",
      "Minibatch iteration 94/100: mean batch inertia: 0.518962, ewa inertia: 0.518962 \n",
      "Minibatch iteration 95/100: mean batch inertia: 0.519287, ewa inertia: 0.519287 \n",
      "Minibatch iteration 96/100: mean batch inertia: 0.522211, ewa inertia: 0.522211 \n",
      "Minibatch iteration 97/100: mean batch inertia: 0.518368, ewa inertia: 0.518368 \n",
      "Minibatch iteration 98/100: mean batch inertia: 0.525116, ewa inertia: 0.525116 \n",
      "Minibatch iteration 99/100: mean batch inertia: 0.527789, ewa inertia: 0.527789 \n",
      "Minibatch iteration 100/100: mean batch inertia: 0.523168, ewa inertia: 0.523168 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=10000, compute_labels=False, max_no_improvement=100,\n",
       "                n_clusters=100, n_init=20, reassignment_ratio=0.0, verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "km_model = hubert.kmeans.get_km_model()\n",
    "km_model.fit(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "developmental-earth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmean.km']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(km_model, 'kmean.km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "blond-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 90)\n",
      "(175, 90)\n"
     ]
    }
   ],
   "source": [
    "for offset, leng in zip(offsets, lengs):\n",
    "    print(feat[offset: offset + leng].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minor-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = hubert.kmeans.ApplyKmeans_TF('kmean.km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "genetic-religion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98, 98, 24, 24, 70,  2, 66, 66, 14, 66, 14, 14, 14,  0, 85, 47, 47,\n",
       "       67, 97, 97, 29, 31, 31, 31, 31, 67, 67, 17, 17, 43, 39, 39, 39, 37,\n",
       "       54, 27, 27, 27, 75, 75, 75, 60, 60, 60, 60,  7,  7,  7, 50, 50, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 33, 33, 33, 33, 26, 81, 81, 81, 46, 99,\n",
       "       32, 97, 22, 35, 24, 24, 72, 24, 24,  2, 14, 57, 57, 21, 21, 32, 32,\n",
       "       75, 75, 75, 75, 60, 60, 60, 62,  5, 35, 89,  9, 32, 75, 75, 60, 23,\n",
       "       23, 61, 61, 61, 61,  5,  5,  5,  5,  5, 71, 71,  2,  2, 45, 45,  2,\n",
       "       45, 66, 66, 66, 66, 14, 66, 14, 14, 66, 14, 66, 14, 14, 66, 14, 14,\n",
       "       14, 45, 66, 14, 14, 45, 66, 14, 66, 45, 14, 14, 66, 14, 14, 14, 41,\n",
       "       45, 14, 66, 66, 66, 66, 14, 45, 66, 66, 66, 66, 66, 66, 66, 66, 14,\n",
       "       14, 14, 14, 57, 19])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean(feat[offset: offset + leng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "interior-motor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/hubert/kmeans.py:18: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMin:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean_tf = kmean(concated)\n",
    "kmean_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "lucky-diving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98, 98, 24, 24, 70,  2, 66, 66, 14, 66, 14, 14, 14,  0, 85, 47, 47,\n",
       "       67, 97, 97, 29, 31, 31, 31, 31, 67, 67, 17, 17, 43, 39, 39, 39, 37,\n",
       "       54, 27, 27, 27, 75, 75, 75, 60, 60, 60, 60,  7,  7,  7, 50, 50, 50,\n",
       "       50, 50, 50, 50, 50, 50, 50, 33, 33, 33, 33, 26, 81, 81, 81, 46, 99,\n",
       "       32, 97, 22, 35, 24, 24, 72, 24, 24,  2, 14, 57, 57, 21, 21, 32, 32,\n",
       "       75, 75, 75, 75, 60, 60, 60, 62,  5, 35, 89,  9, 32, 75, 75, 60, 23,\n",
       "       23, 61, 61, 61, 61,  5,  5,  5,  5,  5, 71, 71,  2,  2, 45, 45,  2,\n",
       "       45, 66, 66, 66, 66, 14, 66, 14, 14, 66, 14, 66, 14, 14, 66, 14, 14,\n",
       "       14, 45, 66, 14, 14, 45, 66, 14, 66, 45, 14, 14, 66, 14, 14, 14, 41,\n",
       "       45, 14, 66, 66, 66, 66, 14, 45, 66, 66, 66, 66, 66, 66, 66, 66, 14,\n",
       "       14, 14, 14, 57, 19])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(kmean_tf, feed_dict = {i: y1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-writer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
