{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.train.model.vits import model\n",
    "from malaya_speech.train.model import vits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False}, 'train': {'log_interval': 200, 'eval_interval': 1000, 'seed': 1234, 'epochs': 20000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 64, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 0}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = vits.HParams(**malaya_speech.config.vits_base_config)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_channels = hparams.data.filter_length // 2 + 1\n",
    "segment_size = hparams.train.segment_size // hparams.data.hop_length\n",
    "spec_channels, segment_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "with open('../speech/imda/output.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "wavs = glob('../speech/imda/*.WAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = malaya_speech.utils.text.TTS_SYMBOLS\n",
    "\n",
    "batch = []\n",
    "for w in wavs:\n",
    "    t = data[os.path.split(w)[1]]\n",
    "    y, _ = malaya_speech.load(w)\n",
    "    batch.append((y, malaya_speech.utils.text.tts_encode(t, vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.filters import mel as librosa_mel_fn\n",
    "\n",
    "melbank = librosa_mel_fn(hparams.data.sampling_rate, hparams.data.filter_length, \n",
    "                          hparams.data.n_mel_channels,hparams.data.mel_fmin, hparams.data.mel_fmax)\n",
    "\n",
    "MEL = tf.convert_to_tensor(melbank)\n",
    "\n",
    "def dynamic_range_compression(x, C=1, clip_val=1e-5):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    C: compression factor\n",
    "    \"\"\"\n",
    "    return tf.log(tf.clip_by_value(x, clip_val, tf.reduce_max(x)) * C)\n",
    "\n",
    "\n",
    "def dynamic_range_decompression(x, C=1):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    C: compression factor used to compress\n",
    "    \"\"\"\n",
    "    return tf.exp(x) / C\n",
    "\n",
    "\n",
    "def spectral_normalize(magnitudes):\n",
    "    output = dynamic_range_compression(magnitudes)\n",
    "    return output\n",
    "\n",
    "\n",
    "def spectral_de_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_decompression(magnitudes)\n",
    "    return output\n",
    "\n",
    "def spectrogram_tf(audio_norm, filter_length, hop_length):\n",
    "    p = int((filter_length-hop_length)/2)\n",
    "    padded = tf.pad(audio_norm, [[p, p]], mode ='reflect')\n",
    "    spec = tf.abs(tf.signal.stft(\n",
    "        padded,\n",
    "        filter_length,\n",
    "        hop_length,\n",
    "        fft_length=None,\n",
    "        window_fn=tf.signal.hann_window,\n",
    "        pad_end=False,\n",
    "    ))\n",
    "    spec = tf.sqrt(spec ** 2 + 1e-6)\n",
    "    return spec\n",
    "\n",
    "def spec_to_mel(spec):\n",
    "    spec = tf.matmul(spec, tf.transpose(MEL))\n",
    "    spec = spectral_normalize(spec)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'TensorArrayStack_2/TensorArrayGatherV3:0' shape=(?, ?, 513) dtype=float32>,\n",
       " <tf.Tensor 'TensorArrayStack_3/TensorArrayGatherV3:0' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "features = tf.TensorArray(dtype = tf.float32, size = batch_size, dynamic_size = True, infer_shape = False)\n",
    "features_len = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "\n",
    "init_state = (0, features, features_len)\n",
    "\n",
    "def condition(i, features, features_len):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, features, features_len):\n",
    "    f = spectrogram_tf(X[i, :X_len[i]], hparams.data.filter_length, hparams.data.hop_length)\n",
    "    f_len = tf.shape(f)[0]\n",
    "    return i + 1, features.write(i, f), features_len.write(i, f_len)\n",
    "\n",
    "_, features, features_len = tf.while_loop(condition, body, init_state)\n",
    "features_len = features_len.stack()\n",
    "\n",
    "padded_features_mel = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_features = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_lens = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "maxlen = tf.reduce_max(features_len)\n",
    "\n",
    "init_state = (0, padded_features_mel, padded_features, padded_lens)\n",
    "\n",
    "def condition(i, padded_features_mel, padded_features, padded_lens):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, padded_features_mel, padded_features, padded_lens):\n",
    "    f = features.read(i)\n",
    "    f_mel = spec_to_mel(f)\n",
    "    len_f = tf.shape(f)[0]\n",
    "    f = tf.pad(f, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    f_mel = tf.pad(f_mel, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    return i + 1, padded_features_mel.write(i, f), padded_features.write(i, f), padded_lens.write(i, len_f)\n",
    "\n",
    "_, padded_features_mel, padded_features, padded_lens = tf.while_loop(condition, body, init_state)\n",
    "padded_features_mel = padded_features_mel.stack()\n",
    "padded_features = padded_features.stack()\n",
    "padded_lens = padded_lens.stack()\n",
    "padded_lens.set_shape((None,))\n",
    "padded_features_mel.set_shape((None, None, hparams.data.n_mel_channels))\n",
    "padded_features.set_shape((None, None, spec_channels))\n",
    "padded_features, padded_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = [b[0] for b in batch], [b[1] for b in batch]\n",
    "x, x_len = malaya_speech.utils.padding.sequence_1d(batch_x, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_len = malaya_speech.utils.padding.sequence_1d(batch_y, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/vits/model.py:301: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = vits.Model(len(vocab), spec_channels, segment_size, **hparams.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tf.placeholder(tf.int32, [None, None])\n",
    "T_lengths = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/vits/attentions.py:8: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n"
     ]
    }
   ],
   "source": [
    "y_hat, l_length, attn, ids_slice, x_mask, z_mask,\\\n",
    "      (z, z_p, m_p, logs_p, m_q, logs_q) = model(T, T_lengths, padded_features, padded_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n",
      "(?, ?, 2) (?, ?, 1)\n",
      "piecewise_rational_quadratic_transform_tf linear\n",
      "(?,) (?,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'generator/Tanh:0' shape=(?, ?, 1) dtype=float32>,\n",
       " <tf.Tensor 'transpose:0' shape=(?, ?, ?) dtype=float32>,\n",
       " <tf.Tensor 'ExpandDims:0' shape=(?, ?, 1) dtype=float32>,\n",
       " (<tf.Tensor 'residual_coupling_block/residual_coupling_layer/concat:0' shape=(?, ?, 192) dtype=float32>,\n",
       "  <tf.Tensor 'add:0' shape=(?, ?, 192) dtype=float32>,\n",
       "  <tf.Tensor 'MatMul:0' shape=(?, ?, 192) dtype=float32>,\n",
       "  <tf.Tensor 'MatMul_1:0' shape=(?, ?, 192) dtype=float32>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.infer(T, T_lengths)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'generator/Tanh:0' shape=(?, ?, 1) dtype=float32>,\n",
       " <tf.Tensor 'transpose:0' shape=(?, ?, ?) dtype=float32>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 8192, 1), (3, 34304, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_ = sess.run([y_hat, outputs[0], outputs[1]], feed_dict = {X: x,\n",
    "                                                        X_len: x_len,\n",
    "                                                        T: y,\n",
    "                                                        T_lengths: y_len})\n",
    "o_[0].shape, o_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
