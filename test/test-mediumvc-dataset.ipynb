{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import malaya_speech\n",
    "from datasets import Audio\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "import torch\n",
    "import json\n",
    "from librosa.util import normalize\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from malaya_speech.augmentation.waveform import random_sampling\n",
    "from malaya_speech.torch_model.hifivoice.env import AttrDict\n",
    "from malaya_speech.torch_model.hifivoice.meldataset import mel_spectrogram, mel_normalize\n",
    "from malaya_speech.torch_model.mediumvc.any2any import MagicModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.IterableDataset):\n",
    "    \n",
    "    sr = 22050\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Dataset).__init__()\n",
    "        \n",
    "        self.speakers = glob('random-embedding-*.pkl') + glob('/home/husein/ssd2/processed-youtube/*.pkl')\n",
    "        self.speakers = shuffle(self.speakers)\n",
    "        \n",
    "        self.audio = Audio(sampling_rate=self.sr)\n",
    "        config = 'hifigan-config.json'\n",
    "        with open(config) as fopen:\n",
    "            json_config = json.load(fopen)\n",
    "\n",
    "        self.config = AttrDict(json_config)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            batch = []\n",
    "            for i in range(len(self.speakers)):\n",
    "                with open(self.speakers[i], 'rb') as fopen:\n",
    "                    data = pickle.load(fopen)\n",
    "                    \n",
    "                data = random.sample(data, min(len(data), 4))\n",
    "                for d in data:\n",
    "                    spk_emb = d['classification_model'][0]\n",
    "                    y = dataset.audio.decode_example(dataset.audio.encode_example(d['wav_data']))\n",
    "                    y = y['array']\n",
    "                    y = random_sampling(y, 22050, length = 8000)\n",
    "                    batch.append((y, spk_emb))\n",
    "                    \n",
    "                if len(batch) >= 32:\n",
    "                    batch = shuffle(batch)\n",
    "                    for y, spk_emb in batch:\n",
    "                        spk_emb = normalize(spk_emb)\n",
    "                        audio = normalize(y) * 0.95\n",
    "                        audio = torch.FloatTensor(audio)\n",
    "                        audio = audio.unsqueeze(0)\n",
    "\n",
    "                        mel = mel_spectrogram(audio, \n",
    "                                              self.config[\"n_fft\"], \n",
    "                                              self.config[\"num_mels\"], \n",
    "                                              self.config[\"sampling_rate\"],\n",
    "                                              self.config[\"hop_size\"], \n",
    "                                              self.config[\"win_size\"], \n",
    "                                              self.config[\"fmin\"], \n",
    "                                              self.config[\"fmax\"],\n",
    "                                              center=False)\n",
    "\n",
    "                        mel = mel.squeeze(0).transpose(0, 1)\n",
    "                        mel = mel_normalize(mel)\n",
    "                        \n",
    "                        yield mel, torch.tensor(spk_emb)\n",
    "                        \n",
    "                    batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(batches):\n",
    "    ori_mels, spk_input_mels = zip(*batches)\n",
    "    \n",
    "    spk_input_mels = torch.stack(spk_input_mels)\n",
    "    ori_lens = [len(ori_mel) for ori_mel in ori_mels]\n",
    "\n",
    "    overlap_lens = ori_lens\n",
    "    ori_mels = pad_sequence(ori_mels, batch_first=True)\n",
    "    mel_masks = [torch.arange(ori_mels.size(1)) >= mel_len for mel_len in ori_lens]\n",
    "    mel_masks = torch.stack(mel_masks)  #\n",
    "\n",
    "    return spk_input_mels, ori_mels, mel_masks, overlap_lens\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size = 4, collate_fn = batch)\n",
    "loader = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = next(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Generator = MagicModel(d_model = 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_embs, input_mels, input_masks, overlap_lens = d\n",
    "fake_mels = Generator(spk_embs,input_mels,input_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for fake_mel, target_mel, overlap_len in zip(fake_mels.unbind(), input_mels.unbind(), overlap_lens):\n",
    "    temp_loss = criterion(fake_mel[:overlap_len, :], target_mel[:overlap_len, :])\n",
    "    losses.append(temp_loss)\n",
    "loss = sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5427, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Generator.state_dict(), 'mediumvc.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
