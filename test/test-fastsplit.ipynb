{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naughty-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "jewish-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinguished-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:38: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "from malaya_speech.train.model import fastsplit, fastspeech\n",
    "import malaya_speech.augmentation.waveform as augmentation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cross-amplifier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "wavs = glob('../speech/example-speaker/*.wav')\n",
    "len(wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norwegian-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sr = 22050\n",
    "speakers_size = 4\n",
    "\n",
    "# noise = malaya_speech.load('noise.wav', sr = sr)[0]\n",
    "\n",
    "def read_wav(f):\n",
    "    return malaya_speech.load(f, sr = sr)\n",
    "\n",
    "def random_sampling(s, length):\n",
    "    return augmentation.random_sampling(s, sr = sr, length = length)\n",
    "\n",
    "def add_padding(sample, pad, pad_value):\n",
    "    if pad[0]:\n",
    "        if pad[0] > len(pad_value):\n",
    "            left_pad = np.tile(pad_value, int(np.ceil(pad[0] / len(pad_value))))\n",
    "        else:\n",
    "            left_pad = pad_value[np.random.randint(0, len(pad_value) - pad[0] + 1) :]\n",
    "        left_pad = left_pad[ :pad[0]]\n",
    "    else:\n",
    "        left_pad = 0\n",
    "    \n",
    "    if pad[1]:\n",
    "        if pad[1] > len(pad_value):\n",
    "            right_pad = np.tile(pad_value, int(np.ceil(pad[1] / len(pad_value))))\n",
    "        else:\n",
    "            right_pad = pad_value[np.random.randint(0, len(pad_value) - pad[1] + 1) :]\n",
    "        right_pad = right_pad[ :pad[1]]\n",
    "    else:\n",
    "        right_pad = 0\n",
    "        \n",
    "    return np.pad(sample, pad, constant_values = (left_pad, right_pad))   \n",
    "\n",
    "# def combine_speakers(files, n = 5, limit = 4):\n",
    "#     w_samples = random.sample(files, n)\n",
    "#     w_samples = [\n",
    "#         random_sampling(\n",
    "#             read_wav(f)[0],\n",
    "#             length = random.randint(1500, max(10000 // n, 6000)),\n",
    "#         )\n",
    "#         for f in w_samples\n",
    "#     ]\n",
    "#     y = [w_samples[0]]\n",
    "#     left = w_samples[0].copy()\n",
    "\n",
    "#     combined = None\n",
    "\n",
    "#     for i in range(1, n):\n",
    "#         right = w_samples[i].copy()\n",
    "#         overlap = random.uniform(0.1, 0.8)\n",
    "#         print(i, overlap)\n",
    "#         len_overlap = int(overlap * len(right))\n",
    "#         minus = len(left) - len_overlap\n",
    "#         if minus < 0:\n",
    "#             minus = 0\n",
    "#         padded_right = np.pad(right, (minus, 0))\n",
    "#         padded_right_noise = add_padding(right, (minus, 0), noise)\n",
    "#         left = np.pad(left, (0, len(padded_right) - len(left)))\n",
    "#         left = left + padded_right\n",
    "\n",
    "#         if i >= (limit - 1):\n",
    "#             if combined is None:\n",
    "#                 combined = padded_right_noise\n",
    "#             else:\n",
    "#                 combined = np.pad(\n",
    "#                     combined, (0, len(padded_right) - len(combined))\n",
    "#                 )\n",
    "#                 combined += padded_right\n",
    "\n",
    "#         else:\n",
    "#             print(len(padded_right_noise))\n",
    "#             y.append(padded_right_noise)\n",
    "\n",
    "#     if combined is not None:\n",
    "#         print(len(combined))\n",
    "#         y.append(combined)\n",
    "\n",
    "#     for i in range(len(y)):\n",
    "#         if len(y[i]) != len(left):\n",
    "#             y[i] = add_padding(y[i], (0, len(left) - len(y[i])), noise)\n",
    "#             y[i] = y[i] / np.max(np.abs(y[i]))\n",
    "\n",
    "#     left = left / np.max(np.abs(left))\n",
    "#     return left, y\n",
    "\n",
    "def combine_speakers(files, n = 5, limit = 4):\n",
    "    w_samples = random.sample(files, n)\n",
    "    w_samples = [\n",
    "        random_sampling(\n",
    "            read_wav(f)[0],\n",
    "            length = min(\n",
    "                random.randint(10000 // n, 20000 // n), 10000\n",
    "            ),\n",
    "        )\n",
    "        for f in w_samples\n",
    "    ]\n",
    "    y = [w_samples[0]]\n",
    "    left = w_samples[0].copy() * random.uniform(0.5, 1.0)\n",
    "    start, end = [], []\n",
    "    start.append(0)\n",
    "    end.append(len(left))\n",
    "\n",
    "    combined = None\n",
    "\n",
    "    for i in range(1, n):\n",
    "        right = w_samples[i].copy() * random.uniform(0.5, 1.0)\n",
    "        overlap = random.uniform(0.1, 0.9)\n",
    "        print(i, overlap, len(right))\n",
    "        len_overlap = int(overlap * len(right))\n",
    "        minus = len(left) - len_overlap\n",
    "        if minus < 0:\n",
    "            minus = 0\n",
    "        \n",
    "        padded_right = np.pad(right, (minus, 0))\n",
    "        start.append(minus)\n",
    "        end.append(len(padded_right))\n",
    "        left = np.pad(left, (0, len(padded_right) - len(left)))\n",
    "\n",
    "        left = left + padded_right\n",
    "\n",
    "        if i >= (limit - 1):\n",
    "            if combined is None:\n",
    "                combined = padded_right\n",
    "            else:\n",
    "                combined = np.pad(\n",
    "                    combined, (0, len(padded_right) - len(combined))\n",
    "                )\n",
    "                combined += padded_right\n",
    "\n",
    "        else:\n",
    "            y.append(padded_right)\n",
    "\n",
    "    if combined is not None:\n",
    "        y.append(combined)\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if len(y[i]) != len(left):\n",
    "            y[i] = np.pad(y[i], (0, len(left) - len(y[i])), constant_values = 0.0005)\n",
    "            y[i] = y[i] / np.max(np.abs(y[i]))\n",
    "\n",
    "    left = left / np.max(np.abs(left))\n",
    "    \n",
    "    while len(y) < limit:\n",
    "        y.append(np.zeros((len(left))))\n",
    "        start.append(0)\n",
    "        end.append(0)\n",
    "        \n",
    "    return left, y\n",
    "\n",
    "# y, _ = malaya_speech.load('../speech/example-speaker/husein-zolkepli.wav')\n",
    "# y = np.expand_dims(y, 0).astype(np.float32)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "average-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.611060484845585 59466\n",
      "2 0.28415860403694804 71170\n",
      "3 0.5442890554839764 59290\n",
      "4 0.7123869307136937 63272\n",
      "5 0.5820755067972073 39842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.191428571428572, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, y = combine_speakers(wavs, 6)\n",
    "len(left) / sr, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chicken-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_mel = malaya_speech.featurization.universal_mel(left)\n",
    "y_mel = [malaya_speech.featurization.universal_mel(i) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "academic-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.fastspeech_config\n",
    "dim = 192\n",
    "config['encoder_hidden_size'] = dim * speakers_size\n",
    "config['decoder_hidden_size'] = dim * speakers_size\n",
    "config = fastspeech.Config(vocab_size = 1, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "heavy-elements",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/fastspeech/layer.py:11: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = fastsplit.Model(config, O = dim, C = speakers_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complex-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, [None, None, 80])\n",
    "Y = tf.placeholder(tf.float32, [None, speakers_size, None, 80])\n",
    "lengths = tf.placeholder(tf.int32, [None])\n",
    "outputs = model(X, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dedicated-lightning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/fastsplit/loss.py:32: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/fastsplit/loss.py:36: The name tf.div_no_nan is deprecated. Please use tf.math.divide_no_nan instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss = fastsplit.calculate_loss(Y, outputs, lengths, C = speakers_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "legislative-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indian-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "affiliated-making",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.61 s, sys: 136 ms, total: 2.74 s\n",
      "Wall time: 705 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "o = sess.run(outputs, feed_dict = {X: [left_mel], lengths: [len(left_mel)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seeing-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0078783"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(loss, feed_dict = {X: [left_mel], Y: [y_mel], lengths: [len(left_mel)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "demanding-attention",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "piano-impossible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test/model.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(sess, 'test/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "amber-drive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 432936\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    77B Mar  7 00:12 checkpoint\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff   181M Mar  7 00:12 model.ckpt.data-00000-of-00001\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff   5.6K Mar  7 00:12 model.ckpt.index\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    25M Mar  7 00:12 model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "innocent-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-facial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
