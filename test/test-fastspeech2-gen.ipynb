{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/e2e-tts-dataset.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install tensorflow==1.15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.train.model import vits\n",
    "from malaya_speech.train.model.vits import gen\n",
    "from malaya_speech.train.model import fastspeech2\n",
    "from malaya_speech.train.model.fastspeech2 import model_stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0.1, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [8, 8, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'n_layers_q': 3, 'use_spectral_norm': False}, 'train': {'log_interval': 200, 'eval_interval': 1000, 'seed': 1234, 'epochs': 20000, 'learning_rate': 0.0002, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 64, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 8192, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 22050, 'filter_length': 1024, 'hop_length': 256, 'win_length': 1024, 'n_mel_channels': 80, 'mel_fmin': 0.0, 'mel_fmax': None, 'add_blank': True, 'n_speakers': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = vits.HParams(**malaya_speech.config.vits_base_config)\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_channels = hparams.data.filter_length // 2 + 1\n",
    "segment_size = hparams.train.segment_size // hparams.data.hop_length\n",
    "spec_channels, segment_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "with open('../speech/imda/output.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "    \n",
    "wavs = glob('../speech/imda/*.WAV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('e2e-tts-dataset.pkl', 'rb') as fopen:\n",
    "    e2e_dataset = pickle.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.50058964e-05, 1.55870686e-04, 1.46839827e-04, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_dataset[0]['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = malaya_speech.utils.text.TTS_SYMBOLS\n",
    "\n",
    "batch = []\n",
    "for w in wavs:\n",
    "    t = data[os.path.split(w)[1]]\n",
    "    y, _ = malaya_speech.load(w)\n",
    "    batch.append((y, malaya_speech.utils.text.tts_encode(t, vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from librosa.filters import mel as librosa_mel_fn\n",
    "\n",
    "melbank = librosa_mel_fn(hparams.data.sampling_rate, hparams.data.filter_length, \n",
    "                          hparams.data.n_mel_channels,hparams.data.mel_fmin, hparams.data.mel_fmax)\n",
    "\n",
    "MEL = tf.convert_to_tensor(melbank)\n",
    "\n",
    "def dynamic_range_compression(x, C=1, clip_val=1e-5):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    C: compression factor\n",
    "    \"\"\"\n",
    "    return tf.math.log(tf.clip_by_value(x, clip_val, tf.reduce_max(x)) * C)\n",
    "\n",
    "\n",
    "def dynamic_range_decompression(x, C=1):\n",
    "    \"\"\"\n",
    "    PARAMS\n",
    "    ------\n",
    "    C: compression factor used to compress\n",
    "    \"\"\"\n",
    "    return tf.exp(x) / C\n",
    "\n",
    "\n",
    "def spectral_normalize(magnitudes):\n",
    "    output = dynamic_range_compression(magnitudes)\n",
    "    return output\n",
    "\n",
    "\n",
    "def spectral_de_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_decompression(magnitudes)\n",
    "    return output\n",
    "\n",
    "def spectrogram_tf(audio_norm, filter_length, hop_length):\n",
    "    p = int((filter_length-hop_length)/2)\n",
    "    padded = tf.pad(audio_norm, [[p, p]], mode ='reflect')\n",
    "    spec = tf.abs(tf.signal.stft(\n",
    "        padded,\n",
    "        filter_length,\n",
    "        hop_length,\n",
    "        fft_length=None,\n",
    "        window_fn=tf.signal.hann_window,\n",
    "        pad_end=False,\n",
    "    ))\n",
    "    spec = tf.sqrt(spec ** 2 + 1e-6)\n",
    "    return spec\n",
    "\n",
    "def spec_to_mel(spec):\n",
    "    spec = tf.matmul(spec, tf.transpose(MEL))\n",
    "    spec = spectral_normalize(spec)\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'TensorArrayStack_2/TensorArrayGatherV3:0' shape=(?, ?, 513) dtype=float32>,\n",
       " <tf.Tensor 'TensorArrayStack_3/TensorArrayGatherV3:0' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "features = tf.TensorArray(dtype = tf.float32, size = batch_size, dynamic_size = True, infer_shape = False)\n",
    "features_len = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "\n",
    "init_state = (0, features, features_len)\n",
    "\n",
    "def condition(i, features, features_len):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, features, features_len):\n",
    "    f = spectrogram_tf(X[i, :X_len[i]], hparams.data.filter_length, hparams.data.hop_length)\n",
    "    f_len = tf.shape(f)[0]\n",
    "    return i + 1, features.write(i, f), features_len.write(i, f_len)\n",
    "\n",
    "_, features, features_len = tf.while_loop(condition, body, init_state)\n",
    "features_len = features_len.stack()\n",
    "\n",
    "padded_features_mel = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_features = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_lens = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "maxlen = tf.reduce_max(features_len)\n",
    "\n",
    "init_state = (0, padded_features_mel, padded_features, padded_lens)\n",
    "\n",
    "def condition(i, padded_features_mel, padded_features, padded_lens):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, padded_features_mel, padded_features, padded_lens):\n",
    "    f = features.read(i)\n",
    "    f_mel = spec_to_mel(f)\n",
    "    len_f = tf.shape(f)[0]\n",
    "    f = tf.pad(f, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    f_mel = tf.pad(f_mel, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    return i + 1, padded_features_mel.write(i, f), padded_features.write(i, f), padded_lens.write(i, len_f)\n",
    "\n",
    "_, padded_features_mel, padded_features, padded_lens = tf.while_loop(condition, body, init_state)\n",
    "padded_features_mel = padded_features_mel.stack()\n",
    "padded_features = padded_features.stack()\n",
    "padded_lens = padded_lens.stack()\n",
    "padded_lens.set_shape((None,))\n",
    "padded_features_mel.set_shape((None, None, hparams.data.n_mel_channels))\n",
    "padded_features.set_shape((None, None, spec_channels))\n",
    "padded_features, padded_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = [b[0] for b in batch], [b[1] for b in batch]\n",
    "x, x_len = malaya_speech.utils.padding.sequence_1d(batch_x, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, y_len = malaya_speech.utils.padding.sequence_1d(batch_y, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/vits/model.py:301: The name tf.keras.initializers.RandomNormal is deprecated. Please use tf.compat.v1.keras.initializers.RandomNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = gen.Model(len(vocab), spec_channels, segment_size, **hparams.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
    "T_lengths = tf.compat.v1.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_fs = malaya_speech.config.fastspeech2_config\n",
    "config_fs = fastspeech2.Config(\n",
    "    vocab_size=len(vocab), **config_fs\n",
    ")\n",
    "config_fs.enable_postnet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/fastspeech/layer.py:11: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model_fs = model_stochastic.Model(config_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = tf.placeholder(tf.int32, [None, None])\n",
    "energies = tf.placeholder(tf.float32, [None, None])\n",
    "energies_lengths = tf.placeholder(tf.int32, [None])\n",
    "f0s = tf.placeholder(tf.float32, [None, None])\n",
    "f0s_lengths = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/vits/transforms.py:84: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "mel_before, _, duration_outputs, f0_outputs, energy_outputs = model_fs(\n",
    "    T, lens, f0s, energies, training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from malaya_speech.train import loss\n",
    "\n",
    "loss_f = tf.losses.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = tf.cast(tf.reduce_max(energies_lengths), tf.int32)\n",
    "mask = tf.sequence_mask(\n",
    "    lengths = energies_lengths, maxlen = max_length, dtype = tf.float32\n",
    ")\n",
    "energies_mel = partial(\n",
    "    loss_f,\n",
    "    weights = mask\n",
    ")\n",
    "energies_loss = loss.calculate_2d_loss(energies, energy_outputs, energies_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_loss = duration_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = tf.cast(tf.reduce_max(f0s_lengths), tf.int32)\n",
    "mask = tf.sequence_mask(\n",
    "    lengths = f0s_lengths, maxlen = max_length, dtype = tf.float32\n",
    ")\n",
    "energies_mel = partial(\n",
    "    loss_f,\n",
    "    weights = mask\n",
    ")\n",
    "f0s_loss = loss.calculate_2d_loss(f0s, f0_outputs, energies_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'mean_squared_error/value:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'model_1/Sum_1:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'mean_squared_error_1/value:0' shape=() dtype=float32>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energies_loss, duration_loss, f0s_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'model_1/mel_before/BiasAdd:0' shape=(?, ?, 80) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'model/generator/Tanh:0' shape=(?, ?, 1) dtype=float32>,\n",
       " <tf.Tensor 'model/Cast_1:0' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat, ids_slice = model(mel_before, padded_lens)\n",
    "y_hat, ids_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'generator/Tanh:0' shape=(?, ?, 1) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.infer(mel_before)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mel', 'text_ids', 'len_mel', 'len_text_ids', 'stop_token_target', 'f0', 'len_f0', 'energy', 'len_energy', 'f', 'alignment', 'audio', 'len_audio'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00,  0.00000000e+00,  2.21143413e+00,  9.05393302e-01,\n",
       "        9.35836256e-01,  2.09698558e+00,  2.21143413e+00,  1.79257405e+00,\n",
       "        1.17414594e+00,  1.01634789e+00,  7.93029308e-01,  5.85050583e-01,\n",
       "        1.24123044e-01, -1.22731633e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.22875735e-01, -5.07767618e-01,  2.21143413e+00,  8.78810883e-01,\n",
       "       -2.46541604e-01,  9.76493359e-01, -4.39082146e-01, -1.53875756e+00,\n",
       "       -1.83528638e+00,  1.70695603e+00,  2.21143413e+00,  2.21143413e+00,\n",
       "        2.00131238e-01,  8.64442587e-02, -4.05265614e-02, -6.66145980e-02,\n",
       "        1.74258664e-01, -3.21222767e-02,  1.52887389e-01,  1.56236038e-01,\n",
       "        5.45233309e-01,  4.67070639e-01, -3.88945609e-01,  2.21143413e+00,\n",
       "       -1.30476981e-01, -3.90558451e-01, -1.52522489e-01, -2.29833692e-01,\n",
       "       -5.26054144e-01, -4.31837589e-01, -8.68138019e-03,  1.61830533e+00,\n",
       "        8.42465878e-01, -5.97679496e-01, -1.44224799e+00,  2.21143413e+00,\n",
       "        2.21143413e+00,  2.21143413e+00,  2.21143413e+00, -3.91260087e-01,\n",
       "        2.16596290e-01,  4.20851588e-01,  4.69096392e-01,  1.10434997e+00,\n",
       "        2.21143413e+00,  4.16898668e-01, -5.95399559e-01,  1.81219840e+00,\n",
       "       -4.11853313e-01, -9.08841640e-02, -8.54765892e-01,  6.58995807e-01,\n",
       "       -5.81482828e-01, -5.08403957e-01, -2.21340984e-01,  3.51905316e-01,\n",
       "        1.25962436e+00, -5.59225738e-01,  2.21143413e+00, -6.25893474e-01,\n",
       "       -7.12152660e-01, -7.58028507e-01, -5.27826786e-01, -6.66424274e-01,\n",
       "       -1.00374699e+00,  8.16856995e-02, -6.48279727e-01, -3.61286432e-01,\n",
       "       -2.55696386e-01,  2.30321541e-01,  3.04457873e-01, -2.31993198e-01,\n",
       "        1.92460835e-01, -9.60910857e-01, -6.25229061e-01, -1.25934049e-01,\n",
       "        3.85205746e-02,  5.47506034e-01,  4.95559633e-01,  4.79916185e-01,\n",
       "        3.41515839e-01,  1.02015018e-01, -3.44203353e-01, -7.02221930e-01,\n",
       "       -7.58690774e-01, -3.62927765e-01, -1.07321091e-01,  9.49999034e-01,\n",
       "       -7.65341222e-02, -7.58013546e-01,  2.21143413e+00,  2.06293955e-01,\n",
       "       -9.62663352e-01, -1.20855904e+00, -1.17017806e+00, -8.08284938e-01,\n",
       "       -4.56920594e-01, -2.66786635e-01,  2.21143413e+00,  4.56340373e-01,\n",
       "       -9.04323626e-03, -5.45548558e-01, -7.08393157e-01, -8.57438087e-01,\n",
       "       -8.29361796e-01, -9.60462093e-01,  1.02873015e+00, -6.48777373e-03,\n",
       "        7.98144042e-01,  2.83304721e-01, -4.83549625e-01,  3.87430310e-01,\n",
       "       -2.01501638e-01, -2.72522271e-01,  1.42233580e-01,  7.51930177e-01,\n",
       "        1.54072309e+00,  1.72369647e+00,  3.42854947e-01, -4.20209408e-01,\n",
       "        1.35288978e+00, -4.25093561e-01,  3.00443769e-01, -3.70430350e-02,\n",
       "        5.51686808e-02,  8.28652859e-01,  1.34311542e-01, -7.84503341e-01,\n",
       "       -8.57827127e-01, -5.68804562e-01, -2.07887334e-03,  5.73084474e-01,\n",
       "        2.21143413e+00,  2.21143413e+00,  8.72971475e-01,  1.61434984e+00,\n",
       "        9.33593988e-01,  2.92899162e-01, -1.02757692e+00, -1.79746687e+00,\n",
       "       -1.85747361e+00, -1.70136499e+00,  1.00395358e+00,  0.00000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_dataset[0]['f0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {\n",
    "    X: [e2e_dataset[0]['audio']],\n",
    "    X_len: e2e_dataset[0]['len_audio'],\n",
    "    T: [e2e_dataset[0]['text_ids']],\n",
    "    T_lengths: e2e_dataset[0]['len_text_ids'],\n",
    "    lens: [e2e_dataset[0]['alignment']],\n",
    "    f0s: [e2e_dataset[0]['f0']],\n",
    "    energies: [e2e_dataset[0]['energy']],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 8192, 1), (1, 198656, 1))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_ = sess.run([y_hat, outputs, mel_before, duration_outputs, f0_outputs, energy_outputs], feed_dict = feed_dict)\n",
    "o_[0].shape, o_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1322074"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 160), (1, 160))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_[-2].shape, o_[-1].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
