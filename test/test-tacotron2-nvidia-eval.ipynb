{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:38: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:6: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/openseq2seq/attention.py:4: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import malaya_speech.train\n",
    "from malaya_speech.train.model import tacotron2_nvidia as tacotron2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tf.placeholder(tf.int32, [1, None])\n",
    "input_lengths = tf.placeholder(tf.int32, [1])\n",
    "mel_outputs = tf.placeholder(tf.float32, [1, None, 80])\n",
    "mel_lengths = tf.placeholder(tf.int32, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/openseq2seq/abstract.py:147: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:60: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:340: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:358: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:129: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/openseq2seq/rnn.py:111: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:205: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/decoder.py:476: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/decoder.py:392: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tacotron2.Model([input_ids, input_lengths], [mel_outputs, mel_lengths], 20, training = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': [array([[[-1.39928563e-03,  2.92870239e-03,  1.34721841e-03, ...,\n",
       "            1.18097793e-02, -1.17986873e-02, -1.60298427e-03],\n",
       "          [-1.38117303e-03,  3.12317954e-03,  1.25317695e-03, ...,\n",
       "            1.17469765e-02, -1.18051879e-02, -1.58673315e-03],\n",
       "          [-1.31968432e-03,  3.38663673e-03,  1.22286414e-03, ...,\n",
       "            1.17728785e-02, -1.18405409e-02, -1.51197310e-03],\n",
       "          ...,\n",
       "          [-9.10762465e-05,  4.46293829e-03,  2.40484299e-03, ...,\n",
       "            1.07262926e-02, -1.67298224e-02,  3.69156303e-04],\n",
       "          [-3.64296138e-05,  4.35378961e-03,  2.46658782e-03, ...,\n",
       "            1.07684005e-02, -1.66802034e-02,  3.33685573e-04],\n",
       "          [-1.71444844e-06,  4.27839160e-03,  2.52104504e-03, ...,\n",
       "            1.07483249e-02, -1.66058317e-02,  3.28557886e-04]]],\n",
       "        dtype=float32),\n",
       "  array([[[-9.0684573e-04,  4.3984815e-03,  4.7664009e-03, ...,\n",
       "            8.1904763e-03, -8.5839350e-03,  8.7585812e-04],\n",
       "          [-9.8860555e-04,  7.2225593e-03,  4.2628851e-03, ...,\n",
       "            8.3997883e-03, -9.8983189e-03, -2.5471721e-03],\n",
       "          [-1.0268692e-03,  5.8387434e-03,  4.8966859e-03, ...,\n",
       "            9.4499132e-03, -9.8044146e-03, -6.3082986e-03],\n",
       "          ...,\n",
       "          [-1.9596193e-03,  6.3539930e-03,  1.7513568e-04, ...,\n",
       "            5.0127096e-03, -1.4993654e-02, -1.0551576e-02],\n",
       "          [-1.1989516e-03,  5.6273383e-03,  3.4846431e-03, ...,\n",
       "            7.9262890e-03, -1.7682947e-02, -8.2397684e-03],\n",
       "          [ 9.0578724e-06,  4.3553906e-03,  2.6392187e-03, ...,\n",
       "            6.6854674e-03, -1.8521443e-02, -4.9915351e-03]]], dtype=float32),\n",
       "  array([[[0.10977416, 0.10963502, 0.10949758, 0.10936205, 0.10922864,\n",
       "           0.10909738, 0.10896847, 0.10884198, 0.10871809, 0.10859679,\n",
       "           0.10847823, 0.10836235, 0.10824927, 0.10813913, 0.10803167,\n",
       "           0.10792693, 0.10782474, 0.10772461, 0.10762688, 0.10753179,\n",
       "           0.10743863, 0.10734695, 0.1072567 , 0.10716819, 0.10708179,\n",
       "           0.10699718, 0.10691386, 0.10683163, 0.10675041, 0.10666923,\n",
       "           0.10658857, 0.10650893, 0.10642922, 0.10635111, 0.10627363,\n",
       "           0.10619703, 0.10612014, 0.10604344, 0.10596692, 0.1058896 ,\n",
       "           0.10581157, 0.10573254, 0.10565306, 0.10557353, 0.10549268,\n",
       "           0.10541189, 0.10532935, 0.10524657, 0.10516345, 0.10507792,\n",
       "           0.10499178, 0.10490546, 0.10481682, 0.10472845, 0.10463888,\n",
       "           0.10454839, 0.10445466, 0.10436023, 0.10426562, 0.10417287,\n",
       "           0.10407896, 0.10398427, 0.10388775, 0.10379081, 0.10369271,\n",
       "           0.10359358, 0.10349344, 0.10339348, 0.1032916 , 0.10318954,\n",
       "           0.10308808, 0.10298555, 0.10288314, 0.1027775 , 0.10267055,\n",
       "           0.10256229, 0.10245544, 0.10234894, 0.10224303, 0.10213456,\n",
       "           0.10202597, 0.10191745, 0.10181028, 0.10170077, 0.10159237,\n",
       "           0.10148566, 0.10138001, 0.10127267, 0.10116629, 0.10105951],\n",
       "          [0.11020536, 0.11041108, 0.11061841, 0.11082729, 0.11103775,\n",
       "           0.11124964, 0.11146299, 0.11167767, 0.11189373, 0.11211101,\n",
       "           0.11232954, 0.11254925, 0.11277006, 0.11299206, 0.11321504,\n",
       "           0.11343905, 0.11366379, 0.11388905, 0.11411514, 0.11434209,\n",
       "           0.11456954, 0.11479706, 0.1150247 , 0.11525284, 0.11548162,\n",
       "           0.11571102, 0.11594077, 0.11617047, 0.11640059, 0.11663041,\n",
       "           0.11686011, 0.11709035, 0.11732034, 0.11755124, 0.11778267,\n",
       "           0.11801429, 0.11824543, 0.11847721, 0.11870912, 0.11894055,\n",
       "           0.11917222, 0.11940341, 0.11963493, 0.11986727, 0.1200993 ,\n",
       "           0.12033149, 0.12056272, 0.12079294, 0.12102406, 0.12125418,\n",
       "           0.12148391, 0.12171318, 0.12194131, 0.12216982, 0.12239785,\n",
       "           0.12262485, 0.12285028, 0.1230759 , 0.12329971, 0.12352426,\n",
       "           0.12374806, 0.12397211, 0.12419503, 0.1244179 , 0.12464055,\n",
       "           0.12486193, 0.12508124, 0.12529966, 0.12551567, 0.12572962,\n",
       "           0.12594396, 0.12615712, 0.12636906, 0.12657696, 0.1267845 ,\n",
       "           0.12699127, 0.12719809, 0.12740523, 0.12761103, 0.12781574,\n",
       "           0.12801822, 0.12821984, 0.12842208, 0.12862086, 0.12881814,\n",
       "           0.12901516, 0.12920934, 0.12940349, 0.12959605, 0.1297864 ],\n",
       "          [0.11103582, 0.11052147, 0.11001378, 0.1095131 , 0.10901987,\n",
       "           0.10853434, 0.10805694, 0.1075879 , 0.10712758, 0.10667626,\n",
       "           0.10623423, 0.10580165, 0.10537878, 0.10496588, 0.10456327,\n",
       "           0.10417115, 0.10378922, 0.10341787, 0.10305727, 0.10270747,\n",
       "           0.10236842, 0.10204019, 0.1017228 , 0.10141632, 0.10112046,\n",
       "           0.1008357 , 0.10056222, 0.10029929, 0.10004757, 0.09980655,\n",
       "           0.09957608, 0.09935661, 0.09914777, 0.09894925, 0.09876119,\n",
       "           0.09858333, 0.09841521, 0.09825751, 0.09810957, 0.09797075,\n",
       "           0.09784237, 0.09772447, 0.09761612, 0.09751717, 0.09742685,\n",
       "           0.0973456 , 0.09727366, 0.09720974, 0.09715507, 0.0971093 ,\n",
       "           0.09707163, 0.0970417 , 0.09701964, 0.09700517, 0.09699849,\n",
       "           0.09699993, 0.09700786, 0.09702446, 0.09704667, 0.09707659,\n",
       "           0.09711449, 0.0971589 , 0.09721071, 0.09727021, 0.09733569,\n",
       "           0.09740602, 0.09748153, 0.0975633 , 0.09765078, 0.09774223,\n",
       "           0.09783994, 0.09794287, 0.09804946, 0.09816011, 0.09827589,\n",
       "           0.09839629, 0.09852317, 0.09865568, 0.09879366, 0.09893928,\n",
       "           0.09908745, 0.09923783, 0.09939098, 0.09954681, 0.09970696,\n",
       "           0.09987196, 0.10003845, 0.10021   , 0.10038509, 0.10056309],\n",
       "          [0.11197886, 0.11162662, 0.11127312, 0.11091848, 0.11056288,\n",
       "           0.11020643, 0.10984941, 0.10949194, 0.10913425, 0.10877656,\n",
       "           0.10841905, 0.10806204, 0.10770571, 0.10735042, 0.10699647,\n",
       "           0.1066442 , 0.10629354, 0.10594499, 0.10559898, 0.10525554,\n",
       "           0.10491502, 0.10457761, 0.10424367, 0.1039134 , 0.10358712,\n",
       "           0.10326493, 0.10294726, 0.10263418, 0.10232641, 0.1020238 ,\n",
       "           0.10172651, 0.10143439, 0.10114738, 0.10086618, 0.10059091,\n",
       "           0.10032158, 0.10005798, 0.0998013 , 0.09955093, 0.09930633,\n",
       "           0.09906869, 0.09883819, 0.09861437, 0.09839734, 0.09818693,\n",
       "           0.09798275, 0.09778504, 0.09759268, 0.09740745, 0.09722883,\n",
       "           0.09705695, 0.09689102, 0.09673166, 0.09657834, 0.09643172,\n",
       "           0.09629177, 0.0961578 , 0.0960312 , 0.09590925, 0.09579398,\n",
       "           0.09568485, 0.09558234, 0.09548549, 0.09539545, 0.09531148,\n",
       "           0.09523215, 0.09515827, 0.09508969, 0.09502617, 0.09496691,\n",
       "           0.0949131 , 0.09486498, 0.09482232, 0.09478352, 0.09475048,\n",
       "           0.09472167, 0.09469777, 0.09467953, 0.0946651 , 0.0946572 ,\n",
       "           0.09465275, 0.09465183, 0.09465572, 0.09466281, 0.09467331,\n",
       "           0.09468859, 0.09470706, 0.09472967, 0.09475645, 0.09478647],\n",
       "          [0.11189685, 0.11195425, 0.11200581, 0.11205145, 0.11209116,\n",
       "           0.11212488, 0.11215268, 0.11217453, 0.11219051, 0.11220054,\n",
       "           0.11220474, 0.11220314, 0.11219576, 0.11218263, 0.11216394,\n",
       "           0.11213972, 0.1121099 , 0.1120747 , 0.11203378, 0.11198746,\n",
       "           0.11193579, 0.11187909, 0.11181732, 0.1117502 , 0.11167801,\n",
       "           0.11160073, 0.11151879, 0.11143208, 0.11134044, 0.11124431,\n",
       "           0.11114401, 0.11103898, 0.11092972, 0.11081559, 0.11069708,\n",
       "           0.11057449, 0.11044756, 0.11031638, 0.11018173, 0.11004376,\n",
       "           0.10990249, 0.10975764, 0.10960997, 0.1094586 , 0.10930441,\n",
       "           0.10914712, 0.10898791, 0.10882509, 0.10865844, 0.10848936,\n",
       "           0.10831797, 0.1081444 , 0.10796865, 0.10779015, 0.10761023,\n",
       "           0.10742892, 0.10724609, 0.10706272, 0.10687698, 0.10668939,\n",
       "           0.10650004, 0.10630934, 0.10611843, 0.10592601, 0.10573263,\n",
       "           0.10553832, 0.10534341, 0.10514776, 0.10495171, 0.10475478,\n",
       "           0.10455725, 0.10435972, 0.10416213, 0.10396497, 0.10376895,\n",
       "           0.10357356, 0.10337772, 0.10318165, 0.10298691, 0.10279351,\n",
       "           0.10260057, 0.10240803, 0.10221514, 0.10202353, 0.1018321 ,\n",
       "           0.1016412 , 0.10144913, 0.10125759, 0.10106871, 0.10088218],\n",
       "          [0.11192803, 0.11245269, 0.11297764, 0.11350232, 0.1140262 ,\n",
       "           0.11454876, 0.11506954, 0.11558804, 0.1161038 , 0.11661629,\n",
       "           0.11712504, 0.11762977, 0.11813007, 0.11862531, 0.11911521,\n",
       "           0.11959952, 0.12007828, 0.12055103, 0.12101705, 0.12147619,\n",
       "           0.12192815, 0.12237348, 0.12281188, 0.1232425 , 0.12366576,\n",
       "           0.12408091, 0.12448838, 0.12488844, 0.12528011, 0.12566376,\n",
       "           0.12603955, 0.12640755, 0.12676875, 0.12712146, 0.1274656 ,\n",
       "           0.12780215, 0.12813164, 0.12845334, 0.12876688, 0.12907423,\n",
       "           0.12937362, 0.12966624, 0.12995264, 0.1302319 , 0.13050589,\n",
       "           0.13077381, 0.13103661, 0.13129304, 0.13154185, 0.13178582,\n",
       "           0.13202414, 0.13225748, 0.13248572, 0.13270803, 0.13292679,\n",
       "           0.13314106, 0.13335219, 0.13355887, 0.13376133, 0.13395824,\n",
       "           0.13415048, 0.13433814, 0.13452286, 0.13470182, 0.13487734,\n",
       "           0.13505085, 0.13522123, 0.13538806, 0.1355534 , 0.13571751,\n",
       "           0.1358782 , 0.13603514, 0.1361882 , 0.13634084, 0.13649084,\n",
       "           0.13664004, 0.13678394, 0.13692291, 0.13706031, 0.13719623,\n",
       "           0.1373312 , 0.13746594, 0.137597  , 0.13772872, 0.13785768,\n",
       "           0.13798372, 0.13810638, 0.13822582, 0.13834335, 0.1384623 ],\n",
       "          [0.1114705 , 0.1115539 , 0.1116373 , 0.11172066, 0.11180388,\n",
       "           0.11188698, 0.11196986, 0.11205252, 0.11213491, 0.11221682,\n",
       "           0.11229823, 0.11237914, 0.11245947, 0.11253901, 0.11261767,\n",
       "           0.11269542, 0.11277261, 0.11284908, 0.11292451, 0.1129988 ,\n",
       "           0.11307213, 0.11314477, 0.11321667, 0.11328736, 0.11335678,\n",
       "           0.11342475, 0.11349129, 0.11355697, 0.11362048, 0.11368283,\n",
       "           0.11374412, 0.11380365, 0.11386219, 0.11391893, 0.11397377,\n",
       "           0.11402693, 0.11407924, 0.1141291 , 0.11417689, 0.11422325,\n",
       "           0.11426765, 0.11431005, 0.11435001, 0.11438781, 0.11442389,\n",
       "           0.11445798, 0.11449091, 0.11452352, 0.11455331, 0.11458174,\n",
       "           0.11460866, 0.11463422, 0.11465836, 0.1146792 , 0.11469842,\n",
       "           0.1147159 , 0.11473207, 0.11474518, 0.11475741, 0.11476695,\n",
       "           0.11477488, 0.1147796 , 0.11478171, 0.11478133, 0.11477955,\n",
       "           0.1147759 , 0.11477037, 0.11476406, 0.11475711, 0.11474919,\n",
       "           0.11473746, 0.11472384, 0.11470927, 0.11469574, 0.11468007,\n",
       "           0.11466239, 0.11464216, 0.11461926, 0.11459438, 0.11456572,\n",
       "           0.11453574, 0.11450348, 0.11446735, 0.11443146, 0.11439405,\n",
       "           0.11435395, 0.11431322, 0.11427133, 0.11422706, 0.11418097],\n",
       "          [0.11100025, 0.11094342, 0.11088344, 0.11082035, 0.11075405,\n",
       "           0.11068469, 0.11061226, 0.11053681, 0.11045837, 0.11037701,\n",
       "           0.1102928 , 0.11020587, 0.11011619, 0.1100239 , 0.10992912,\n",
       "           0.10983187, 0.10973261, 0.10963144, 0.10952877, 0.10942423,\n",
       "           0.10931846, 0.10921147, 0.10910334, 0.10899448, 0.10888438,\n",
       "           0.10877338, 0.10866174, 0.10854968, 0.10843768, 0.10832585,\n",
       "           0.10821381, 0.10810186, 0.10799025, 0.10787883, 0.10776775,\n",
       "           0.10765699, 0.10754748, 0.10743845, 0.10733004, 0.10722242,\n",
       "           0.10711543, 0.10700922, 0.10690314, 0.10679776, 0.10669298,\n",
       "           0.10658947, 0.10648708, 0.10638717, 0.10628918, 0.1061928 ,\n",
       "           0.10609721, 0.10600272, 0.10591036, 0.10581844, 0.10572732,\n",
       "           0.10563704, 0.1055486 , 0.10545949, 0.10537265, 0.10528558,\n",
       "           0.1051998 , 0.1051146 , 0.10503094, 0.10494793, 0.10486586,\n",
       "           0.10478487, 0.10470565, 0.10462744, 0.10455088, 0.1044748 ,\n",
       "           0.10439813, 0.10432244, 0.10424764, 0.10417442, 0.10410067,\n",
       "           0.10402715, 0.10395394, 0.10388105, 0.10380776, 0.10373411,\n",
       "           0.10366134, 0.10358862, 0.1035166 , 0.10344511, 0.10337345,\n",
       "           0.10330115, 0.10323113, 0.10316206, 0.10309189, 0.10302018],\n",
       "          [0.11071022, 0.11090152, 0.1110929 , 0.11128432, 0.11147565,\n",
       "           0.11166685, 0.11185783, 0.11204852, 0.11223887, 0.1124287 ,\n",
       "           0.11261808, 0.11280682, 0.11299466, 0.11318158, 0.11336755,\n",
       "           0.11355212, 0.1137353 , 0.11391722, 0.11409762, 0.11427645,\n",
       "           0.11445386, 0.11462944, 0.11480284, 0.1149747 , 0.11514416,\n",
       "           0.11531132, 0.11547559, 0.11563721, 0.11579632, 0.11595324,\n",
       "           0.11610721, 0.11625769, 0.1164043 , 0.11654741, 0.11668736,\n",
       "           0.11682316, 0.11695529, 0.11708327, 0.11720794, 0.11732899,\n",
       "           0.11744595, 0.11755824, 0.11766572, 0.11776859, 0.11786702,\n",
       "           0.1179598 , 0.11804672, 0.11812922, 0.11820717, 0.11828014,\n",
       "           0.11834774, 0.1184098 , 0.11846753, 0.1185224 , 0.11857027,\n",
       "           0.11861213, 0.11865042, 0.11868201, 0.11871032, 0.11873209,\n",
       "           0.11874855, 0.11876066, 0.11876709, 0.11876854, 0.11876422,\n",
       "           0.11875626, 0.11874487, 0.11872655, 0.1187027 , 0.1186754 ,\n",
       "           0.11864385, 0.11860827, 0.11856887, 0.11852592, 0.11847802,\n",
       "           0.11842533, 0.11836779, 0.11830574, 0.11823788, 0.11816358,\n",
       "           0.11808683, 0.11800691, 0.11792485, 0.11783995, 0.11775195,\n",
       "           0.11765865, 0.11756533, 0.11746735, 0.11736506, 0.11725894]]],\n",
       "        dtype=float32),\n",
       "  array([[[0.49895665],\n",
       "          [0.49893346],\n",
       "          [0.4989354 ],\n",
       "          [0.4989534 ],\n",
       "          [0.49896646],\n",
       "          [0.4989923 ],\n",
       "          [0.49901402],\n",
       "          [0.49903688],\n",
       "          [0.49904943],\n",
       "          [0.49908048],\n",
       "          [0.49909082],\n",
       "          [0.49909332],\n",
       "          [0.49909696],\n",
       "          [0.49910215],\n",
       "          [0.49909127],\n",
       "          [0.4990366 ],\n",
       "          [0.49899372],\n",
       "          [0.4989578 ],\n",
       "          [0.49893242],\n",
       "          [0.4989163 ],\n",
       "          [0.49893492],\n",
       "          [0.49892175],\n",
       "          [0.4988798 ],\n",
       "          [0.4988595 ],\n",
       "          [0.49883506],\n",
       "          [0.4988136 ],\n",
       "          [0.49877796],\n",
       "          [0.498729  ],\n",
       "          [0.49870136],\n",
       "          [0.498674  ],\n",
       "          [0.49865043],\n",
       "          [0.49864587],\n",
       "          [0.49863607],\n",
       "          [0.4986126 ],\n",
       "          [0.4985963 ],\n",
       "          [0.49858826],\n",
       "          [0.49861792],\n",
       "          [0.49864078],\n",
       "          [0.49868068],\n",
       "          [0.49871856],\n",
       "          [0.49873343],\n",
       "          [0.49873975],\n",
       "          [0.498719  ],\n",
       "          [0.49871635],\n",
       "          [0.49871892],\n",
       "          [0.49868947],\n",
       "          [0.49866396],\n",
       "          [0.498658  ],\n",
       "          [0.4986768 ],\n",
       "          [0.49865356],\n",
       "          [0.4986265 ],\n",
       "          [0.4986348 ],\n",
       "          [0.49865353],\n",
       "          [0.49864382],\n",
       "          [0.49863726],\n",
       "          [0.49860337],\n",
       "          [0.4986115 ],\n",
       "          [0.49862617],\n",
       "          [0.4986578 ],\n",
       "          [0.49870414],\n",
       "          [0.49870425],\n",
       "          [0.49870917],\n",
       "          [0.49868846],\n",
       "          [0.4986769 ],\n",
       "          [0.49866822],\n",
       "          [0.49866343],\n",
       "          [0.49867988],\n",
       "          [0.4986895 ],\n",
       "          [0.49868125],\n",
       "          [0.49869958],\n",
       "          [0.49871945],\n",
       "          [0.4987116 ],\n",
       "          [0.49868897],\n",
       "          [0.49867347],\n",
       "          [0.49865228],\n",
       "          [0.49861944],\n",
       "          [0.4985851 ],\n",
       "          [0.49857265],\n",
       "          [0.49859023],\n",
       "          [0.4985969 ],\n",
       "          [0.4986204 ],\n",
       "          [0.49861127],\n",
       "          [0.49859717],\n",
       "          [0.49859205],\n",
       "          [0.49858436],\n",
       "          [0.49859312],\n",
       "          [0.49860483],\n",
       "          [0.49859855],\n",
       "          [0.49857676],\n",
       "          [0.49859324]]], dtype=float32),\n",
       "  array([90], dtype=int32),\n",
       "  array([[[0.]]], dtype=float32)],\n",
       " 'stop_token_prediction': array([[[-0.00417335],\n",
       "         [-0.00426618],\n",
       "         [-0.00425842],\n",
       "         [-0.0041864 ],\n",
       "         [-0.00413418],\n",
       "         [-0.00403079],\n",
       "         [-0.00394395],\n",
       "         [-0.00385253],\n",
       "         [-0.00380225],\n",
       "         [-0.00367809],\n",
       "         [-0.00363672],\n",
       "         [-0.00362675],\n",
       "         [-0.00361221],\n",
       "         [-0.00359145],\n",
       "         [-0.00363494],\n",
       "         [-0.00385351],\n",
       "         [-0.00402511],\n",
       "         [-0.00416876],\n",
       "         [-0.00427033],\n",
       "         [-0.00433485],\n",
       "         [-0.00426031],\n",
       "         [-0.00431304],\n",
       "         [-0.00448084],\n",
       "         [-0.00456206],\n",
       "         [-0.00465974],\n",
       "         [-0.00474555],\n",
       "         [-0.00488822],\n",
       "         [-0.005084  ],\n",
       "         [-0.00519451],\n",
       "         [-0.005304  ],\n",
       "         [-0.0053983 ],\n",
       "         [-0.00541651],\n",
       "         [-0.00545571],\n",
       "         [-0.00554959],\n",
       "         [-0.00561481],\n",
       "         [-0.00564697],\n",
       "         [-0.0055284 ],\n",
       "         [-0.00543697],\n",
       "         [-0.00527726],\n",
       "         [-0.00512576],\n",
       "         [-0.00506633],\n",
       "         [-0.00504102],\n",
       "         [-0.00512393],\n",
       "         [-0.00513464],\n",
       "         [-0.0051244 ],\n",
       "         [-0.00524209],\n",
       "         [-0.00534411],\n",
       "         [-0.00536796],\n",
       "         [-0.0052928 ],\n",
       "         [-0.00538573],\n",
       "         [-0.00549403],\n",
       "         [-0.00546088],\n",
       "         [-0.00538591],\n",
       "         [-0.0054248 ],\n",
       "         [-0.00545095],\n",
       "         [-0.00558653],\n",
       "         [-0.00555398],\n",
       "         [-0.00549538],\n",
       "         [-0.0053689 ],\n",
       "         [-0.00518351],\n",
       "         [-0.005183  ],\n",
       "         [-0.00516335],\n",
       "         [-0.0052462 ],\n",
       "         [-0.00529239],\n",
       "         [-0.0053271 ],\n",
       "         [-0.0053463 ],\n",
       "         [-0.00528045],\n",
       "         [-0.00524195],\n",
       "         [-0.00527506],\n",
       "         [-0.00520168],\n",
       "         [-0.0051222 ],\n",
       "         [-0.00515366],\n",
       "         [-0.00524418],\n",
       "         [-0.00530617],\n",
       "         [-0.00539088],\n",
       "         [-0.00552221],\n",
       "         [-0.00565961],\n",
       "         [-0.00570947],\n",
       "         [-0.00563908],\n",
       "         [-0.00561241],\n",
       "         [-0.00551843],\n",
       "         [-0.0055549 ],\n",
       "         [-0.00561126],\n",
       "         [-0.00563184],\n",
       "         [-0.00566258],\n",
       "         [-0.00562756],\n",
       "         [-0.00558065],\n",
       "         [-0.00560583],\n",
       "         [-0.00569294],\n",
       "         [-0.00562696]]], dtype=float32)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(model.decoder_logits, feed_dict = {input_ids: [[1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                        input_lengths: [9]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
