{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer.py:34: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer.py:35: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer.py:36: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer.py:38: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer.py:39: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/quartznet/layer.py:6: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import malaya_speech.augmentation.waveform as augmentation\n",
    "import malaya_speech.augmentation.spectrogram as mask_augmentation\n",
    "import malaya_speech.train.model.ctc as ctc\n",
    "import malaya_speech.train as train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(normalize_per_feature = True)\n",
    "n_mels = featurizer.num_feature_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from glob import glob\n",
    "\n",
    "noises = glob('../noise-44k/noise/*.wav') + glob('../noise-44k/clean-wav/*.wav')\n",
    "basses = glob('HHDS/Sources/**/*bass.wav', recursive = True)\n",
    "drums = glob('HHDS/Sources/**/*drums.wav', recursive = True)\n",
    "others = glob('HHDS/Sources/**/*other.wav', recursive = True)\n",
    "noises = noises + basses + drums + others\n",
    "random.shuffle(noises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav(f):\n",
    "    return malaya_speech.load(f, sr = 16000)\n",
    "\n",
    "def random_amplitude_threshold(sample, low = 1, high = 2, threshold = 0.4):\n",
    "    y_aug = sample.copy()\n",
    "    y_aug = y_aug / (np.max(np.abs(y_aug)) + 1e-9)\n",
    "    dyn_change = np.random.uniform(low = low, high = high)\n",
    "    y_aug[np.abs(y_aug) >= threshold] = (\n",
    "        y_aug[np.abs(y_aug) >= threshold] * dyn_change\n",
    "    )\n",
    "    return np.clip(y_aug, -1, 1)\n",
    "\n",
    "def calc(signal, seed, add_uniform = False):\n",
    "    random.seed(seed)\n",
    "\n",
    "    choice = random.randint(0, 8)\n",
    "    if choice == 0:\n",
    "\n",
    "        x = augmentation.sox_augment_high(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(25, 50),\n",
    "            reverberance = random.randint(0, 30),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 30),\n",
    "            negate = 1,\n",
    "        )\n",
    "    if choice == 1:\n",
    "        x = augmentation.sox_augment_high(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(25, 70),\n",
    "            reverberance = random.randint(0, 30),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 30),\n",
    "            negate = 0,\n",
    "        )\n",
    "    if choice == 2:\n",
    "        x = augmentation.sox_augment_low(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(5, 30),\n",
    "            reverberance = random.randint(0, 30),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 30),\n",
    "            negate = random.randint(0, 1),\n",
    "        )\n",
    "    if choice == 3:\n",
    "        x = augmentation.sox_augment_combine(\n",
    "            signal,\n",
    "            min_bass_gain_high = random.randint(25, 70),\n",
    "            min_bass_gain_low = random.randint(5, 30),\n",
    "            reverberance = random.randint(0, 30),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 30),\n",
    "        )\n",
    "    if choice == 4:\n",
    "        x = augmentation.sox_reverb(\n",
    "            signal,\n",
    "            reverberance = random.randint(10, 30),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(10, 30),\n",
    "        )\n",
    "    if choice == 5:\n",
    "        x = random_amplitude_threshold(\n",
    "            signal, threshold = random.uniform(0.35, 0.8)\n",
    "        )\n",
    "\n",
    "    if choice > 5:\n",
    "        x = signal\n",
    "\n",
    "    if choice != 5 and random.gauss(0.5, 0.14) > 0.6:\n",
    "        x = random_amplitude_threshold(\n",
    "            x, low = 1.0, high = 2.0, threshold = random.uniform(0.7, 0.9)\n",
    "        )\n",
    "\n",
    "    if random.gauss(0.5, 0.14) > 0.6 and add_uniform:\n",
    "        x = augmentation.add_uniform_noise(\n",
    "            x, power = random.uniform(0.005, 0.015)\n",
    "        )\n",
    "\n",
    "    return x\n",
    "\n",
    "def signal_augmentation(wav):\n",
    "    seed = random.randint(0, 100_000_000)\n",
    "    wav = calc(wav, seed)\n",
    "    if random.gauss(0.5, 0.14) > 0.6:\n",
    "        n = read_wav(random.choice(noises))[0]\n",
    "        n = calc(n, seed, True)\n",
    "        combined = augmentation.add_noise(\n",
    "            wav, n, factor = random.uniform(0.05, 0.3)\n",
    "        )\n",
    "    else:\n",
    "        combined = wav\n",
    "    return combined.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_augmentation(features):\n",
    "    features = mask_augmentation.mask_frequency(features)\n",
    "    return mask_augmentation.mask_time(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(example):\n",
    "    w = tf.compat.v1.numpy_function(signal_augmentation, [example['waveforms']], tf.float32)\n",
    "    w = tf.reshape(w, (1, -1))\n",
    "    s = featurizer.vectorize(w[0])\n",
    "    s = tf.reshape(s, (-1, n_mels))\n",
    "    s = tf.compat.v1.numpy_function(mel_augmentation, [s], tf.float32)\n",
    "    mel_fbanks = tf.reshape(s, (-1, n_mels))\n",
    "    length = tf.cast(tf.shape(mel_fbanks)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['waveforms'] = w[0]\n",
    "    example['inputs'] = mel_fbanks\n",
    "    example['inputs_length'] = length\n",
    "\n",
    "    return example\n",
    "\n",
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.VarLenFeature(tf.float32),\n",
    "        'targets': tf.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example, features = data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "\n",
    "    features = preprocess_inputs(features)\n",
    "\n",
    "    keys = list(features.keys())\n",
    "    for k in keys:\n",
    "        if k not in ['waveforms', 'inputs', 'inputs_length', 'targets']:\n",
    "            features.pop(k, None)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_dataset(path, batch_size = 32, shuffle_size = 32, thread_count = 24, maxlen_feature = 1800):\n",
    "    def get():\n",
    "        files = glob(path)\n",
    "        dataset = tf.data.TFRecordDataset(files)\n",
    "        dataset = dataset.shuffle(shuffle_size)\n",
    "        dataset = dataset.map(parse, num_parallel_calls = thread_count)\n",
    "        dataset = dataset.filter(lambda x: tf.less_equal(tf.shape(x['inputs'])[0], maxlen_feature))\n",
    "        dataset = dataset.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes = {\n",
    "                'waveforms': tf.TensorShape([None]),\n",
    "                'inputs': tf.TensorShape([None, n_mels]),\n",
    "                'inputs_length': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values = {\n",
    "                'waveforms': tf.constant(0, dtype = tf.float32),\n",
    "                'inputs': tf.constant(0, dtype = tf.float32),\n",
    "                'inputs_length': tf.constant(0, dtype = tf.int32),\n",
    "                'targets': tf.constant(0, dtype = tf.int64),\n",
    "            },\n",
    "        )\n",
    "        dataset = dataset.repeat()\n",
    "        return dataset\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-8-b052cc2cf68d>:4: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32, 833, 80)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "iterator = get_dataset('../speech-bahasa/bahasa-asr/data/bahasa-asr-train-*')()\n",
    "iterator = iterator.make_one_shot_iterator().get_next()\n",
    "r = sess.run(iterator)\n",
    "r['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 813, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sess.run(iterator)\n",
    "r['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
