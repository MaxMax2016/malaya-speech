{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tribal-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "finnish-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opponent-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "wavs = glob('../speech/example-speaker/*.wav')\n",
    "len(wavs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "quick-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import malaya_speech.augmentation.waveform as augmentation\n",
    "import malaya_speech\n",
    "import numpy as np\n",
    "\n",
    "sr = 8000\n",
    "speakers_size = 4\n",
    "\n",
    "# noise = malaya_speech.load('noise.wav', sr = sr)[0]\n",
    "\n",
    "def read_wav(f):\n",
    "    return malaya_speech.load(f, sr = sr)\n",
    "\n",
    "\n",
    "def random_sampling(s, length):\n",
    "    return augmentation.random_sampling(s, sr = sr, length = length)\n",
    "\n",
    "def to_mel(y):\n",
    "    mel = malaya_speech.featurization.universal_mel(y)\n",
    "    mel[mel <= np.log(1e-2)] = np.log(1e-2)\n",
    "    return mel\n",
    "\n",
    "def combine_speakers(files, n = 5, limit = 4):\n",
    "    w_samples = random.sample(files, n)\n",
    "    w_samples = [read_wav(f)[0] for f in w_samples]\n",
    "    w_lens = [len(w) / sr for w in w_samples]\n",
    "    w_lens = int(min(min(w_lens) * 1000, random.randint(2000, 10000)))\n",
    "    w_samples = [random_sampling(w, length = w_lens) for w in w_samples]\n",
    "    y = [w_samples[0]]\n",
    "    left = w_samples[0].copy()\n",
    "\n",
    "    combined = None\n",
    "\n",
    "    for i in range(1, n):\n",
    "        right = w_samples[i].copy()\n",
    "        overlap = random.uniform(0.98, 1.0)\n",
    "        print(i, overlap)\n",
    "        len_overlap = int(overlap * len(right))\n",
    "        minus = len(left) - len_overlap\n",
    "        if minus < 0:\n",
    "            minus = 0\n",
    "        padded_right = np.pad(right, (minus, 0))\n",
    "        left = np.pad(left, (0, len(padded_right) - len(left)))\n",
    "\n",
    "        left = left + padded_right\n",
    "\n",
    "        if i >= (limit - 1):\n",
    "            if combined is None:\n",
    "                combined = padded_right\n",
    "            else:\n",
    "                combined = np.pad(\n",
    "                    combined, (0, len(padded_right) - len(combined))\n",
    "                )\n",
    "                combined += padded_right\n",
    "\n",
    "        else:\n",
    "            y.append(padded_right)\n",
    "\n",
    "    if combined is not None:\n",
    "        y.append(combined)\n",
    "        \n",
    "    maxs = [max(left)]\n",
    "    for i in range(len(y)):\n",
    "        if len(y[i]) != len(left):\n",
    "            y[i] = np.pad(y[i], (0, len(left) - len(y[i])))\n",
    "            maxs.append(max(y[i]))\n",
    "            \n",
    "    max_amp = max(maxs)\n",
    "    mix_scaling = 1 / max_amp * 0.95\n",
    "    left = left * mix_scaling\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        y[i] = y[i] * mix_scaling\n",
    "\n",
    "#     for i in range(len(y)):\n",
    "#         if len(y[i]) != len(left):\n",
    "#             y[i] = np.pad(y[i], (0, len(left) - len(y[i])))\n",
    "#             y[i] = y[i] / np.max(np.abs(y[i]))\n",
    "\n",
    "#     left = left / np.max(np.abs(left))\n",
    "        \n",
    "    return left, y\n",
    "\n",
    "# y, _ = malaya_speech.load('../speech/example-speaker/husein-zolkepli.wav')\n",
    "# y = np.expand_dims(y, 0).astype(np.float32)\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "perceived-taste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.991702905607049\n",
      "2 0.9913397320058862\n",
      "3 0.993411257433154\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.000125, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left, y = combine_speakers(wavs, 4)\n",
    "y = np.array([y]).astype(np.float32)\n",
    "left = np.array([left]).astype(np.float32)\n",
    "x = np.random.normal(size = y.shape).astype(np.float32)\n",
    "len(left) / sr, len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "parental-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_pt = torch.from_numpy(x)\n",
    "x_tf = tf.constant(x)\n",
    "y_pt = torch.from_numpy(y)\n",
    "y_tf = tf.constant(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "minute-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=245, shape=(1, 4, 21889), dtype=float32, numpy=\n",
       "array([[[-0.01159313,  2.4352384 , -0.49477547, ...,  0.5427677 ,\n",
       "         -0.50842077,  1.3719425 ],\n",
       "        [-0.62613714,  0.40092194,  0.98418045, ..., -0.33143365,\n",
       "          0.03194261,  0.6151522 ],\n",
       "        [ 1.2165703 ,  0.6483659 ,  0.9452555 , ..., -0.12862363,\n",
       "         -0.5408644 , -0.96836466],\n",
       "        [ 1.8071035 ,  0.52183706, -1.4022133 , ..., -0.6891508 ,\n",
       "         -0.8197269 , -0.27434656]]], dtype=float32)>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "polar-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T, B, C\n",
    "source = y_pt.permute((2,0,1))\n",
    "estimate_source = x_pt.permute((2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "hairy-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lengths = torch.tensor(\n",
    "    [estimate_source.shape[0]] * estimate_source.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "motivated-emergency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = (\n",
    "    source_lengths.contiguous().reshape(1, -1, 1).float()\n",
    ")\n",
    "num_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "exclusive-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(source, source_lengths):\n",
    "    T, B, _ = source.size()\n",
    "    mask = source.new_ones((T, B, 1))\n",
    "    for i in range(B):\n",
    "        mask[source_lengths[i] :, i, :] = 0\n",
    "    return mask\n",
    "\n",
    "mask = get_mask(source, source_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cubic-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimate_source *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "identified-triangle",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "guilty-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target = torch.sum(source, dim=0, keepdim=True) / num_samples\n",
    "mean_estimate = (\n",
    "    torch.sum(estimate_source, dim=0, keepdim=True) / num_samples\n",
    ")\n",
    "zero_mean_target = source - mean_target\n",
    "zero_mean_estimate = estimate_source - mean_estimate\n",
    "# mask padding position along T\n",
    "zero_mean_target *= mask\n",
    "zero_mean_estimate *= mask\n",
    "s_target = zero_mean_target  # [T, B, C]\n",
    "s_estimate = zero_mean_estimate  # [T, B, C]\n",
    "# s_target = <s', s>s / ||s||^2\n",
    "dot = torch.sum(s_estimate * s_target, dim=0, keepdim=True)  # [1, B, C]\n",
    "s_target_energy = (\n",
    "    torch.sum(s_target ** 2, dim=0, keepdim=True) + EPS\n",
    ")  # [1, B, C]\n",
    "proj = dot * s_target / s_target_energy  # [T, B, C]\n",
    "# e_noise = s' - s_target\n",
    "e_noise = s_estimate - proj  # [T, B, C]\n",
    "# SI-SNR = 10 * log_10(||s_target||^2 / ||e_noise||^2)\n",
    "si_snr_beforelog = torch.sum(proj ** 2, dim=0) / (\n",
    "    torch.sum(e_noise ** 2, dim=0) + EPS\n",
    ")\n",
    "si_snr = 10 * torch.log10(si_snr_beforelog + EPS)  # [B, C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "modified-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-46.3737, -58.6511, -40.0519, -53.9084]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "placed-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T, B, C\n",
    "source_tf = tf.transpose(y_tf, [2,0,1])\n",
    "estimate_source_tf = tf.transpose(x_tf, [2,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "growing-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_lengths_tf = tf.tile([tf.shape(source_tf)[0]], [tf.shape(source_tf)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "floating-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(1)])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lengths_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "tropical-knife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(21889), Dimension(1)])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = tf.cast(\n",
    "        tf.sequence_mask(source_lengths_tf, tf.reduce_max(source_lengths_tf)),\n",
    "        source_tf.dtype,\n",
    "    )\n",
    "mask = tf.transpose(mask)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "another-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = tf.expand_dims(mask, 2)\n",
    "estimate_source_tf *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "charitable-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21889, 1, 4])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimate_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fatal-sierra",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207, shape=(1,), dtype=int32, numpy=array([21889], dtype=int32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_lengths_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "indoor-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=225, shape=(1, 1, 1), dtype=float32, numpy=array([[[21889.]]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = tf.cast(tf.reshape(source_lengths_tf, (1, -1, 1)), tf.float32)\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "detailed-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_target = tf.reduce_sum(source_tf, axis = 0, keepdims = True) / num_samples\n",
    "mean_estimate = (\n",
    "    tf.reduce_sum(estimate_source_tf, axis = 0, keepdims = True) / num_samples\n",
    ")\n",
    "zero_mean_target_tf = source_tf - mean_target\n",
    "zero_mean_estimate_tf = estimate_source_tf - mean_estimate\n",
    "\n",
    "zero_mean_target_tf *= mask\n",
    "zero_mean_estimate_tf *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "egyptian-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0130, -0.6242,  1.2104,  1.8028]],\n",
       "\n",
       "        [[ 2.4338,  0.4028,  0.6422,  0.5176]],\n",
       "\n",
       "        [[-0.4962,  0.9861,  0.9391, -1.4065]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5414, -0.3295, -0.1348, -0.6934]],\n",
       "\n",
       "        [[-0.5098,  0.0339, -0.5471, -0.8240]],\n",
       "\n",
       "        [[ 1.3705,  0.6171, -0.9746, -0.2786]]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mean_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hungry-insertion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=244, shape=(21889, 1, 4), dtype=float32, numpy=\n",
       "array([[[-0.01298668, -0.6242194 ,  1.2103798 ,  1.8028239 ]],\n",
       "\n",
       "       [[ 2.4338448 ,  0.40283966,  0.6421755 ,  0.5175575 ]],\n",
       "\n",
       "       [[-0.49616903,  0.9860982 ,  0.9390651 , -1.406493  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.54137415, -0.32951593, -0.13481408, -0.69343036]],\n",
       "\n",
       "       [[-0.5098143 ,  0.03386034, -0.5470548 , -0.82400644]],\n",
       "\n",
       "       [[ 1.370549  ,  0.6170699 , -0.9745551 , -0.2786261 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_mean_estimate_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-mention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
