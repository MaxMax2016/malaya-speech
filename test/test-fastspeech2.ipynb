{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "from malaya_speech.train.model import fastspeech2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.fastspeech2_config\n",
    "config['encoder_hidden_size'] = 128\n",
    "config['encoder_num_hidden_layers'] = 2\n",
    "config['encoder_intermediate_size'] = 512\n",
    "config['decoder_hidden_size'] = 128\n",
    "config['decoder_num_hidden_layers'] = 2\n",
    "config['decoder_intermediate_size'] = 512\n",
    "config['hidden_dropout_prob'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/fastspeech/layer.py:11: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/initializers/initializers_v1.py:409: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# config = malaya_speech.config.fastspeech2_config\n",
    "config = fastspeech2.Config(vocab_size = 66, **config)\n",
    "model = fastspeech2.Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.placeholder(tf.int32, [None, None])\n",
    "lens = tf.placeholder(tf.int32, [None, None])\n",
    "mel_outputs = tf.placeholder(tf.float32, [None, None, 80])\n",
    "mel_lengths = tf.placeholder(tf.int32, [None])\n",
    "energies = tf.placeholder(tf.float32, [None, None])\n",
    "energies_lengths = tf.placeholder(tf.int32, [None])\n",
    "f0s = tf.placeholder(tf.float32, [None, None])\n",
    "f0s_lengths = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Model.call of <malaya_speech.train.model.fastspeech2.model.Model object at 0x186d0b110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Model.call of <malaya_speech.train.model.fastspeech2.model.Model object at 0x186d0b110>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechEmbeddings.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechEmbeddings object at 0x186339e90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechEmbeddings.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechEmbeddings object at 0x186339e90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFEmbedding.call of <malaya_speech.train.model.fastspeech.model.TFEmbedding object at 0x186caf0d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFEmbedding.call of <malaya_speech.train.model.fastspeech.model.TFEmbedding object at 0x186caf0d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechEncoder.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechEncoder object at 0x186b43a90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechEncoder.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechEncoder object at 0x186b43a90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechLayer.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechLayer object at 0x186d5bc90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechLayer.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechLayer object at 0x186d5bc90>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechAttention.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechAttention object at 0x186d5bc10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechAttention.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechAttention object at 0x186d5bc10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechSelfAttention.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechSelfAttention object at 0x186d5b490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechSelfAttention.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechSelfAttention object at 0x186d5b490>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechSelfOutput.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechSelfOutput object at 0x186dbbd50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechSelfOutput.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechSelfOutput object at 0x186dbbd50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechIntermediate.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechIntermediate object at 0x186d1bf10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechIntermediate.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechIntermediate object at 0x186d1bf10>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechOutput.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechOutput object at 0x186d3b810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechOutput.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechOutput object at 0x186d3b810>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method FastSpeechVariantPredictor.call of <malaya_speech.train.model.fastspeech2.model.FastSpeechVariantPredictor object at 0x186f29050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method FastSpeechVariantPredictor.call of <malaya_speech.train.model.fastspeech2.model.FastSpeechVariantPredictor object at 0x186f29050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechLengthRegulator.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechLengthRegulator object at 0x186ecf610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechLengthRegulator.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechLengthRegulator object at 0x186ecf610>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFFastSpeechDecoder.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechDecoder object at 0x186eec410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFFastSpeechDecoder.call of <malaya_speech.train.model.fastspeech.model.TFFastSpeechDecoder object at 0x186eec410>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFTacotronPostnet.call of <malaya_speech.train.model.fastspeech.model.TFTacotronPostnet object at 0x186d0b2d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFTacotronPostnet.call of <malaya_speech.train.model.fastspeech.model.TFTacotronPostnet object at 0x186d0b2d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "mel_before, mel_after, duration_outputs, f0_outputs, energy_outputs = model(i, lens, f0s, energies, training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'model/mel_before/BiasAdd:0' shape=(None, None, 80) dtype=float32>,\n",
       " <tf.Tensor 'model/add_3:0' shape=(None, None, 80) dtype=float32>,\n",
       " <tf.Tensor 'model/duration_predictor/Squeeze:0' shape=(None, None) dtype=float32>,\n",
       " <tf.Tensor 'model/f0_predictor/Squeeze:0' shape=(None, None) dtype=float32>,\n",
       " <tf.Tensor 'model/energy_predictor/Squeeze:0' shape=(None, None) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_before, mel_after, duration_outputs, f0_outputs, energy_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = tf.losses.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_duration = tf.math.log(\n",
    "    tf.cast(tf.math.add(lens, 1), tf.float32)\n",
    ")\n",
    "duration_loss = loss_f(log_duration, duration_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ExpandDims:0' shape=(None, None, 1) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = tf.cast(tf.reduce_max(mel_lengths), tf.int32)\n",
    "mask = tf.sequence_mask(\n",
    "    lengths = mel_lengths, maxlen = max_length, dtype = tf.float32\n",
    ")\n",
    "mask = tf.expand_dims(mask, axis = -1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function malaya_boilerplate.train.loss.calculate_2d_loss(y_gt, y_pred, loss_fn)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "loss.calculate_2d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from malaya_speech.train import loss\n",
    "\n",
    "mse_mel = partial(\n",
    "    loss_f,\n",
    "    weights = mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mean_squared_error_1/value:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_loss_before = loss.calculate_3d_loss(mel_outputs, mel_before, mse_mel)\n",
    "mel_loss_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mean_squared_error_2/value:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel_loss_after = loss.calculate_3d_loss(mel_outputs, mel_after, mse_mel)\n",
    "mel_loss_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = tf.cast(tf.reduce_max(energies_lengths), tf.int32)\n",
    "mask = tf.sequence_mask(\n",
    "    lengths = energies_lengths, maxlen = max_length, dtype = tf.float32\n",
    ")\n",
    "energies_mel = partial(\n",
    "    loss_f,\n",
    "    weights = mask\n",
    ")\n",
    "energies_loss = loss.calculate_2d_loss(energies, energy_outputs, energies_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = tf.cast(tf.reduce_max(f0s_lengths), tf.int32)\n",
    "mask = tf.sequence_mask(\n",
    "    lengths = f0s_lengths, maxlen = max_length, dtype = tf.float32\n",
    ")\n",
    "energies_mel = partial(\n",
    "    loss_f,\n",
    "    weights = mask\n",
    ")\n",
    "f0s_loss = loss.calculate_2d_loss(f0s, f0_outputs, energies_mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = duration_loss + mel_loss_before + mel_loss_after + energies_loss + f0s_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset-mel.pkl', 'rb') as fopen:\n",
    "    data, d = pickle.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mel', 'text_ids', 'len_mel', 'len_text_ids', 'stop_token_target', 'f0', 'len_f0', 'energy', 'len_energy', 'g'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_by_duration(x, durs):\n",
    "    mel_len = durs.sum()\n",
    "    durs_cum = np.cumsum(np.pad(durs, (1, 0)))\n",
    "    \n",
    "    x_char = np.zeros((durs.shape[0],), dtype=np.float32)\n",
    "    for idx, start, end in zip(range(mel_len), durs_cum[:-1], durs_cum[1:]):\n",
    "        values = x[start:end][np.where(x[start:end] != 0.0)[0]]\n",
    "        x_char[idx] = np.mean(values) if len(values) > 0 else 0.0\n",
    "\n",
    "    return x_char.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = average_by_duration(data['f0'][0], d)\n",
    "energy = average_by_duration(data['energy'][0], d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72,), (72,), (72,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0.shape, energy.shape, d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 72)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sess.run([mel_before, mel_after, duration_outputs, f0_outputs, energy_outputs], \n",
    "         feed_dict = {i: data['text_ids'],\n",
    "                      lens: [d],\n",
    "                      energies: [energy],\n",
    "                      f0s: [f0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 408, 80), (1, 408, 80), (1, 72), (1, 72), (1, 72))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].shape, r[1].shape, r[2].shape, r[3].shape, r[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 483 ms, sys: 66.2 ms, total: 549 ms\n",
      "Wall time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = sess.run([duration_loss, mel_loss_before, mel_loss_after, energies_loss, f0s_loss], \n",
    "         feed_dict = {i: data['text_ids'],\n",
    "                      lens: [d],\n",
    "                      mel_outputs:data['mel'],\n",
    "                      mel_lengths:data['len_mel'][0],\n",
    "                      energies: [energy],\n",
    "                      energies_lengths: [len(energy)],\n",
    "                      f0s: [f0],\n",
    "                      f0s_lengths: [len(f0)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:test/model.ckpt.meta\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:test/model.ckpt.index\n",
      "INFO:tensorflow:1000\n",
      "INFO:tensorflow:test/model.ckpt.data-00000-of-00001\n",
      "INFO:tensorflow:33600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test/model.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'test/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 65680\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    77B Aug 14 19:46 checkpoint\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff    31M Aug 14 19:46 model.ckpt.data-00000-of-00001\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff   5.4K Aug 14 19:46 model.ckpt.index\r\n",
      "-rw-r--r--  1 huseinzolkepli  staff   958K Aug 14 19:46 model.ckpt.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
