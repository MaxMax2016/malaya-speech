{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "removed-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "effective-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size = (3, 100, 1)).astype(np.float32)\n",
    "x_pt = torch.from_numpy(x)\n",
    "x_tf = tf.convert_to_tensor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threatened-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lengths = [3, 100, 5]\n",
    "padding_mask = tf.sequence_mask(\n",
    "    lengths=output_lengths,\n",
    "    maxlen=np.max(output_lengths),\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "padding_mask_pt = torch.from_numpy(padding_mask.numpy())\n",
    "padding_mask_pt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunrise-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt.transpose(0, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tamil-arcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=81, shape=(108,), dtype=float32, numpy=\n",
       "array([ 3.38462949e-01, -6.35046184e-01,  2.13632852e-01,  1.53364733e-01,\n",
       "       -1.34568727e+00,  1.06948406e-01, -1.74812365e+00,  1.01804054e+00,\n",
       "        9.87234890e-01, -1.84313834e+00, -1.87800527e+00, -4.64344054e-01,\n",
       "        1.77438676e+00, -1.59402418e+00, -1.20399988e+00,  7.21421123e-01,\n",
       "       -7.89118707e-01,  4.95642543e-01,  3.24080437e-01,  2.01840430e-01,\n",
       "       -6.59769773e-01,  3.16196457e-02, -1.05242014e+00, -3.66903469e-02,\n",
       "        1.43766546e+00,  2.57406592e+00, -1.60762012e+00, -1.78636789e-01,\n",
       "        1.41232741e+00, -9.56038535e-01,  1.05740726e+00, -1.12573457e+00,\n",
       "       -7.56094307e-02, -4.74803478e-01,  8.63383234e-01, -2.31545281e+00,\n",
       "       -8.98107886e-02,  4.86101240e-01, -1.04549181e+00,  6.03562534e-01,\n",
       "       -3.12780231e-01, -1.52889025e+00,  9.37858343e-01, -2.20938828e-02,\n",
       "       -9.62873623e-02,  1.26268899e+00, -1.70238781e+00, -1.25917113e+00,\n",
       "       -4.57065135e-01, -5.54267406e-01, -1.22457230e+00, -1.33845019e+00,\n",
       "        1.48192489e+00, -7.00559378e-01, -5.62965393e-01, -4.55317050e-01,\n",
       "        8.22801948e-01,  1.88157940e-03, -2.33688951e-01,  3.55968857e-03,\n",
       "        8.31074417e-01, -6.90440834e-01, -7.13283479e-01,  1.32012916e+00,\n",
       "        4.39428210e-01, -2.13554844e-01, -6.10051513e-01,  2.23854557e-01,\n",
       "        6.01890385e-01,  6.94017589e-01,  6.88436329e-01,  1.38180912e+00,\n",
       "       -5.31047642e-01,  3.20297062e-01, -2.45465040e-01, -1.25685543e-01,\n",
       "       -1.21466937e-02,  2.16726914e-01, -9.30959284e-01,  1.00569069e+00,\n",
       "        4.70344901e-01, -3.61457646e-01, -4.07333553e-01, -2.90369540e-01,\n",
       "       -5.38139999e-01, -2.63539433e-01,  8.64221990e-01, -8.99450064e-01,\n",
       "       -4.80414242e-01,  1.88194811e+00,  7.71369278e-01,  1.16775858e+00,\n",
       "       -1.70516622e+00,  1.46217138e-01,  2.25894749e-01, -2.11609983e+00,\n",
       "        1.73744071e+00, -2.95387328e-01,  1.13903368e+00,  8.17249000e-01,\n",
       "       -9.59894300e-01,  9.91718113e-01,  1.48174569e-01, -2.93893307e-01,\n",
       "        1.65032625e+00, -8.95766675e-01,  9.73997042e-02,  1.40394127e+00],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.boolean_mask(x_tf, tf.tile(tf.expand_dims(padding_mask, -1), [1, 1, 1])).s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "functional-michael",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 100, 100, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[padding_mask.numpy().astype(np.int32)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "rubber-allocation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padding_mask_pt.unsqueeze(-1).bool().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "present-harvey",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.5688, -0.1369,  2.0314,  0.2374,  0.3746, -1.2605,  0.4525, -0.6086,\n",
       "         2.1494, -1.3149,  1.2698,  0.1092,  0.1596,  0.6734,  0.1225, -0.9097,\n",
       "         0.1927,  0.9456,  1.5768, -1.0985,  0.0094, -0.4810, -1.1770,  0.3579,\n",
       "        -0.7677, -1.8369, -0.7058,  2.0028,  0.7547,  0.2322, -0.3943, -2.1176,\n",
       "         1.1133,  1.7600, -0.0945,  0.8551, -0.2697,  1.1765, -1.7323,  1.1995,\n",
       "        -0.0353, -0.6526,  1.8293,  0.4331,  0.3854,  0.6786, -1.2477,  0.9455,\n",
       "         0.7174, -0.5418, -0.4377, -0.3733, -0.3115,  0.5365, -0.5707, -0.7118,\n",
       "        -0.6033,  1.1990, -2.1197, -1.7821,  0.4774,  0.7284,  0.4489,  2.8216,\n",
       "        -0.2272,  1.2279, -0.8120,  0.2259, -0.3078,  0.7548,  1.3289, -0.1539,\n",
       "        -0.5898, -0.9377,  0.5244,  1.1241, -0.7318, -1.3450,  0.2875, -0.3368,\n",
       "        -1.0886, -0.2456,  1.0493,  0.1633,  2.7832,  1.6036,  0.3745, -0.1218,\n",
       "        -1.0803,  0.9071, -0.3658,  0.3623, -1.2778,  0.9690,  0.6340, -0.8451,\n",
       "         0.5150,  0.4699, -1.4764,  0.4996, -0.1045,  0.6023, -1.5755, -0.2654,\n",
       "         0.5036, -0.4516, -0.8984,  0.5289])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt[padding_mask_pt.unsqueeze(-1).bool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "rotary-burst",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])) with an unsupported type (<class 'torch.Tensor'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-072a0491ee6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding_mask_pt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(x, dtype, name)\u001b[0m\n\u001b[1;32m    700\u001b[0m       \u001b[0;31m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m       \u001b[0;31m# strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1184\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                          as_ref=False):\n\u001b[1;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m   \"\"\"\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (tensor([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])) with an unsupported type (<class 'torch.Tensor'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "tf.gather(x_tf, tf.cast(padding_mask_pt, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "advised-record",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert value torch.float32 to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-39a440c92d78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_tf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpadding_mask_pt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    764\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m       \u001b[0m_check_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[0;31m# * any object with a dtype has a sizeable shape attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m   if (dtype is None or dtypes.as_dtype(dtype) not in _SUPPORTED_SLICE_DTYPES or\n\u001b[0m\u001b[1;32m    652\u001b[0m       idx.shape and len(idx.shape) == 1):\n\u001b[1;32m    653\u001b[0m     \u001b[0;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/tensorflow_core/python/framework/dtypes.py\u001b[0m in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m   raise TypeError(\"Cannot convert value %r to a TensorFlow DType.\" %\n\u001b[0;32m--> 721\u001b[0;31m                   (type_value,))\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert value torch.float32 to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "x_tf[padding_mask_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "drawn-laptop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt[:,[1,2,3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "imperial-township",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(3), Dimension(1)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(x_tf, [1,2,3], axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "appreciated-timing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.index_select(x_pt, 0, torch.from_numpy(np.array([1,2,0]))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "wireless-ceramic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(100), Dimension(1)])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(x_tf, [1,2,0], axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "waiting-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pt.expand(-1, -1, 6).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "incorporated-communication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21, shape=(10, 100, 6), dtype=float32, numpy=\n",
       "array([[[ 0.9153284 ,  0.9153284 ,  0.9153284 ,  0.9153284 ,\n",
       "          0.9153284 ,  0.9153284 ],\n",
       "        [ 0.08095221,  0.08095221,  0.08095221,  0.08095221,\n",
       "          0.08095221,  0.08095221],\n",
       "        [-0.95507604, -0.95507604, -0.95507604, -0.95507604,\n",
       "         -0.95507604, -0.95507604],\n",
       "        ...,\n",
       "        [ 0.13944565,  0.13944565,  0.13944565,  0.13944565,\n",
       "          0.13944565,  0.13944565],\n",
       "        [-0.0308761 , -0.0308761 , -0.0308761 , -0.0308761 ,\n",
       "         -0.0308761 , -0.0308761 ],\n",
       "        [ 1.3147918 ,  1.3147918 ,  1.3147918 ,  1.3147918 ,\n",
       "          1.3147918 ,  1.3147918 ]],\n",
       "\n",
       "       [[-0.7827208 , -0.7827208 , -0.7827208 , -0.7827208 ,\n",
       "         -0.7827208 , -0.7827208 ],\n",
       "        [ 1.3557469 ,  1.3557469 ,  1.3557469 ,  1.3557469 ,\n",
       "          1.3557469 ,  1.3557469 ],\n",
       "        [ 0.3887306 ,  0.3887306 ,  0.3887306 ,  0.3887306 ,\n",
       "          0.3887306 ,  0.3887306 ],\n",
       "        ...,\n",
       "        [ 1.0441831 ,  1.0441831 ,  1.0441831 ,  1.0441831 ,\n",
       "          1.0441831 ,  1.0441831 ],\n",
       "        [ 0.7315912 ,  0.7315912 ,  0.7315912 ,  0.7315912 ,\n",
       "          0.7315912 ,  0.7315912 ],\n",
       "        [ 1.6482099 ,  1.6482099 ,  1.6482099 ,  1.6482099 ,\n",
       "          1.6482099 ,  1.6482099 ]],\n",
       "\n",
       "       [[ 0.26974767,  0.26974767,  0.26974767,  0.26974767,\n",
       "          0.26974767,  0.26974767],\n",
       "        [ 0.05700943,  0.05700943,  0.05700943,  0.05700943,\n",
       "          0.05700943,  0.05700943],\n",
       "        [ 0.04027934,  0.04027934,  0.04027934,  0.04027934,\n",
       "          0.04027934,  0.04027934],\n",
       "        ...,\n",
       "        [ 0.59404784,  0.59404784,  0.59404784,  0.59404784,\n",
       "          0.59404784,  0.59404784],\n",
       "        [ 0.66722274,  0.66722274,  0.66722274,  0.66722274,\n",
       "          0.66722274,  0.66722274],\n",
       "        [ 0.27191845,  0.27191845,  0.27191845,  0.27191845,\n",
       "          0.27191845,  0.27191845]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.10611051,  0.10611051,  0.10611051,  0.10611051,\n",
       "          0.10611051,  0.10611051],\n",
       "        [-0.93901974, -0.93901974, -0.93901974, -0.93901974,\n",
       "         -0.93901974, -0.93901974],\n",
       "        [-0.8249437 , -0.8249437 , -0.8249437 , -0.8249437 ,\n",
       "         -0.8249437 , -0.8249437 ],\n",
       "        ...,\n",
       "        [ 0.5161041 ,  0.5161041 ,  0.5161041 ,  0.5161041 ,\n",
       "          0.5161041 ,  0.5161041 ],\n",
       "        [-0.87839884, -0.87839884, -0.87839884, -0.87839884,\n",
       "         -0.87839884, -0.87839884],\n",
       "        [-1.5346546 , -1.5346546 , -1.5346546 , -1.5346546 ,\n",
       "         -1.5346546 , -1.5346546 ]],\n",
       "\n",
       "       [[-0.8221768 , -0.8221768 , -0.8221768 , -0.8221768 ,\n",
       "         -0.8221768 , -0.8221768 ],\n",
       "        [-0.8104339 , -0.8104339 , -0.8104339 , -0.8104339 ,\n",
       "         -0.8104339 , -0.8104339 ],\n",
       "        [ 0.6772148 ,  0.6772148 ,  0.6772148 ,  0.6772148 ,\n",
       "          0.6772148 ,  0.6772148 ],\n",
       "        ...,\n",
       "        [-0.22541876, -0.22541876, -0.22541876, -0.22541876,\n",
       "         -0.22541876, -0.22541876],\n",
       "        [ 0.8042883 ,  0.8042883 ,  0.8042883 ,  0.8042883 ,\n",
       "          0.8042883 ,  0.8042883 ],\n",
       "        [ 0.5975683 ,  0.5975683 ,  0.5975683 ,  0.5975683 ,\n",
       "          0.5975683 ,  0.5975683 ]],\n",
       "\n",
       "       [[-0.15110521, -0.15110521, -0.15110521, -0.15110521,\n",
       "         -0.15110521, -0.15110521],\n",
       "        [ 1.312111  ,  1.312111  ,  1.312111  ,  1.312111  ,\n",
       "          1.312111  ,  1.312111  ],\n",
       "        [ 0.5831541 ,  0.5831541 ,  0.5831541 ,  0.5831541 ,\n",
       "          0.5831541 ,  0.5831541 ],\n",
       "        ...,\n",
       "        [ 0.17586215,  0.17586215,  0.17586215,  0.17586215,\n",
       "          0.17586215,  0.17586215],\n",
       "        [ 0.6737831 ,  0.6737831 ,  0.6737831 ,  0.6737831 ,\n",
       "          0.6737831 ,  0.6737831 ],\n",
       "        [ 0.76186645,  0.76186645,  0.76186645,  0.76186645,\n",
       "          0.76186645,  0.76186645]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.tile(x_tf, [1, 1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "satisfied-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(10).reshape(5,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "refined-hamilton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [2, 3]]),\n",
       " tensor([[4, 5],\n",
       "         [6, 7]]),\n",
       " tensor([[8, 9]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.split(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "little-fabric",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "start (0) + length (12) exceeds dimension size (5).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1f8dc0e99827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# split_size_or_sections. The branching code is in tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# equivalent to itertools.product(indices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf-1.15/env/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: start (0) + length (12) exceeds dimension size (5)."
     ]
    }
   ],
   "source": [
    "torch.split(a, [12],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-receipt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
