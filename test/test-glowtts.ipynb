{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# import warnings\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:41: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/optimizer/__init__.py:44: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "from malaya_speech.train.model import glowtts\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = malaya_speech.config.fastspeech2_config\n",
    "config['encoder_hidden_size'] = 192\n",
    "config['encoder_num_hidden_layers'] = 6\n",
    "config['encoder_attention_head_size'] = 32\n",
    "config['encoder_intermediate_size'] = 768\n",
    "config = glowtts.Config(vocab_size = 66, **config)\n",
    "config_glowtts = glowtts.Config_GlowTTS(malaya_speech.config.glowtts_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = tf.placeholder(tf.int32, [None, None])\n",
    "i_lengths = tf.placeholder(tf.int32, [None])\n",
    "mel_outputs = tf.placeholder(tf.float32, [None, None, 80])\n",
    "mel_lengths = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mel', 'text_ids', 'len_mel', 'len_text_ids', 'stop_token_target', 'f0', 'len_f0', 'energy', 'len_energy', 'g'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset-mel.pkl', 'rb') as fopen:\n",
    "    data, d = pickle.load(fopen)\n",
    "    \n",
    "with open('dataset-mel-wav.pkl', 'rb') as fopen:\n",
    "    wav = pickle.load(fopen)\n",
    "    \n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_ids'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# i = tf.convert_to_tensor([data['text_ids'][0],data['text_ids'][0]])\n",
    "# i_lengths = tf.convert_to_tensor([data['len_text_ids'][0,0], data['len_text_ids'][0,0]])\n",
    "# mel_outputs = tf.convert_to_tensor([data['mel'].astype(np.float32)[0],data['mel'].astype(np.float32)[0]])\n",
    "# mel_lengths = tf.convert_to_tensor([408,408])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/fastspeech/layer.py:11: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/glowtts/model.py:80: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/glowtts/modules.py:135: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = glowtts.Model(config, config_glowtts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/utils.py:71: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/utils.py:71: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/utils.py:469: The name tf.debugging.assert_equal is deprecated. Please use tf.compat.v1.debugging.assert_equal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/utils.py:469: The name tf.debugging.assert_equal is deprecated. Please use tf.compat.v1.debugging.assert_equal instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor 'glowtts/FlowSpecDecoder/mul_4:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/MatMul_2:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/MatMul_3:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/FlowSpecDecoder/add_35:0' shape=<unknown> dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/transpose_1:0' shape=(?, ?, 1) dtype=float32>),\n",
       " (<tf.Tensor 'glowtts/Encoder/mul:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/Encoder/zeros_like:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/Encoder/ExpandDims:0' shape=(?, ?, 1) dtype=float32>),\n",
       " (<tf.Tensor 'glowtts/ExpandDims_5:0' shape=(?, 1, ?, ?) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/Encoder/ExpandDims_1:0' shape=(?, ?, 1) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts/mul_8:0' shape=(?, ?, 1) dtype=float32>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(i, y = mel_outputs, y_lengths = mel_lengths, training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor 'glowtts_1/FlowSpecDecoder/mul_4:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/MatMul_2:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/MatMul_3:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/FlowSpecDecoder/add_35:0' shape=<unknown> dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/transpose_1:0' shape=(?, ?, 1) dtype=float32>),\n",
       " (<tf.Tensor 'glowtts_1/Encoder/mul:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/Encoder/zeros_like:0' shape=(?, ?, 80) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/Encoder/ExpandDims:0' shape=(?, ?, 1) dtype=float32>),\n",
       " (<tf.Tensor 'glowtts_1/ExpandDims_5:0' shape=(?, 1, ?, ?) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/Encoder/ExpandDims_1:0' shape=(?, ?, 1) dtype=float32>,\n",
       "  <tf.Tensor 'glowtts_1/mul_8:0' shape=(?, ?, 1) dtype=float32>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(z, z_m, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_) = model(i, y = mel_outputs, y_lengths = mel_lengths, training = True)\n",
    "(z, z_m, z_logs, logdet, z_mask), (x_m, x_logs, x_mask), (attn, logw, logw_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commons.mle_loss(z, z_m, z_logs, logdet, z_mask)\n",
    "\n",
    "def mle_loss(z, m, logs, logdet, mask):\n",
    "    l = tf.reduce_sum(logs) + 0.5 * tf.reduce_sum(tf.math.exp(-2 * logs) * ((z - m)**2))\n",
    "    l = l - tf.reduce_sum(logdet)\n",
    "    l = l / tf.reduce_sum(tf.ones_like(z) * mask)\n",
    "    l = l + 0.5 * math.log(2 * math.pi)\n",
    "    return l\n",
    "\n",
    "l_mle = mle_loss(z, z_m, z_logs, logdet, z_mask)\n",
    "l_mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'truediv_1:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# commons.duration_loss(logw, logw_, x_lengths)\n",
    "\n",
    "def duration_loss(logw, logw_, lengths):\n",
    "    # l = torch.sum((logw - logw_)**2) / torch.sum(lengths)\n",
    "    l = tf.reduce_sum((logw - logw_)**2) / tf.reduce_sum(tf.cast(lengths, tf.float32))\n",
    "    return l\n",
    "\n",
    "l_length = duration_loss(logw, logw_, i_lengths)\n",
    "l_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = l_mle + l_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/utils.py:79: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/utils.py:79: The name tf.matrix_inverse is deprecated. Please use tf.linalg.inv instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate = 1e-4).minimize(loss_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9556974, 3.9095027]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_ = sess.run([l_mle, l_length], feed_dict = {i: data['text_ids'],\n",
    "                                   i_lengths: data['len_text_ids'][:,0],\n",
    "                        mel_outputs: data['mel'],\n",
    "                        mel_lengths: data['len_mel'][:,0]})\n",
    "o_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[1., 1., 1., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n",
       " array([[[-1.0855805 ],\n",
       "         [-2.1624827 ],\n",
       "         [-2.2424912 ],\n",
       "         [ 2.9815078 ],\n",
       "         [ 2.369071  ],\n",
       "         [-0.0254643 ],\n",
       "         [ 0.9144008 ],\n",
       "         [ 2.726525  ],\n",
       "         [ 1.1177864 ],\n",
       "         [-0.8327439 ],\n",
       "         [-2.7358584 ],\n",
       "         [-0.62314224],\n",
       "         [-2.6793656 ],\n",
       "         [-1.4983382 ],\n",
       "         [ 2.022946  ],\n",
       "         [-1.7799454 ],\n",
       "         [ 2.964044  ],\n",
       "         [-3.0438938 ],\n",
       "         [ 1.2168528 ],\n",
       "         [-1.6940856 ],\n",
       "         [-1.2651424 ],\n",
       "         [-2.5859165 ],\n",
       "         [ 0.65048265],\n",
       "         [ 1.2858726 ],\n",
       "         [-0.23371303],\n",
       "         [-1.1799268 ],\n",
       "         [ 0.33944398],\n",
       "         [-0.6694351 ],\n",
       "         [ 0.10020971],\n",
       "         [ 1.6052235 ],\n",
       "         [-0.7276659 ],\n",
       "         [ 2.1668248 ],\n",
       "         [-0.490862  ],\n",
       "         [ 2.9816136 ],\n",
       "         [ 1.1758854 ],\n",
       "         [ 0.1434229 ],\n",
       "         [-0.15024436],\n",
       "         [-1.3701739 ],\n",
       "         [-0.4398955 ],\n",
       "         [-0.36513445],\n",
       "         [-0.6510818 ],\n",
       "         [ 1.9733092 ],\n",
       "         [-2.2780046 ],\n",
       "         [ 1.6226574 ],\n",
       "         [ 0.91720015],\n",
       "         [-0.49089587],\n",
       "         [-0.02481496],\n",
       "         [ 5.032892  ],\n",
       "         [-1.9067441 ],\n",
       "         [-2.58255   ],\n",
       "         [-0.32035822],\n",
       "         [-0.7185992 ],\n",
       "         [-1.4495299 ],\n",
       "         [ 1.4545336 ],\n",
       "         [ 1.5059963 ],\n",
       "         [-3.790968  ],\n",
       "         [ 0.4359162 ],\n",
       "         [ 0.92167836],\n",
       "         [ 3.2903578 ],\n",
       "         [-4.2339325 ],\n",
       "         [ 1.1547219 ],\n",
       "         [ 1.9261138 ],\n",
       "         [-1.7196033 ],\n",
       "         [-0.8310281 ],\n",
       "         [-1.7716029 ],\n",
       "         [-2.0707135 ],\n",
       "         [ 0.64470565],\n",
       "         [-0.25926155],\n",
       "         [ 4.090277  ],\n",
       "         [-0.        ],\n",
       "         [-0.        ],\n",
       "         [ 0.        ]]], dtype=float32),\n",
       " array([[[ 1.0986123],\n",
       "         [ 1.0986123],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 2.0794415],\n",
       "         [ 0.       ],\n",
       "         [ 1.609438 ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 2.3978953],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.6931472],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.6931472],\n",
       "         [ 0.       ],\n",
       "         [ 5.7300997],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.6931472],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.6931472],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.6931472],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 1.0986123],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [ 0.       ],\n",
       "         [-0.       ],\n",
       "         [-0.       ],\n",
       "         [-0.       ]]], dtype=float32),\n",
       " array([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]], dtype=float32)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_ = sess.run([attn, logw, logw_, x_mask], feed_dict = {i: data['text_ids'],\n",
    "                                   i_lengths: data['len_text_ids'][:,0],\n",
    "                        mel_outputs: data['mel'],\n",
    "                        mel_lengths: data['len_mel'][:,0]})\n",
    "o_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k in range(300):\n",
    "    print(k, sess.run([optimizer, l_mle, l_length], feed_dict = {i: data['text_ids'],\n",
    "                                       i_lengths: data['len_text_ids'][:,0],\n",
    "                            mel_outputs: data['mel'],\n",
    "                            mel_lengths: data['len_mel'][:,0]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'test/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lh test\n",
    "# !rm -rf test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
