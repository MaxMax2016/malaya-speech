{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "SOURCE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__name__)))\n",
    "sys.path.insert(0, SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.train.model.vits import modules, transforms, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal(shape = (1, 10, 192))\n",
    "x_mask = tf.ones(shape = (1, 10, 1))\n",
    "w = tf.random.normal(shape = (1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = model.StochasticDurationPredictor(192, 192, 3, 0.3, 4, gin_channels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 2) (1, 10, 1)\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/vits/transforms.py:85: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/huseinzolkepli/Documents/malaya-speech/malaya_speech/train/model/vits/transforms.py:225: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "(10,) (10,)\n",
      "(1, 10, 2) (1, 10, 1)\n",
      "(10,) (10,)\n",
      "(1, 10, 2) (1, 10, 1)\n",
      "(10,) (10,)\n",
      "(1, 10, 2) (1, 10, 1)\n",
      "(10,) (10,)\n",
      "(1, 10, 2) (1, 10, 1)\n",
      "(10,) (10,)\n",
      "(1, 10, 2) (1, 10, 1)\n",
      "(3,) (3,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 3 values, but the requested shape has 10 [Op:Reshape]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-090d0b2211f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    897\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/malaya-speech/malaya_speech/train/model/vits/model.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, x_mask, w, g, reverse, noise_scale, training)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mlogdet_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdet_tot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    897\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/malaya-speech/malaya_speech/train/model/vits/modules.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, x_mask, g, reverse, training)\u001b[0m\n\u001b[1;32m    355\u001b[0m                                                                   \u001b[0minverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                                                                   \u001b[0mtails\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m                                                                   \u001b[0mtail_bound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m                                                                   )\n\u001b[1;32m    359\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/malaya-speech/malaya_speech/train/model/vits/transforms.py\u001b[0m in \u001b[0;36mpiecewise_rational_quadratic_transform_tf\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, tails, tail_bound, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmin_bin_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_bin_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmin_derivative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_derivative\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mspline_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     )\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/malaya-speech/malaya_speech/train/model/vits/transforms.py\u001b[0m in \u001b[0;36munconstrained_rational_quadratic_spline_tf\u001b[0;34m(inputs, unnormalized_widths, unnormalized_heights, unnormalized_derivatives, inverse, tails, tail_bound, min_bin_width, min_bin_height, min_derivative)\u001b[0m\n\u001b[1;32m    113\u001b[0m     )\n\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogabsdet_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0moutputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minside_interval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0mlogabsdet_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogabsdet_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minside_interval_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \"\"\"\n\u001b[0;32m--> 131\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8110\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8111\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8112\u001b[0;31m       \u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8113\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8114\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 3 values, but the requested shape has 10 [Op:Reshape]"
     ]
    }
   ],
   "source": [
    "dp(x, x_mask, tf.expand_dims(w, -1), training = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.],\n",
       "        [0.]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Parameter(torch.zeros(channels,1))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m * torch.randn((1, 2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "o += tf.reduce_sum(tf.zeros([1, channels]) * tf.random.normal((1, 10, 2)), axis = [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules.ConvFlow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StochasticDurationPredictor(hidden_channels, 192, 3, 0.5, 4, gin_channels=gin_channels)\n",
    "# def __init__(self, in_channels, filter_channels, kernel_size, p_dropout, n_flows=4, gin_channels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_channels = 192\n",
    "kernel_size = 3\n",
    "convflow = modules.ConvFlow(2, filter_channels, kernel_size, n_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal(shape = (1, 100, 2))\n",
    "x_mask = tf.ones(shape = (1, 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=5157, shape=(1, 100, 2), dtype=float32, numpy=\n",
       "array([[[ 1.5666072 , -2.4329512 ],\n",
       "        [ 0.9565053 ,  0.7426468 ],\n",
       "        [ 0.9703825 ,  0.74713105],\n",
       "        [ 1.1183755 ,  0.5719689 ],\n",
       "        [ 0.12016225, -1.4151428 ],\n",
       "        [ 0.44691294, -1.2847147 ],\n",
       "        [-0.61637676,  0.3745149 ],\n",
       "        [ 0.28276357, -0.10016853],\n",
       "        [-0.0167621 , -0.50790286],\n",
       "        [-0.81279355, -2.5225022 ],\n",
       "        [ 1.9150769 , -0.95889354],\n",
       "        [ 0.3612458 , -0.7331414 ],\n",
       "        [ 0.48345795,  0.6402668 ],\n",
       "        [-1.2884052 ,  0.41396394],\n",
       "        [-2.2541056 ,  1.1267474 ],\n",
       "        [ 0.11691213,  0.61497796],\n",
       "        [ 0.21372145, -1.3142843 ],\n",
       "        [-0.30053446,  1.7102852 ],\n",
       "        [ 0.2008264 ,  0.13372372],\n",
       "        [-0.5892715 ,  0.48494962],\n",
       "        [ 0.58625406,  0.72502786],\n",
       "        [-0.40763742,  0.22599801],\n",
       "        [-0.16812006,  0.6694594 ],\n",
       "        [ 0.37198266, -0.23508203],\n",
       "        [-0.86109346, -0.08036351],\n",
       "        [-0.09207939,  0.1364009 ],\n",
       "        [-1.8958372 , -0.23528218],\n",
       "        [-0.96353906,  0.5241898 ],\n",
       "        [ 0.32585993,  0.2159466 ],\n",
       "        [-0.36992007,  0.235297  ],\n",
       "        [-0.39920914, -0.09593755],\n",
       "        [-1.1672248 , -0.23016483],\n",
       "        [-1.5792913 ,  0.9242062 ],\n",
       "        [ 0.11693151, -1.0576327 ],\n",
       "        [ 1.0303993 ,  1.0695347 ],\n",
       "        [-0.35167238,  0.90632504],\n",
       "        [ 2.3980641 ,  0.20485084],\n",
       "        [ 0.88592994,  2.3950095 ],\n",
       "        [-0.9141022 ,  0.5517139 ],\n",
       "        [-1.397203  ,  0.15908813],\n",
       "        [-0.6154751 ,  1.1258471 ],\n",
       "        [ 0.9379502 ,  0.6896757 ],\n",
       "        [ 0.8356625 ,  0.14453624],\n",
       "        [-0.2815559 , -0.24633235],\n",
       "        [-0.14627066,  0.68984896],\n",
       "        [-0.9784577 ,  0.9051984 ],\n",
       "        [ 1.8311464 ,  0.89322525],\n",
       "        [-0.00436953,  0.82434994],\n",
       "        [-0.2913955 ,  0.2915769 ],\n",
       "        [-0.3005556 ,  0.8748893 ],\n",
       "        [ 0.60687   , -0.5895709 ],\n",
       "        [ 0.13066548,  1.359009  ],\n",
       "        [-2.0371432 ,  1.4594074 ],\n",
       "        [-0.16000056, -0.10183638],\n",
       "        [ 1.3242931 , -0.16100824],\n",
       "        [-2.9103878 , -0.23520511],\n",
       "        [-0.0817306 ,  0.16308288],\n",
       "        [ 0.63802195,  0.4515296 ],\n",
       "        [-0.30405617,  0.39383122],\n",
       "        [ 0.9943537 , -0.11261362],\n",
       "        [-0.02771535, -0.09191948],\n",
       "        [ 0.114461  , -1.4350178 ],\n",
       "        [ 0.794507  , -0.3099658 ],\n",
       "        [ 0.77172   , -1.3468347 ],\n",
       "        [-1.9925917 ,  0.9175597 ],\n",
       "        [ 0.29711384, -0.04187989],\n",
       "        [ 0.8863586 ,  0.5040297 ],\n",
       "        [ 2.5062168 ,  1.288007  ],\n",
       "        [-1.1734703 ,  0.7398101 ],\n",
       "        [-0.074788  , -0.41680306],\n",
       "        [-0.97870857,  1.2407576 ],\n",
       "        [ 0.42564073,  0.41684613],\n",
       "        [-0.09987252, -0.5712608 ],\n",
       "        [ 0.06145861,  1.6761894 ],\n",
       "        [ 0.59357524, -1.3098035 ],\n",
       "        [ 0.94475144, -1.0386426 ],\n",
       "        [-2.0270185 ,  1.5804884 ],\n",
       "        [-0.22918943, -0.51585114],\n",
       "        [-0.13242623,  1.445109  ],\n",
       "        [-0.97454834, -0.32566345],\n",
       "        [-0.10542113,  0.23042165],\n",
       "        [ 0.02212391,  0.44022724],\n",
       "        [-2.0187047 , -0.97543734],\n",
       "        [ 0.50848734, -1.9687744 ],\n",
       "        [ 0.42194828,  0.6649147 ],\n",
       "        [-0.5557753 , -1.3231723 ],\n",
       "        [-1.4652473 ,  1.3340213 ],\n",
       "        [ 0.87852085, -0.5451687 ],\n",
       "        [-0.14796688, -1.6849171 ],\n",
       "        [-1.0623555 ,  1.1263595 ],\n",
       "        [ 1.3146648 , -1.8624549 ],\n",
       "        [ 1.6364596 ,  0.5484715 ],\n",
       "        [ 0.7562297 ,  0.47200307],\n",
       "        [-0.97388995,  0.84779143],\n",
       "        [-1.1555318 , -0.22951788],\n",
       "        [-1.4858409 ,  0.24105936],\n",
       "        [ 0.0540045 ,  0.82895684],\n",
       "        [ 0.53995854, -1.3993876 ],\n",
       "        [-0.41567418,  0.38102344],\n",
       "        [-0.2895029 , -1.654239  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convflow(x, x_mask, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,unnormalized_widths, unnormalized_heights, unnormalized_derivatives = convflow(x, x_mask, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_pt = torch.from_numpy(x1.numpy())\n",
    "unnormalized_widths_pt = torch.from_numpy(unnormalized_widths.numpy())\n",
    "unnormalized_heights_pt = torch.from_numpy(unnormalized_heights.numpy())\n",
    "unnormalized_derivatives_pt = torch.from_numpy(unnormalized_derivatives.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEFAULT_MIN_BIN_WIDTH = 1e-3\n",
    "DEFAULT_MIN_BIN_HEIGHT = 1e-3\n",
    "DEFAULT_MIN_DERIVATIVE = 1e-3\n",
    "\n",
    "\n",
    "def piecewise_rational_quadratic_transform_tf(inputs,\n",
    "                                           unnormalized_widths,\n",
    "                                           unnormalized_heights,\n",
    "                                           unnormalized_derivatives,\n",
    "                                           inverse=False,\n",
    "                                           tails=None,\n",
    "                                           tail_bound=1.,\n",
    "                                           min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "                                           min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "                                           min_derivative=DEFAULT_MIN_DERIVATIVE):\n",
    "\n",
    "    if tails is None:\n",
    "        spline_fn = rational_quadratic_spline_tf\n",
    "        spline_kwargs = {}\n",
    "    else:\n",
    "        spline_fn = unconstrained_rational_quadratic_spline_tf\n",
    "        spline_kwargs = {\n",
    "            'tails': tails,\n",
    "            'tail_bound': tail_bound\n",
    "        }\n",
    "\n",
    "    outputs, logabsdet = spline_fn_tf(\n",
    "        inputs=inputs,\n",
    "        unnormalized_widths=unnormalized_widths,\n",
    "        unnormalized_heights=unnormalized_heights,\n",
    "        unnormalized_derivatives=unnormalized_derivatives,\n",
    "        inverse=inverse,\n",
    "        min_bin_width=min_bin_width,\n",
    "        min_bin_height=min_bin_height,\n",
    "        min_derivative=min_derivative,\n",
    "        **spline_kwargs\n",
    "    )\n",
    "    return outputs, logabsdet\n",
    "\n",
    "\n",
    "def searchsorted_tf(bin_locations, inputs, eps=1e-6):\n",
    "    bin_locations = tf.concat([\n",
    "        bin_locations[..., :-1],\n",
    "        tf.expand_dims(bin_locations[..., -1] + 1e-6, -1)], axis=-1)\n",
    "    return tf.reduce_sum(\n",
    "        tf.cast(inputs[..., None] >= bin_locations, tf.int32),\n",
    "        axis=-1\n",
    "    ) - 1\n",
    "\n",
    "\n",
    "def unconstrained_rational_quadratic_spline_tf(inputs,\n",
    "                                            unnormalized_widths,\n",
    "                                            unnormalized_heights,\n",
    "                                            unnormalized_derivatives,\n",
    "                                            inverse=False,\n",
    "                                            tails='linear',\n",
    "                                            tail_bound=1.,\n",
    "                                            min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "                                            min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "                                            min_derivative=DEFAULT_MIN_DERIVATIVE):\n",
    "    inside_interval_mask = (inputs >= -tail_bound) & (inputs <= tail_bound)\n",
    "    outside_interval_mask = ~inside_interval_mask\n",
    "\n",
    "    outputs = tf.zeros_like(inputs)\n",
    "    logabsdet = tf.zeros_like(inputs)\n",
    "\n",
    "    if tails == 'linear':\n",
    "        unnormalized_derivatives = tf.pad(unnormalized_derivatives, [(0, 0), (0, 0), (0, 0), (1, 1)])\n",
    "        constant = np.log(np.exp(1 - min_derivative) - 1)\n",
    "\n",
    "        unnormalized_derivatives = tf.concat([\n",
    "            tf.expand_dims(unnormalized_derivatives[..., 0] + constant, -1),\n",
    "            unnormalized_derivatives[..., 1:-1],\n",
    "            tf.expand_dims(unnormalized_derivatives[..., -1] + constant, -1),\n",
    "        ], axis=-1)\n",
    "\n",
    "        # outputs[outside_interval_mask] = inputs[outside_interval_mask]\n",
    "        # logabsdet[outside_interval_mask] = 0\n",
    "\n",
    "        outputs = tf.where(outside_interval_mask, inputs, outputs)\n",
    "        tiled = tf.fill(tf.shape(logabsdet), 0.0)\n",
    "        logabsdet = tf.where(outside_interval_mask, tiled, logabsdet)\n",
    "    else:\n",
    "        raise RuntimeError(f'{tails} tails are not implemented.')\n",
    "\n",
    "    d = tf.shape(unnormalized_widths)[-1]\n",
    "    unnormalized_widths = unnormalized_widths[tf.tile(tf.expand_dims(inside_interval_mask, -1), [1, 1, 1, d])]\n",
    "    unnormalized_widths = tf.reshape(unnormalized_widths, [-1, d])\n",
    "\n",
    "    d = tf.shape(unnormalized_heights)[-1]\n",
    "    unnormalized_heights = unnormalized_heights[tf.tile(tf.expand_dims(inside_interval_mask, -1), [1, 1, 1, d])]\n",
    "    unnormalized_heights = tf.reshape(unnormalized_heights, [-1, d])\n",
    "\n",
    "    d = tf.shape(unnormalized_derivatives)[-1]\n",
    "    unnormalized_derivatives = unnormalized_derivatives[tf.tile(tf.expand_dims(inside_interval_mask, -1), [1, 1, 1, d])]\n",
    "    unnormalized_derivatives = tf.reshape(unnormalized_derivatives, [-1, d])\n",
    "\n",
    "    return rational_quadratic_spline_tf(\n",
    "        inputs=inputs[inside_interval_mask],\n",
    "        unnormalized_widths=unnormalized_widths,\n",
    "        unnormalized_heights=unnormalized_heights,\n",
    "        unnormalized_derivatives=unnormalized_derivatives,\n",
    "        inverse=inverse,\n",
    "        left=-tail_bound, right=tail_bound, bottom=-tail_bound, top=tail_bound,\n",
    "        min_bin_width=min_bin_width,\n",
    "        min_bin_height=min_bin_height,\n",
    "        min_derivative=min_derivative\n",
    "    )\n",
    "    outputs_ = tf.reshape(outputs_, tf.shape(inside_interval_mask))\n",
    "    logabsdet_ = tf.reshape(logabsdet_, tf.shape(inside_interval_mask))\n",
    "\n",
    "    outputs = tf.where(inside_interval_mask, outputs_, outputs)\n",
    "    logabsdet = tf.where(inside_interval_mask, logabsdet_, logabsdet)\n",
    "\n",
    "    return outputs, logabsdet\n",
    "\n",
    "\n",
    "def rational_quadratic_spline_tf(inputs,\n",
    "                              unnormalized_widths,\n",
    "                              unnormalized_heights,\n",
    "                              unnormalized_derivatives,\n",
    "                              inverse=False,\n",
    "                              left=0., right=1., bottom=0., top=1.,\n",
    "                              min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "                              min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "                              min_derivative=DEFAULT_MIN_DERIVATIVE):\n",
    "\n",
    "    num_bins = tf.shape(unnormalized_widths)[-1]\n",
    "\n",
    "    widths = tf.nn.softmax(unnormalized_widths, axis=-1)\n",
    "    widths = min_bin_width + (1 - min_bin_width * tf.cast(num_bins, tf.float32)) * widths\n",
    "    cumwidths = tf.cumsum(widths, axis=-1)\n",
    "    cumwidths = tf.pad(cumwidths, [[0, 0], [1, 0]])\n",
    "    cumwidths = (right - left) * cumwidths + left\n",
    "\n",
    "    # cumwidths[..., 0] = left\n",
    "    # cumwidths[..., -1] = right\n",
    "\n",
    "    cumwidths = tf.concat([\n",
    "        tf.expand_dims(tf.fill(tf.shape(cumwidths[..., 0]), left), -1),\n",
    "        cumwidths[..., 1:-1],\n",
    "        tf.expand_dims(tf.fill(tf.shape(cumwidths[..., -1]), right), -1),\n",
    "    ], axis=-1)\n",
    "    widths = cumwidths[..., 1:] - cumwidths[..., :-1]\n",
    "\n",
    "    derivatives = min_derivative + tf.math.softplus(unnormalized_derivatives)\n",
    "\n",
    "    heights = tf.nn.softmax(unnormalized_heights, axis=-1)\n",
    "    heights = min_bin_height + (1 - min_bin_height * tf.cast(num_bins, tf.float32)) * heights\n",
    "    cumheights = tf.cumsum(heights, axis=-1)\n",
    "    cumheights = tf.pad(cumheights, [[0, 0], [1, 0]])\n",
    "    cumheights = (top - bottom) * cumheights + bottom\n",
    "\n",
    "    # cumheights[..., 0] = bottom\n",
    "    # cumheights[..., -1] = top\n",
    "\n",
    "    cumheights = tf.concat([\n",
    "        tf.expand_dims(tf.fill(tf.shape(cumheights[..., 0]), bottom), -1),\n",
    "        cumheights[..., 1:-1],\n",
    "        tf.expand_dims(tf.fill(tf.shape(cumheights[..., -1]), top), -1),\n",
    "    ], axis=-1)\n",
    "\n",
    "    heights = cumheights[..., 1:] - cumheights[..., :-1]\n",
    "\n",
    "    if inverse:\n",
    "        bin_idx = searchsorted_tf(cumheights, inputs)[..., None]\n",
    "    else:\n",
    "        bin_idx = searchsorted_tf(cumwidths, inputs)[..., None]\n",
    "\n",
    "    input_cumwidths = tf.gather_nd(cumwidths, bin_idx, batch_dims=1)\n",
    "    input_bin_widths = tf.gather_nd(widths, bin_idx, batch_dims=1)\n",
    "\n",
    "    input_cumheights = tf.gather_nd(cumheights, bin_idx, batch_dims=1)\n",
    "    delta = heights / widths\n",
    "    input_delta = tf.gather_nd(delta, bin_idx, batch_dims=1)\n",
    "\n",
    "    input_derivatives = tf.gather_nd(derivatives, bin_idx, batch_dims=1)\n",
    "    input_derivatives_plus_one = tf.gather_nd(derivatives[..., 1:], bin_idx, batch_dims=1)\n",
    "\n",
    "    input_heights = tf.gather_nd(heights, bin_idx, batch_dims=1)\n",
    "\n",
    "    if inverse:\n",
    "        a = (((inputs - input_cumheights) * (input_derivatives\n",
    "                                             + input_derivatives_plus_one\n",
    "                                             - 2 * input_delta)\n",
    "              + input_heights * (input_delta - input_derivatives)))\n",
    "        b = (input_heights * input_derivatives\n",
    "             - (inputs - input_cumheights) * (input_derivatives\n",
    "                                              + input_derivatives_plus_one\n",
    "                                              - 2 * input_delta))\n",
    "        c = - input_delta * (inputs - input_cumheights)\n",
    "\n",
    "        discriminant = (b ** 2) - 4 * a * c\n",
    "\n",
    "        root = (2 * c) / (-b - tf.sqrt(discriminant))\n",
    "        outputs = root * input_bin_widths + input_cumwidths\n",
    "\n",
    "        theta_one_minus_theta = root * (1 - root)\n",
    "        denominator = input_delta + ((input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "                                     * theta_one_minus_theta)\n",
    "        derivative_numerator = (input_delta ** 2) * (input_derivatives_plus_one * (root**2)\n",
    "                                                     + 2 * input_delta * theta_one_minus_theta\n",
    "                                                     + input_derivatives * ((1 - root)**2))\n",
    "        logabsdet = tf.log(derivative_numerator) - 2 * tf.log(denominator)\n",
    "        return outputs, -logabsdet\n",
    "    else:\n",
    "        theta = (inputs - input_cumwidths) / input_bin_widths\n",
    "        theta_one_minus_theta = theta * (1 - theta)\n",
    "\n",
    "        numerator = input_heights * (input_delta * (theta**2)\n",
    "                                     + input_derivatives * theta_one_minus_theta)\n",
    "        denominator = input_delta + ((input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "                                     * theta_one_minus_theta)\n",
    "        outputs = input_cumheights + numerator / denominator\n",
    "\n",
    "        derivative_numerator = (input_delta**2) * (input_derivatives_plus_one * (theta**2)\n",
    "                                                   + 2 * input_delta * theta_one_minus_theta\n",
    "                                                   + input_derivatives * ((1 - theta)**2))\n",
    "        logabsdet = tf.log(derivative_numerator) - 2 * tf.log(denominator)\n",
    "\n",
    "        return outputs, logabsdet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEFAULT_MIN_BIN_WIDTH = 1e-3\n",
    "DEFAULT_MIN_BIN_HEIGHT = 1e-3\n",
    "DEFAULT_MIN_DERIVATIVE = 1e-3\n",
    "\n",
    "\n",
    "def piecewise_rational_quadratic_transform(inputs, \n",
    "                                           unnormalized_widths,\n",
    "                                           unnormalized_heights,\n",
    "                                           unnormalized_derivatives,\n",
    "                                           inverse=False,\n",
    "                                           tails=None, \n",
    "                                           tail_bound=1.,\n",
    "                                           min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "                                           min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "                                           min_derivative=DEFAULT_MIN_DERIVATIVE):\n",
    "\n",
    "    if tails is None:\n",
    "        spline_fn = rational_quadratic_spline\n",
    "        spline_kwargs = {}\n",
    "    else:\n",
    "        spline_fn = unconstrained_rational_quadratic_spline\n",
    "        spline_kwargs = {\n",
    "            'tails': tails,\n",
    "            'tail_bound': tail_bound\n",
    "        }\n",
    "\n",
    "    outputs, logabsdet = spline_fn(\n",
    "            inputs=inputs,\n",
    "            unnormalized_widths=unnormalized_widths,\n",
    "            unnormalized_heights=unnormalized_heights,\n",
    "            unnormalized_derivatives=unnormalized_derivatives,\n",
    "            inverse=inverse,\n",
    "            min_bin_width=min_bin_width,\n",
    "            min_bin_height=min_bin_height,\n",
    "            min_derivative=min_derivative,\n",
    "            **spline_kwargs\n",
    "    )\n",
    "    return outputs, logabsdet\n",
    "\n",
    "\n",
    "def searchsorted(bin_locations, inputs, eps=1e-6):\n",
    "    bin_locations[..., -1] += eps\n",
    "    return torch.sum(\n",
    "        inputs[..., None] >= bin_locations,\n",
    "        dim=-1\n",
    "    ) - 1\n",
    "\n",
    "\n",
    "def unconstrained_rational_quadratic_spline(inputs,\n",
    "                                            unnormalized_widths,\n",
    "                                            unnormalized_heights,\n",
    "                                            unnormalized_derivatives,\n",
    "                                            inverse=False,\n",
    "                                            tails='linear',\n",
    "                                            tail_bound=1.,\n",
    "                                            min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "                                            min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "                                            min_derivative=DEFAULT_MIN_DERIVATIVE):\n",
    "    inside_interval_mask = (inputs >= -tail_bound) & (inputs <= tail_bound)\n",
    "    outside_interval_mask = ~inside_interval_mask\n",
    "\n",
    "    outputs = torch.zeros_like(inputs)\n",
    "    logabsdet = torch.zeros_like(inputs)\n",
    "\n",
    "    if tails == 'linear':\n",
    "        unnormalized_derivatives = F.pad(unnormalized_derivatives, pad=(1, 1))\n",
    "        constant = np.log(np.exp(1 - min_derivative) - 1)\n",
    "        unnormalized_derivatives[..., 0] = constant\n",
    "        unnormalized_derivatives[..., -1] = constant\n",
    "\n",
    "        outputs[outside_interval_mask] = inputs[outside_interval_mask]\n",
    "        logabsdet[outside_interval_mask] = 0\n",
    "    else:\n",
    "        raise RuntimeError('{} tails are not implemented.'.format(tails))\n",
    "\n",
    "    return rational_quadratic_spline(\n",
    "        inputs=inputs[inside_interval_mask],\n",
    "        unnormalized_widths=unnormalized_widths[inside_interval_mask, :],\n",
    "        unnormalized_heights=unnormalized_heights[inside_interval_mask, :],\n",
    "        unnormalized_derivatives=unnormalized_derivatives[inside_interval_mask, :],\n",
    "        inverse=inverse,\n",
    "        left=-tail_bound, right=tail_bound, bottom=-tail_bound, top=tail_bound,\n",
    "        min_bin_width=min_bin_width,\n",
    "        min_bin_height=min_bin_height,\n",
    "        min_derivative=min_derivative\n",
    "    )\n",
    "\n",
    "    return outputs, logabsdet\n",
    "\n",
    "def rational_quadratic_spline(inputs,\n",
    "                              unnormalized_widths,\n",
    "                              unnormalized_heights,\n",
    "                              unnormalized_derivatives,\n",
    "                              inverse=False,\n",
    "                              left=0., right=1., bottom=0., top=1.,\n",
    "                              min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "                              min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "                              min_derivative=DEFAULT_MIN_DERIVATIVE):\n",
    "    if torch.min(inputs) < left or torch.max(inputs) > right:\n",
    "        raise ValueError('Input to a transform is not within its domain')\n",
    "\n",
    "    num_bins = unnormalized_widths.shape[-1]\n",
    "\n",
    "    if min_bin_width * num_bins > 1.0:\n",
    "        raise ValueError('Minimal bin width too large for the number of bins')\n",
    "    if min_bin_height * num_bins > 1.0:\n",
    "        raise ValueError('Minimal bin height too large for the number of bins')\n",
    "\n",
    "    widths = F.softmax(unnormalized_widths, dim=-1)\n",
    "    widths = min_bin_width + (1 - min_bin_width * num_bins) * widths\n",
    "    cumwidths = torch.cumsum(widths, dim=-1)\n",
    "    cumwidths = F.pad(cumwidths, pad=(1, 0), mode='constant', value=0.0)\n",
    "    cumwidths = (right - left) * cumwidths + left\n",
    "    cumwidths[..., 0] = left\n",
    "    cumwidths[..., -1] = right\n",
    "    widths = cumwidths[..., 1:] - cumwidths[..., :-1]\n",
    "\n",
    "    derivatives = min_derivative + F.softplus(unnormalized_derivatives)\n",
    "\n",
    "    heights = F.softmax(unnormalized_heights, dim=-1)\n",
    "    heights = min_bin_height + (1 - min_bin_height * num_bins) * heights\n",
    "    cumheights = torch.cumsum(heights, dim=-1)\n",
    "    cumheights = F.pad(cumheights, pad=(1, 0), mode='constant', value=0.0)\n",
    "    cumheights = (top - bottom) * cumheights + bottom\n",
    "    cumheights[..., 0] = bottom\n",
    "    cumheights[..., -1] = top\n",
    "    heights = cumheights[..., 1:] - cumheights[..., :-1]\n",
    "\n",
    "    if inverse:\n",
    "        bin_idx = searchsorted(cumheights, inputs)[..., None]\n",
    "    else:\n",
    "        bin_idx = searchsorted(cumwidths, inputs)[..., None]\n",
    "\n",
    "    input_cumwidths = cumwidths.gather(-1, bin_idx)[..., 0]\n",
    "    input_bin_widths = widths.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_cumheights = cumheights.gather(-1, bin_idx)[..., 0]\n",
    "    delta = heights / widths\n",
    "    input_delta = delta.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_derivatives = derivatives.gather(-1, bin_idx)[..., 0]\n",
    "    input_derivatives_plus_one = derivatives[..., 1:].gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_heights = heights.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    if inverse:\n",
    "        a = (((inputs - input_cumheights) * (input_derivatives\n",
    "                                             + input_derivatives_plus_one\n",
    "                                             - 2 * input_delta)\n",
    "              + input_heights * (input_delta - input_derivatives)))\n",
    "        b = (input_heights * input_derivatives\n",
    "             - (inputs - input_cumheights) * (input_derivatives\n",
    "                                              + input_derivatives_plus_one\n",
    "                                              - 2 * input_delta))\n",
    "        c = - input_delta * (inputs - input_cumheights)\n",
    "\n",
    "        discriminant = b.pow(2) - 4 * a * c\n",
    "        assert (discriminant >= 0).all()\n",
    "\n",
    "        root = (2 * c) / (-b - torch.sqrt(discriminant))\n",
    "        outputs = root * input_bin_widths + input_cumwidths\n",
    "\n",
    "        theta_one_minus_theta = root * (1 - root)\n",
    "        denominator = input_delta + ((input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "                                     * theta_one_minus_theta)\n",
    "        derivative_numerator = input_delta.pow(2) * (input_derivatives_plus_one * root.pow(2)\n",
    "                                                     + 2 * input_delta * theta_one_minus_theta\n",
    "                                                     + input_derivatives * (1 - root).pow(2))\n",
    "        logabsdet = torch.log(derivative_numerator) - 2 * torch.log(denominator)\n",
    "\n",
    "        return outputs, -logabsdet\n",
    "    else:\n",
    "        theta = (inputs - input_cumwidths) / input_bin_widths\n",
    "        theta_one_minus_theta = theta * (1 - theta)\n",
    "\n",
    "        numerator = input_heights * (input_delta * theta.pow(2)\n",
    "                                     + input_derivatives * theta_one_minus_theta)\n",
    "        denominator = input_delta + ((input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "                                     * theta_one_minus_theta)\n",
    "        outputs = input_cumheights + numerator / denominator\n",
    "\n",
    "        derivative_numerator = input_delta.pow(2) * (input_derivatives_plus_one * theta.pow(2)\n",
    "                                                     + 2 * input_delta * theta_one_minus_theta\n",
    "                                                     + input_derivatives * (1 - theta).pow(2))\n",
    "        logabsdet = torch.log(derivative_numerator) - 2 * torch.log(denominator)\n",
    "\n",
    "        return outputs, logabsdet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = unconstrained_rational_quadratic_spline_tf(x1,unnormalized_widths, unnormalized_heights, unnormalized_derivatives,\n",
    "                                              inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_ = unconstrained_rational_quadratic_spline(x1_pt,\n",
    "                                               unnormalized_widths_pt, \n",
    "                                               unnormalized_heights_pt, \n",
    "                                               unnormalized_derivatives_pt,\n",
    "                                            inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05678736, -0.0098166 ,  0.01044229,  0.0735354 , -0.13982725,\n",
       "       -0.03779516, -0.0739321 , -0.03838192, -0.059025  , -0.15811585,\n",
       "        0.2956113 , -0.1489464 , -0.09486258,  0.13871124, -0.1059899 ,\n",
       "        0.10900342,  0.00734042, -0.09219503, -0.00995589,  0.06337629,\n",
       "        0.20660332,  0.204175  , -0.12512851,  0.072561  , -0.00676407,\n",
       "       -0.0847249 , -0.16315411, -0.15471725,  0.20482239, -0.05685115,\n",
       "        0.10210255, -0.08964671, -0.15427431, -0.15324904,  0.09378422,\n",
       "       -0.01161253,  0.17617188, -0.13418545, -0.11416645,  0.27521446,\n",
       "       -0.1041963 , -0.01744099, -0.09826891, -0.16538204, -0.1498066 ,\n",
       "       -0.13355224,  0.21563107,  0.05228442,  0.32177058,  0.1965512 ,\n",
       "       -0.08011378, -0.14907351, -0.16229387, -0.08457458, -0.14544663,\n",
       "       -0.14124686, -0.14556038,  0.10976223, -0.15190524,  0.253829  ,\n",
       "       -0.08667484, -0.13336745, -0.10382208, -0.04184897, -0.15833366,\n",
       "        0.04673608, -0.16403833, -0.12818797, -0.10544764,  0.01236355,\n",
       "        0.2598064 , -0.13642217, -0.13454539, -0.16583793], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05678749, -0.0098166 ,  0.01044229,  0.07353435, -0.13982715,\n",
       "       -0.03779517, -0.07393204, -0.03838255, -0.05902572, -0.15811591,\n",
       "        0.29561293, -0.1489464 , -0.09486258,  0.13871126, -0.1059899 ,\n",
       "        0.10900281,  0.00734036, -0.09219503, -0.00995589,  0.06337596,\n",
       "        0.20660332,  0.20417497, -0.1251285 ,  0.07256101, -0.00676407,\n",
       "       -0.08472489, -0.16315414, -0.15471706,  0.20482239, -0.05685115,\n",
       "        0.10210252, -0.08964673, -0.15427394, -0.15324941,  0.09378422,\n",
       "       -0.01161253,  0.17617188, -0.1341853 , -0.11416645,  0.27521303,\n",
       "       -0.10419588, -0.01744106, -0.09826925, -0.16538204, -0.1498064 ,\n",
       "       -0.13355221,  0.21563256,  0.05228443,  0.32177058,  0.1965512 ,\n",
       "       -0.08011378, -0.14907353, -0.16229387, -0.08457451, -0.14544664,\n",
       "       -0.14124684, -0.14556038,  0.10976223, -0.15190522,  0.253829  ,\n",
       "       -0.08667539, -0.13336746, -0.10382172, -0.04184894, -0.15833366,\n",
       "        0.04673606, -0.16403833, -0.12818809, -0.10544764,  0.01236439,\n",
       "        0.25980496, -0.13642187, -0.13454539, -0.16583793], dtype=float32)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
