{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('mkdir tacotron2-yasmin-alignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:6: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/attention.py:4: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import malaya_speech.train\n",
    "from malaya_speech.train.model import tacotron2_nvidia as tacotron2\n",
    "import malaya_speech.config\n",
    "import numpy as np\n",
    "import json\n",
    "import malaya_speech.train as train\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_mean_std(x, mean, std):\n",
    "    zero_idxs = np.where(x == 0.0)[0]\n",
    "    x = (x - mean) / std\n",
    "    x[zero_idxs] = 0.0\n",
    "    return x\n",
    "\n",
    "def average_by_duration(x, durs):\n",
    "    mel_len = durs.sum()\n",
    "    durs_cum = np.cumsum(np.pad(durs, (1, 0)))\n",
    "    \n",
    "    x_char = np.zeros((durs.shape[0],), dtype=np.float32)\n",
    "    for idx, start, end in zip(range(mel_len), durs_cum[:-1], durs_cum[1:]):\n",
    "        values = x[start:end][np.where(x[start:end] != 0.0)[0]]\n",
    "        x_char[idx] = np.mean(values) if len(values) > 0 else 0.0\n",
    "\n",
    "    return x_char.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_stat = np.load('../speech-bahasa/yasmin-stats/stats_f0.npy')\n",
    "energy_stat = np.load('../speech-bahasa/yasmin-stats/stats_energy.npy')\n",
    "mel_stat = np.load('../speech-bahasa/yasmin-stats/stats.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mels-yasmin.json') as fopen:\n",
    "    files = json.load(fopen)\n",
    "    \n",
    "reduction_factor = 1\n",
    "maxlen = 1280\n",
    "minlen = 32\n",
    "pad_to = 8\n",
    "data_min = 1e-2\n",
    "\n",
    "_pad = 'pad'\n",
    "_start = 'start'\n",
    "_eos = 'eos'\n",
    "_punctuation = \"!'(),.:;? \"\n",
    "_special = '-'\n",
    "_letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "MALAYA_SPEECH_SYMBOLS = (\n",
    "    [_pad, _start, _eos] + list(_special) + list(_punctuation) + list(_letters)\n",
    ")\n",
    "\n",
    "def generate(files):\n",
    "    for f in files:\n",
    "        f = f.decode()\n",
    "        mel = np.load(f)\n",
    "        mel_length = len(mel)\n",
    "        \n",
    "        if mel_length > maxlen or mel_length < minlen:\n",
    "            continue\n",
    "            \n",
    "        mel = norm_mean_std(mel, mel_stat[0], mel_stat[1])\n",
    "\n",
    "        stop_token_target = np.zeros([len(mel)], dtype = np.float32)\n",
    "\n",
    "        text_ids = np.load(f.replace('mels', 'text_ids'), allow_pickle=True)[\n",
    "            0\n",
    "        ]\n",
    "        text_ids = ''.join([c for c in text_ids if c in MALAYA_SPEECH_SYMBOLS])\n",
    "        text_ids = re.sub(r'[ ]+', ' ', text_ids).strip()\n",
    "        text_input = np.array(\n",
    "            [\n",
    "                MALAYA_SPEECH_SYMBOLS.index(c)\n",
    "                for c in text_ids\n",
    "            ]\n",
    "        )\n",
    "        num_pad = pad_to - ((len(text_input) + 2) % pad_to)\n",
    "        text_input = np.pad(\n",
    "            text_input, ((1, 1)), 'constant', constant_values = ((1, 2))\n",
    "        )\n",
    "        text_input = np.pad(\n",
    "            text_input, ((0, num_pad)), 'constant', constant_values = 0\n",
    "        )\n",
    "        num_pad = pad_to - ((len(mel) + 1) % pad_to) + 1\n",
    "        pad_value_mel = np.log(data_min)\n",
    "        mel = np.pad(\n",
    "            mel,\n",
    "            ((0, num_pad), (0, 0)),\n",
    "            'constant',\n",
    "            constant_values = pad_value_mel,\n",
    "        )\n",
    "        stop_token_target = np.pad(\n",
    "            stop_token_target, ((0, num_pad)), 'constant', constant_values = 1\n",
    "        )\n",
    "        len_mel = [len(mel)]\n",
    "        len_text_ids = [len(text_input)]\n",
    "        \n",
    "        \n",
    "        f0 = np.load(f.replace('mels', 'f0s'))\n",
    "        num_pad = pad_to - ((len(f0) + 1) % pad_to) + 1\n",
    "        f0 = np.pad(\n",
    "            f0,\n",
    "            ((0, num_pad)),\n",
    "            'constant',\n",
    "        )\n",
    "        f0 = norm_mean_std(f0, f0_stat[0], f0_stat[1])\n",
    "        len_f0 = [len(f0)]\n",
    "        \n",
    "        energy = np.load(f.replace('mels', 'energies'))\n",
    "        num_pad = pad_to - ((len(energy) + 1) % pad_to) + 1\n",
    "        energy = np.pad(\n",
    "            energy,\n",
    "            ((0, num_pad)),\n",
    "            'constant',\n",
    "        )\n",
    "        energy = norm_mean_std(energy, energy_stat[0], energy_stat[1])\n",
    "        len_energy = [len(energy)]\n",
    "        \n",
    "        \n",
    "        yield {\n",
    "            'mel': mel,\n",
    "            'text_ids': text_input,\n",
    "            'len_mel': len_mel,\n",
    "            'len_text_ids': len_text_ids,\n",
    "            'stop_token_target': stop_token_target,\n",
    "            'f0': f0,\n",
    "            'len_f0': len_f0,\n",
    "            'energy': energy,\n",
    "            'len_energy': len_energy,\n",
    "            'f': [f]\n",
    "        }\n",
    "\n",
    "def parse(example):\n",
    "    mel_len = example['len_mel'][0]\n",
    "    input_len = example['len_text_ids'][0]\n",
    "    g = tacotron2.generate_guided_attention(mel_len, input_len, reduction_factor = reduction_factor)\n",
    "    example['g'] = g\n",
    "    return example\n",
    "    \n",
    "    \n",
    "def get_dataset(files, batch_size = 32, shuffle_size = 32, thread_count = 24):\n",
    "    def get():\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generate,\n",
    "            {\n",
    "                'mel': tf.float32,\n",
    "                'text_ids': tf.int32,\n",
    "                'len_mel': tf.int32,\n",
    "                'len_text_ids': tf.int32,\n",
    "                'stop_token_target': tf.float32,\n",
    "                'f0': tf.float32,\n",
    "                'len_f0': tf.int32,\n",
    "                'energy': tf.float32,\n",
    "                'len_energy': tf.int32,\n",
    "                'f': tf.string\n",
    "            },\n",
    "            output_shapes = {\n",
    "                'mel': tf.TensorShape([None, 80]),\n",
    "                'text_ids': tf.TensorShape([None]),\n",
    "                'len_mel': tf.TensorShape([1]),\n",
    "                'len_text_ids': tf.TensorShape([1]),\n",
    "                'stop_token_target': tf.TensorShape([None]),\n",
    "                'f0': tf.TensorShape([None]),\n",
    "                'len_f0': tf.TensorShape([1]),\n",
    "                'energy': tf.TensorShape([None]),\n",
    "                'len_energy': tf.TensorShape([1]),\n",
    "                'f': tf.TensorShape([1]),\n",
    "            },\n",
    "            args = (files,),\n",
    "        )\n",
    "        dataset = dataset.map(parse, num_parallel_calls = thread_count)\n",
    "        dataset = dataset.padded_batch(\n",
    "            shuffle_size,\n",
    "            padded_shapes = {\n",
    "                'mel': tf.TensorShape([None, 80]),\n",
    "                'text_ids': tf.TensorShape([None]),\n",
    "                'len_mel': tf.TensorShape([1]),\n",
    "                'len_text_ids': tf.TensorShape([1]),\n",
    "                'g': tf.TensorShape([None, None]),\n",
    "                'stop_token_target': tf.TensorShape([None]),\n",
    "                'f0': tf.TensorShape([None]),\n",
    "                'len_f0': tf.TensorShape([1]),\n",
    "                'energy': tf.TensorShape([None]),\n",
    "                'len_energy': tf.TensorShape([1]),\n",
    "                'f': tf.TensorShape([1]),\n",
    "            },\n",
    "            padding_values = {\n",
    "                'mel': tf.constant(0, dtype = tf.float32),\n",
    "                'text_ids': tf.constant(0, dtype = tf.int32),\n",
    "                'len_mel': tf.constant(0, dtype = tf.int32),\n",
    "                'len_text_ids': tf.constant(0, dtype = tf.int32),\n",
    "                'g': tf.constant(-1.0, dtype = tf.float32),\n",
    "                'stop_token_target': tf.constant(0, dtype = tf.float32),\n",
    "                'f0': tf.constant(0, dtype = tf.float32),\n",
    "                'len_f0': tf.constant(0, dtype = tf.int32),\n",
    "                'energy': tf.constant(0, dtype = tf.float32),\n",
    "                'len_energy': tf.constant(0, dtype = tf.int32),\n",
    "                'f': tf.constant('', dtype = tf.string),\n",
    "            },\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-8c3208f117e4>:2: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "features = get_dataset(files['test'])()\n",
    "features = features.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = features['text_ids']\n",
    "input_lengths = features['len_text_ids'][:, 0]\n",
    "speaker_ids = tf.constant([0], dtype = tf.int32)\n",
    "mel_outputs = features['mel']\n",
    "mel_lengths = features['len_mel'][:, 0]\n",
    "guided = features['g']\n",
    "stop_token_target = features['stop_token_target']\n",
    "batch_size = tf.shape(guided)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/abstract.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:60: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:340: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:358: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:129: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/rnn.py:111: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:205: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:236: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:958: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn_cell_impl.py:962: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/encoder.py:255: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/decoder.py:496: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/tacotron2_nvidia/decoder.py:412: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = tacotron2.Model(\n",
    "    [input_ids, input_lengths],\n",
    "    [mel_outputs, mel_lengths],\n",
    "    len(MALAYA_SPEECH_SYMBOLS),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = model.decoder_logits['outputs']\n",
    "decoder_output, post_mel_outputs, alignment_histories, _, _, _ = r\n",
    "stop_token_predictions = model.decoder_logits['stop_token_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tacotron2-yasmin/model.ckpt-60000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'tacotron2-yasmin'\n",
    "ckpt_path = tf.train.latest_checkpoint(path)\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from tacotron2-yasmin/model.ckpt-60000\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x):\n",
    "    return ''.join([MALAYA_SPEECH_SYMBOLS[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration_from_alignment(alignment):\n",
    "    D = np.array([0 for _ in range(np.shape(alignment)[0])])\n",
    "\n",
    "    for i in range(np.shape(alignment)[1]):\n",
    "        max_index = list(alignment[:, i]).index(alignment[:, i].max())\n",
    "        D[max_index] = D[max_index] + 1\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "while True:\n",
    "    try:\n",
    "        o = sess.run([decoder_output, post_mel_outputs, stop_token_predictions, alignment_histories, features])\n",
    "        f = o[-1]\n",
    "        for i in range(len(f['f'])):\n",
    "            file = f['f'][i,0].decode().replace('../speech-bahasa/', '').replace('/', '-')\n",
    "            file = f'tacotron2-yasmin-alignment/{file}'\n",
    "            len_mel = f['len_mel'][i, 0]\n",
    "            len_text_ids = f['len_text_ids'][i, 0]\n",
    "            d = get_duration_from_alignment(o[3][i, :len_text_ids, :len_mel])\n",
    "            assert d.sum() == len_mel\n",
    "            np.save(file, d)\n",
    "        count += 1\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419M\ttacotron2-yasmin-alignment\r\n"
     ]
    }
   ],
   "source": [
    "!du -hs tacotron2-yasmin-alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105890"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('tacotron2-yasmin-alignment/*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
