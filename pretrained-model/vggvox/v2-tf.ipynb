{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation, Conv1D, Conv2D, Input, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block_2D(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "\n",
    "    conv_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce'\n",
    "    bn_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce/bn'\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_1)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3'\n",
    "    bn_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3/bn'\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_2)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_2)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase'\n",
    "    bn_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase/bn'\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_3)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_3)(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_2D(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "\n",
    "    conv_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce'\n",
    "    bn_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce/bn'\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               strides=strides,\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_1)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3'\n",
    "    bn_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3/bn'\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_2)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_2)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase'\n",
    "    bn_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase/bn'\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_3)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_3)(x)\n",
    "\n",
    "    conv_name_4 = 'conv' + str(stage) + '_' + str(block) + '_1x1_proj'\n",
    "    bn_name_4 = 'conv' + str(stage) + '_' + str(block) + '_1x1_proj/bn'\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      kernel_initializer='orthogonal',\n",
    "                      use_bias=False,\n",
    "                      trainable=trainable,\n",
    "                      kernel_regularizer=l2(weight_decay),\n",
    "                      name=conv_name_4)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_4)(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_2D_v1(inputs, mode='train'):\n",
    "    bn_axis = 3\n",
    "#     if mode == 'train':\n",
    "#         inputs = Input(shape=input_dim, name='input')\n",
    "#     else:\n",
    "#         inputs = Input(shape=(input_dim[0], None, input_dim[-1]), name='input')\n",
    "    # ===============================================\n",
    "    #            Convolution Block 1\n",
    "    # ===============================================\n",
    "    x1 = Conv2D(64, (7, 7),\n",
    "                kernel_initializer='orthogonal',\n",
    "                use_bias=False, trainable=True,\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                padding='same',\n",
    "                name='conv1_1/3x3_s1')(inputs)\n",
    "\n",
    "    x1 = BatchNormalization(axis=bn_axis, name='conv1_1/3x3_s1/bn', trainable=True)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2), strides=(2, 2))(x1)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 2\n",
    "    # ===============================================\n",
    "    x2 = conv_block_2D(x1, 3, [48, 48, 96], stage=2, block='a', strides=(1, 1), trainable=True)\n",
    "    x2 = identity_block_2D(x2, 3, [48, 48, 96], stage=2, block='b', trainable=True)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 3\n",
    "    # ===============================================\n",
    "    x3 = conv_block_2D(x2, 3, [96, 96, 128], stage=3, block='a', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [96, 96, 128], stage=3, block='b', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [96, 96, 128], stage=3, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 4\n",
    "    # ===============================================\n",
    "    x4 = conv_block_2D(x3, 3, [128, 128, 256], stage=4, block='a', trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [128, 128, 256], stage=4, block='b', trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [128, 128, 256], stage=4, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 5\n",
    "    # ===============================================\n",
    "    x5 = conv_block_2D(x4, 3, [256, 256, 512], stage=5, block='a', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [256, 256, 512], stage=5, block='b', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [256, 256, 512], stage=5, block='c', trainable=True)\n",
    "    y = MaxPooling2D((3, 1), strides=(2, 1), name='mpool2')(x5)\n",
    "    return inputs, y\n",
    "\n",
    "\n",
    "def resnet_2D_v2(inputs, mode='train'):\n",
    "    bn_axis = 3\n",
    "#     if mode == 'train':\n",
    "#         inputs = Input(shape=input_dim, name='input')\n",
    "#     else:\n",
    "#         inputs = Input(shape=(input_dim[0], None, input_dim[-1]), name='input')\n",
    "    # ===============================================\n",
    "    #            Convolution Block 1\n",
    "    # ===============================================\n",
    "    x1 = Conv2D(64, (7, 7), strides=(2, 2),\n",
    "                kernel_initializer='orthogonal',\n",
    "                use_bias=False, trainable=True,\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                padding='same',\n",
    "                name='conv1_1/3x3_s1')(inputs)\n",
    "\n",
    "    x1 = BatchNormalization(axis=bn_axis, name='conv1_1/3x3_s1/bn', trainable=True)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2), strides=(2, 2))(x1)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 2\n",
    "    # ===============================================\n",
    "    x2 = conv_block_2D(x1, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable=True)\n",
    "    x2 = identity_block_2D(x2, 3, [64, 64, 256], stage=2, block='b', trainable=True)\n",
    "    x2 = identity_block_2D(x2, 3, [64, 64, 256], stage=2, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 3\n",
    "    # ===============================================\n",
    "    x3 = conv_block_2D(x2, 3, [128, 128, 512], stage=3, block='a', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [128, 128, 512], stage=3, block='b', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [128, 128, 512], stage=3, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 4\n",
    "    # ===============================================\n",
    "    x4 = conv_block_2D(x3, 3, [256, 256, 1024], stage=4, block='a', strides=(1, 1), trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [256, 256, 1024], stage=4, block='b', trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [256, 256, 1024], stage=4, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 5\n",
    "    # ===============================================\n",
    "    x5 = conv_block_2D(x4, 3, [512, 512, 2048], stage=5, block='a', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [512, 512, 2048], stage=5, block='b', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [512, 512, 2048], stage=5, block='c', trainable=True)\n",
    "    y = MaxPooling2D((3, 1), strides=(2, 1), name='mpool2')(x5)\n",
    "    return inputs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VladPooling(keras.layers.Layer):\n",
    "    '''\n",
    "    This layer follows the NetVlad, GhostVlad\n",
    "    '''\n",
    "    def __init__(self, mode, k_centers, g_centers=0, **kwargs):\n",
    "        self.k_centers = k_centers\n",
    "        self.g_centers = g_centers\n",
    "        self.mode = mode\n",
    "        super(VladPooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.cluster = self.add_weight(shape=[self.k_centers+self.g_centers, input_shape[0][-1]],\n",
    "                                       name='centers',\n",
    "                                       initializer='orthogonal')\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape\n",
    "        return (input_shape[0][0], self.k_centers*input_shape[0][-1])\n",
    "\n",
    "    def call(self, x):\n",
    "        # feat : bz x W x H x D, cluster_score: bz X W x H x clusters.\n",
    "        feat, cluster_score = x\n",
    "        num_features = feat.shape[-1]\n",
    "\n",
    "        # softmax normalization to get soft-assignment.\n",
    "        # A : bz x W x H x clusters\n",
    "        max_cluster_score = K.max(cluster_score, -1, keepdims=True)\n",
    "        exp_cluster_score = K.exp(cluster_score - max_cluster_score)\n",
    "        A = exp_cluster_score / K.sum(exp_cluster_score, axis=-1, keepdims = True)\n",
    "\n",
    "        # Now, need to compute the residual, self.cluster: clusters x D\n",
    "        A = K.expand_dims(A, -1)    # A : bz x W x H x clusters x 1\n",
    "        feat_broadcast = K.expand_dims(feat, -2)    # feat_broadcast : bz x W x H x 1 x D\n",
    "        feat_res = feat_broadcast - self.cluster    # feat_res : bz x W x H x clusters x D\n",
    "        weighted_res = tf.multiply(A, feat_res)     # weighted_res : bz x W x H x clusters x D\n",
    "        cluster_res = K.sum(weighted_res, [1, 2])\n",
    "\n",
    "        if self.mode == 'gvlad':\n",
    "            cluster_res = cluster_res[:, :self.k_centers, :]\n",
    "\n",
    "        cluster_l2 = K.l2_normalize(cluster_res, -1)\n",
    "        outputs = K.reshape(cluster_l2, [-1, int(self.k_centers) * int(num_features)])\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def vggvox_resnet2d_icassp(inputs, num_class=8631, mode='train', args=None):\n",
    "    \n",
    "    # python predict.py --gpu 1 --net resnet34s --ghost_cluster 2 \n",
    "    # --vlad_cluster 8 --loss softmax --resume\n",
    "    \n",
    "    net='resnet34s'\n",
    "    loss='softmax'\n",
    "    vlad_clusters=8\n",
    "    ghost_clusters=2\n",
    "    bottleneck_dim=512\n",
    "    aggregation = 'gvlad'\n",
    "    mgpu = 0\n",
    "\n",
    "    if net == 'resnet34s':\n",
    "        inputs, x = resnet_2D_v1(inputs, mode=mode)\n",
    "    else:\n",
    "        inputs, x = resnet_2D_v2(inputs, mode=mode)\n",
    "    print(x)\n",
    "    # ===============================================\n",
    "    #            Fully Connected Block 1\n",
    "    # ===============================================\n",
    "    x_fc = keras.layers.Conv2D(bottleneck_dim, (7, 1),\n",
    "                               strides=(1, 1),\n",
    "                               activation='relu',\n",
    "                               kernel_initializer='orthogonal',\n",
    "                               use_bias=True, trainable=True,\n",
    "                               kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               name='x_fc')(x)\n",
    "    print(x_fc)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Feature Aggregation\n",
    "    # ===============================================\n",
    "    if aggregation == 'avg':\n",
    "        if mode == 'train':\n",
    "            x = keras.layers.AveragePooling2D((1, 5), strides=(1, 1), name='avg_pool')(x)\n",
    "            x = keras.layers.Reshape((-1, bottleneck_dim))(x)\n",
    "        else:\n",
    "            x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "            x = keras.layers.Reshape((1, bottleneck_dim))(x)\n",
    "\n",
    "    elif aggregation == 'vlad':\n",
    "        x_k_center = keras.layers.Conv2D(vlad_clusters, (7, 1),\n",
    "                                         strides=(1, 1),\n",
    "                                         kernel_initializer='orthogonal',\n",
    "                                         use_bias=True, trainable=True,\n",
    "                                         kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         name='vlad_center_assignment')(x)\n",
    "        x = VladPooling(k_centers=vlad_clusters, mode='vlad', name='vlad_pool')([x_fc, x_k_center])\n",
    "\n",
    "    elif aggregation == 'gvlad':\n",
    "        x_k_center = keras.layers.Conv2D(vlad_clusters+ghost_clusters, (7, 1),\n",
    "                                         strides=(1, 1),\n",
    "                                         kernel_initializer='orthogonal',\n",
    "                                         use_bias=True, trainable=True,\n",
    "                                         kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         name='gvlad_center_assignment')(x)\n",
    "        print(x_k_center)\n",
    "        x = VladPooling(k_centers=vlad_clusters, g_centers=ghost_clusters, mode='gvlad', name='gvlad_pool')([x_fc, x_k_center])\n",
    "        print(x)\n",
    "\n",
    "    else:\n",
    "        raise IOError('==> unknown aggregation mode')\n",
    "\n",
    "    # ===============================================\n",
    "    #            Fully Connected Block 2\n",
    "    # ===============================================\n",
    "    x = keras.layers.Dense(bottleneck_dim, activation='relu',\n",
    "                           kernel_initializer='orthogonal',\n",
    "                           use_bias=True, trainable=True,\n",
    "                           kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                           bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                           name='fc6')(x)\n",
    "    \n",
    "    x_l2 = keras.layers.Lambda(lambda x: K.l2_normalize(x, 1))(x)\n",
    "    y = keras.layers.Dense(num_class,\n",
    "                           kernel_initializer='orthogonal',\n",
    "                           use_bias=False, trainable=True,\n",
    "                           kernel_constraint=keras.constraints.unit_norm(),\n",
    "                           kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                           bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                           name='prediction')(x_l2)\n",
    "\n",
    "    if mode == 'eval':\n",
    "        y = keras.layers.Lambda(lambda x: keras.backend.l2_normalize(x, 1))(x)\n",
    "        \n",
    "    return y\n",
    "\n",
    "#     model = keras.models.Model(inputs, y, name='vggvox_resnet2D_{}_{}'.format(loss, aggregation))\n",
    "\n",
    "#     if mode == 'train':\n",
    "#         if mgpu > 1:\n",
    "#             model = ModelMGPU(model, gpus=mgpu)\n",
    "#         # set up optimizer.\n",
    "#         if args.optimizer == 'adam':  opt = keras.optimizers.Adam(lr=1e-3)\n",
    "#         elif args.optimizer =='sgd':  opt = keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=True)\n",
    "#         else: raise IOError('==> unknown optimizer type')\n",
    "#         model.compile(optimizer=opt, loss=trnloss, metrics=['acc'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 257, None, 1])\n",
    "        \n",
    "        params = {'dim': (257, None, 1),\n",
    "            'nfft': 512,\n",
    "            'spec_len': 250,\n",
    "            'win_length': 400,\n",
    "            'hop_length': 160,\n",
    "            'n_classes': 5994,\n",
    "            'sampling_rate': 16000,\n",
    "            'normalize': True,\n",
    "        }\n",
    "        self.logits = vggvox_resnet2d_icassp(self.X, num_class=2, mode='train')\n",
    "        self.logits = tf.identity(self.logits, name = 'logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'v2/vggvox.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"mpool2/MaxPool:0\", shape=(?, 7, ?, 512), dtype=float32)\n",
      "Tensor(\"x_fc/Relu:0\", shape=(?, 1, ?, 512), dtype=float32)\n",
      "Tensor(\"gvlad_center_assignment/BiasAdd:0\", shape=(?, 1, ?, 10), dtype=float32)\n",
      "Tensor(\"gvlad_pool/Reshape:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'logits:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "var_lists = [v for v in var_lists if 'prediction' not in v.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv1_1/3x3_s1/kernel:0' shape=(7, 7, 1, 64) dtype=float32>,\n",
       " <tf.Variable 'conv1_1/3x3_s1/bn/gamma:0' shape=(64,) dtype=float32>,\n",
       " <tf.Variable 'conv1_1/3x3_s1/bn/beta:0' shape=(64,) dtype=float32>,\n",
       " <tf.Variable 'conv1_1/3x3_s1/bn/moving_mean:0' shape=(64,) dtype=float32>,\n",
       " <tf.Variable 'conv1_1/3x3_s1/bn/moving_variance:0' shape=(64,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_reduce/kernel:0' shape=(1, 1, 64, 48) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_reduce/bn/gamma:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_reduce/bn/beta:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_reduce/bn/moving_mean:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_reduce/bn/moving_variance:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_3x3/kernel:0' shape=(3, 3, 48, 48) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_3x3/bn/gamma:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_3x3/bn/beta:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_3x3/bn/moving_mean:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_3x3/bn/moving_variance:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_increase/kernel:0' shape=(1, 1, 48, 96) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_increase/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_increase/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_increase/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_increase/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_proj/kernel:0' shape=(1, 1, 64, 96) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_proj/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_proj/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_proj/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_a_1x1_proj/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_reduce/kernel:0' shape=(1, 1, 96, 48) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_reduce/bn/gamma:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_reduce/bn/beta:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_reduce/bn/moving_mean:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_reduce/bn/moving_variance:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_3x3/kernel:0' shape=(3, 3, 48, 48) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_3x3/bn/gamma:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_3x3/bn/beta:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_3x3/bn/moving_mean:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_3x3/bn/moving_variance:0' shape=(48,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_increase/kernel:0' shape=(1, 1, 48, 96) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_increase/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_increase/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_increase/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv2_b_1x1_increase/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_reduce/kernel:0' shape=(1, 1, 96, 96) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_reduce/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_reduce/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_reduce/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_reduce/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_3x3/kernel:0' shape=(3, 3, 96, 96) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_3x3/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_3x3/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_3x3/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_3x3/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_increase/kernel:0' shape=(1, 1, 96, 128) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_increase/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_increase/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_increase/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_increase/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_proj/kernel:0' shape=(1, 1, 96, 128) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_proj/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_proj/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_proj/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_a_1x1_proj/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_reduce/kernel:0' shape=(1, 1, 128, 96) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_reduce/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_reduce/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_reduce/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_reduce/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_3x3/kernel:0' shape=(3, 3, 96, 96) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_3x3/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_3x3/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_3x3/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_3x3/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_increase/kernel:0' shape=(1, 1, 96, 128) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_increase/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_increase/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_increase/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_b_1x1_increase/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_reduce/kernel:0' shape=(1, 1, 128, 96) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_reduce/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_reduce/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_reduce/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_reduce/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_3x3/kernel:0' shape=(3, 3, 96, 96) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_3x3/bn/gamma:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_3x3/bn/beta:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_3x3/bn/moving_mean:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_3x3/bn/moving_variance:0' shape=(96,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_increase/kernel:0' shape=(1, 1, 96, 128) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_increase/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_increase/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_increase/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv3_c_1x1_increase/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_reduce/kernel:0' shape=(1, 1, 128, 128) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_reduce/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_reduce/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_3x3/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_3x3/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_3x3/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_3x3/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_increase/kernel:0' shape=(1, 1, 128, 256) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_increase/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_increase/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_proj/kernel:0' shape=(1, 1, 128, 256) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_proj/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_proj/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_proj/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_a_1x1_proj/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_reduce/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_reduce/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_3x3/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_3x3/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_3x3/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_3x3/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_increase/kernel:0' shape=(1, 1, 128, 256) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_increase/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_b_1x1_increase/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_reduce/kernel:0' shape=(1, 1, 256, 128) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_reduce/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_reduce/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_reduce/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_reduce/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_3x3/kernel:0' shape=(3, 3, 128, 128) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_3x3/bn/gamma:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_3x3/bn/beta:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_3x3/bn/moving_mean:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_3x3/bn/moving_variance:0' shape=(128,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_increase/kernel:0' shape=(1, 1, 128, 256) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_increase/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_increase/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_increase/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv4_c_1x1_increase/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_reduce/kernel:0' shape=(1, 1, 256, 256) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_reduce/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_reduce/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_3x3/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_3x3/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_3x3/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_3x3/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_increase/kernel:0' shape=(1, 1, 256, 512) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_increase/bn/moving_mean:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_increase/bn/moving_variance:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_proj/kernel:0' shape=(1, 1, 256, 512) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_proj/bn/gamma:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_proj/bn/beta:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_proj/bn/moving_mean:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_a_1x1_proj/bn/moving_variance:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_reduce/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_reduce/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_3x3/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_3x3/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_3x3/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_3x3/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_increase/kernel:0' shape=(1, 1, 256, 512) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_increase/bn/moving_mean:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_b_1x1_increase/bn/moving_variance:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_reduce/kernel:0' shape=(1, 1, 512, 256) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_reduce/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_reduce/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_reduce/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_reduce/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_3x3/kernel:0' shape=(3, 3, 256, 256) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_3x3/bn/gamma:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_3x3/bn/beta:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_3x3/bn/moving_mean:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_3x3/bn/moving_variance:0' shape=(256,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_increase/kernel:0' shape=(1, 1, 256, 512) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_increase/bn/gamma:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_increase/bn/beta:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_increase/bn/moving_mean:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'conv5_c_1x1_increase/bn/moving_variance:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'x_fc/kernel:0' shape=(7, 1, 512, 512) dtype=float32>,\n",
       " <tf.Variable 'x_fc/bias:0' shape=(512,) dtype=float32>,\n",
       " <tf.Variable 'gvlad_center_assignment/kernel:0' shape=(7, 1, 512, 10) dtype=float32>,\n",
       " <tf.Variable 'gvlad_center_assignment/bias:0' shape=(10,) dtype=float32>,\n",
       " <tf.Variable 'gvlad_pool/centers:0' shape=(10, 512) dtype=float32>,\n",
       " <tf.Variable 'fc6/kernel:0' shape=(4096, 512) dtype=float32>,\n",
       " <tf.Variable 'fc6/bias:0' shape=(512,) dtype=float32>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from v2/vggvox.ckpt\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# ===============================================\n",
    "#       code from Arsha for loading data.\n",
    "# ===============================================\n",
    "def load_wav(vid_path, sr, mode='train'):\n",
    "    wav, sr_ret = librosa.load(vid_path, sr=sr)\n",
    "    assert sr_ret == sr\n",
    "    if mode == 'train':\n",
    "        extended_wav = np.append(wav, wav)\n",
    "        if np.random.random() < 0.3:\n",
    "            extended_wav = extended_wav[::-1]\n",
    "        return extended_wav\n",
    "    else:\n",
    "        extended_wav = np.append(wav, wav[::-1])\n",
    "        return extended_wav\n",
    "\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=1024):\n",
    "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
    "    return linear.T\n",
    "\n",
    "\n",
    "def load_data(wav, win_length=400, sr=16000, hop_length=160, n_fft=512, spec_len=250, mode='train'):\n",
    "    # wav = load_wav(path, sr=sr, mode=mode)\n",
    "    linear_spect = lin_spectogram_from_wav(wav, hop_length, win_length, n_fft)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    mag_T = mag.T\n",
    "    freq, time = mag_T.shape\n",
    "    if mode == 'train':\n",
    "        if time < spec_len:\n",
    "            spec_mag = np.pad(mag_T, ((0, 0), (0, spec_len - time)), 'constant')\n",
    "        else:\n",
    "            spec_mag = mag_T\n",
    "    else:\n",
    "        spec_mag = mag_T\n",
    "    # preprocessing, subtract mean, divided by time-wise var\n",
    "    mu = np.mean(spec_mag, 0, keepdims=True)\n",
    "    std = np.std(spec_mag, 0, keepdims=True)\n",
    "    return (spec_mag - mu) / (std + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 1001)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(np.random.normal(size = (16000 * 10))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "files = glob('data/wav/enroll/*.wav')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(257, 2538), (257, 3006), (257, 1936)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "files = glob('data/wav/enroll/*.wav')\n",
    "wavs = [load_data(wav, mode = 'eval') for wav in files]\n",
    "[wav.shape for wav in wavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pred(x):\n",
    "    return sess.run(model.logits, feed_dict = {model.X: np.expand_dims([x], -1)})\n",
    "\n",
    "r = [pred(wav) for wav in wavs]\n",
    "r = np.concatenate(r)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.62801496e-01, 3.06282490e-01],\n",
       "       [3.62801496e-01, 2.22044605e-16, 3.22202758e-01],\n",
       "       [3.06282490e-01, 3.22202758e-01, 2.22044605e-16]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "cdist(r, r, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "files = glob('../voxceleb/aac/**/*.m4a', recursive = True)\n",
    "files = random.sample(files, 10000)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test-*.wav pickle-*.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:30<00:00,  1.33it/s]\n",
      "100%|██████████| 200/200 [02:30<00:00,  1.37it/s]\n",
      " 98%|█████████▊| 197/200 [02:30<00:02,  1.45it/s]\n",
      "100%|██████████| 200/200 [02:31<00:00,  1.32it/s]\n",
      " 98%|█████████▊| 195/200 [02:31<00:03,  1.32it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.32it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      " 98%|█████████▊| 197/200 [02:32<00:02,  1.22it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.10it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      " 98%|█████████▊| 197/200 [02:32<00:02,  1.22it/s]\n",
      "100%|██████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      "100%|█████████▉| 199/200 [02:33<00:00,  1.24it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.31it/s]\n",
      "100%|█████████▉| 199/200 [02:33<00:00,  1.26it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      " 99%|█████████▉| 198/200 [02:33<00:01,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.30it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:34<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.29it/s]\n",
      "100%|██████████| 200/200 [02:35<00:00,  1.28it/s]\n",
      "100%|██████████| 200/200 [02:42<00:00,  1.23it/s]\n",
      "100%|██████████| 200/200 [02:43<00:00,  1.22it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-30218d411244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mfiles_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/vggvox-speaker-identification/mp.py\u001b[0m in \u001b[0;36mmultiprocessing\u001b[0;34m(strings, function, cores, returned)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpooled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import mp\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def loop(args):\n",
    "    files = args[0]\n",
    "    index = args[1]\n",
    "    results = []\n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        audio = AudioSegment.from_file(file[1])\n",
    "        audio.set_frame_rate(16000).set_channels(1).export(f'test-{index}.wav', format=\"wav\")\n",
    "        l = load_data(f'test-{index}.wav', mode = 'eval')\n",
    "        results.append((file[0], file[1], l))\n",
    "        \n",
    "    with open(f'pickle-{index}.pkl', 'wb') as fopen:\n",
    "        pickle.dump(results, fopen)\n",
    "\n",
    "files_index = [(no, f) for no, f in enumerate(files)]\n",
    "r = mp.multiprocessing(files_index, loop, cores = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test-*.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../voxceleb/vox2_meta.csv')\n",
    "df = df[df['Set '] == 'test ']\n",
    "speakers = df['VoxCeleb2 ID '].unique().tolist()\n",
    "speakers = [s.strip() for s in speakers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "speakers_idx = defaultdict(list)\n",
    "\n",
    "for speaker in speakers:\n",
    "    for file in files:\n",
    "        if speaker in file:\n",
    "            speakers_idx[speaker].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:17<00:00, 566.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "k = 10\n",
    "labels = []\n",
    "\n",
    "def get_id(file):\n",
    "    return file.split('/')[3]\n",
    "\n",
    "for file in tqdm(files):\n",
    "    left_speaker = get_id(file)\n",
    "    for speaker in speakers:\n",
    "        if left_speaker == speaker:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        samples = random.sample(speakers_idx[speaker], min(k, len(speakers_idx[speaker])))\n",
    "        for s in samples:\n",
    "            labels.append((label, file, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "\n",
    "pickles = glob('pickle-*.pkl')\n",
    "\n",
    "pooled = []\n",
    "for p in pickles:\n",
    "    with open(p, 'rb') as fopen:\n",
    "        pooled.append(pickle.load(fopen))\n",
    "        \n",
    "pooled = list(itertools.chain(*pooled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:36<00:00, 36.11it/s]\n"
     ]
    }
   ],
   "source": [
    "mapping = {i[1]: pred(i[2]) for i in tqdm(pooled)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11710000/11710000 [02:17<00:00, 85377.21it/s]\n"
     ]
    }
   ],
   "source": [
    "scores, ls = [], []\n",
    "\n",
    "for i in tqdm(range(len(labels))):\n",
    "    ls.append(labels[i][0])\n",
    "    scores.append(np.sum(mapping[labels[i][1]][0] * mapping[labels[i][2]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eer(y, y_score):\n",
    "    \n",
    "    from scipy.optimize import brentq\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.044729718189581553, array(0.76060986))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_eer(ls, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
