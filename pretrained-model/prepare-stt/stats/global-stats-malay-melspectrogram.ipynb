{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`pyaudio` is not available, `malaya_speech.streaming.stream` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import torch\n",
    "from malaya_speech.utils import torch_featurization\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _ = malaya_speech.load('speech/singlish/singlish0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalayaDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    SR = 16000\n",
    "\n",
    "    def __init__(self, file):\n",
    "        with open(file) as fopen:\n",
    "            self.data = json.load(fopen)\n",
    "        self.audio = Audio(sampling_rate=self.SR)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data['X'][idx]\n",
    "        y = self.data['Y'][idx]\n",
    "\n",
    "        r = self.audio.decode_example(self.audio.encode_example(x))\n",
    "        return r['array']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MalayaDataset('/home/husein/speech-bahasa/malay-asr-train-shuffled.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_statistics(samples):\n",
    "    E_x = 0\n",
    "    E_x_2 = 0\n",
    "    N = 0\n",
    "\n",
    "    for idx, sample in tqdm(enumerate(samples)):\n",
    "        mel_spec = torch_featurization.melspectrogram(sample[0].squeeze())\n",
    "        scaled_mel_spec = torch_featurization.piecewise_linear_log(mel_spec)\n",
    "        sum = scaled_mel_spec.sum(0)\n",
    "        sq_sum = scaled_mel_spec.pow(2).sum(0)\n",
    "        M = scaled_mel_spec.size(0)\n",
    "\n",
    "        E_x = E_x * (N / (N + M)) + sum / (N + M)\n",
    "        E_x_2 = E_x_2 * (N / (N + M)) + sq_sum / (N + M)\n",
    "        N += M\n",
    "\n",
    "    return E_x, (E_x_2 - E_x**2) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "79562it [15:30, 17.56it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "470801it [1:38:27, 111.28it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "873675it [3:00:37, 101.93it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "1223281it [4:28:41, 72.82it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "1538138it [5:58:54, 12.32it/s] IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean, stddev = generate_statistics(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = json.dumps({\"mean\": mean.tolist(), \"invstddev\": (1 / stddev).tolist()}, indent=2)\n",
    "with open('malay-stats.json', \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
