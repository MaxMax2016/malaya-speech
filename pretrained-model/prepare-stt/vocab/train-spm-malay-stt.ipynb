{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/husein/speech-bahasa/malay-asr-train-shuffled.json') as fopen:\n",
    "    data = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('malay-tts.txt', 'w') as fopen:\n",
    "    fopen.write('\\n'.join(data['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: malay-tts.txt\n",
      "  input_format: \n",
      "  model_prefix: malay-tts\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1023\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 1\n",
      "  input_sentence_size: 18446744073709551615\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 0\n",
      "  eos_id: 2\n",
      "  pad_id: 1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(319) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(174) LOG(INFO) Loading corpus: malay-tts.txt\n",
      "trainer_interface.cc(136) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(113) LOG(WARNING) Too many sentences are loaded! (1635599), which may slow down training.\n",
      "trainer_interface.cc(115) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(118) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(375) LOG(INFO) Loaded all 1635599 sentences\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(390) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(395) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(456) LOG(INFO) all chars count=110068328\n",
      "trainer_interface.cc(477) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(478) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(510) LOG(INFO) Done! preprocessed 1635599 sentences.\n",
      "unigram_model_trainer.cc(138) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(142) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(193) LOG(INFO) Initialized 168506 seed sentencepieces\n",
      "trainer_interface.cc(516) LOG(INFO) Tokenizing input sentences with whitespace: 1635599\n",
      "trainer_interface.cc(526) LOG(INFO) Done! 105918\n",
      "unigram_model_trainer.cc(488) LOG(INFO) Using 105918 sentences for EM training\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=74947 obj=9.8485 num_tokens=202413 num_tokens/piece=2.70075\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=54129 obj=7.84111 num_tokens=199592 num_tokens/piece=3.68734\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=40588 obj=7.76155 num_tokens=203829 num_tokens/piece=5.0219\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=40518 obj=7.7486 num_tokens=203988 num_tokens/piece=5.0345\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=30388 obj=7.7557 num_tokens=219388 num_tokens/piece=7.21956\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=30385 obj=7.75234 num_tokens=219388 num_tokens/piece=7.22027\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=22788 obj=7.77396 num_tokens=239311 num_tokens/piece=10.5016\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=22788 obj=7.76865 num_tokens=239262 num_tokens/piece=10.4995\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=17091 obj=7.81309 num_tokens=260628 num_tokens/piece=15.2494\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=17091 obj=7.80336 num_tokens=260559 num_tokens/piece=15.2454\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=12818 obj=7.87885 num_tokens=281689 num_tokens/piece=21.976\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=12818 obj=7.86331 num_tokens=281637 num_tokens/piece=21.972\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=9613 obj=7.97927 num_tokens=302048 num_tokens/piece=31.4208\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=9613 obj=7.95603 num_tokens=302021 num_tokens/piece=31.418\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=7209 obj=8.11564 num_tokens=321389 num_tokens/piece=44.5816\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=7209 obj=8.08507 num_tokens=321417 num_tokens/piece=44.5855\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=5406 obj=8.28822 num_tokens=340009 num_tokens/piece=62.8947\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=5406 obj=8.25054 num_tokens=340019 num_tokens/piece=62.8966\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=4054 obj=8.49723 num_tokens=356979 num_tokens/piece=88.056\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=4054 obj=8.45182 num_tokens=356977 num_tokens/piece=88.0555\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=3040 obj=8.73198 num_tokens=373508 num_tokens/piece=122.864\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=3040 obj=8.68081 num_tokens=373509 num_tokens/piece=122.865\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=2280 obj=9.00364 num_tokens=387918 num_tokens/piece=170.139\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=2280 obj=8.94357 num_tokens=387916 num_tokens/piece=170.139\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1710 obj=9.31627 num_tokens=403895 num_tokens/piece=236.196\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1710 obj=9.24807 num_tokens=403906 num_tokens/piece=236.202\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1282 obj=9.65338 num_tokens=420135 num_tokens/piece=327.718\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1282 obj=9.57238 num_tokens=420151 num_tokens/piece=327.731\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=0 size=1125 obj=9.7594 num_tokens=426589 num_tokens/piece=379.19\n",
      "unigram_model_trainer.cc(504) LOG(INFO) EM sub_iter=1 size=1125 obj=9.72493 num_tokens=426608 num_tokens/piece=379.207\n",
      "trainer_interface.cc(604) LOG(INFO) Saving model: malay-tts.model\n",
      "trainer_interface.cc(615) LOG(INFO) Saving vocabs: malay-tts.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(\n",
    "    input='malay-tts.txt', model_prefix='malay-tts',\n",
    "    vocab_size=1023,\n",
    "    model_type=\"unigram\",\n",
    "    input_sentence_size=-1,\n",
    "    character_coverage=1.0,\n",
    "    bos_id=0,\n",
    "    pad_id=1,\n",
    "    eos_id=2,\n",
    "    unk_id=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
