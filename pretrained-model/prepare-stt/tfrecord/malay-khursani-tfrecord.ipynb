{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e60ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dedff650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import upload_file\n",
    "import tensorflow as tf\n",
    "import malaya_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95b5e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import six\n",
    "\n",
    "def to_example(dictionary):\n",
    "    \"\"\"Helper: build tf.Example from (string -> int/float/str list) dictionary.\"\"\"\n",
    "    features = {}\n",
    "    for (k, v) in six.iteritems(dictionary):\n",
    "        if not v:\n",
    "            raise ValueError('Empty generated field: %s' % str((k, v)))\n",
    "        # Subtly in PY2 vs PY3, map is not scriptable in py3. As a result,\n",
    "        # map objects will fail with TypeError, unless converted to a list.\n",
    "        if six.PY3 and isinstance(v, map):\n",
    "            v = list(v)\n",
    "        if isinstance(v[0], six.integer_types) or np.issubdtype(\n",
    "            type(v[0]), np.integer\n",
    "        ):\n",
    "            features[k] = tf.train.Feature(\n",
    "                int64_list=tf.train.Int64List(value=v)\n",
    "            )\n",
    "        elif isinstance(v[0], float):\n",
    "            features[k] = tf.train.Feature(\n",
    "                float_list=tf.train.FloatList(value=v)\n",
    "            )\n",
    "        elif isinstance(v[0], six.string_types):\n",
    "            if not six.PY2:  # Convert in python 3.\n",
    "                v = [bytes(x, 'utf-8') for x in v]\n",
    "            features[k] = tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=v)\n",
    "            )\n",
    "        elif isinstance(v[0], bytes):\n",
    "            features[k] = tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=v)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Value for %s is not a recognized type; v: %s type: %s'\n",
    "                % (k, str(v[0]), str(type(v[0])))\n",
    "            )\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcb5eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.core.example.example_pb2.Example,\n",
       " tensorflow.core.example.feature_pb2.Features,\n",
       " tensorflow.python.lib.io.tf_record.TFRecordWriter)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Example, tf.train.Features, tf.io.TFRecordWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9fe06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdd00212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_vocabs = [''] + list(string.ascii_lowercase + string.digits) + [' ']\n",
    "len(char_vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b642e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329515"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sani = glob('data/raw/clean/**/*.wav', recursive = True)\n",
    "len(sani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "598d37a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329515/329515 [00:02<00:00, 113178.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "329359"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanis = []\n",
    "for i in tqdm(sani):\n",
    "    with open(i[:-4] + '.txt') as fopen:\n",
    "        text = fopen.read()\n",
    "    if len(text):\n",
    "        sanis.append((i, text))\n",
    "    \n",
    "len(sanis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0383705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios, texts = zip(*sanis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88f6d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "def preprocessing_text(string):\n",
    "        \n",
    "    string = unicodedata.normalize('NFC', string.lower())\n",
    "    string = ''.join([c if c in vocabs else ' ' for c in string])\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    string = (\n",
    "        ''.join(''.join(s)[:2] for _, s in itertools.groupby(string))\n",
    "    )\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7247011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 329359/329359 [00:05<00:00, 58978.61it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_text = [preprocessing_text(t) for t in tqdm(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78ae34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(zip(audios, processed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afdfb49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data/raw/clean/speech_done/cardock/7fe328841e81e17b4e855cd5e9e32294_445.wav',\n",
       "  'bunyi dia tak pecah jom kita tukar masih lagi menggunakan mak yang sama tanpa'),\n",
       " ('data/raw/clean/speech_done/cardock/fd2ffe802733a167a8ab03205fc55f0f_60.wav',\n",
       "  'apabila kehilangan seorang sepupu dan sahabat akibat pandemik itu hospital serdang')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "483ddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "maxlen = 18\n",
    "maxlen_subwords = 100\n",
    "minlen_text = 1\n",
    "global_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f790e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def loop(files):\n",
    "    \n",
    "    files, index = files\n",
    "    output_file = f'{index}-{global_count}.tfrecord'\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "    for s in tqdm(files):\n",
    "        try:\n",
    "            t = s[1]\n",
    "            f = s[0]\n",
    "            if len(s[1]) < minlen_text:\n",
    "                continue\n",
    "            y, _ = malaya_speech.load(f)\n",
    "            if (len(y) / sr) > maxlen:\n",
    "                continue\n",
    "            \n",
    "            t = ''.join([c if c in char_vocabs else ' ' for c in t])\n",
    "            t = re.sub(r'[ ]+', ' ', t).strip()\n",
    "            \n",
    "            new_t = [char_vocabs.index(c) for c in t]\n",
    "            example = to_example({'waveforms': y.tolist(), \n",
    "                                  'targets': new_t, \n",
    "                                  'targets_length': [len(new_t)],\n",
    "                                 'lang': [0]})\n",
    "            writer.write(example.SerializeToString())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    writer.close()\n",
    "    while True:\n",
    "        try:\n",
    "            upload_file(path_or_fileobj=output_file,\n",
    "                            path_in_repo=output_file,\n",
    "                            repo_id='huseinzol05/Khursani-Malay-TFRecord')\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    os.system(f'rm {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3609871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:28<00:00, 88.33it/s] \n",
      "100%|██████████| 2500/2500 [00:28<00:00, 87.23it/s] \n",
      "100%|██████████| 2500/2500 [00:29<00:00, 86.07it/s] \n",
      "100%|██████████| 2500/2500 [00:29<00:00, 85.33it/s] \n",
      "100%|██████████| 2500/2500 [00:30<00:00, 82.10it/s] \n",
      "100%|██████████| 2500/2500 [00:30<00:00, 82.10it/s] \n",
      "100%|██████████| 2500/2500 [00:30<00:00, 81.91it/s] \n",
      "100%|██████████| 2500/2500 [00:30<00:00, 81.06it/s] \n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.57it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.67it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.85it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.85it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.47it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.39it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 96.99it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 96.19it/s] \n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.30it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.04it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.03it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.80it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.52it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.09it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 98.87it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 98.63it/s] \n",
      "100%|██████████| 2500/2500 [00:23<00:00, 107.39it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 107.37it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 106.82it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 106.51it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 105.72it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 105.47it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 105.45it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 104.96it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 97.36it/s]]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 96.83it/s] \n",
      "100%|██████████| 2500/2500 [00:26<00:00, 95.93it/s] \n",
      "100%|██████████| 2500/2500 [00:26<00:00, 95.63it/s] \n",
      "100%|██████████| 2500/2500 [00:26<00:00, 95.15it/s] \n",
      "100%|██████████| 2500/2500 [00:26<00:00, 95.13it/s] \n",
      "100%|██████████| 2500/2500 [00:26<00:00, 94.93it/s] \n",
      "100%|██████████| 2500/2500 [00:26<00:00, 94.51it/s] \n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.96it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.49it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.44it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.97it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.78it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.88it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 100.60it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.68it/s] \n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.53it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.52it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.37it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.70it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.28it/s]\n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.88it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.71it/s] \n",
      "100%|██████████| 2500/2500 [00:25<00:00, 99.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:23<00:00, 106.06it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 104.63it/s]\n",
      "100%|██████████| 2500/2500 [00:23<00:00, 104.48it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.88it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.30it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 103.17it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 102.40it/s]\n",
      "100%|██████████| 2500/2500 [00:24<00:00, 101.87it/s]\n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.44it/s] \n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.35it/s] \n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.33it/s] \n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.19it/s] \n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.17it/s] \n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.04it/s] \n",
      "100%|██████████| 2500/2500 [00:50<00:00, 49.20it/s] \n",
      "100%|██████████| 2500/2500 [00:51<00:00, 48.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2500/2500 [00:35<00:00, 70.03it/s] \n",
      "100%|██████████| 2500/2500 [00:35<00:00, 69.94it/s]\n",
      "100%|██████████| 2500/2500 [00:35<00:00, 69.55it/s] \n",
      "100%|██████████| 2500/2500 [00:36<00:00, 69.22it/s] \n",
      "100%|██████████| 2500/2500 [00:36<00:00, 68.95it/s] \n",
      "100%|██████████| 2500/2500 [00:37<00:00, 66.04it/s] \n",
      "100%|██████████| 2500/2500 [00:39<00:00, 63.63it/s] \n",
      "100%|██████████| 2500/2500 [00:39<00:00, 62.87it/s] \n",
      "100%|██████████| 2500/2500 [00:31<00:00, 78.34it/s] \n",
      "100%|██████████| 2500/2500 [00:35<00:00, 71.42it/s]]\n",
      "100%|██████████| 2500/2500 [00:35<00:00, 71.04it/s] \n",
      "100%|██████████| 2500/2500 [00:35<00:00, 69.55it/s] \n",
      "100%|██████████| 2500/2500 [00:36<00:00, 69.23it/s]]\n",
      "100%|██████████| 2500/2500 [00:36<00:00, 68.78it/s] \n",
      "100%|██████████| 2500/2500 [00:36<00:00, 68.24it/s] \n",
      "100%|██████████| 2500/2500 [00:36<00:00, 67.89it/s] \n",
      "100%|██████████| 2500/2500 [00:29<00:00, 85.67it/s]]\n",
      "100%|██████████| 2500/2500 [00:30<00:00, 80.74it/s]]\n",
      "100%|██████████| 2500/2500 [00:31<00:00, 80.26it/s] \n",
      "100%|██████████| 2500/2500 [00:31<00:00, 79.49it/s]]\n",
      "100%|██████████| 2500/2500 [00:31<00:00, 78.38it/s] \n",
      "100%|██████████| 2500/2500 [00:31<00:00, 78.13it/s] \n",
      "100%|██████████| 2500/2500 [00:32<00:00, 78.00it/s] \n",
      "100%|██████████| 2500/2500 [00:32<00:00, 77.05it/s] \n",
      "100%|██████████| 2500/2500 [00:45<00:00, 55.27it/s] \n",
      "100%|██████████| 2500/2500 [00:46<00:00, 54.08it/s]\n",
      "100%|██████████| 2500/2500 [00:47<00:00, 52.42it/s]]\n",
      "100%|██████████| 2500/2500 [00:47<00:00, 52.09it/s]]\n",
      "100%|██████████| 2500/2500 [00:48<00:00, 51.81it/s] \n",
      "100%|██████████| 2500/2500 [00:48<00:00, 51.39it/s] \n",
      "100%|██████████| 2500/2500 [00:48<00:00, 51.20it/s] \n",
      "100%|██████████| 2500/2500 [00:49<00:00, 50.02it/s] \n",
      "100%|██████████| 2500/2500 [00:35<00:00, 70.63it/s] \n",
      "100%|██████████| 2500/2500 [00:36<00:00, 68.66it/s]\n",
      "100%|██████████| 2500/2500 [00:38<00:00, 64.99it/s]\n",
      "100%|██████████| 2500/2500 [00:40<00:00, 62.37it/s]]\n",
      "100%|██████████| 2500/2500 [00:41<00:00, 60.89it/s] \n",
      "100%|██████████| 2500/2500 [00:41<00:00, 60.39it/s] \n",
      "100%|██████████| 2500/2500 [00:41<00:00, 59.55it/s] \n",
      "100%|██████████| 2500/2500 [00:42<00:00, 58.70it/s] \n",
      "100%|██████████| 2500/2500 [00:42<00:00, 58.17it/s] \n",
      "100%|██████████| 2500/2500 [00:45<00:00, 55.20it/s]]\n",
      "100%|██████████| 2500/2500 [00:45<00:00, 54.46it/s] \n",
      "100%|██████████| 2500/2500 [00:45<00:00, 54.40it/s] \n",
      "100%|██████████| 2500/2500 [00:46<00:00, 54.33it/s]\n",
      "100%|██████████| 2500/2500 [00:46<00:00, 54.09it/s] \n",
      "100%|██████████| 2500/2500 [00:51<00:00, 48.80it/s] \n",
      "100%|██████████| 2500/2500 [00:52<00:00, 47.18it/s] \n",
      "100%|██████████| 2500/2500 [00:29<00:00, 84.22it/s]]\n",
      "100%|██████████| 2500/2500 [00:31<00:00, 80.57it/s] \n",
      "100%|██████████| 2500/2500 [00:32<00:00, 77.72it/s] \n",
      "100%|██████████| 2500/2500 [00:38<00:00, 64.77it/s] \n",
      "100%|██████████| 2500/2500 [00:43<00:00, 57.61it/s]\n",
      "100%|██████████| 2500/2500 [00:43<00:00, 57.49it/s]\n",
      "100%|██████████| 2500/2500 [00:43<00:00, 57.40it/s]\n",
      "100%|██████████| 2500/2500 [00:43<00:00, 56.89it/s] \n",
      "100%|██████████| 1169/1169 [00:12<00:00, 89.94it/s] \n",
      "100%|██████████| 1169/1169 [00:13<00:00, 83.54it/s] \n",
      "100%|██████████| 1169/1169 [00:14<00:00, 81.58it/s] \n",
      "100%|██████████| 1169/1169 [00:14<00:00, 78.83it/s] \n",
      "100%|██████████| 1169/1169 [00:14<00:00, 78.77it/s]]\n",
      "100%|██████████| 1169/1169 [00:14<00:00, 77.95it/s] \n",
      "100%|██████████| 1169/1169 [00:15<00:00, 77.85it/s] \n",
      "100%|██████████| 1169/1169 [00:15<00:00, 77.74it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 106.06it/s]\n"
     ]
    }
   ],
   "source": [
    "import mp\n",
    "\n",
    "batch_size = 20000\n",
    "for i in range(0, len(files), batch_size):\n",
    "    batch = files[i: i + batch_size]\n",
    "    mp.multiprocessing(batch, loop, cores = 8, returned = False)\n",
    "    global_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4ee99c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/huseinzol05/Khursani-Malay-TFRecord/resolve/main/0-0.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8514a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.compat.v1.VarLenFeature(tf.float32),\n",
    "        'targets': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'targets_length': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'lang': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.compat.v1.parse_single_example(\n",
    "        serialized_example, features=data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "\n",
    "    keys = list(features.keys())\n",
    "    for k in keys:\n",
    "        if k not in ['waveforms', 'waveforms_length', 'targets']:\n",
    "            features.pop(k, None)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ca4d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecords = ['0-0.tfrecord']\n",
    "num_cpu_threads = 2\n",
    "thread_count = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "997a9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 17:46:43.786844: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-24 17:46:43.787482: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: huseincomel-desktop\n",
      "2022-05-24 17:46:43.787545: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: huseincomel-desktop\n",
      "2022-05-24 17:46:43.788308: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-05-24 17:46:43.789095: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.129.6\n",
      "2022-05-24 17:46:43.797064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "d = tf.data.Dataset.from_tensor_slices(tf.constant(tfrecords))\n",
    "d = d.shuffle(buffer_size=len(tfrecords))\n",
    "cycle_length = min(num_cpu_threads, len(tfrecords))\n",
    "d = d.interleave(\n",
    "    tf.data.TFRecordDataset,\n",
    "    cycle_length=cycle_length,\n",
    "    block_length=thread_count)\n",
    "d = d.shuffle(buffer_size=100)\n",
    "d = d.map(parse, num_parallel_calls=num_cpu_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd09241f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 17:46:54.210549: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "d = d.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4eb62a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = next(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acc3f803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mereka ini kau nak buat defisit kalian apa semua'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([char_vocabs[t] for t in r['targets']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8433206a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
