{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_recognition/conf/SpeakerNet_recognition_3x2x512.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat conf/SpeakerNet_recognition_3x2x512.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install nemo-toolkit[asr]==1.0.0b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torchaudio>=0.6.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-10-25 01:55:34 nemo_logging:349] /home/ubuntu/.local/lib/python3.6/site-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "      warnings.warn(msg)\n",
      "    \n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.AudioLabelDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text._TarredAudioToTextDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToCharDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text.TarredAudioToBPEDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2020-10-25 01:55:34 experimental:28] Module <class 'nemo.collections.asr.losses.ctc.CTCLoss'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: SpeakerNet\n",
      "sample_rate: 16000\n",
      "repeat: 2\n",
      "dropout: 0.5\n",
      "separable: true\n",
      "n_filters: 512\n",
      "model:\n",
      "  train_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "  validation_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "  test_ds:\n",
      "    manifest_filepath: ???\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 1\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    embedding_dir: .\n",
      "  preprocessor:\n",
      "    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n",
      "    normalize: per_feature\n",
      "    window_size: 0.02\n",
      "    sample_rate: 16000\n",
      "    window_stride: 0.01\n",
      "    window: hann\n",
      "    features: 64\n",
      "    n_fft: 512\n",
      "    frame_splicing: 1\n",
      "    dither: 1.0e-05\n",
      "    stft_conv: false\n",
      "  encoder:\n",
      "    _target_: nemo.collections.asr.modules.ConvASREncoder\n",
      "    feat_in: 64\n",
      "    activation: relu\n",
      "    conv_mask: true\n",
      "    jasper:\n",
      "    - filters: 512\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 3\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.5\n",
      "      residual: true\n",
      "      separable: true\n",
      "    - filters: 512\n",
      "      repeat: 2\n",
      "      kernel:\n",
      "      - 7\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.5\n",
      "      residual: true\n",
      "      separable: true\n",
      "    - filters: 512\n",
      "      repeat: 2\n",
      "      kernel:\n",
      "      - 11\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.5\n",
      "      residual: true\n",
      "      separable: true\n",
      "    - filters: 512\n",
      "      repeat: 2\n",
      "      kernel:\n",
      "      - 15\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.5\n",
      "      residual: true\n",
      "      separable: true\n",
      "    - filters: 1500\n",
      "      repeat: 1\n",
      "      kernel:\n",
      "      - 1\n",
      "      stride:\n",
      "      - 1\n",
      "      dilation:\n",
      "      - 1\n",
      "      dropout: 0.0\n",
      "      residual: false\n",
      "      separable: true\n",
      "  decoder:\n",
      "    _target_: nemo.collections.asr.modules.SpeakerDecoder\n",
      "    feat_in: 1500\n",
      "    num_classes: 7205\n",
      "    pool_mode: xvector\n",
      "    emb_sizes: 512,512\n",
      "    angular: false\n",
      "  loss:\n",
      "    scale: 30\n",
      "    margin: 0.2\n",
      "  optim:\n",
      "    name: novograd\n",
      "    lr: 0.006\n",
      "    args:\n",
      "      name: auto\n",
      "      betas:\n",
      "      - 0.95\n",
      "      - 0.5\n",
      "      weight_decay: 0.001\n",
      "    sched:\n",
      "      name: CosineAnnealing\n",
      "      iters_per_batch: 1\n",
      "      max_steps: null\n",
      "      args:\n",
      "        name: auto\n",
      "        warmup_steps: null\n",
      "        warmup_ratio: 0.1\n",
      "        min_lr: 0.0\n",
      "        last_epoch: -1\n",
      "trainer:\n",
      "  gpus: 1\n",
      "  max_epochs: 7205\n",
      "  max_steps: null\n",
      "  num_nodes: 1\n",
      "  accelerator: ddp\n",
      "  accumulate_grad_batches: 1\n",
      "  amp_level: O0\n",
      "  deterministic: true\n",
      "  checkpoint_callback: false\n",
      "  logger: false\n",
      "  log_every_n_steps: 1\n",
      "  val_check_interval: 1.0\n",
      "exp_manager:\n",
      "  exp_dir: null\n",
      "  name: SpeakerNet\n",
      "  create_tensorboard_logger: true\n",
      "  create_checkpoint_callback: true\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load('SpeakerNet_recognition_3x2x512.yaml')\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://api.ngc.nvidia.com/v2/models/nvidia/nemospeechmodels/versions/1.0.0a5/files/SpeakerNet_verification.nemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-10-25 01:55:35 modelPT:102] Please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/samsungSSD/NVIDIA/repos/NeMo/examples/speaker_recognition/myExps/datasets/combined/train_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 8\n",
      "    \n",
      "[NeMo W 2020-10-25 01:55:35 modelPT:109] Please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/samsungSSD/NVIDIA/repos/NeMo/examples/speaker_recognition/myExps/datasets/voxceleb/train/small_manifest.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 8\n",
      "    \n",
      "[NeMo W 2020-10-25 01:55:35 nemo_logging:349] /home/ubuntu/.local/lib/python3.6/site-packages/hydra/_internal/utils.py:584: UserWarning: \n",
      "    Field 'params' is deprecated since Hydra 1.0 and will be removed in Hydra 1.1.\n",
      "    Inline the content of params directly at the containing node.\n",
      "    See https://hydra.cc/docs/next/upgrades/0.11_to_1.0/object_instantiation_changes\n",
      "      warnings.warn(category=UserWarning, message=msg)\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-10-25 01:55:35 features:241] PADDING: 16\n",
      "[NeMo I 2020-10-25 01:55:35 features:258] STFT using torch\n",
      "[NeMo I 2020-10-25 01:55:35 label_models:86] Training with Softmax-CrossEntropy loss\n",
      "[NeMo I 2020-10-25 01:55:35 modelPT:237] Model ExtractSpeakerEmbeddingsModel was successfully restored from SpeakerNet_verification.nemo.\n"
     ]
    }
   ],
   "source": [
    "verification_model = nemo_asr.models.ExtractSpeakerEmbeddingsModel.restore_from('SpeakerNet_verification.nemo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/quartznet/layer.py:6: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import malaya_speech.train.model.speakernet as speakernet\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, None, 64])\n",
    "inputs_length = tf.placeholder(tf.int32, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/speakernet/abstract.py:141: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/speakernet/layer.py:205: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/speakernet/layer.py:219: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/speakernet/layer.py:238: separable_conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.SeparableConv1D` instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/speakernet/abstract.py:369: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/malay/malaya-speech/malaya_speech/train/model/speakernet/model.py:86: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/MatMul:0' shape=(?, 7205) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = speakernet.Model(inputs, inputs_length, mode = 'eval')\n",
    "model.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(3000, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(512, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/gamma:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/beta:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_2/kernel:0' shape=(512, 7205) dtype=float32_ref>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = [v for v in tf.get_collection('variables')]\n",
    "encoder = [v for v in variables if 'encoder' in v.name]\n",
    "decoder = [v for v in variables if 'encoder' not in v.name]\n",
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-d622222ebd2e>:1: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
     ]
    }
   ],
   "source": [
    "encoder[0].load(verification_model.encoder.encoder[0].res[0][0].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[1].load(verification_model.encoder.encoder[0].res[0][1].weight.detach().numpy())\n",
    "encoder[2].load(verification_model.encoder.encoder[0].res[0][1].bias.detach().numpy())\n",
    "encoder[3].load(verification_model.encoder.encoder[0].res[0][1].running_mean.detach().numpy())\n",
    "encoder[4].load(verification_model.encoder.encoder[0].res[0][1].running_var.detach().numpy())\n",
    "encoder[5].load(verification_model.encoder.encoder[0].mconv[0].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[6].load(verification_model.encoder.encoder[0].mconv[1].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[7].load(verification_model.encoder.encoder[0].mconv[2].weight.detach().numpy())\n",
    "encoder[8].load(verification_model.encoder.encoder[0].mconv[2].bias.detach().numpy())\n",
    "encoder[9].load(verification_model.encoder.encoder[0].mconv[2].running_mean.detach().numpy())\n",
    "encoder[10].load(verification_model.encoder.encoder[0].mconv[2].running_var.detach().numpy())\n",
    "\n",
    "encoder[11].load(verification_model.encoder.encoder[1].mconv[0].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[12].load(verification_model.encoder.encoder[1].mconv[1].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[13].load(verification_model.encoder.encoder[1].mconv[2].weight.detach().numpy())\n",
    "encoder[14].load(verification_model.encoder.encoder[1].mconv[2].bias.detach().numpy())\n",
    "encoder[15].load(verification_model.encoder.encoder[1].mconv[2].running_mean.detach().numpy())\n",
    "encoder[16].load(verification_model.encoder.encoder[1].mconv[2].running_var.detach().numpy())\n",
    "encoder[17].load(verification_model.encoder.encoder[1].res[0][0].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[18].load(verification_model.encoder.encoder[1].res[0][1].weight.detach().numpy())\n",
    "encoder[19].load(verification_model.encoder.encoder[1].res[0][1].bias.detach().numpy())\n",
    "encoder[20].load(verification_model.encoder.encoder[1].res[0][1].running_mean.detach().numpy())\n",
    "encoder[21].load(verification_model.encoder.encoder[1].res[0][1].running_var.detach().numpy())\n",
    "encoder[22].load(verification_model.encoder.encoder[1].mconv[5].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[23].load(verification_model.encoder.encoder[1].mconv[6].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[24].load(verification_model.encoder.encoder[1].mconv[7].weight.detach().numpy())\n",
    "encoder[25].load(verification_model.encoder.encoder[1].mconv[7].bias.detach().numpy())\n",
    "encoder[26].load(verification_model.encoder.encoder[1].mconv[7].running_mean.detach().numpy())\n",
    "encoder[27].load(verification_model.encoder.encoder[1].mconv[7].running_var.detach().numpy())\n",
    "\n",
    "encoder[28].load(verification_model.encoder.encoder[2].mconv[0].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[29].load(verification_model.encoder.encoder[2].mconv[1].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[30].load(verification_model.encoder.encoder[2].mconv[2].weight.detach().numpy())\n",
    "encoder[31].load(verification_model.encoder.encoder[2].mconv[2].bias.detach().numpy())\n",
    "encoder[32].load(verification_model.encoder.encoder[2].mconv[2].running_mean.detach().numpy())\n",
    "encoder[33].load(verification_model.encoder.encoder[2].mconv[2].running_var.detach().numpy())\n",
    "encoder[34].load(verification_model.encoder.encoder[2].res[0][0].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[35].load(verification_model.encoder.encoder[2].res[0][1].weight.detach().numpy())\n",
    "encoder[36].load(verification_model.encoder.encoder[2].res[0][1].bias.detach().numpy())\n",
    "encoder[37].load(verification_model.encoder.encoder[2].res[0][1].running_mean.detach().numpy())\n",
    "encoder[38].load(verification_model.encoder.encoder[2].res[0][1].running_var.detach().numpy())\n",
    "encoder[39].load(verification_model.encoder.encoder[2].mconv[5].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[40].load(verification_model.encoder.encoder[2].mconv[6].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[41].load(verification_model.encoder.encoder[2].mconv[7].weight.detach().numpy())\n",
    "encoder[42].load(verification_model.encoder.encoder[2].mconv[7].bias.detach().numpy())\n",
    "encoder[43].load(verification_model.encoder.encoder[2].mconv[7].running_mean.detach().numpy())\n",
    "encoder[44].load(verification_model.encoder.encoder[2].mconv[7].running_var.detach().numpy())\n",
    "\n",
    "encoder[45].load(verification_model.encoder.encoder[3].mconv[0].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[46].load(verification_model.encoder.encoder[3].mconv[1].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[47].load(verification_model.encoder.encoder[3].mconv[2].weight.detach().numpy())\n",
    "encoder[48].load(verification_model.encoder.encoder[3].mconv[2].bias.detach().numpy())\n",
    "encoder[49].load(verification_model.encoder.encoder[3].mconv[2].running_mean.detach().numpy())\n",
    "encoder[50].load(verification_model.encoder.encoder[3].mconv[2].running_var.detach().numpy())\n",
    "encoder[51].load(verification_model.encoder.encoder[3].res[0][0].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[52].load(verification_model.encoder.encoder[3].res[0][1].weight.detach().numpy())\n",
    "encoder[53].load(verification_model.encoder.encoder[3].res[0][1].bias.detach().numpy())\n",
    "encoder[54].load(verification_model.encoder.encoder[3].res[0][1].running_mean.detach().numpy())\n",
    "encoder[55].load(verification_model.encoder.encoder[3].res[0][1].running_var.detach().numpy())\n",
    "encoder[56].load(verification_model.encoder.encoder[3].mconv[5].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[57].load(verification_model.encoder.encoder[3].mconv[6].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[58].load(verification_model.encoder.encoder[3].mconv[7].weight.detach().numpy())\n",
    "encoder[59].load(verification_model.encoder.encoder[3].mconv[7].bias.detach().numpy())\n",
    "encoder[60].load(verification_model.encoder.encoder[3].mconv[7].running_mean.detach().numpy())\n",
    "encoder[61].load(verification_model.encoder.encoder[3].mconv[7].running_var.detach().numpy())\n",
    "\n",
    "encoder[62].load(verification_model.encoder.encoder[4].mconv[0].conv.weight.permute([2,0,1]).detach().numpy())\n",
    "encoder[63].load(verification_model.encoder.encoder[4].mconv[1].conv.weight.permute([2,1,0]).detach().numpy())\n",
    "encoder[64].load(verification_model.encoder.encoder[4].mconv[2].weight.detach().numpy())\n",
    "encoder[65].load(verification_model.encoder.encoder[4].mconv[2].bias.detach().numpy())\n",
    "encoder[66].load(verification_model.encoder.encoder[4].mconv[2].running_mean.detach().numpy())\n",
    "encoder[67].load(verification_model.encoder.encoder[4].mconv[2].running_var.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder[0].load(verification_model.decoder.emb_layers[0][0].weight.T.detach().numpy())\n",
    "decoder[1].load(verification_model.decoder.emb_layers[0][0].bias.detach().numpy())\n",
    "decoder[4].load(verification_model.decoder.emb_layers[0][1].running_mean.detach().numpy())\n",
    "decoder[5].load(verification_model.decoder.emb_layers[0][1].running_var.detach().numpy())\n",
    "\n",
    "decoder[6].load(verification_model.decoder.emb_layers[1][0].weight.T.detach().numpy())\n",
    "decoder[7].load(verification_model.decoder.emb_layers[1][0].bias.detach().numpy())\n",
    "decoder[10].load(verification_model.decoder.emb_layers[1][1].running_mean.detach().numpy())\n",
    "decoder[11].load(verification_model.decoder.emb_layers[1][1].running_var.detach().numpy())\n",
    "decoder[12].load(verification_model.decoder.final.weight.detach().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speakernet/model.ckpt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'speakernet/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech.config\n",
    "\n",
    "config = malaya_speech.config.speakernet_featurizer_config\n",
    "featurizer = malaya_speech.featurization.SpeakerNetFeaturizer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['speech/example-speaker/khalil-nooh.wav',\n",
       " 'speech/example-speaker/husein-zolkepli.wav',\n",
       " 'speech/example-speaker/mas-aisyah.wav',\n",
       " 'speech/example-speaker/shafiqah-idayu.wav']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "speakers = glob('speech/example-speaker/*.wav')\n",
    "speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 564, 64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wavs = [malaya_speech.load(f, sr = 16000)[0] for f in speakers]\n",
    "vectors = [featurizer.vectorize(w) for w in wavs]\n",
    "padded, l = malaya_speech.padding.sequence_nd(vectors, dim = 0, return_len = True)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7205)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = sess.run(model.logits, feed_dict = {inputs: padded, inputs_length: l})\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.91986295, 0.85895558, 0.85036781],\n",
       "       [0.91986295, 1.        , 0.85086457, 0.86070392],\n",
       "       [0.85895558, 0.85086457, 1.        , 0.88895706],\n",
       "       [0.85036781, 0.86070392, 0.88895706, 1.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "1 - cdist(logits, logits, metric = 'cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speakernet/\n",
      "speakernet/model.ckpt.index\n",
      "speakernet/model.ckpt.meta\n",
      "speakernet/model.ckpt.data-00000-of-00001\n",
      "speakernet/checkpoint\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf speakernet.tar.gz speakernet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
