{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import NUM_FBANKS, NUM_FRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda, Dense\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSpeakerModel:\n",
    "\n",
    "    # I thought it was 3 but maybe energy is added at a 4th dimension.\n",
    "    # would be better to have 4 dimensions:\n",
    "    # MFCC, DIFF(MFCC), DIFF(DIFF(MFCC)), ENERGIES (probably tiled across the frequency domain).\n",
    "    # this seems to help match the parameter counts.\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.clipped_relu_count = 0\n",
    "\n",
    "    def keras_model(self):\n",
    "        return self.m\n",
    "\n",
    "    def get_weights(self):\n",
    "        w = self.m.get_weights()\n",
    "        if self.include_softmax:\n",
    "            w.pop()  # last 2 are the W_softmax and b_softmax.\n",
    "            w.pop()\n",
    "        return w\n",
    "\n",
    "    def clipped_relu(self, inputs):\n",
    "        relu = Lambda(lambda y: K.minimum(K.maximum(y, 0), 20), name=f'clipped_relu_{self.clipped_relu_count}')(inputs)\n",
    "        self.clipped_relu_count += 1\n",
    "        return relu\n",
    "\n",
    "    def identity_block(self, input_tensor, kernel_size, filters, stage, block):\n",
    "        conv_name_base = f'res{stage}_{block}_branch'\n",
    "\n",
    "        x = Conv2D(filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=1,\n",
    "                   activation=None,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   kernel_regularizer=regularizers.l2(l=0.0001),\n",
    "                   name=conv_name_base + '_2a')(input_tensor)\n",
    "        x = BatchNormalization(name=conv_name_base + '_2a_bn')(x)\n",
    "        x = self.clipped_relu(x)\n",
    "\n",
    "        x = Conv2D(filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=1,\n",
    "                   activation=None,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   kernel_regularizer=regularizers.l2(l=0.0001),\n",
    "                   name=conv_name_base + '_2b')(x)\n",
    "        x = BatchNormalization(name=conv_name_base + '_2b_bn')(x)\n",
    "\n",
    "        x = self.clipped_relu(x)\n",
    "\n",
    "        x = layers.add([x, input_tensor])\n",
    "        x = self.clipped_relu(x)\n",
    "        return x\n",
    "\n",
    "    def conv_and_res_block(self, inp, filters, stage):\n",
    "        conv_name = 'conv{}-s'.format(filters)\n",
    "        # TODO: why kernel_regularizer?\n",
    "        o = Conv2D(filters,\n",
    "                   kernel_size=5,\n",
    "                   strides=2,\n",
    "                   activation=None,\n",
    "                   padding='same',\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   kernel_regularizer=regularizers.l2(l=0.0001), name=conv_name)(inp)\n",
    "        o = BatchNormalization(name=conv_name + '_bn')(o)\n",
    "        o = self.clipped_relu(o)\n",
    "        for i in range(3):\n",
    "            o = self.identity_block(o, kernel_size=3, filters=filters, stage=stage, block=i)\n",
    "        return o\n",
    "\n",
    "    def cnn_component(self, inp):\n",
    "        x = self.conv_and_res_block(inp, 64, stage=1)\n",
    "        x = self.conv_and_res_block(x, 128, stage=2)\n",
    "        x = self.conv_and_res_block(x, 256, stage=3)\n",
    "        x = self.conv_and_res_block(x, 512, stage=4)\n",
    "        return x\n",
    "\n",
    "    def set_weights(self, w):\n",
    "        for layer, layer_w in zip(self.m.layers, w):\n",
    "            layer.set_weights(layer_w)\n",
    "            logger.info(f'Setting weights for [{layer.name}]...')\n",
    "            \n",
    "deepspeaker = DeepSpeakerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, (None, None, NUM_FBANKS, 1))\n",
    "        x = deepspeaker.cnn_component(self.X)\n",
    "        x = Reshape((-1, 2048))(x)\n",
    "        x = Lambda(lambda y: K.mean(y, axis=1), name='average')(x)\n",
    "        x = Dense(512, name='affine')(x)\n",
    "        x = Lambda(lambda y: K.l2_normalize(y, axis=1), name='ln')(x)\n",
    "        self.logits = tf.identity(x, name = 'logits')\n",
    "        print(self.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Tensor(\"logits:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from out/vggvox.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, 'out/vggvox.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mas-aisyah.wav',\n",
       " 'shafiqah-idayu.wav',\n",
       " 'husein-zolkepli.wav',\n",
       " 'khalil-nooh.wav']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "wavs = glob('*.wav')\n",
    "wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from audio import read_mfcc\n",
    "import numpy as np\n",
    "from constants import SAMPLE_RATE, NUM_FRAMES\n",
    "SAMPLE_RATE, NUM_FRAMES\n",
    "\n",
    "read_mfcc(wavs[0], SAMPLE_RATE).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(file):\n",
    "    return np.array([np.expand_dims(read_mfcc(file, SAMPLE_RATE), -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = [f(file) for file in wavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 166, 64, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(mfcc):\n",
    "    return sess.run(model.logits, feed_dict = {model.X: mfcc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [pred(mfcc) for mfcc in mfccs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.concatenate(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.32191291, 0.19461663, 0.23876474],\n",
       "       [0.32191291, 1.        , 0.24097232, 0.23889481],\n",
       "       [0.19461663, 0.24097232, 1.        , 0.33842044],\n",
       "       [0.23876474, 0.23889481, 0.33842044, 1.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "1 - cdist(r, r, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deep-speaker-out/model.ckpt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'deep-speaker-out/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name\n",
    "        or 'self/Softmax' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from deep-speaker-out/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-22-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 170 variables.\n",
      "INFO:tensorflow:Converted 170 variables to const ops.\n",
      "1238 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('deep-speaker-out', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename, **kwargs):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # https://github.com/onnx/tensorflow-onnx/issues/77#issuecomment-445066091\n",
    "    # to fix import T5\n",
    "    for node in graph_def.node:\n",
    "        if node.op == 'RefSwitch':\n",
    "            node.op = 'Switch'\n",
    "            for index in xrange(len(node.input)):\n",
    "                if 'moving_' in node.input[index]:\n",
    "                    node.input[index] = node.input[index] + '/read'\n",
    "        elif node.op == 'AssignSub':\n",
    "            node.op = 'Sub'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'AssignAdd':\n",
    "            node.op = 'Add'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'Assign':\n",
    "            node.op = 'Identity'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "            if 'validate_shape' in node.attr:\n",
    "                del node.attr['validate_shape']\n",
    "            if len(node.input) == 2:\n",
    "                node.input[0] = node.input[1]\n",
    "                del node.input[1]\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('deep-speaker-out/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.52379973e-02,  2.57481169e-02, -6.28858060e-02,\n",
       "         4.04050201e-02, -2.26131728e-04,  5.66876568e-02,\n",
       "         1.18383556e-03, -4.22953954e-03, -6.06642552e-02,\n",
       "        -5.22606596e-02,  1.16289295e-02,  1.49290841e-02,\n",
       "         6.79407595e-03, -5.07222116e-02,  2.65879724e-02,\n",
       "        -1.28893480e-02, -1.13314763e-03, -2.55147684e-02,\n",
       "        -1.35199614e-02, -2.59618666e-02,  2.09014192e-02,\n",
       "        -1.54670011e-02, -2.34773718e-02,  4.52116244e-02,\n",
       "        -8.32604337e-03,  2.89497431e-02,  5.44677228e-02,\n",
       "         1.08679058e-02, -3.14984769e-02,  7.59129599e-02,\n",
       "        -4.80681919e-02,  3.53878178e-02, -1.00509912e-01,\n",
       "         5.17397560e-03, -1.94912236e-02,  6.09882176e-02,\n",
       "         2.42635068e-02, -3.76226730e-03,  3.01365778e-02,\n",
       "        -2.33786886e-05,  1.33099407e-01, -3.13142762e-02,\n",
       "        -2.57999636e-02,  3.96155901e-02,  4.48607504e-02,\n",
       "        -1.67979449e-02, -2.63978336e-02,  1.43880742e-02,\n",
       "         5.40309884e-02,  2.99838297e-02,  5.72429821e-02,\n",
       "         6.43709442e-03, -7.24937692e-02, -6.27631880e-03,\n",
       "        -3.11463494e-02,  1.12579845e-01,  1.91161446e-02,\n",
       "         3.04446872e-02, -1.61914732e-02, -2.88510974e-02,\n",
       "         1.23700115e-03, -2.16188654e-02, -1.38179185e-02,\n",
       "         6.93898052e-02, -4.49642539e-02, -1.46795586e-02,\n",
       "         1.23610236e-02, -3.08626313e-02,  7.23239034e-02,\n",
       "        -2.23247539e-02,  3.06907818e-02, -2.54712831e-02,\n",
       "         1.78144407e-02,  9.63947028e-02, -1.06592942e-02,\n",
       "         3.24446298e-02, -3.77861154e-03,  8.29008035e-03,\n",
       "        -8.58263075e-02, -2.09467509e-03,  1.07739503e-02,\n",
       "        -2.96751708e-02,  4.46406230e-02,  9.53021199e-02,\n",
       "         4.53914180e-02, -3.07539422e-02, -1.35687403e-02,\n",
       "         3.57578397e-02, -3.65264639e-02, -5.07574119e-02,\n",
       "        -2.69342400e-03,  7.31929094e-02, -3.27527151e-02,\n",
       "         1.67453419e-02,  8.41227360e-03, -1.70793254e-02,\n",
       "         7.38833449e-04,  3.80574912e-02,  6.55430257e-02,\n",
       "         9.03485790e-02, -3.66020948e-02,  4.61964868e-02,\n",
       "        -5.97039936e-03, -2.65235547e-02,  7.91156068e-02,\n",
       "         3.72770429e-02,  6.80842325e-02, -1.87550019e-02,\n",
       "        -1.78673677e-02, -7.31638968e-02,  4.17052545e-02,\n",
       "         5.64384535e-02,  2.54199393e-02, -5.02770469e-02,\n",
       "         6.91808388e-02,  1.12372153e-02, -1.52792139e-02,\n",
       "         5.74768335e-02, -2.78448835e-02, -2.48512980e-02,\n",
       "        -2.14900896e-02,  3.60456780e-02, -6.68042824e-02,\n",
       "         1.60976965e-02, -2.91683176e-03, -3.38500217e-02,\n",
       "         6.36236817e-02,  1.96307921e-03, -7.21308589e-02,\n",
       "         4.08560112e-02,  8.62123538e-03, -1.17436796e-01,\n",
       "        -1.18264984e-02, -4.52997908e-02,  8.60686228e-02,\n",
       "        -7.29568815e-03,  5.60573451e-02, -1.71611961e-02,\n",
       "         2.43198927e-02,  1.16238967e-01,  4.29006433e-03,\n",
       "        -3.87876183e-02, -5.90032432e-03,  6.66262070e-03,\n",
       "         2.42406595e-02, -1.86831001e-02,  1.17407786e-02,\n",
       "        -1.29063735e-02,  4.68239300e-02, -4.22564000e-02,\n",
       "        -3.53183746e-02, -4.37707603e-02, -8.17552879e-02,\n",
       "        -5.43399714e-02, -6.59211492e-03,  4.20217812e-02,\n",
       "        -2.54687760e-02,  5.06665558e-02, -7.19498619e-02,\n",
       "        -3.10858275e-04,  4.18626219e-02, -1.03171822e-02,\n",
       "         1.24135772e-02, -3.66960764e-02,  2.11690478e-02,\n",
       "        -8.35535154e-02, -5.36862854e-03, -3.20653766e-02,\n",
       "         1.34139182e-02, -2.12326404e-02, -5.15081994e-02,\n",
       "        -6.79085702e-02,  6.54470772e-02,  2.72607487e-02,\n",
       "         2.91889943e-02,  7.98183903e-02, -6.46957988e-03,\n",
       "        -1.06113711e-02,  4.56778593e-02,  1.95640996e-02,\n",
       "         1.20258518e-02, -3.81726958e-02, -8.01241398e-02,\n",
       "         1.08747110e-02,  6.66402057e-02, -1.50844513e-03,\n",
       "         4.79471497e-02,  3.87553237e-02,  4.95395176e-02,\n",
       "        -4.64345925e-02, -3.34349200e-02, -5.80569915e-02,\n",
       "         5.95608950e-02,  3.60376351e-02,  1.33463629e-02,\n",
       "         1.61669939e-03, -3.23484801e-02,  5.44241630e-02,\n",
       "        -1.56536642e-02, -1.50570581e-02,  9.27705411e-03,\n",
       "         2.78517790e-02, -8.44056159e-03,  2.20896630e-03,\n",
       "         1.10196304e-02,  5.65923043e-02, -1.93511210e-02,\n",
       "         2.71759182e-03,  3.43590453e-02, -2.03683302e-02,\n",
       "         4.01253439e-02, -1.22073945e-03, -7.18801692e-02,\n",
       "         2.19093100e-03, -2.03003138e-02,  3.19358520e-02,\n",
       "        -9.25476570e-03,  2.33318866e-03,  4.91270684e-02,\n",
       "         3.63831117e-04, -6.83789328e-03,  2.71009607e-03,\n",
       "        -7.29143769e-02, -8.22831020e-02,  1.26154516e-02,\n",
       "         7.50450476e-04, -1.94360633e-04, -3.53913717e-02,\n",
       "        -4.38837148e-02,  2.55078487e-02,  1.64466258e-02,\n",
       "        -1.61441322e-02,  1.19840419e-02,  2.77910139e-02,\n",
       "         3.01731247e-02, -7.30640208e-03,  4.03510518e-02,\n",
       "        -6.28918558e-02, -3.82512733e-02, -3.68411988e-02,\n",
       "         1.21914577e-02,  1.94343086e-02,  9.39193461e-03,\n",
       "        -8.65753833e-03,  1.87658574e-02,  4.21778299e-02,\n",
       "         2.98343636e-02,  7.27018341e-03, -4.12746845e-03,\n",
       "        -1.47853568e-02,  1.03862628e-01, -1.96745526e-03,\n",
       "         1.52536817e-02,  3.47172357e-02, -6.07524738e-02,\n",
       "        -2.10600514e-02,  5.72563196e-03, -8.84006917e-03,\n",
       "        -6.11232519e-02, -2.86199618e-03,  4.28835303e-02,\n",
       "        -4.31968123e-02, -3.11469547e-02,  8.76511782e-02,\n",
       "        -6.72136107e-03, -1.03917876e-02, -3.87008451e-02,\n",
       "        -3.82633395e-02,  1.64250843e-02, -3.68183106e-02,\n",
       "        -5.65943681e-03, -2.58445926e-02,  4.98480946e-02,\n",
       "         5.13032861e-02,  1.49158454e-02,  7.36274943e-02,\n",
       "        -8.20161367e-04,  3.16771567e-02, -4.58293445e-02,\n",
       "         1.11590112e-02,  2.00361665e-02,  8.77184235e-03,\n",
       "         3.05495393e-02, -6.05540201e-02, -2.64383890e-02,\n",
       "         2.77032740e-02, -8.01952407e-02,  5.19682281e-02,\n",
       "         1.22103365e-02,  2.55208202e-02,  1.87565107e-02,\n",
       "         5.79364523e-02, -1.06315396e-03,  2.17525065e-02,\n",
       "        -1.19985759e-01,  3.26706953e-02, -3.82160060e-02,\n",
       "         5.36241308e-02,  2.43120175e-02, -8.13924894e-02,\n",
       "         2.38742866e-02, -1.74130220e-02, -2.88060289e-02,\n",
       "         5.03259152e-02,  3.85314934e-02, -1.91843341e-04,\n",
       "        -7.93333258e-03, -2.50786170e-02,  1.92440003e-02,\n",
       "        -1.21185416e-02, -5.94922062e-03,  6.08639568e-02,\n",
       "        -1.08078700e-02,  7.97248334e-02,  5.02050761e-03,\n",
       "         1.67070571e-02,  4.13316023e-03,  2.24780105e-02,\n",
       "         2.37904582e-03,  4.44718543e-03, -5.29266261e-02,\n",
       "        -1.03271186e-01, -2.42521223e-02,  5.93973920e-02,\n",
       "        -8.23097751e-02, -5.08674458e-02,  1.13136051e-02,\n",
       "         8.44611414e-03,  3.07513550e-02, -2.72166673e-02,\n",
       "         2.91285012e-02, -4.41054301e-03,  2.12161876e-02,\n",
       "         4.77015786e-02, -6.15077838e-03,  3.28818150e-02,\n",
       "        -4.59628664e-02, -1.42809644e-03,  1.17485842e-03,\n",
       "        -4.83451858e-02,  2.74073845e-03, -2.38619950e-02,\n",
       "        -7.13815074e-03,  6.77644685e-02,  9.46747884e-03,\n",
       "        -2.54796259e-02,  2.08412413e-03, -1.22642554e-02,\n",
       "         4.25918698e-02, -5.97829372e-02, -2.87293200e-03,\n",
       "         2.74984352e-02, -2.53217737e-03,  1.45186195e-02,\n",
       "         1.34782447e-02,  2.43702866e-02,  1.18412618e-02,\n",
       "        -6.15926273e-02, -2.02826113e-02, -9.98019896e-05,\n",
       "         4.95309122e-02,  3.09931226e-02,  4.62644687e-03,\n",
       "         9.39218998e-02, -3.26186493e-02,  4.86367978e-02,\n",
       "         2.17185542e-02,  1.19702257e-02, -9.83098708e-03,\n",
       "        -4.68344763e-02, -8.31662267e-02, -4.02703509e-02,\n",
       "        -1.36953983e-02,  3.44010326e-03,  5.67006692e-02,\n",
       "        -5.23452014e-02,  3.65582071e-02,  5.52049764e-02,\n",
       "         1.12453271e-02,  3.85274775e-02, -5.05144224e-02,\n",
       "        -5.93088344e-02, -5.64298257e-02,  1.44263273e-02,\n",
       "         1.47174569e-02,  2.79517379e-02, -6.22610599e-02,\n",
       "        -4.38366383e-02, -4.18627486e-02,  6.13241596e-03,\n",
       "         2.19367389e-02, -5.78105599e-02,  1.45221886e-03,\n",
       "         1.32400272e-02,  4.96037258e-03, -7.20430017e-02,\n",
       "         3.99792334e-03, -5.35414135e-03,  5.06056510e-02,\n",
       "         4.84764650e-02, -6.52997289e-03, -4.04196456e-02,\n",
       "         8.23740438e-02, -2.44193077e-02,  6.85527548e-02,\n",
       "        -2.99876276e-02,  4.30633575e-02, -2.85342634e-02,\n",
       "         2.14459654e-02,  1.99954342e-02, -6.28375122e-03,\n",
       "        -1.92440357e-02,  5.34903035e-02,  8.51895008e-03,\n",
       "        -2.62211673e-02,  3.95637564e-02,  2.65391953e-02,\n",
       "         2.97017582e-03,  2.33537350e-02, -1.47997811e-02,\n",
       "        -3.51146683e-02,  4.01511490e-02, -1.10812681e-02,\n",
       "        -1.58442054e-02, -1.99131407e-02,  4.61774953e-02,\n",
       "         1.37768090e-01, -7.65534211e-03, -4.03450280e-02,\n",
       "        -1.02631070e-01,  7.79596390e-03, -3.11060306e-02,\n",
       "        -1.99495852e-02,  5.83048090e-02, -1.48806479e-02,\n",
       "        -2.00381260e-02, -1.33928694e-02, -3.41393836e-02,\n",
       "        -7.80588463e-02,  4.48780693e-02,  2.36769347e-03,\n",
       "        -3.36805470e-02, -1.24098427e-04,  1.12606548e-02,\n",
       "        -4.39311676e-02, -5.04958034e-02, -8.72640219e-03,\n",
       "        -1.40721351e-02, -5.15557528e-02, -5.45863109e-03,\n",
       "         2.65019666e-02, -1.75490770e-02,  1.68591570e-02,\n",
       "        -3.44603360e-02, -4.69672047e-02,  3.79803218e-02,\n",
       "         4.02006544e-02, -6.77586049e-02,  6.43302873e-02,\n",
       "         5.00806049e-02,  3.68748121e-02,  1.01250708e-01,\n",
       "         4.57671843e-03,  3.09468284e-02,  6.38815993e-03,\n",
       "        -4.98118289e-02, -1.93107706e-02,  9.37325531e-04,\n",
       "         5.08346558e-02,  1.12630352e-01,  1.20544238e-02,\n",
       "         3.29485089e-02,  3.29272412e-02, -9.74037349e-02,\n",
       "        -5.35627641e-02,  5.58897480e-02,  2.19595563e-02,\n",
       "        -9.60912257e-02,  2.93024052e-02, -5.16288206e-02,\n",
       "         5.56390248e-02, -3.23774181e-02, -3.66709977e-02,\n",
       "         6.24411255e-02,  7.74146393e-02, -1.13966037e-02,\n",
       "         3.61510850e-02,  1.84178911e-02,  2.30667144e-02,\n",
       "         3.50972675e-02,  2.47182660e-02, -6.05276320e-03,\n",
       "        -2.50792392e-02,  3.49343172e-03,  3.11245385e-04,\n",
       "         4.02748995e-02,  1.78282987e-02,  1.86056066e-02,\n",
       "        -5.53433364e-03,  1.07669301e-01, -9.49867368e-02,\n",
       "         3.18496644e-01, -1.97970662e-02, -1.63312387e-02,\n",
       "        -3.04960664e-02, -1.02294926e-02, -1.08001223e-02,\n",
       "         2.93604843e-02, -2.28071958e-02,  1.10946698e-02,\n",
       "        -5.97619303e-02, -6.10768981e-02]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sess.run(logits, feed_dict = {x: mfccs[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
