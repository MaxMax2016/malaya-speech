{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/WeidiXie/VGG-Speaker-Recognition/blob/master/src/predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation, Conv1D, Conv2D, Input, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block_2D(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "\n",
    "    conv_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce'\n",
    "    bn_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce/bn'\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_1)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3'\n",
    "    bn_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3/bn'\n",
    "    x = Conv2D(filters2, kernel_size,\n",
    "               padding='same',\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_2)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_2)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase'\n",
    "    bn_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase/bn'\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_3)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_3)(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_2D(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "\n",
    "    conv_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce'\n",
    "    bn_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce/bn'\n",
    "    x = Conv2D(filters1, (1, 1),\n",
    "               strides=strides,\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_1)(input_tensor)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_1)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3'\n",
    "    bn_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3/bn'\n",
    "    x = Conv2D(filters2, kernel_size, padding='same',\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_2)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_2)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase'\n",
    "    bn_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase/bn'\n",
    "    x = Conv2D(filters3, (1, 1),\n",
    "               kernel_initializer='orthogonal',\n",
    "               use_bias=False,\n",
    "               trainable=trainable,\n",
    "               kernel_regularizer=l2(weight_decay),\n",
    "               name=conv_name_3)(x)\n",
    "    x = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_3)(x)\n",
    "\n",
    "    conv_name_4 = 'conv' + str(stage) + '_' + str(block) + '_1x1_proj'\n",
    "    bn_name_4 = 'conv' + str(stage) + '_' + str(block) + '_1x1_proj/bn'\n",
    "    shortcut = Conv2D(filters3, (1, 1), strides=strides,\n",
    "                      kernel_initializer='orthogonal',\n",
    "                      use_bias=False,\n",
    "                      trainable=trainable,\n",
    "                      kernel_regularizer=l2(weight_decay),\n",
    "                      name=conv_name_4)(input_tensor)\n",
    "    shortcut = BatchNormalization(axis=bn_axis, trainable=trainable, name=bn_name_4)(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_2D_v1(input_dim, mode='train'):\n",
    "    bn_axis = 3\n",
    "    if mode == 'train':\n",
    "        inputs = Input(shape=input_dim, name='input')\n",
    "    else:\n",
    "        inputs = Input(shape=(input_dim[0], None, input_dim[-1]), name='input')\n",
    "    # ===============================================\n",
    "    #            Convolution Block 1\n",
    "    # ===============================================\n",
    "    x1 = Conv2D(64, (7, 7),\n",
    "                kernel_initializer='orthogonal',\n",
    "                use_bias=False, trainable=True,\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                padding='same',\n",
    "                name='conv1_1/3x3_s1')(inputs)\n",
    "\n",
    "    x1 = BatchNormalization(axis=bn_axis, name='conv1_1/3x3_s1/bn', trainable=True)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2), strides=(2, 2))(x1)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 2\n",
    "    # ===============================================\n",
    "    x2 = conv_block_2D(x1, 3, [48, 48, 96], stage=2, block='a', strides=(1, 1), trainable=True)\n",
    "    x2 = identity_block_2D(x2, 3, [48, 48, 96], stage=2, block='b', trainable=True)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 3\n",
    "    # ===============================================\n",
    "    x3 = conv_block_2D(x2, 3, [96, 96, 128], stage=3, block='a', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [96, 96, 128], stage=3, block='b', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [96, 96, 128], stage=3, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 4\n",
    "    # ===============================================\n",
    "    x4 = conv_block_2D(x3, 3, [128, 128, 256], stage=4, block='a', trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [128, 128, 256], stage=4, block='b', trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [128, 128, 256], stage=4, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 5\n",
    "    # ===============================================\n",
    "    x5 = conv_block_2D(x4, 3, [256, 256, 512], stage=5, block='a', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [256, 256, 512], stage=5, block='b', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [256, 256, 512], stage=5, block='c', trainable=True)\n",
    "    y = MaxPooling2D((3, 1), strides=(2, 1), name='mpool2')(x5)\n",
    "    return inputs, y\n",
    "\n",
    "\n",
    "def resnet_2D_v2(input_dim, mode='train'):\n",
    "    bn_axis = 3\n",
    "    if mode == 'train':\n",
    "        inputs = Input(shape=input_dim, name='input')\n",
    "    else:\n",
    "        inputs = Input(shape=(input_dim[0], None, input_dim[-1]), name='input')\n",
    "    # ===============================================\n",
    "    #            Convolution Block 1\n",
    "    # ===============================================\n",
    "    x1 = Conv2D(64, (7, 7), strides=(2, 2),\n",
    "                kernel_initializer='orthogonal',\n",
    "                use_bias=False, trainable=True,\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                padding='same',\n",
    "                name='conv1_1/3x3_s1')(inputs)\n",
    "\n",
    "    x1 = BatchNormalization(axis=bn_axis, name='conv1_1/3x3_s1/bn', trainable=True)(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2), strides=(2, 2))(x1)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 2\n",
    "    # ===============================================\n",
    "    x2 = conv_block_2D(x1, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable=True)\n",
    "    x2 = identity_block_2D(x2, 3, [64, 64, 256], stage=2, block='b', trainable=True)\n",
    "    x2 = identity_block_2D(x2, 3, [64, 64, 256], stage=2, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 3\n",
    "    # ===============================================\n",
    "    x3 = conv_block_2D(x2, 3, [128, 128, 512], stage=3, block='a', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [128, 128, 512], stage=3, block='b', trainable=True)\n",
    "    x3 = identity_block_2D(x3, 3, [128, 128, 512], stage=3, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 4\n",
    "    # ===============================================\n",
    "    x4 = conv_block_2D(x3, 3, [256, 256, 1024], stage=4, block='a', strides=(1, 1), trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [256, 256, 1024], stage=4, block='b', trainable=True)\n",
    "    x4 = identity_block_2D(x4, 3, [256, 256, 1024], stage=4, block='c', trainable=True)\n",
    "    # ===============================================\n",
    "    #            Convolution Section 5\n",
    "    # ===============================================\n",
    "    x5 = conv_block_2D(x4, 3, [512, 512, 2048], stage=5, block='a', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [512, 512, 2048], stage=5, block='b', trainable=True)\n",
    "    x5 = identity_block_2D(x5, 3, [512, 512, 2048], stage=5, block='c', trainable=True)\n",
    "    y = MaxPooling2D((3, 1), strides=(2, 1), name='mpool2')(x5)\n",
    "    return inputs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VladPooling(keras.layers.Layer):\n",
    "    '''\n",
    "    This layer follows the NetVlad, GhostVlad\n",
    "    '''\n",
    "    def __init__(self, mode, k_centers, g_centers=0, **kwargs):\n",
    "        self.k_centers = k_centers\n",
    "        self.g_centers = g_centers\n",
    "        self.mode = mode\n",
    "        super(VladPooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.cluster = self.add_weight(shape=[self.k_centers+self.g_centers, input_shape[0][-1]],\n",
    "                                       name='centers',\n",
    "                                       initializer='orthogonal')\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape\n",
    "        return (input_shape[0][0], self.k_centers*input_shape[0][-1])\n",
    "\n",
    "    def call(self, x):\n",
    "        # feat : bz x W x H x D, cluster_score: bz X W x H x clusters.\n",
    "        feat, cluster_score = x\n",
    "        num_features = feat.shape[-1]\n",
    "\n",
    "        # softmax normalization to get soft-assignment.\n",
    "        # A : bz x W x H x clusters\n",
    "        max_cluster_score = K.max(cluster_score, -1, keepdims=True)\n",
    "        exp_cluster_score = K.exp(cluster_score - max_cluster_score)\n",
    "        A = exp_cluster_score / K.sum(exp_cluster_score, axis=-1, keepdims = True)\n",
    "\n",
    "        # Now, need to compute the residual, self.cluster: clusters x D\n",
    "        A = K.expand_dims(A, -1)    # A : bz x W x H x clusters x 1\n",
    "        feat_broadcast = K.expand_dims(feat, -2)    # feat_broadcast : bz x W x H x 1 x D\n",
    "        feat_res = feat_broadcast - self.cluster    # feat_res : bz x W x H x clusters x D\n",
    "        weighted_res = tf.multiply(A, feat_res)     # weighted_res : bz x W x H x clusters x D\n",
    "        cluster_res = K.sum(weighted_res, [1, 2])\n",
    "\n",
    "        if self.mode == 'gvlad':\n",
    "            cluster_res = cluster_res[:, :self.k_centers, :]\n",
    "\n",
    "        cluster_l2 = K.l2_normalize(cluster_res, -1)\n",
    "        outputs = K.reshape(cluster_l2, [-1, int(self.k_centers) * int(num_features)])\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def amsoftmax_loss(y_true, y_pred, scale=30, margin=0.35):\n",
    "    y_pred = y_true * (y_pred - margin) + (1 - y_true) * y_pred\n",
    "    y_pred *= scale\n",
    "    return K.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "\n",
    "\n",
    "def vggvox_resnet2d_icassp(input_dim=(257, 250, 1), num_class=8631, mode='train', args=None):\n",
    "    \n",
    "    # python predict.py --gpu 1 --net resnet34s --ghost_cluster 2 \n",
    "    # --vlad_cluster 8 --loss softmax --resume\n",
    "    \n",
    "    net='resnet34s'\n",
    "    loss='softmax'\n",
    "    vlad_clusters=8\n",
    "    ghost_clusters=2\n",
    "    bottleneck_dim=512\n",
    "    aggregation = 'gvlad'\n",
    "    mgpu = 0\n",
    "\n",
    "    if net == 'resnet34s':\n",
    "        inputs, x = resnet_2D_v1(input_dim=input_dim, mode=mode)\n",
    "    else:\n",
    "        inputs, x = resnet_2D_v2(input_dim=input_dim, mode=mode)\n",
    "    # ===============================================\n",
    "    #            Fully Connected Block 1\n",
    "    # ===============================================\n",
    "    x_fc = keras.layers.Conv2D(bottleneck_dim, (7, 1),\n",
    "                               strides=(1, 1),\n",
    "                               activation='relu',\n",
    "                               kernel_initializer='orthogonal',\n",
    "                               use_bias=True, trainable=True,\n",
    "                               kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               name='x_fc')(x)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Feature Aggregation\n",
    "    # ===============================================\n",
    "    if aggregation == 'avg':\n",
    "        if mode == 'train':\n",
    "            x = keras.layers.AveragePooling2D((1, 5), strides=(1, 1), name='avg_pool')(x)\n",
    "            x = keras.layers.Reshape((-1, bottleneck_dim))(x)\n",
    "        else:\n",
    "            x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "            x = keras.layers.Reshape((1, bottleneck_dim))(x)\n",
    "\n",
    "    elif aggregation == 'vlad':\n",
    "        x_k_center = keras.layers.Conv2D(vlad_clusters, (7, 1),\n",
    "                                         strides=(1, 1),\n",
    "                                         kernel_initializer='orthogonal',\n",
    "                                         use_bias=True, trainable=True,\n",
    "                                         kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         name='vlad_center_assignment')(x)\n",
    "        x = VladPooling(k_centers=vlad_clusters, mode='vlad', name='vlad_pool')([x_fc, x_k_center])\n",
    "\n",
    "    elif aggregation == 'gvlad':\n",
    "        x_k_center = keras.layers.Conv2D(vlad_clusters+ghost_clusters, (7, 1),\n",
    "                                         strides=(1, 1),\n",
    "                                         kernel_initializer='orthogonal',\n",
    "                                         use_bias=True, trainable=True,\n",
    "                                         kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                                         name='gvlad_center_assignment')(x)\n",
    "        x = VladPooling(k_centers=vlad_clusters, g_centers=ghost_clusters, mode='gvlad', name='gvlad_pool')([x_fc, x_k_center])\n",
    "\n",
    "    else:\n",
    "        raise IOError('==> unknown aggregation mode')\n",
    "\n",
    "    # ===============================================\n",
    "    #            Fully Connected Block 2\n",
    "    # ===============================================\n",
    "    x = keras.layers.Dense(bottleneck_dim, activation='relu',\n",
    "                           kernel_initializer='orthogonal',\n",
    "                           use_bias=True, trainable=True,\n",
    "                           kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                           bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                           name='fc6')(x)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Softmax Vs AMSoftmax\n",
    "    # ===============================================\n",
    "    if loss == 'softmax':\n",
    "        y = keras.layers.Dense(num_class, activation='softmax',\n",
    "                               kernel_initializer='orthogonal',\n",
    "                               use_bias=False, trainable=True,\n",
    "                               kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               name='prediction')(x)\n",
    "        trnloss = 'categorical_crossentropy'\n",
    "\n",
    "    elif loss == 'amsoftmax':\n",
    "        x_l2 = keras.layers.Lambda(lambda x: K.l2_normalize(x, 1))(x)\n",
    "        y = keras.layers.Dense(num_class,\n",
    "                               kernel_initializer='orthogonal',\n",
    "                               use_bias=False, trainable=True,\n",
    "                               kernel_constraint=keras.constraints.unit_norm(),\n",
    "                               kernel_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               bias_regularizer=keras.regularizers.l2(weight_decay),\n",
    "                               name='prediction')(x_l2)\n",
    "        trnloss = amsoftmax_loss\n",
    "\n",
    "    else:\n",
    "        raise IOError('==> unknown loss.')\n",
    "\n",
    "    if mode == 'eval':\n",
    "        y = keras.layers.Lambda(lambda x: keras.backend.l2_normalize(x, 1))(x)\n",
    "\n",
    "    model = keras.models.Model(inputs, y, name='vggvox_resnet2D_{}_{}'.format(loss, aggregation))\n",
    "\n",
    "    if mode == 'train':\n",
    "        if mgpu > 1:\n",
    "            model = ModelMGPU(model, gpus=mgpu)\n",
    "        # set up optimizer.\n",
    "        if args.optimizer == 'adam':  opt = keras.optimizers.Adam(lr=1e-3)\n",
    "        elif args.optimizer =='sgd':  opt = keras.optimizers.SGD(lr=0.1, momentum=0.9, decay=0.0, nesterov=True)\n",
    "        else: raise IOError('==> unknown optimizer type')\n",
    "        model.compile(optimizer=opt, loss=trnloss, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'dim': (257, None, 1),\n",
    "    'nfft': 512,\n",
    "    'spec_len': 250,\n",
    "    'win_length': 400,\n",
    "    'hop_length': 160,\n",
    "    'n_classes': 5994,\n",
    "    'sampling_rate': 16000,\n",
    "    'normalize': True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "network_eval = vggvox_resnet2d_icassp(input_dim=params['dim'],\n",
    "                                            num_class=params['n_classes'],\n",
    "                                            mode='eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-23 00:52:32--  https://f000.backblazeb2.com/file/malaya-speech-model/vggvox/weights-v2.h5\n",
      "Resolving f000.backblazeb2.com (f000.backblazeb2.com)... 104.153.233.177\n",
      "Connecting to f000.backblazeb2.com (f000.backblazeb2.com)|104.153.233.177|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 \n",
      "Length: 31052704 (30M) [application/octet-stream]\n",
      "Saving to: ‘weights-v2.h5’\n",
      "\n",
      "weights-v2.h5       100%[===================>]  29.61M  6.83MB/s    in 5.6s    \n",
      "\n",
      "2021-01-23 00:52:39 (5.32 MB/s) - ‘weights-v2.h5’ saved [31052704/31052704]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://f000.backblazeb2.com/file/malaya-speech-model/vggvox/weights-v2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_eval.load_weights('weights-v2.h5')\n",
    "session = tf.keras.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# ===============================================\n",
    "#       code from Arsha for loading data.\n",
    "# ===============================================\n",
    "def load_wav(vid_path, sr, mode='train'):\n",
    "    wav, sr_ret = librosa.load(vid_path, sr=sr)\n",
    "    assert sr_ret == sr\n",
    "    if mode == 'train':\n",
    "        extended_wav = np.append(wav, wav)\n",
    "        if np.random.random() < 0.3:\n",
    "            extended_wav = extended_wav[::-1]\n",
    "        return extended_wav\n",
    "    else:\n",
    "        extended_wav = np.append(wav, wav[::-1])\n",
    "        return extended_wav\n",
    "\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft=1024):\n",
    "    linear = librosa.stft(wav, n_fft=n_fft, win_length=win_length, hop_length=hop_length) # linear spectrogram\n",
    "    return linear.T\n",
    "\n",
    "\n",
    "def load_data(path, win_length=400, sr=16000, hop_length=160, n_fft=512, spec_len=250, mode='train'):\n",
    "    wav = load_wav(path, sr=sr, mode=mode)\n",
    "    linear_spect = lin_spectogram_from_wav(wav, hop_length, win_length, n_fft)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    mag_T = mag.T\n",
    "    freq, time = mag_T.shape\n",
    "    if mode == 'train':\n",
    "        if time > spec_len:\n",
    "            randtime = np.random.randint(0, time-spec_len)\n",
    "            spec_mag = mag_T[:, randtime:randtime+spec_len]\n",
    "        else:\n",
    "            spec_mag = np.pad(mag_T, ((0, 0), (0, spec_len - time)), 'constant')\n",
    "    else:\n",
    "        spec_mag = mag_T\n",
    "    # preprocessing, subtract mean, divided by time-wise var\n",
    "    mu = np.mean(spec_mag, 0, keepdims=True)\n",
    "    std = np.std(spec_mag, 0, keepdims=True)\n",
    "    return (spec_mag - mu) / (std + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('../speech/*.wav')\n",
    "wavs = [load_data(wav, mode = 'eval') for wav in files]\n",
    "[wav.shape for wav in wavs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [network_eval.predict(np.expand_dims([wav], -1)) for wav in wavs]\n",
    "r = np.concatenate(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.01467531, 0.03102608, ..., 0.01148013, 0.        ,\n",
       "        0.05208063],\n",
       "       [0.02824944, 0.01553196, 0.04535802, ..., 0.01659117, 0.0483754 ,\n",
       "        0.        ],\n",
       "       [0.04382843, 0.0547012 , 0.03658917, ..., 0.03810009, 0.        ,\n",
       "        0.01376203]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 3.62801550e-01, 3.06282542e-01],\n",
       "       [3.62801550e-01, 0.00000000e+00, 3.22202792e-01],\n",
       "       [3.06282542e-01, 3.22202792e-01, 1.11022302e-16]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "cdist(r, r, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out/vggvox.ckpt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(session, \"out/vggvox.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
