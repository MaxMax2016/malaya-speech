{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/tensorflow/models/master/research/slim/nets/inception_utils.py\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import inception_utils\n",
    "\n",
    "\n",
    "def block_inception_a(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Inception-A block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockInceptionA', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 96, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 96, [3, 3], scope = 'Conv2d_0b_3x3'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.conv2d(\n",
    "                    inputs, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 96, [3, 3], scope = 'Conv2d_0b_3x3'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 96, [3, 3], scope = 'Conv2d_0c_3x3'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_3'):\n",
    "                branch_3 = slim.avg_pool2d(\n",
    "                    inputs, [3, 3], scope = 'AvgPool_0a_3x3'\n",
    "                )\n",
    "                branch_3 = slim.conv2d(\n",
    "                    branch_3, 96, [1, 1], scope = 'Conv2d_0b_1x1'\n",
    "                )\n",
    "            return tf.concat(\n",
    "                axis = 3, values = [branch_0, branch_1, branch_2, branch_3]\n",
    "            )\n",
    "\n",
    "\n",
    "def block_reduction_a(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Reduction-A block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockReductionA', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs,\n",
    "                    384,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 224, [3, 3], scope = 'Conv2d_0b_3x3'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1,\n",
    "                    256,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.max_pool2d(\n",
    "                    inputs,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'MaxPool_1a_3x3',\n",
    "                )\n",
    "            return tf.concat(axis = 3, values = [branch_0, branch_1, branch_2])\n",
    "\n",
    "\n",
    "def block_inception_b(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Inception-B block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockInceptionB', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 384, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 224, [1, 7], scope = 'Conv2d_0b_1x7'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 256, [7, 1], scope = 'Conv2d_0c_7x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 192, [7, 1], scope = 'Conv2d_0b_7x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 224, [1, 7], scope = 'Conv2d_0c_1x7'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 224, [7, 1], scope = 'Conv2d_0d_7x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 256, [1, 7], scope = 'Conv2d_0e_1x7'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_3'):\n",
    "                branch_3 = slim.avg_pool2d(\n",
    "                    inputs, [3, 3], scope = 'AvgPool_0a_3x3'\n",
    "                )\n",
    "                branch_3 = slim.conv2d(\n",
    "                    branch_3, 128, [1, 1], scope = 'Conv2d_0b_1x1'\n",
    "                )\n",
    "            return tf.concat(\n",
    "                axis = 3, values = [branch_0, branch_1, branch_2, branch_3]\n",
    "            )\n",
    "\n",
    "\n",
    "def block_reduction_b(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Reduction-B block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockReductionB', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_0 = slim.conv2d(\n",
    "                    branch_0,\n",
    "                    192,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 256, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 256, [1, 7], scope = 'Conv2d_0b_1x7'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 320, [7, 1], scope = 'Conv2d_0c_7x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1,\n",
    "                    320,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.max_pool2d(\n",
    "                    inputs,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'MaxPool_1a_3x3',\n",
    "                )\n",
    "            return tf.concat(axis = 3, values = [branch_0, branch_1, branch_2])\n",
    "\n",
    "\n",
    "def block_inception_c(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Inception-C block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockInceptionC', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 256, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 384, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = tf.concat(\n",
    "                    axis = 3,\n",
    "                    values = [\n",
    "                        slim.conv2d(\n",
    "                            branch_1, 256, [1, 3], scope = 'Conv2d_0b_1x3'\n",
    "                        ),\n",
    "                        slim.conv2d(\n",
    "                            branch_1, 256, [3, 1], scope = 'Conv2d_0c_3x1'\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.conv2d(\n",
    "                    inputs, 384, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 448, [3, 1], scope = 'Conv2d_0b_3x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 512, [1, 3], scope = 'Conv2d_0c_1x3'\n",
    "                )\n",
    "                branch_2 = tf.concat(\n",
    "                    axis = 3,\n",
    "                    values = [\n",
    "                        slim.conv2d(\n",
    "                            branch_2, 256, [1, 3], scope = 'Conv2d_0d_1x3'\n",
    "                        ),\n",
    "                        slim.conv2d(\n",
    "                            branch_2, 256, [3, 1], scope = 'Conv2d_0e_3x1'\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            with tf.variable_scope('Branch_3'):\n",
    "                branch_3 = slim.avg_pool2d(\n",
    "                    inputs, [3, 3], scope = 'AvgPool_0a_3x3'\n",
    "                )\n",
    "                branch_3 = slim.conv2d(\n",
    "                    branch_3, 256, [1, 1], scope = 'Conv2d_0b_1x1'\n",
    "                )\n",
    "            return tf.concat(\n",
    "                axis = 3, values = [branch_0, branch_1, branch_2, branch_3]\n",
    "            )\n",
    "\n",
    "\n",
    "def inception_v4_base(inputs, final_endpoint = 'Mixed_7d', scope = None):\n",
    "    \"\"\"Creates the Inception V4 network up to the given final endpoint.\n",
    "  Args:\n",
    "    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n",
    "    final_endpoint: specifies the endpoint to construct the network up to.\n",
    "      It can be one of [ 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n",
    "      'Mixed_3a', 'Mixed_4a', 'Mixed_5a', 'Mixed_5b', 'Mixed_5c', 'Mixed_5d',\n",
    "      'Mixed_5e', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c', 'Mixed_6d', 'Mixed_6e',\n",
    "      'Mixed_6f', 'Mixed_6g', 'Mixed_6h', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c',\n",
    "      'Mixed_7d']\n",
    "    scope: Optional variable_scope.\n",
    "  Returns:\n",
    "    logits: the logits outputs of the model.\n",
    "    end_points: the set of end_points from the inception model.\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "  \"\"\"\n",
    "    end_points = {}\n",
    "\n",
    "    def add_and_check_final(name, net):\n",
    "        end_points[name] = net\n",
    "        return name == final_endpoint\n",
    "\n",
    "    with tf.variable_scope(scope, 'InceptionV4', [inputs]):\n",
    "        with slim.arg_scope(\n",
    "            [slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "            stride = 1,\n",
    "            padding = 'SAME',\n",
    "        ):\n",
    "            # 299 x 299 x 3\n",
    "            net = slim.conv2d(\n",
    "                inputs,\n",
    "                32,\n",
    "                [3, 3],\n",
    "                stride = 2,\n",
    "                padding = 'VALID',\n",
    "                scope = 'Conv2d_1a_3x3',\n",
    "            )\n",
    "            if add_and_check_final('Conv2d_1a_3x3', net):\n",
    "                return net, end_points\n",
    "            # 149 x 149 x 32\n",
    "            net = slim.conv2d(\n",
    "                net, 32, [3, 3], padding = 'VALID', scope = 'Conv2d_2a_3x3'\n",
    "            )\n",
    "            if add_and_check_final('Conv2d_2a_3x3', net):\n",
    "                return net, end_points\n",
    "            # 147 x 147 x 32\n",
    "            net = slim.conv2d(net, 64, [3, 3], scope = 'Conv2d_2b_3x3')\n",
    "            if add_and_check_final('Conv2d_2b_3x3', net):\n",
    "                return net, end_points\n",
    "            # 147 x 147 x 64\n",
    "            with tf.variable_scope('Mixed_3a'):\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.max_pool2d(\n",
    "                        net,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'MaxPool_0a_3x3',\n",
    "                    )\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        net,\n",
    "                        96,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_0a_3x3',\n",
    "                    )\n",
    "                net = tf.concat(axis = 3, values = [branch_0, branch_1])\n",
    "                if add_and_check_final('Mixed_3a', net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 73 x 73 x 160\n",
    "            with tf.variable_scope('Mixed_4a'):\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(\n",
    "                        net, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                    )\n",
    "                    branch_0 = slim.conv2d(\n",
    "                        branch_0,\n",
    "                        96,\n",
    "                        [3, 3],\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_1a_3x3',\n",
    "                    )\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        net, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                    )\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        branch_1, 64, [1, 7], scope = 'Conv2d_0b_1x7'\n",
    "                    )\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        branch_1, 64, [7, 1], scope = 'Conv2d_0c_7x1'\n",
    "                    )\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        branch_1,\n",
    "                        96,\n",
    "                        [3, 3],\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_1a_3x3',\n",
    "                    )\n",
    "                net = tf.concat(axis = 3, values = [branch_0, branch_1])\n",
    "                if add_and_check_final('Mixed_4a', net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 71 x 71 x 192\n",
    "            with tf.variable_scope('Mixed_5a'):\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(\n",
    "                        net,\n",
    "                        192,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_1a_3x3',\n",
    "                    )\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.max_pool2d(\n",
    "                        net,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'MaxPool_1a_3x3',\n",
    "                    )\n",
    "                net = tf.concat(axis = 3, values = [branch_0, branch_1])\n",
    "                if add_and_check_final('Mixed_5a', net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 35 x 35 x 384\n",
    "            # 4 x Inception-A blocks\n",
    "            for idx in range(4):\n",
    "                block_scope = 'Mixed_5' + chr(ord('b') + idx)\n",
    "                net = block_inception_a(net, block_scope)\n",
    "                if add_and_check_final(block_scope, net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 35 x 35 x 384\n",
    "            # Reduction-A block\n",
    "            net = block_reduction_a(net, 'Mixed_6a')\n",
    "            if add_and_check_final('Mixed_6a', net):\n",
    "                return net, end_points\n",
    "\n",
    "            # 17 x 17 x 1024\n",
    "            # 7 x Inception-B blocks\n",
    "            for idx in range(7):\n",
    "                block_scope = 'Mixed_6' + chr(ord('b') + idx)\n",
    "                net = block_inception_b(net, block_scope)\n",
    "                if add_and_check_final(block_scope, net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 17 x 17 x 1024\n",
    "            # Reduction-B block\n",
    "            net = block_reduction_b(net, 'Mixed_7a')\n",
    "            if add_and_check_final('Mixed_7a', net):\n",
    "                return net, end_points\n",
    "\n",
    "            # 8 x 8 x 1536\n",
    "            # 3 x Inception-C blocks\n",
    "            for idx in range(3):\n",
    "                block_scope = 'Mixed_7' + chr(ord('b') + idx)\n",
    "                net = block_inception_c(net, block_scope)\n",
    "                if add_and_check_final(block_scope, net):\n",
    "                    return net, end_points\n",
    "    raise ValueError('Unknown final endpoint %s' % final_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    inputs,\n",
    "    is_training = True,\n",
    "    dropout_keep_prob = 0.8,\n",
    "    reuse = None,\n",
    "    scope = 'InceptionV4',\n",
    "    bottleneck_dim = 512,\n",
    "):\n",
    "    # inputs = tf.image.grayscale_to_rgb(inputs)\n",
    "    with tf.variable_scope(\n",
    "        scope, 'InceptionV4', [inputs], reuse = reuse\n",
    "    ) as scope:\n",
    "        with slim.arg_scope(\n",
    "            [slim.batch_norm, slim.dropout], is_training = is_training\n",
    "        ):\n",
    "            net, end_points = inception_v4_base(inputs, scope = scope)\n",
    "            print(net.shape)\n",
    "\n",
    "            with slim.arg_scope(\n",
    "                [slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "                stride = 1,\n",
    "                padding = 'SAME',\n",
    "            ):\n",
    "                with tf.variable_scope('Logits'):\n",
    "                    # 8 x 8 x 1536\n",
    "                    kernel_size = net.get_shape()[1:3]\n",
    "                    print(kernel_size)\n",
    "                    if kernel_size.is_fully_defined():\n",
    "                        net = slim.avg_pool2d(\n",
    "                            net,\n",
    "                            kernel_size,\n",
    "                            padding = 'VALID',\n",
    "                            scope = 'AvgPool_1a',\n",
    "                        )\n",
    "                    else:\n",
    "                        net = tf.reduce_mean(\n",
    "                            input_tensor = net,\n",
    "                            axis = [1, 2],\n",
    "                            keepdims = True,\n",
    "                            name = 'global_pool',\n",
    "                        )\n",
    "                    end_points['global_pool'] = net\n",
    "                    # 1 x 1 x 1536\n",
    "                    net = slim.dropout(\n",
    "                        net, dropout_keep_prob, scope = 'Dropout_1b'\n",
    "                    )\n",
    "                    net = slim.flatten(net, scope = 'PreLogitsFlatten')\n",
    "                    end_points['PreLogitsFlatten'] = net\n",
    "                    \n",
    "                    bottleneck = slim.fully_connected(\n",
    "                        net, bottleneck_dim, scope = 'bottleneck'\n",
    "                    )\n",
    "                    logits = slim.fully_connected(\n",
    "                        bottleneck,\n",
    "                        5994,\n",
    "                        activation_fn = None,\n",
    "                        scope = 'Logits',\n",
    "                    )\n",
    "                    return logits, bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 257, None, 1])\n",
    "        with slim.arg_scope(inception_utils.inception_arg_scope()):\n",
    "            self.l, self.bottleneck = model(self.X, is_training = True)\n",
    "        print(self.l, self.bottleneck)\n",
    "        self.bottleneck = tf.keras.layers.Lambda(lambda x: tf.keras.backend.l2_normalize(x, 1))(self.bottleneck)\n",
    "        self.logits = tf.identity(self.bottleneck, name = 'logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "(?, 6, ?, 1536)\n",
      "(6, ?)\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "Tensor(\"InceptionV4/Logits/Logits/BiasAdd:0\", shape=(?, 5994), dtype=float32) Tensor(\"InceptionV4/Logits/bottleneck/Relu:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model_ = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-inception-v4/model.ckpt-401000\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, 'output-inception-v4/model.ckpt-401000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_wav(vid_path, sr = 16000, mode = 'eval'):\n",
    "    wav, sr_ret = librosa.load(vid_path, sr = sr)\n",
    "    assert sr_ret == sr\n",
    "    if mode == 'train':\n",
    "        extended_wav = np.append(wav, wav)\n",
    "        if np.random.random() < 0.3:\n",
    "            extended_wav = extended_wav[::-1]\n",
    "        return extended_wav\n",
    "    else:\n",
    "        extended_wav = np.append(wav, wav[::-1])\n",
    "        return extended_wav\n",
    "\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft = 1024):\n",
    "    linear = librosa.stft(\n",
    "        wav, n_fft = n_fft, win_length = win_length, hop_length = hop_length\n",
    "    )\n",
    "    return linear.T\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    wav,\n",
    "    win_length = 400,\n",
    "    sr = 16000,\n",
    "    hop_length = 160,\n",
    "    n_fft = 512,\n",
    "    spec_len = 120,\n",
    "    mode = 'eval',\n",
    "):\n",
    "    # wav = load_wav(wav, sr=sr, mode=mode)\n",
    "    linear_spect = lin_spectogram_from_wav(wav, hop_length, win_length, n_fft)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    mag_T = mag.T\n",
    "    freq, time = mag_T.shape\n",
    "    if mode == 'train':\n",
    "        if time < spec_len:\n",
    "            spec_mag = np.pad(mag_T, ((0, 0), (0, spec_len - time)), 'constant')\n",
    "        else:\n",
    "            spec_mag = mag_T\n",
    "    else:\n",
    "        spec_mag = mag_T\n",
    "    mu = np.mean(spec_mag, 0, keepdims = True)\n",
    "    std = np.std(spec_mag, 0, keepdims = True)\n",
    "    return (spec_mag - mu) / (std + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'husein-zolkepli.wav',\n",
    "    'khalil-nooh.wav',\n",
    "    'mas-aisyah.wav',\n",
    "    'shafiqah-idayu.wav'\n",
    "]\n",
    "wavs = [load_data(load_wav(f)) for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return sess.run(model_.bottleneck, \n",
    "                    feed_dict = {model_.X: np.expand_dims([x], -1)})\n",
    "\n",
    "#tf.math.l2_normalize(model_.bottleneck, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [pred(wav) for wav in wavs]\n",
    "r = np.concatenate(r)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22044605e-16, 1.14528449e-01, 7.90296252e-02, 8.54184667e-02],\n",
       "       [1.14528449e-01, 0.00000000e+00, 1.21785993e-01, 1.45189653e-01],\n",
       "       [7.90296252e-02, 1.21785993e-01, 2.22044605e-16, 9.33602606e-02],\n",
       "       [8.54184667e-02, 1.45189653e-01, 9.33602606e-02, 0.00000000e+00]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "cdist(r, r, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -czvf inception-v4-30-09-2020.tar.gz inception-v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('../vggvox-speaker-identification/indices.json') as fopen:\n",
    "    data = json.load(fopen)\n",
    "\n",
    "files = data['files']\n",
    "speakers = data['speakers']\n",
    "unique_speakers = sorted(list(speakers.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(file):\n",
    "    return file.split('/')[-1].split('-')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "cycle_files = itertools.cycle(files)\n",
    "\n",
    "def random_sample(sample, sr, length = 500):\n",
    "    sr = int(sr / 1000)\n",
    "    r = np.random.randint(0, len(sample) - (sr * length))\n",
    "    return sample[r : r + sr * length]\n",
    "\n",
    "def generate(sample_rate = 16000, max_length = 5):\n",
    "    while True:\n",
    "        file = next(cycle_files)\n",
    "        try:\n",
    "            y = unique_speakers.index(get_id(file))\n",
    "            w = load_wav(file)\n",
    "            if len(w) / sample_rate > max_length:\n",
    "                w = random_sample(\n",
    "                    w, sample_rate, random.randint(500, max_length * 1000)\n",
    "                )\n",
    "\n",
    "            # if random.randint(0, 1):\n",
    "            #     w = add_noise(\n",
    "            #         w, random.choice(noises), random.uniform(0.1, 0.5)\n",
    "            #     )\n",
    "            w = load_data(w)\n",
    "            yield {'inputs': np.expand_dims(w, -1), 'targets': [y]}\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(batch_size = 32, shuffle_size = 5):\n",
    "    def get():\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generate,\n",
    "            {'inputs': tf.float32, 'targets': tf.int32},\n",
    "            output_shapes = {\n",
    "                'inputs': tf.TensorShape([257, None, 1]),\n",
    "                'targets': tf.TensorShape([1]),\n",
    "            },\n",
    "        )\n",
    "        dataset = dataset.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes = {\n",
    "                'inputs': tf.TensorShape([257, None, 1]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values = {\n",
    "                'inputs': tf.constant(0, dtype = tf.float32),\n",
    "                'targets': tf.constant(0, dtype = tf.int32),\n",
    "            },\n",
    "        )\n",
    "        dataset = dataset.shuffle(shuffle_size)\n",
    "        return dataset\n",
    "\n",
    "    return get\n",
    "\n",
    "dataset = get_dataset()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-21-2a2c36f7bd20>:1: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return sess.run(model_.l, feed_dict = {model_.X: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2240, 3614, 1654, 3004, 1424, 5416, 3495,  759,  812, 1334, 1392,\n",
       "        5394, 5058, 2722, 5160, 1296, 5667, 4540, 4739, 1318, 5868, 2505,\n",
       "        1286, 3943, 3533, 4754, 5473, 5006, 2982, 2207, 2503, 3765]),\n",
       " array([2240, 3614, 1654, 3004, 1424, 5416, 3495,  759,  812, 1334, 1392,\n",
       "        5394, 5058, 2722, 5160, 1296,  897, 4540, 4739, 1318, 5868, 2505,\n",
       "        1286, 3943, 3533, 4754, 5473, 5006, 2982, 2207, 2503, 3765],\n",
       "       dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sess.run(iterator)\n",
    "np.argmax(pred(data['inputs']), axis = 1), data['targets'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'inception-v4/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name\n",
    "        or 'self/Softmax' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from inception-v4/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-25-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 600 variables.\n",
      "INFO:tensorflow:Converted 600 variables to const ops.\n",
      "1900 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('inception-v4', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename, **kwargs):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # https://github.com/onnx/tensorflow-onnx/issues/77#issuecomment-445066091\n",
    "    # to fix import T5\n",
    "    for node in graph_def.node:\n",
    "        if node.op == 'RefSwitch':\n",
    "            node.op = 'Switch'\n",
    "            for index in xrange(len(node.input)):\n",
    "                if 'moving_' in node.input[index]:\n",
    "                    node.input[index] = node.input[index] + '/read'\n",
    "        elif node.op == 'AssignSub':\n",
    "            node.op = 'Sub'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'AssignAdd':\n",
    "            node.op = 'Add'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'Assign':\n",
    "            node.op = 'Identity'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "            if 'validate_shape' in node.attr:\n",
    "                del node.attr['validate_shape']\n",
    "            if len(node.input) == 2:\n",
    "                node.input[0] = node.input[1]\n",
    "                del node.input[1]\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('inception-v4/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 257, 498, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['inputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sess.run(logits, feed_dict = {x: data['inputs'][:2]}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
