{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# !wget https://raw.githubusercontent.com/tensorflow/models/master/research/slim/nets/inception_utils.py\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tf_slim as slim\n",
    "import inception_utils\n",
    "\n",
    "\n",
    "def block_inception_a(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Inception-A block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockInceptionA', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 96, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 96, [3, 3], scope = 'Conv2d_0b_3x3'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.conv2d(\n",
    "                    inputs, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 96, [3, 3], scope = 'Conv2d_0b_3x3'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 96, [3, 3], scope = 'Conv2d_0c_3x3'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_3'):\n",
    "                branch_3 = slim.avg_pool2d(\n",
    "                    inputs, [3, 3], scope = 'AvgPool_0a_3x3'\n",
    "                )\n",
    "                branch_3 = slim.conv2d(\n",
    "                    branch_3, 96, [1, 1], scope = 'Conv2d_0b_1x1'\n",
    "                )\n",
    "            return tf.concat(\n",
    "                axis = 3, values = [branch_0, branch_1, branch_2, branch_3]\n",
    "            )\n",
    "\n",
    "\n",
    "def block_reduction_a(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Reduction-A block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockReductionA', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs,\n",
    "                    384,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 224, [3, 3], scope = 'Conv2d_0b_3x3'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1,\n",
    "                    256,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.max_pool2d(\n",
    "                    inputs,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'MaxPool_1a_3x3',\n",
    "                )\n",
    "            return tf.concat(axis = 3, values = [branch_0, branch_1, branch_2])\n",
    "\n",
    "\n",
    "def block_inception_b(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Inception-B block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockInceptionB', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 384, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 224, [1, 7], scope = 'Conv2d_0b_1x7'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 256, [7, 1], scope = 'Conv2d_0c_7x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 192, [7, 1], scope = 'Conv2d_0b_7x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 224, [1, 7], scope = 'Conv2d_0c_1x7'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 224, [7, 1], scope = 'Conv2d_0d_7x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 256, [1, 7], scope = 'Conv2d_0e_1x7'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_3'):\n",
    "                branch_3 = slim.avg_pool2d(\n",
    "                    inputs, [3, 3], scope = 'AvgPool_0a_3x3'\n",
    "                )\n",
    "                branch_3 = slim.conv2d(\n",
    "                    branch_3, 128, [1, 1], scope = 'Conv2d_0b_1x1'\n",
    "                )\n",
    "            return tf.concat(\n",
    "                axis = 3, values = [branch_0, branch_1, branch_2, branch_3]\n",
    "            )\n",
    "\n",
    "\n",
    "def block_reduction_b(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Reduction-B block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockReductionB', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 192, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_0 = slim.conv2d(\n",
    "                    branch_0,\n",
    "                    192,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 256, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 256, [1, 7], scope = 'Conv2d_0b_1x7'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1, 320, [7, 1], scope = 'Conv2d_0c_7x1'\n",
    "                )\n",
    "                branch_1 = slim.conv2d(\n",
    "                    branch_1,\n",
    "                    320,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'Conv2d_1a_3x3',\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.max_pool2d(\n",
    "                    inputs,\n",
    "                    [3, 3],\n",
    "                    stride = 2,\n",
    "                    padding = 'VALID',\n",
    "                    scope = 'MaxPool_1a_3x3',\n",
    "                )\n",
    "            return tf.concat(axis = 3, values = [branch_0, branch_1, branch_2])\n",
    "\n",
    "\n",
    "def block_inception_c(inputs, scope = None, reuse = None):\n",
    "    \"\"\"Builds Inception-C block for Inception v4 network.\"\"\"\n",
    "    # By default use stride=1 and SAME padding\n",
    "    with slim.arg_scope(\n",
    "        [slim.conv2d, slim.avg_pool2d, slim.max_pool2d],\n",
    "        stride = 1,\n",
    "        padding = 'SAME',\n",
    "    ):\n",
    "        with tf.variable_scope(\n",
    "            scope, 'BlockInceptionC', [inputs], reuse = reuse\n",
    "        ):\n",
    "            with tf.variable_scope('Branch_0'):\n",
    "                branch_0 = slim.conv2d(\n",
    "                    inputs, 256, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "            with tf.variable_scope('Branch_1'):\n",
    "                branch_1 = slim.conv2d(\n",
    "                    inputs, 384, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_1 = tf.concat(\n",
    "                    axis = 3,\n",
    "                    values = [\n",
    "                        slim.conv2d(\n",
    "                            branch_1, 256, [1, 3], scope = 'Conv2d_0b_1x3'\n",
    "                        ),\n",
    "                        slim.conv2d(\n",
    "                            branch_1, 256, [3, 1], scope = 'Conv2d_0c_3x1'\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            with tf.variable_scope('Branch_2'):\n",
    "                branch_2 = slim.conv2d(\n",
    "                    inputs, 384, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 448, [3, 1], scope = 'Conv2d_0b_3x1'\n",
    "                )\n",
    "                branch_2 = slim.conv2d(\n",
    "                    branch_2, 512, [1, 3], scope = 'Conv2d_0c_1x3'\n",
    "                )\n",
    "                branch_2 = tf.concat(\n",
    "                    axis = 3,\n",
    "                    values = [\n",
    "                        slim.conv2d(\n",
    "                            branch_2, 256, [1, 3], scope = 'Conv2d_0d_1x3'\n",
    "                        ),\n",
    "                        slim.conv2d(\n",
    "                            branch_2, 256, [3, 1], scope = 'Conv2d_0e_3x1'\n",
    "                        ),\n",
    "                    ],\n",
    "                )\n",
    "            with tf.variable_scope('Branch_3'):\n",
    "                branch_3 = slim.avg_pool2d(\n",
    "                    inputs, [3, 3], scope = 'AvgPool_0a_3x3'\n",
    "                )\n",
    "                branch_3 = slim.conv2d(\n",
    "                    branch_3, 256, [1, 1], scope = 'Conv2d_0b_1x1'\n",
    "                )\n",
    "            return tf.concat(\n",
    "                axis = 3, values = [branch_0, branch_1, branch_2, branch_3]\n",
    "            )\n",
    "\n",
    "\n",
    "def inception_v4_base(inputs, final_endpoint = 'Mixed_7d', scope = None):\n",
    "    \"\"\"Creates the Inception V4 network up to the given final endpoint.\n",
    "  Args:\n",
    "    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n",
    "    final_endpoint: specifies the endpoint to construct the network up to.\n",
    "      It can be one of [ 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n",
    "      'Mixed_3a', 'Mixed_4a', 'Mixed_5a', 'Mixed_5b', 'Mixed_5c', 'Mixed_5d',\n",
    "      'Mixed_5e', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c', 'Mixed_6d', 'Mixed_6e',\n",
    "      'Mixed_6f', 'Mixed_6g', 'Mixed_6h', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c',\n",
    "      'Mixed_7d']\n",
    "    scope: Optional variable_scope.\n",
    "  Returns:\n",
    "    logits: the logits outputs of the model.\n",
    "    end_points: the set of end_points from the inception model.\n",
    "  Raises:\n",
    "    ValueError: if final_endpoint is not set to one of the predefined values,\n",
    "  \"\"\"\n",
    "    end_points = {}\n",
    "\n",
    "    def add_and_check_final(name, net):\n",
    "        end_points[name] = net\n",
    "        return name == final_endpoint\n",
    "\n",
    "    with tf.variable_scope(scope, 'InceptionV4', [inputs]):\n",
    "        with slim.arg_scope(\n",
    "            [slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "            stride = 1,\n",
    "            padding = 'SAME',\n",
    "        ):\n",
    "            # 299 x 299 x 3\n",
    "            net = slim.conv2d(\n",
    "                inputs,\n",
    "                32,\n",
    "                [3, 3],\n",
    "                stride = 2,\n",
    "                padding = 'VALID',\n",
    "                scope = 'Conv2d_1a_3x3',\n",
    "            )\n",
    "            if add_and_check_final('Conv2d_1a_3x3', net):\n",
    "                return net, end_points\n",
    "            # 149 x 149 x 32\n",
    "            net = slim.conv2d(\n",
    "                net, 32, [3, 3], padding = 'VALID', scope = 'Conv2d_2a_3x3'\n",
    "            )\n",
    "            if add_and_check_final('Conv2d_2a_3x3', net):\n",
    "                return net, end_points\n",
    "            # 147 x 147 x 32\n",
    "            net = slim.conv2d(net, 64, [3, 3], scope = 'Conv2d_2b_3x3')\n",
    "            if add_and_check_final('Conv2d_2b_3x3', net):\n",
    "                return net, end_points\n",
    "            # 147 x 147 x 64\n",
    "            with tf.variable_scope('Mixed_3a'):\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.max_pool2d(\n",
    "                        net,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'MaxPool_0a_3x3',\n",
    "                    )\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        net,\n",
    "                        96,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_0a_3x3',\n",
    "                    )\n",
    "                net = tf.concat(axis = 3, values = [branch_0, branch_1])\n",
    "                if add_and_check_final('Mixed_3a', net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 73 x 73 x 160\n",
    "            with tf.variable_scope('Mixed_4a'):\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(\n",
    "                        net, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                    )\n",
    "                    branch_0 = slim.conv2d(\n",
    "                        branch_0,\n",
    "                        96,\n",
    "                        [3, 3],\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_1a_3x3',\n",
    "                    )\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        net, 64, [1, 1], scope = 'Conv2d_0a_1x1'\n",
    "                    )\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        branch_1, 64, [1, 7], scope = 'Conv2d_0b_1x7'\n",
    "                    )\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        branch_1, 64, [7, 1], scope = 'Conv2d_0c_7x1'\n",
    "                    )\n",
    "                    branch_1 = slim.conv2d(\n",
    "                        branch_1,\n",
    "                        96,\n",
    "                        [3, 3],\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_1a_3x3',\n",
    "                    )\n",
    "                net = tf.concat(axis = 3, values = [branch_0, branch_1])\n",
    "                if add_and_check_final('Mixed_4a', net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 71 x 71 x 192\n",
    "            with tf.variable_scope('Mixed_5a'):\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(\n",
    "                        net,\n",
    "                        192,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'Conv2d_1a_3x3',\n",
    "                    )\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.max_pool2d(\n",
    "                        net,\n",
    "                        [3, 3],\n",
    "                        stride = 2,\n",
    "                        padding = 'VALID',\n",
    "                        scope = 'MaxPool_1a_3x3',\n",
    "                    )\n",
    "                net = tf.concat(axis = 3, values = [branch_0, branch_1])\n",
    "                if add_and_check_final('Mixed_5a', net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 35 x 35 x 384\n",
    "            # 4 x Inception-A blocks\n",
    "            for idx in range(4):\n",
    "                block_scope = 'Mixed_5' + chr(ord('b') + idx)\n",
    "                net = block_inception_a(net, block_scope)\n",
    "                if add_and_check_final(block_scope, net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 35 x 35 x 384\n",
    "            # Reduction-A block\n",
    "            net = block_reduction_a(net, 'Mixed_6a')\n",
    "            if add_and_check_final('Mixed_6a', net):\n",
    "                return net, end_points\n",
    "\n",
    "            # 17 x 17 x 1024\n",
    "            # 7 x Inception-B blocks\n",
    "            for idx in range(7):\n",
    "                block_scope = 'Mixed_6' + chr(ord('b') + idx)\n",
    "                net = block_inception_b(net, block_scope)\n",
    "                if add_and_check_final(block_scope, net):\n",
    "                    return net, end_points\n",
    "\n",
    "            # 17 x 17 x 1024\n",
    "            # Reduction-B block\n",
    "            net = block_reduction_b(net, 'Mixed_7a')\n",
    "            if add_and_check_final('Mixed_7a', net):\n",
    "                return net, end_points\n",
    "\n",
    "            # 8 x 8 x 1536\n",
    "            # 3 x Inception-C blocks\n",
    "            for idx in range(3):\n",
    "                block_scope = 'Mixed_7' + chr(ord('b') + idx)\n",
    "                net = block_inception_c(net, block_scope)\n",
    "                if add_and_check_final(block_scope, net):\n",
    "                    return net, end_points\n",
    "    raise ValueError('Unknown final endpoint %s' % final_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(\n",
    "    inputs,\n",
    "    is_training = True,\n",
    "    dropout_keep_prob = 0.8,\n",
    "    reuse = None,\n",
    "    scope = 'InceptionV4',\n",
    "    bottleneck_dim = 512,\n",
    "):\n",
    "    # inputs = tf.image.grayscale_to_rgb(inputs)\n",
    "    with tf.variable_scope(\n",
    "        scope, 'InceptionV4', [inputs], reuse = reuse\n",
    "    ) as scope:\n",
    "        with slim.arg_scope(\n",
    "            [slim.batch_norm, slim.dropout], is_training = is_training\n",
    "        ):\n",
    "            net, end_points = inception_v4_base(inputs, scope = scope)\n",
    "            print(net.shape)\n",
    "\n",
    "            with slim.arg_scope(\n",
    "                [slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\n",
    "                stride = 1,\n",
    "                padding = 'SAME',\n",
    "            ):\n",
    "                with tf.variable_scope('Logits'):\n",
    "                    # 8 x 8 x 1536\n",
    "                    kernel_size = net.get_shape()[1:3]\n",
    "                    print(kernel_size)\n",
    "                    if kernel_size.is_fully_defined():\n",
    "                        net = slim.avg_pool2d(\n",
    "                            net,\n",
    "                            kernel_size,\n",
    "                            padding = 'VALID',\n",
    "                            scope = 'AvgPool_1a',\n",
    "                        )\n",
    "                    else:\n",
    "                        net = tf.reduce_mean(\n",
    "                            input_tensor = net,\n",
    "                            axis = [1, 2],\n",
    "                            keepdims = True,\n",
    "                            name = 'global_pool',\n",
    "                        )\n",
    "                    end_points['global_pool'] = net\n",
    "                    # 1 x 1 x 1536\n",
    "                    net = slim.dropout(\n",
    "                        net, dropout_keep_prob, scope = 'Dropout_1b'\n",
    "                    )\n",
    "                    net = slim.flatten(net, scope = 'PreLogitsFlatten')\n",
    "                    end_points['PreLogitsFlatten'] = net\n",
    "                    \n",
    "                    bottleneck = slim.fully_connected(\n",
    "                        net, bottleneck_dim, scope = 'bottleneck'\n",
    "                    )\n",
    "                    logits = slim.fully_connected(\n",
    "                        bottleneck,\n",
    "                        5994,\n",
    "                        activation_fn = None,\n",
    "                        scope = 'Logits',\n",
    "                    )\n",
    "                    return logits, bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 257, None, 1])\n",
    "        with slim.arg_scope(inception_utils.inception_arg_scope()):\n",
    "            self.logits, self.bottleneck = model(self.X, is_training = True)\n",
    "        print(self.logits, self.bottleneck)\n",
    "        self.bottleneck = tf.keras.layers.Lambda(lambda x: tf.keras.backend.l2_normalize(x, 1))(self.bottleneck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "(?, 6, ?, 1536)\n",
      "(6, ?)\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:1666: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "Tensor(\"InceptionV4/Logits/Logits/BiasAdd:0\", shape=(?, 5994), dtype=float32) Tensor(\"InceptionV4/Logits/bottleneck/Relu:0\", shape=(?, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model_ = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../malaya-speech/output-inception-v4/model.ckpt-301000\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, '../malaya-speech/output-inception-v4/model.ckpt-301000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def load_wav(vid_path, sr = 16000, mode = 'eval'):\n",
    "    wav, sr_ret = librosa.load(vid_path, sr = sr)\n",
    "    assert sr_ret == sr\n",
    "    if mode == 'train':\n",
    "        extended_wav = np.append(wav, wav)\n",
    "        if np.random.random() < 0.3:\n",
    "            extended_wav = extended_wav[::-1]\n",
    "        return extended_wav\n",
    "    else:\n",
    "        extended_wav = np.append(wav, wav[::-1])\n",
    "        return extended_wav\n",
    "\n",
    "\n",
    "def lin_spectogram_from_wav(wav, hop_length, win_length, n_fft = 1024):\n",
    "    linear = librosa.stft(\n",
    "        wav, n_fft = n_fft, win_length = win_length, hop_length = hop_length\n",
    "    )\n",
    "    return linear.T\n",
    "\n",
    "\n",
    "def load_data(\n",
    "    wav,\n",
    "    win_length = 400,\n",
    "    sr = 16000,\n",
    "    hop_length = 160,\n",
    "    n_fft = 512,\n",
    "    spec_len = 120,\n",
    "    mode = 'eval',\n",
    "):\n",
    "    # wav = load_wav(wav, sr=sr, mode=mode)\n",
    "    linear_spect = lin_spectogram_from_wav(wav, hop_length, win_length, n_fft)\n",
    "    mag, _ = librosa.magphase(linear_spect)  # magnitude\n",
    "    mag_T = mag.T\n",
    "    freq, time = mag_T.shape\n",
    "    if mode == 'train':\n",
    "        if time < spec_len:\n",
    "            spec_mag = np.pad(mag_T, ((0, 0), (0, spec_len - time)), 'constant')\n",
    "        else:\n",
    "            spec_mag = mag_T\n",
    "    else:\n",
    "        spec_mag = mag_T\n",
    "    mu = np.mean(spec_mag, 0, keepdims = True)\n",
    "    std = np.std(spec_mag, 0, keepdims = True)\n",
    "    return (spec_mag - mu) / (std + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test-*.wav pickle-*.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import random\n",
    "\n",
    "files = glob('../voxceleb/aac/**/*.m4a', recursive = True)\n",
    "files = random.sample(files, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 194/200 [00:59<00:01,  3.09it/s]\n",
      " 98%|█████████▊| 195/200 [00:59<00:01,  2.94it/s]\n",
      "100%|██████████| 200/200 [00:59<00:00,  3.35it/s]\n",
      "100%|██████████| 200/200 [00:59<00:00,  3.34it/s]\n",
      " 99%|█████████▉| 198/200 [01:00<00:00,  2.87it/s]\n",
      "100%|██████████| 200/200 [01:00<00:00,  3.30it/s]\n",
      "\n",
      " 98%|█████████▊| 196/200 [01:00<00:01,  2.61it/s]\n",
      "100%|██████████| 200/200 [01:00<00:00,  3.29it/s]\n",
      "100%|██████████| 200/200 [01:00<00:00,  3.28it/s]\n",
      " 98%|█████████▊| 197/200 [01:00<00:01,  2.29it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.28it/s]\n",
      "\n",
      "\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.27it/s]\n",
      " 98%|█████████▊| 196/200 [01:01<00:01,  2.56it/s]\n",
      " 98%|█████████▊| 195/200 [01:01<00:02,  2.06it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.26it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.26it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.25it/s]\n",
      " 98%|█████████▊| 196/200 [01:01<00:01,  2.12it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.24it/s]\n",
      " 94%|█████████▍| 189/200 [01:01<00:03,  2.78it/s]\n",
      "100%|██████████| 200/200 [01:01<00:00,  3.23it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.22it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.21it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.21it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.21it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.21it/s]\n",
      "100%|██████████| 200/200 [01:02<00:00,  3.18it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.17it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  2.01it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.15it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.15it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.14it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.14it/s]\n",
      "100%|██████████| 200/200 [01:03<00:00,  3.14it/s]\n",
      "100%|██████████| 200/200 [01:04<00:00,  3.12it/s]\n",
      "100%|██████████| 200/200 [01:04<00:00,  3.11it/s]\n",
      "100%|██████████| 200/200 [01:05<00:00,  3.08it/s]\n",
      "100%|██████████| 200/200 [01:07<00:00,  2.95it/s]\n",
      "100%|██████████| 200/200 [01:08<00:00,  2.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import mp\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def loop(args):\n",
    "    files = args[0]\n",
    "    index = args[1]\n",
    "    results = []\n",
    "    for file in tqdm(files):\n",
    "        \n",
    "        audio = AudioSegment.from_file(file[1])\n",
    "        audio.set_frame_rate(16000).set_channels(1).export(f'test-{index}.wav', format=\"wav\")\n",
    "        l = load_data(load_wav(f'test-{index}.wav'))\n",
    "        results.append((file[0], file[1], l))\n",
    "        \n",
    "    with open(f'pickle-{index}.pkl', 'wb') as fopen:\n",
    "        pickle.dump(results, fopen)\n",
    "\n",
    "files_index = [(no, f) for no, f in enumerate(files)]\n",
    "r = mp.multiprocessing(files_index, loop, cores = 50, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test-*.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../voxceleb/vox2_meta.csv')\n",
    "df = df[df['Set '] == 'test ']\n",
    "speakers = df['VoxCeleb2 ID '].unique().tolist()\n",
    "speakers = [s.strip() for s in speakers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "speakers_idx = defaultdict(list)\n",
    "\n",
    "for speaker in speakers:\n",
    "    for file in files:\n",
    "        if speaker in file:\n",
    "            speakers_idx[speaker].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:16<00:00, 593.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "k = 10\n",
    "labels = []\n",
    "\n",
    "def get_id(file):\n",
    "    return file.split('/')[3]\n",
    "\n",
    "for file in tqdm(files):\n",
    "    left_speaker = get_id(file)\n",
    "    for speaker in speakers:\n",
    "        if left_speaker == speaker:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "        samples = random.sample(speakers_idx[speaker], min(k, len(speakers_idx[speaker])))\n",
    "        for s in samples:\n",
    "            labels.append((label, file, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "\n",
    "pickles = glob('pickle-*.pkl')\n",
    "\n",
    "pooled = []\n",
    "for p in pickles:\n",
    "    with open(p, 'rb') as fopen:\n",
    "        pooled.append(pickle.load(fopen))\n",
    "        \n",
    "pooled = list(itertools.chain(*pooled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(x):\n",
    "    return sess.run(model_.bottleneck, \n",
    "                    feed_dict = {model_.X: np.expand_dims([x], -1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [34:04<00:00,  4.89it/s] \n"
     ]
    }
   ],
   "source": [
    "mapping = {i[1]: pred(i[2]) for i in tqdm(pooled)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11740000/11740000 [01:58<00:00, 99155.18it/s] \n"
     ]
    }
   ],
   "source": [
    "scores, ls = [], []\n",
    "\n",
    "for i in tqdm(range(len(labels))):\n",
    "    ls.append(labels[i][0])\n",
    "    scores.append(np.sum(mapping[labels[i][1]][0] * mapping[labels[i][2]][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eer(y, y_score):\n",
    "    \n",
    "    from scipy.optimize import brentq\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4948220059836142, array(0.88095476))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_eer(ls, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test-*.wav pickle-*.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
