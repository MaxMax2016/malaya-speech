{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/voxceleb/voxceleb2-test-sample.json\n",
    "# !wget https://f000.backblazeb2.com/file/malay-dataset/voxceleb/voxceleb2-test-labels.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import malaya_speech.train.model.conformer as conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('voxceleb2-test-sample.json') as fopen:\n",
    "    sample_files = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('voxceleb2-test-labels.pkl', 'rb') as fopen:\n",
    "    labels = pickle.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_files = []\n",
    "for l in labels:\n",
    "    unique_files.extend(l[1:])\n",
    "    \n",
    "unique_files = list(set(unique_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "wav2mel = torch.jit.load('wav2mel.pt')\n",
    "dvector = torch.jit.load('dvector-step250000.pt').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = wav2mel.cuda()\n",
    "_ = dvector.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                 | 0/36237 [00:00<?, ?it/s]/tmp/ipykernel_3651179/3707568404.py:6: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:968.)\n",
      "  emb_tensor = dvector.embed_utterance(mel_tensor.cuda())\n",
      "100%|█████████████████████████████████████| 36237/36237 [07:39<00:00, 78.82it/s]\n"
     ]
    }
   ],
   "source": [
    "vectors = {}\n",
    "for f in tqdm(unique_files):\n",
    "    y_, _ = malaya_speech.load(f.replace('/home/husein/youtube/', '/home/husein/'))\n",
    "    try:\n",
    "        mel_tensor = wav2mel(torch.tensor(y_.astype('float32')).unsqueeze(0), 16000)\n",
    "        emb_tensor = dvector.embed_utterance(mel_tensor.cuda())\n",
    "        v = emb_tensor.cpu().detach().numpy()\n",
    "        vectors[f] = v\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 5900000/5900000 [00:15<00:00, 380148.90it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scores, ls = [], []\n",
    "\n",
    "for i in tqdm(range(len(labels))):\n",
    "    if labels[i][1] in vectors and labels[i][2] in vectors:\n",
    "        ls.append(labels[i][0])\n",
    "        scores.append(np.sum(vectors[labels[i][1]] * vectors[labels[i][2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5900000, 36237)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores), len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_eer(y, y_score):\n",
    "    \n",
    "    from scipy.optimize import brentq\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "    thresh = interp1d(fpr, thresholds)(eer)\n",
    "    return eer, thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13564905982985956, array(0.20760974))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_eer(ls, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
