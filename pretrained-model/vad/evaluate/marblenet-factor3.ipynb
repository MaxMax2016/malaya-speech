{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:6: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech.train as train\n",
    "import malaya_speech\n",
    "import malaya_speech.train.model.marblenet as marblenet\n",
    "import tensorflow as tf\n",
    "import malaya_speech.config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.ctc_featurizer_config\n",
    "config['feature_type'] = 'mfcc'\n",
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(**config)\n",
    "n_mels = featurizer.num_feature_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_inputs(example):\n",
    "    s = featurizer.vectorize(example['waveforms'])\n",
    "    s = tf.reshape(s, (-1, n_mels))\n",
    "    length = tf.cast(tf.shape(s)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['inputs'] = s\n",
    "    example['inputs_length'] = length\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.VarLenFeature(tf.float32),\n",
    "        'targets': tf.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.parse_single_example(\n",
    "        serialized_example, features=data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "\n",
    "    features = preprocess_inputs(features)\n",
    "\n",
    "    keys = list(features.keys())\n",
    "    for k in keys:\n",
    "        if k not in ['inputs', 'inputs_length', 'targets']:\n",
    "            features.pop(k, None)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_dataset(files, batch_size=32, shuffle_size=32, num_cpu_threads=6,\n",
    "                thread_count=24, is_training=True):\n",
    "    def get():\n",
    "        if is_training:\n",
    "            d = tf.data.Dataset.from_tensor_slices(tf.constant(files))\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size=len(files))\n",
    "            cycle_length = min(num_cpu_threads, len(files))\n",
    "            d = d.interleave(\n",
    "                tf.data.TFRecordDataset,\n",
    "                cycle_length=cycle_length,\n",
    "                block_length=batch_size)\n",
    "            d = d.shuffle(buffer_size=100)\n",
    "        else:\n",
    "            d = tf.data.TFRecordDataset(files)\n",
    "            d = d.repeat()\n",
    "        d = d.map(parse, num_parallel_calls=thread_count)\n",
    "        d = d.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes={\n",
    "                'inputs': tf.TensorShape([None, n_mels]),\n",
    "                'inputs_length': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values={\n",
    "                'inputs': tf.constant(0, dtype=tf.float32),\n",
    "                'inputs_length': tf.constant(0, dtype=tf.int32),\n",
    "                'targets': tf.constant(0, dtype=tf.int64),\n",
    "            },\n",
    "        )\n",
    "        return d\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-e5b4f8c97c59>:5: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int64>,\n",
       " 'inputs': <tf.Tensor 'IteratorGetNext:0' shape=(?, ?, 80) dtype=float32>,\n",
       " 'inputs_length': <tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_files = tf.io.gfile.glob(\n",
    "    'vad/data/vad-dev*'\n",
    ")\n",
    "dev_dataset = get_dataset(dev_files, is_training=False)()\n",
    "features = dev_dataset.make_one_shot_iterator().get_next()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/abstract.py:143: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:327: separable_conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.SeparableConv1D` instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/convolutional.py:971: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:358: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/model.py:217: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/openseq2seq/layer.py:340: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-1fefca83966c>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    }
   ],
   "source": [
    "Y = tf.cast(features['targets'][:, 0], tf.int32)\n",
    "model = marblenet.Model(features['inputs'], features['inputs_length'][:, 0], factor=3, training=True)\n",
    "logits = tf.reduce_sum(model.logits['outputs'], axis=1)\n",
    "logits = tf.layers.dense(logits, 2)\n",
    "\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=Y\n",
    "    )\n",
    ")\n",
    "\n",
    "accuracy = tf.metrics.accuracy(\n",
    "    labels=Y, predictions=tf.argmax(logits, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from marblenet-factor3/model.ckpt-2000000\n"
     ]
    }
   ],
   "source": [
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'marblenet-factor3/model.ckpt-2000000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:57<00:00, 174.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "eval_step = 10000\n",
    "rs = []\n",
    "for i in tqdm(range(eval_step)):\n",
    "    r = sess.run([Y, logits])\n",
    "    rs.append((r[0] == r[1].argmax(axis = 1)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83855625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
