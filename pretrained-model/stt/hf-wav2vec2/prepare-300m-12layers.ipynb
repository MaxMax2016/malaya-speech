{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2Config,\n",
    "    is_apex_available,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    'mesolitica/wav2vec2-xls-r-300m-mixed', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Config {\n",
       "  \"_name_or_path\": \"mesolitica/wav2vec2-xls-r-300m-mixed\",\n",
       "  \"activation_dropout\": 0.05,\n",
       "  \"adapter_kernel_size\": 3,\n",
       "  \"adapter_stride\": 2,\n",
       "  \"add_adapter\": false,\n",
       "  \"apply_spec_augment\": true,\n",
       "  \"architectures\": [\n",
       "    \"Wav2Vec2ForCTC\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.05,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"classifier_proj_size\": 256,\n",
       "  \"codevector_dim\": 768,\n",
       "  \"contrastive_logits_temperature\": 0.1,\n",
       "  \"conv_bias\": true,\n",
       "  \"conv_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512\n",
       "  ],\n",
       "  \"conv_kernel\": [\n",
       "    10,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"conv_stride\": [\n",
       "    5,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"ctc_loss_reduction\": \"mean\",\n",
       "  \"ctc_zero_infinity\": true,\n",
       "  \"diversity_loss_weight\": 0.1,\n",
       "  \"do_stable_layer_norm\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feat_extract_activation\": \"gelu\",\n",
       "  \"feat_extract_dropout\": 0.0,\n",
       "  \"feat_extract_norm\": \"layer\",\n",
       "  \"feat_proj_dropout\": 0.05,\n",
       "  \"feat_quantizer_dropout\": 0.0,\n",
       "  \"final_dropout\": 0.0,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.05,\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4096,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"layerdrop\": 0.05,\n",
       "  \"mask_feature_length\": 10,\n",
       "  \"mask_feature_min_masks\": 0,\n",
       "  \"mask_feature_prob\": 0.0,\n",
       "  \"mask_time_length\": 10,\n",
       "  \"mask_time_min_masks\": 2,\n",
       "  \"mask_time_prob\": 0.05,\n",
       "  \"model_type\": \"wav2vec2\",\n",
       "  \"num_adapter_layers\": 3,\n",
       "  \"num_attention_heads\": 16,\n",
       "  \"num_codevector_groups\": 2,\n",
       "  \"num_codevectors_per_group\": 320,\n",
       "  \"num_conv_pos_embedding_groups\": 16,\n",
       "  \"num_conv_pos_embeddings\": 128,\n",
       "  \"num_feat_extract_layers\": 7,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_negatives\": 100,\n",
       "  \"output_hidden_size\": 1024,\n",
       "  \"pad_token_id\": 39,\n",
       "  \"proj_codevector_dim\": 768,\n",
       "  \"tdnn_dilation\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"tdnn_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    1500\n",
       "  ],\n",
       "  \"tdnn_kernel\": [\n",
       "    5,\n",
       "    3,\n",
       "    3,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.25.1\",\n",
       "  \"use_weighted_layer_sum\": false,\n",
       "  \"vocab_size\": 40,\n",
       "  \"xvector_output_dim\": 512\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "half_config = Wav2Vec2Config.from_pretrained('mesolitica/wav2vec2-xls-r-300m-mixed', \n",
    "                                             num_hidden_layers = 12,\n",
    "                                            vocab_size = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "half = Wav2Vec2ForCTC(half_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def copy_layers(src_layers, dest_layers, layers_to_copy):\n",
    "    layers_to_copy = nn.ModuleList([src_layers[i] for i in layers_to_copy])\n",
    "    assert len(dest_layers) == len(layers_to_copy), f\"{len(dest_layers)} != {len(layers_to_copy)}\"\n",
    "    dest_layers.load_state_dict(layers_to_copy.state_dict())\n",
    "\n",
    "layers_to_copy = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "copy_layers(model.wav2vec2.encoder.layers, half.wav2vec2.encoder.layers, layers_to_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_extractor, feature_projection\n",
    "\n",
    "half.wav2vec2.feature_extractor.load_state_dict(model.wav2vec2.feature_extractor.state_dict())\n",
    "half.wav2vec2.feature_projection.load_state_dict(model.wav2vec2.feature_projection.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf 300m-12-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "half.save_pretrained(\"300m-12-layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 627M\r\n",
      "-rw-r--r-- 1 husein husein 2.1K Jan  30 13:50 config.json\r\n",
      "-rw-r--r-- 1 husein husein 627M Jan  30 13:50 pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh 300m-12-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "udev             32G     0   32G   0% /dev\r\n",
      "tmpfs           6.3G  3.0M  6.3G   1% /run\r\n",
      "/dev/nvme0n1p2  916G  736G  133G  85% /\r\n",
      "tmpfs            32G  220M   32G   1% /dev/shm\r\n",
      "tmpfs           5.0M  4.0K  5.0M   1% /run/lock\r\n",
      "tmpfs            32G     0   32G   0% /sys/fs/cgroup\r\n",
      "/dev/loop0      128K  128K     0 100% /snap/bare/5\r\n",
      "/dev/loop3      6.9M  6.9M     0 100% /snap/ngrok/89\r\n",
      "/dev/loop2       66M   66M     0 100% /snap/gtk-common-themes/1519\r\n",
      "/dev/loop4       50M   50M     0 100% /snap/snapd/17883\r\n",
      "/dev/loop6      347M  347M     0 100% /snap/gnome-3-38-2004/115\r\n",
      "/dev/loop8       46M   46M     0 100% /snap/snap-store/599\r\n",
      "/dev/loop9       92M   92M     0 100% /snap/gtk-common-themes/1535\r\n",
      "/dev/loop11     347M  347M     0 100% /snap/gnome-3-38-2004/119\r\n",
      "/dev/loop10      46M   46M     0 100% /snap/snap-store/638\r\n",
      "/dev/nvme0n1p1  511M  5.3M  506M   2% /boot/efi\r\n",
      "/dev/sda1       880G  499G  337G  60% /home/husein/ssd1\r\n",
      "tmpfs           6.3G  8.0K  6.3G   1% /run/user/125\r\n",
      "/dev/loop12      64M   64M     0 100% /snap/core20/1738\r\n",
      "none             32G  164K   32G   1% /run/qemu\r\n",
      "/dev/loop5       56M   56M     0 100% /snap/core18/2654\r\n",
      "/dev/loop13      56M   56M     0 100% /snap/core18/2667\r\n",
      "/dev/loop1       64M   64M     0 100% /snap/core20/1778\r\n",
      "tmpfs           6.3G  4.0K  6.3G   1% /run/user/1000\r\n",
      "/dev/nvme1n1    916G  769G  101G  89% /home/husein/ssd2\r\n",
      "/dev/loop7       50M   50M     0 100% /snap/snapd/17950\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoFeatureExtractor, SpeechEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained('mesolitica/wav2vec2-xls-r-300m-mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['300m-12-layers/preprocessor_config.json']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.save_pretrained(\"300m-12-layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
