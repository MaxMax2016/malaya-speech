{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/huseinzol05/language-model-bahasa-manglish-combined/resolve/main/model.klm -O language-model-bahasa-manglish-combined.kelm\n",
    "# !pip3 install pyctcdecode==0.1.0 pypi-kenlm==0.1.20210121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2ForCTC,\n",
    "    Wav2Vec2Processor,\n",
    "    is_apex_available,\n",
    "    set_seed,\n",
    "    AutoModelForCTC,\n",
    "    TFWav2Vec2ForCTC,\n",
    "    TFWav2Vec2PreTrainedModel,\n",
    "    Wav2Vec2PreTrainedModel,\n",
    "    AutoConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForCTC.from_pretrained('mesolitica/wav2vec2-xls-r-300m-mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "\n",
    "CTC_VOCAB = [''] + list(string.ascii_lowercase + string.digits) + [' ']\n",
    "vocab_dict = {v: k for k, v in enumerate(CTC_VOCAB)}\n",
    "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "del vocab_dict[\" \"]\n",
    "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "\n",
    "with open(\"ctc-vocab-export.json\", \"w\") as vocab_file:\n",
    "    json.dump(vocab_dict, vocab_file)\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\n",
    "    \"ctc-vocab-export.json\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    word_delimiter_token=\"|\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import librosa\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/husein/ssd1/speech-bahasa/malay-asr-test.json') as fopen:\n",
    "    test_set = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [librosa.load(f, sr = 16000)[0] for f in test_set['X'][:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _ = librosa.load('husein-zolkepli.wav', sr = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_audio(x):\n",
    "    return (x - x.mean()) / np.sqrt(x.var() + 1e-7)\n",
    "\n",
    "def sequence_1d(\n",
    "    seq, maxlen=None, padding: str = 'post', pad_int=0, return_len=False\n",
    "):\n",
    "    if padding not in ['post', 'pre']:\n",
    "        raise ValueError('padding only supported [`post`, `pre`]')\n",
    "\n",
    "    if not maxlen:\n",
    "        maxlen = max([len(s) for s in seq])\n",
    "\n",
    "    padded_seqs, length = [], []\n",
    "    for s in seq:\n",
    "        if isinstance(s, np.ndarray):\n",
    "            s = s.tolist()\n",
    "        if padding == 'post':\n",
    "            padded_seqs.append(s + [pad_int] * (maxlen - len(s)))\n",
    "        if padding == 'pre':\n",
    "            padded_seqs.append([pad_int] * (maxlen - len(s)) + s)\n",
    "        length.append(len(s))\n",
    "    if return_len:\n",
    "        return np.array(padded_seqs), length\n",
    "    return np.array(padded_seqs)\n",
    "\n",
    "batch, lens = sequence_1d([y] + ys,return_len=True)\n",
    "attentions = [[1] * l for l in lens]\n",
    "attentions = sequence_1d(attentions)\n",
    "normed_input_values = []\n",
    "\n",
    "for vector, length in zip(batch, attentions.sum(-1)):\n",
    "    normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
    "    if length < normed_slice.shape[0]:\n",
    "        normed_slice[length:] = 0.0\n",
    "\n",
    "    normed_input_values.append(normed_slice)\n",
    "    \n",
    "normed_input_values = np.array(normed_input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_pt = model(torch.from_numpy(normed_input_values.astype(np.float32)), \n",
    "             attention_mask = torch.from_numpy(attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testing nama saya hussein bin zolkaple',\n",
       " 'ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf oftik',\n",
       " 'gymnastik s dan joas mempunyai matlamat yang sama menjadikan sukan gybnastik dan lain lain selamat bagi para atlet untuk mengejar impian mereka dalam persekitaran yang selamat positif dan berdaya maju']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_pt = o_pt.logits.detach().numpy()\n",
    "pred_ids = np.argmax(o_pt, axis = -1)\n",
    "tokenizer.batch_decode(pred_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "import kenlm\n",
    "\n",
    "unique_vocab = list(vocab_dict.keys())\n",
    "unique_vocab[-3] = ' ' \n",
    "unique_vocab[-2] = '?'\n",
    "unique_vocab[-1] = '_'\n",
    "kenlm_model = kenlm.Model('language-model-bahasa-manglish-combined.kelm')\n",
    "decoder = build_ctcdecoder(\n",
    "    unique_vocab,\n",
    "    kenlm_model,\n",
    "    alpha=0.2,\n",
    "    beta=1.0,\n",
    "    ctc_token_idx=tokenizer.pad_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 testing nama saya hussein bin zolkapli\n",
      "1 ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik\n",
      "2 ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik\n",
      "3 gymnastik as dan joas mempunyai matlamat yang sama menjadikan sukan gimnastik dan lain lain selamat bagi para atlet untuk mengejar impian mereka dalam persekitaran yang selamat positif dan berdaya maju\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(o_pt)):\n",
    "    out = decoder.decode_beams(o_pt[k], prune_history=True)\n",
    "    d_lm2, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "    print(k, d_lm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "from scipy.special import log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 370/370 [01:36<00:00,  3.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "wer, cer = [], []\n",
    "wer_lm, cer_lm = [], []\n",
    "\n",
    "batch_size = 2\n",
    "for i in tqdm(range(0, len(test_set['X']), batch_size)):\n",
    "    batch_y = test_set['Y'][i: i + batch_size]\n",
    "    ys = [malaya_speech.load(f)[0] for f in test_set['X'][i: i + batch_size]]\n",
    "    batch, lens = sequence_1d(ys,return_len=True)\n",
    "    attentions = [[1] * l for l in lens]\n",
    "    attentions = sequence_1d(attentions)\n",
    "    normed_input_values = []\n",
    "\n",
    "    for vector, length in zip(batch, attentions.sum(-1)):\n",
    "        normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
    "        if length < normed_slice.shape[0]:\n",
    "            normed_slice[length:] = 0.0\n",
    "\n",
    "        normed_input_values.append(normed_slice)\n",
    "    \n",
    "    normed_input_values = np.array(normed_input_values)\n",
    "    o_pt = model(torch.from_numpy(normed_input_values.astype(np.float32)).cuda(), \n",
    "             attention_mask = torch.from_numpy(attentions).cuda())\n",
    "    o_pt = o_pt.logits.detach().cpu().numpy()\n",
    "    o_pt = log_softmax(o_pt, axis = -1)\n",
    "    pred_ids = np.argmax(o_pt, axis = -1)\n",
    "    pred = tokenizer.batch_decode(pred_ids)\n",
    "    for k in range(len(o_pt)):\n",
    "        out = decoder.decode_beams(o_pt[k], prune_history=True)\n",
    "        d_lm2, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "        \n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))\n",
    "        \n",
    "        wer_lm.append(calculate_wer(batch_y[k], d_lm2))\n",
    "        cer_lm.append(calculate_cer(batch_y[k], d_lm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23738612595212136,\n",
       " 0.07055478006684142,\n",
       " 0.1716938954303812,\n",
       " 0.05916313167919988)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer), np.mean(wer_lm), np.mean(cer_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('postprocess-malaya-malay-test-set.json') as fopen:\n",
    "    malaya_malay = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 765/765 [00:20<00:00, 37.30it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "wer_lm, cer_lm = [], []\n",
    "\n",
    "for i in tqdm(range(len(malaya_malay))):\n",
    "    if not malaya_malay[i]['accept']:\n",
    "        continue\n",
    "    \n",
    "    batch_y = [malaya_malay[i]['cleaned']]\n",
    "    ys = [malaya_speech.load(f)[0] for f in [f'malay-test/{i}.wav']]\n",
    "    batch, lens = sequence_1d(ys,return_len=True)\n",
    "    attentions = [[1] * l for l in lens]\n",
    "    attentions = sequence_1d(attentions)\n",
    "    normed_input_values = []\n",
    "\n",
    "    for vector, length in zip(batch, attentions.sum(-1)):\n",
    "        normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
    "        if length < normed_slice.shape[0]:\n",
    "            normed_slice[length:] = 0.0\n",
    "\n",
    "        normed_input_values.append(normed_slice)\n",
    "    \n",
    "    normed_input_values = np.array(normed_input_values)\n",
    "    o_pt = model(torch.from_numpy(normed_input_values.astype(np.float32)).cuda(), \n",
    "             attention_mask = torch.from_numpy(attentions).cuda())\n",
    "    o_pt = o_pt.logits.detach().cpu().numpy()\n",
    "    o_pt = log_softmax(o_pt, axis = -1)\n",
    "    pred_ids = np.argmax(o_pt, axis = -1)\n",
    "    pred = tokenizer.batch_decode(pred_ids)\n",
    "    for k in range(len(o_pt)):\n",
    "        out = decoder.decode_beams(o_pt[k], prune_history=True)\n",
    "        d_lm2, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "        \n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))\n",
    "        \n",
    "        wer_lm.append(calculate_wer(batch_y[k], d_lm2))\n",
    "        cer_lm.append(calculate_cer(batch_y[k], d_lm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1946551289436665,\n",
       " 0.04775798989091143,\n",
       " 0.12849904267888457,\n",
       " 0.0357602212596816)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer), np.mean(wer_lm), np.mean(cer_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('singlish-test.json') as fopen:\n",
    "    singlish = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3579/3579 [01:44<00:00, 34.27it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "wer_lm, cer_lm = [], []\n",
    "\n",
    "for i in tqdm(range(len(singlish))):\n",
    "    \n",
    "    batch_y = [singlish[i]]\n",
    "    ys = [malaya_speech.load(f)[0] for f in [f'singlish-test/{i}.wav']]\n",
    "    batch, lens = sequence_1d(ys,return_len=True)\n",
    "    attentions = [[1] * l for l in lens]\n",
    "    attentions = sequence_1d(attentions)\n",
    "    normed_input_values = []\n",
    "\n",
    "    for vector, length in zip(batch, attentions.sum(-1)):\n",
    "        normed_slice = (vector - vector[:length].mean()) / np.sqrt(vector[:length].var() + 1e-7)\n",
    "        if length < normed_slice.shape[0]:\n",
    "            normed_slice[length:] = 0.0\n",
    "\n",
    "        normed_input_values.append(normed_slice)\n",
    "    \n",
    "    normed_input_values = np.array(normed_input_values)\n",
    "    o_pt = model(torch.from_numpy(normed_input_values.astype(np.float32)).cuda(), \n",
    "             attention_mask = torch.from_numpy(attentions).cuda())\n",
    "    o_pt = o_pt.logits.detach().cpu().numpy()\n",
    "    o_pt = log_softmax(o_pt, axis = -1)\n",
    "    pred_ids = np.argmax(o_pt, axis = -1)\n",
    "    pred = tokenizer.batch_decode(pred_ids)\n",
    "    for k in range(len(o_pt)):\n",
    "        out = decoder.decode_beams(o_pt[k], prune_history=True)\n",
    "        d_lm2, lm_state, timesteps, logit_score, lm_score = out[0]\n",
    "        \n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))\n",
    "        \n",
    "        wer_lm.append(calculate_wer(batch_y[k], d_lm2))\n",
    "        cer_lm.append(calculate_cer(batch_y[k], d_lm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1275885951545911,\n",
       " 0.049492497930946455,\n",
       " 0.09682029107142659,\n",
       " 0.042727603734778574)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer), np.mean(wer_lm), np.mean(cer_lm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
