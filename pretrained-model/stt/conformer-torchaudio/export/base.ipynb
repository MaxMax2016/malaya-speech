{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torchaudio\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchaudio.models import Hypothesis, RNNTBeamSearch\n",
    "from torchaudio.models import Conformer, RNNT\n",
    "from torchaudio.models.rnnt import _Joiner, _Predictor, _TimeReduction, _Transcriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ConformerEncoder(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input_dim: int,\n",
    "        output_dim: int,\n",
    "        time_reduction_stride: int,\n",
    "        conformer_input_dim: int,\n",
    "        conformer_ffn_dim: int,\n",
    "        conformer_num_layers: int,\n",
    "        conformer_num_heads: int,\n",
    "        conformer_depthwise_conv_kernel_size: int,\n",
    "        conformer_dropout: float,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.time_reduction = _TimeReduction(time_reduction_stride)\n",
    "        self.input_linear = torch.nn.Linear(input_dim * time_reduction_stride, conformer_input_dim)\n",
    "        self.conformer = Conformer(\n",
    "            num_layers=conformer_num_layers,\n",
    "            input_dim=conformer_input_dim,\n",
    "            ffn_dim=conformer_ffn_dim,\n",
    "            num_heads=conformer_num_heads,\n",
    "            depthwise_conv_kernel_size=conformer_depthwise_conv_kernel_size,\n",
    "            dropout=conformer_dropout,\n",
    "            use_group_norm=True,\n",
    "            convolution_first=True,\n",
    "        )\n",
    "        self.output_linear = torch.nn.Linear(conformer_input_dim, output_dim)\n",
    "        self.layer_norm = torch.nn.LayerNorm(output_dim)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, lengths: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        time_reduction_out, time_reduction_lengths = self.time_reduction(input, lengths)\n",
    "        input_linear_out = self.input_linear(time_reduction_out)\n",
    "        x, lengths = self.conformer(input_linear_out, time_reduction_lengths)\n",
    "        output_linear_out = self.output_linear(x)\n",
    "        layer_norm_out = self.layer_norm(output_linear_out)\n",
    "        return layer_norm_out, lengths\n",
    "\n",
    "    def infer(\n",
    "        self,\n",
    "        input: torch.Tensor,\n",
    "        lengths: torch.Tensor,\n",
    "        states: Optional[List[List[torch.Tensor]]],\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, List[List[torch.Tensor]]]:\n",
    "        raise RuntimeError(\"Conformer does not support streaming inference.\")\n",
    "\n",
    "\n",
    "def conformer_rnnt_model(\n",
    "    *,\n",
    "    input_dim: int,\n",
    "    encoding_dim: int,\n",
    "    time_reduction_stride: int,\n",
    "    conformer_input_dim: int,\n",
    "    conformer_ffn_dim: int,\n",
    "    conformer_num_layers: int,\n",
    "    conformer_num_heads: int,\n",
    "    conformer_depthwise_conv_kernel_size: int,\n",
    "    conformer_dropout: float,\n",
    "    num_symbols: int,\n",
    "    symbol_embedding_dim: int,\n",
    "    num_lstm_layers: int,\n",
    "    lstm_hidden_dim: int,\n",
    "    lstm_layer_norm: int,\n",
    "    lstm_layer_norm_epsilon: int,\n",
    "    lstm_dropout: int,\n",
    "    joiner_activation: str,\n",
    ") -> RNNT:\n",
    "    r\"\"\"Builds Conformer-based recurrent neural network transducer (RNN-T) model.\n",
    "    Args:\n",
    "        input_dim (int): dimension of input sequence frames passed to transcription network.\n",
    "        encoding_dim (int): dimension of transcription- and prediction-network-generated encodings\n",
    "            passed to joint network.\n",
    "        time_reduction_stride (int): factor by which to reduce length of input sequence.\n",
    "        conformer_input_dim (int): dimension of Conformer input.\n",
    "        conformer_ffn_dim (int): hidden layer dimension of each Conformer layer's feedforward network.\n",
    "        conformer_num_layers (int): number of Conformer layers to instantiate.\n",
    "        conformer_num_heads (int): number of attention heads in each Conformer layer.\n",
    "        conformer_depthwise_conv_kernel_size (int): kernel size of each Conformer layer's depthwise convolution layer.\n",
    "        conformer_dropout (float): Conformer dropout probability.\n",
    "        num_symbols (int): cardinality of set of target tokens.\n",
    "        symbol_embedding_dim (int): dimension of each target token embedding.\n",
    "        num_lstm_layers (int): number of LSTM layers to instantiate.\n",
    "        lstm_hidden_dim (int): output dimension of each LSTM layer.\n",
    "        lstm_layer_norm (bool): if ``True``, enables layer normalization for LSTM layers.\n",
    "        lstm_layer_norm_epsilon (float): value of epsilon to use in LSTM layer normalization layers.\n",
    "        lstm_dropout (float): LSTM dropout probability.\n",
    "        joiner_activation (str): activation function to use in the joiner.\n",
    "            Must be one of (\"relu\", \"tanh\"). (Default: \"relu\")\n",
    "        Returns:\n",
    "            RNNT:\n",
    "                Conformer RNN-T model.\n",
    "    \"\"\"\n",
    "    encoder = _ConformerEncoder(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=encoding_dim,\n",
    "        time_reduction_stride=time_reduction_stride,\n",
    "        conformer_input_dim=conformer_input_dim,\n",
    "        conformer_ffn_dim=conformer_ffn_dim,\n",
    "        conformer_num_layers=conformer_num_layers,\n",
    "        conformer_num_heads=conformer_num_heads,\n",
    "        conformer_depthwise_conv_kernel_size=conformer_depthwise_conv_kernel_size,\n",
    "        conformer_dropout=conformer_dropout,\n",
    "    )\n",
    "    predictor = _Predictor(\n",
    "        num_symbols=num_symbols,\n",
    "        output_dim=encoding_dim,\n",
    "        symbol_embedding_dim=symbol_embedding_dim,\n",
    "        num_lstm_layers=num_lstm_layers,\n",
    "        lstm_hidden_dim=lstm_hidden_dim,\n",
    "        lstm_layer_norm=lstm_layer_norm,\n",
    "        lstm_layer_norm_epsilon=lstm_layer_norm_epsilon,\n",
    "        lstm_dropout=lstm_dropout,\n",
    "    )\n",
    "    joiner = _Joiner(encoding_dim, num_symbols, activation=joiner_activation)\n",
    "    return RNNT(encoder, predictor, joiner)\n",
    "\n",
    "\n",
    "def conformer_rnnt_base() -> RNNT:\n",
    "    r\"\"\"Builds basic version of Conformer RNN-T model.\n",
    "    Returns:\n",
    "        RNNT:\n",
    "            Conformer RNN-T model.\n",
    "    \"\"\"\n",
    "    return conformer_rnnt_model(\n",
    "        input_dim=80,\n",
    "        encoding_dim=1024,\n",
    "        time_reduction_stride=4,\n",
    "        conformer_input_dim=256,\n",
    "        conformer_ffn_dim=1024,\n",
    "        conformer_num_layers=16,\n",
    "        conformer_num_heads=4,\n",
    "        conformer_depthwise_conv_kernel_size=31,\n",
    "        conformer_dropout=0.1,\n",
    "        num_symbols=1024,\n",
    "        symbol_embedding_dim=256,\n",
    "        num_lstm_layers=2,\n",
    "        lstm_hidden_dim=512,\n",
    "        lstm_layer_norm=True,\n",
    "        lstm_layer_norm_epsilon=1e-5,\n",
    "        lstm_dropout=0.3,\n",
    "        joiner_activation=\"tanh\",\n",
    "    )\n",
    "\n",
    "def conformer_rnnt_tiny() -> RNNT:\n",
    "\n",
    "    return conformer_rnnt_model(\n",
    "        input_dim=80,\n",
    "        encoding_dim=1024,\n",
    "        time_reduction_stride=4,\n",
    "        conformer_input_dim=144,\n",
    "        conformer_ffn_dim=576,\n",
    "        conformer_num_layers=8,\n",
    "        conformer_num_heads=4,\n",
    "        conformer_depthwise_conv_kernel_size=31,\n",
    "        conformer_dropout=0.1,\n",
    "        num_symbols=1024,\n",
    "        symbol_embedding_dim=256,\n",
    "        num_lstm_layers=2,\n",
    "        lstm_hidden_dim=512,\n",
    "        lstm_layer_norm=True,\n",
    "        lstm_layer_norm_epsilon=1e-5,\n",
    "        lstm_dropout=0.3,\n",
    "        joiner_activation='tanh',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple(\"Batch\", [\"features\", \"feature_lengths\", \"targets\", \"target_lengths\"])\n",
    "\n",
    "class WarmupLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    r\"\"\"Learning rate scheduler that performs linear warmup and exponential annealing.\n",
    "    Args:\n",
    "        optimizer (torch.optim.Optimizer): optimizer to use.\n",
    "        warmup_steps (int): number of scheduler steps for which to warm up learning rate.\n",
    "        force_anneal_step (int): scheduler step at which annealing of learning rate begins.\n",
    "        anneal_factor (float): factor to scale base learning rate by at each annealing step.\n",
    "        last_epoch (int, optional): The index of last epoch. (Default: -1)\n",
    "        verbose (bool, optional): If ``True``, prints a message to stdout for\n",
    "            each update. (Default: ``False``)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        warmup_steps: int,\n",
    "        force_anneal_step: int,\n",
    "        anneal_factor: float,\n",
    "        last_epoch=-1,\n",
    "        verbose=False,\n",
    "    ):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.force_anneal_step = force_anneal_step\n",
    "        self.anneal_factor = anneal_factor\n",
    "        super().__init__(optimizer, last_epoch=last_epoch, verbose=verbose)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self._step_count < self.force_anneal_step:\n",
    "            return [(min(1.0, self._step_count / self.warmup_steps)) * base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            scaling_factor = self.anneal_factor ** (self._step_count - self.force_anneal_step)\n",
    "            return [scaling_factor * base_lr for base_lr in self.base_lrs]\n",
    "\n",
    "\n",
    "def post_process_hypos(\n",
    "    hypos: List[Hypothesis], sp_model: spm.SentencePieceProcessor\n",
    ") -> List[Tuple[str, float, List[int], List[int]]]:\n",
    "    tokens_idx = 0\n",
    "    score_idx = 3\n",
    "    post_process_remove_list = [\n",
    "        sp_model.unk_id(),\n",
    "        sp_model.eos_id(),\n",
    "        sp_model.pad_id(),\n",
    "    ]\n",
    "    filtered_hypo_tokens = [\n",
    "        [token_index for token_index in h[tokens_idx][1:] if token_index not in post_process_remove_list] for h in hypos\n",
    "    ]\n",
    "    hypos_str = [sp_model.decode(s) for s in filtered_hypo_tokens]\n",
    "    hypos_ids = [h[tokens_idx][1:] for h in hypos]\n",
    "    hypos_score = [[math.exp(h[score_idx])] for h in hypos]\n",
    "\n",
    "    nbest_batch = list(zip(hypos_str, hypos_score, hypos_ids))\n",
    "\n",
    "    return nbest_batch\n",
    "\n",
    "\n",
    "class ConformerRNNTModule(LightningModule):\n",
    "    def __init__(self, sp_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sp_model = sp_model\n",
    "        spm_vocab_size = self.sp_model.get_piece_size()\n",
    "        self.blank_idx = spm_vocab_size\n",
    "\n",
    "        # ``conformer_rnnt_base`` hardcodes a specific Conformer RNN-T configuration.\n",
    "        # For greater customizability, please refer to ``conformer_rnnt_model``.\n",
    "        self.model = conformer_rnnt_base()\n",
    "        self.loss = torchaudio.transforms.RNNTLoss(reduction=\"sum\")\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=8e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "        self.warmup_lr_scheduler = WarmupLR(self.optimizer, 40, 120, 0.96)\n",
    "\n",
    "    def _step(self, batch, _, step_type):\n",
    "        if batch is None:\n",
    "            return None\n",
    "\n",
    "        prepended_targets = batch.targets.new_empty([batch.targets.size(0), batch.targets.size(1) + 1])\n",
    "        prepended_targets[:, 1:] = batch.targets\n",
    "        prepended_targets[:, 0] = self.blank_idx\n",
    "        prepended_target_lengths = batch.target_lengths + 1\n",
    "        output, src_lengths, _, _ = self.model(\n",
    "            batch.features,\n",
    "            batch.feature_lengths,\n",
    "            prepended_targets,\n",
    "            prepended_target_lengths,\n",
    "        )\n",
    "        loss = self.loss(output, batch.targets, src_lengths, batch.target_lengths)\n",
    "        self.log(f\"Losses/{step_type}_loss\", loss, on_step=True, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return (\n",
    "            [self.optimizer],\n",
    "            [{\"scheduler\": self.warmup_lr_scheduler, \"interval\": \"epoch\"}],\n",
    "        )\n",
    "\n",
    "    def forward(self, batch: Batch):\n",
    "        decoder = RNNTBeamSearch(self.model, self.blank_idx)\n",
    "        hypotheses = decoder(batch.features.to(self.device), batch.feature_lengths.to(self.device), 20)\n",
    "        return post_process_hypos(hypotheses, self.sp_model)[0][0]\n",
    "\n",
    "    def training_step(self, batch: Batch, batch_idx = None):\n",
    "        \"\"\"Custom training step.\n",
    "        By default, DDP does the following on each train step:\n",
    "        - For each GPU, compute loss and gradient on shard of training data.\n",
    "        - Sync and average gradients across all GPUs. The final gradient\n",
    "          is (sum of gradients across all GPUs) / N, where N is the world\n",
    "          size (total number of GPUs).\n",
    "        - Update parameters on each GPU.\n",
    "        Here, we do the following:\n",
    "        - For k-th GPU, compute loss and scale it by (N / B_total), where B_total is\n",
    "          the sum of batch sizes across all GPUs. Compute gradient from scaled loss.\n",
    "        - Sync and average gradients across all GPUs. The final gradient\n",
    "          is (sum of gradients across all GPUs) / B_total.\n",
    "        - Update parameters on each GPU.\n",
    "        Doing so allows us to account for the variability in batch sizes that\n",
    "        variable-length sequential data yield.\n",
    "        \"\"\"\n",
    "        loss = self._step(batch, batch_idx, \"train\")\n",
    "        batch_size = batch.features.size(0)\n",
    "        batch_sizes = self.all_gather(batch_size)\n",
    "        self.log(\"Gathered batch size\", batch_sizes.sum(), on_step=True, on_epoch=True)\n",
    "        loss *= batch_sizes.size(0) / batch_sizes.sum()  # world size / batch size\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`pyaudio` is not available, `malaya_speech.streaming.pyaudio_vad.stream` is not able to use.\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "from malaya_speech.utils import torch_featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _ = malaya_speech.load('speech/example-speaker/husein-zolkepli.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_model = spm.SentencePieceProcessor(model_file='/home/husein/malaya-speech/malay-tts.model')\n",
    "global_stats = torch_featurization.GlobalStatsNormalization('malay-stats.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformerRNNTModule.load_from_checkpoint('conformer-base-v2-32/model-epoch=18-step=1890000.ckpt',\n",
    "                                                 sp_model=sp_model).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), 'conformer-base.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([564, 80])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel = torch_featurization.melspectrogram(y)\n",
    "mel = torch_featurization.piecewise_linear_log(mel)\n",
    "mel = global_stats(mel)\n",
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing nama saya hussein bin zulkifli'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = RNNTBeamSearch(model.model, model.blank_idx)\n",
    "hypotheses = decoder(mel, torch.Tensor((len(mel),)), 20)\n",
    "post_process_hypos(hypotheses, model.sp_model)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/husein/ssd1/speech-bahasa/malay-asr-test.json') as fopen:\n",
    "    test_set = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 739/739 [15:08<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(test_set['X']))):\n",
    "    batch_y = [test_set['Y'][i]]\n",
    "    y = malaya_speech.load(test_set['X'][i])[0]\n",
    "    mel = torch_featurization.melspectrogram(y)\n",
    "    mel = torch_featurization.piecewise_linear_log(mel)\n",
    "    mel = global_stats(mel)\n",
    "    \n",
    "    hypotheses = decoder(mel, torch.Tensor((len(mel),)), 20)\n",
    "    pred = post_process_hypos(hypotheses, model.sp_model)[0][0]\n",
    "    \n",
    "    wer.append(calculate_wer(test_set['Y'][i], pred))\n",
    "    cer.append(calculate_cer(test_set['Y'][i], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13267372066651212, 0.05032914857028699)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/husein/malaya-speech/postprocess-malaya-malay-test-set.json') as fopen:\n",
    "    malaya_malay = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 765/765 [04:56<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(malaya_malay))):\n",
    "    if not malaya_malay[i]['accept']:\n",
    "        continue\n",
    "    \n",
    "    y = malaya_speech.load(f'/home/husein/malaya-speech/malay-test/{i}.wav')[0]\n",
    "    mel = torch_featurization.melspectrogram(y)\n",
    "    mel = torch_featurization.piecewise_linear_log(mel)\n",
    "    mel = global_stats(mel)\n",
    "    \n",
    "    hypotheses = decoder(mel, torch.Tensor((len(mel),)), 20)\n",
    "    pred = post_process_hypos(hypotheses, model.sp_model)[0][0]\n",
    "    \n",
    "    wer.append(calculate_wer(malaya_malay[i]['cleaned'], pred))\n",
    "    cer.append(calculate_cer(malaya_malay[i]['cleaned'], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12207612326189402, 0.0387960632484129)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_boilerplate.huggingface import upload_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/huggingface_hub/hf_api.py:101: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.10. Pass `repo_id` instead.\n",
      "  warnings.warn(\n",
      "<class 'requests.exceptions.HTTPError'> (Request ID: Root=1-63e9f32a-6d48e8df36e920f5552c3782)\n",
      "\n",
      "You already created this model repo - You already created this model repo\n"
     ]
    }
   ],
   "source": [
    "files_mapping = {'conformer-base.pt': 'model.pt',\n",
    "                 '/home/husein/malaya-speech/malay-tts.model': 'malay-stt.model',\n",
    "                'malay-stats.json': 'malay-stats.json'}\n",
    "upload_dict(model = 'conformer-base', files_mapping = files_mapping, username = 'mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conformer = malaya_speech.stt.transducer.pt_transformer(model = 'mesolitica/conformer-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testing nama saya hussein bin zulkaply',\n",
       " 'testing nama saya hussein bin zulkaply']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conformer.beam_decoder([y, y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
