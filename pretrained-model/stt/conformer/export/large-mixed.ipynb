{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:41: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:44: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords = malaya_speech.subword.load('transducer-mixed.subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims:0' shape=(?, ?, 80, 1) dtype=float32>,\n",
       " <tf.Tensor 'TensorArrayStack_2/TensorArrayGatherV3:0' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "features = tf.TensorArray(dtype = tf.float32, size = batch_size, dynamic_size = True, infer_shape = False)\n",
    "features_len = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "\n",
    "init_state = (0, features, features_len)\n",
    "\n",
    "def condition(i, features, features_len):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, features, features_len):\n",
    "    f = featurizer(X[i, :X_len[i]])\n",
    "    f_len = tf.shape(f)[0]\n",
    "    return i + 1, features.write(i, f), features_len.write(i, f_len)\n",
    "\n",
    "_, features, features_len = tf.while_loop(condition, body, init_state)\n",
    "features_len = features_len.stack()\n",
    "padded_features = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_lens = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "maxlen = tf.reduce_max(features_len)\n",
    "\n",
    "init_state = (0, padded_features, padded_lens)\n",
    "\n",
    "def condition(i, padded_features, padded_lens):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, padded_features, padded_lens):\n",
    "    f = features.read(i)\n",
    "    len_f = tf.shape(f)[0]\n",
    "    f = tf.pad(f, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    return i + 1, padded_features.write(i, f), padded_lens.write(i, len_f)\n",
    "\n",
    "_, padded_features, padded_lens = tf.while_loop(condition, body, init_state)\n",
    "padded_features = padded_features.stack()\n",
    "padded_lens = padded_lens.stack()\n",
    "padded_lens.set_shape((None,))\n",
    "padded_features.set_shape((None, None, 80))\n",
    "padded_features = tf.expand_dims(padded_features, -1)\n",
    "padded_features, padded_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = tf.identity(padded_features, name = 'padded_features')\n",
    "padded_lens = tf.identity(padded_lens, name = 'padded_lens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.conformer_large_encoder_config\n",
    "config['dropout'] = 0.0\n",
    "conformer_model = conformer.Model(**config)\n",
    "decoder_config = malaya_speech.config.conformer_large_decoder_config\n",
    "decoder_config['embed_dropout'] = 0.0\n",
    "transducer_model = transducer.rnn.Model(\n",
    "    conformer_model, vocabulary_size = subwords.vocab_size, **decoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
    "z = tf.zeros((tf.shape(p)[0], 1),dtype=tf.int32)\n",
    "c = tf.concat([z, p], axis = 1)\n",
    "p_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/transducer/layer.py:37: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transducer/transducer_joint/transducer_joint_vocab/BiasAdd:0' shape=(?, ?, ?, 1015) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = transducer_model([padded_features, c, p_len], training = training)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from asr-large-mixed-conformer-transducer-v2/model.ckpt-1075000\n"
     ]
    }
   ],
   "source": [
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'asr-large-mixed-conformer-transducer-v2/model.ckpt-1075000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'greedy_decoder:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = transducer_model.greedy_decoder(padded_features, padded_lens, training = training)\n",
    "decoded = tf.identity(decoded, name = 'greedy_decoder')\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ytu:0' shape=(1015,) dtype=float32>,\n",
       " <tf.Tensor 'new_states:0' shape=(1, 2, 1, 640) dtype=float32>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = transducer_model.encoder(padded_features, training = training)\n",
    "encoded = tf.identity(encoded, name = 'encoded')\n",
    "encoded_placeholder = tf.placeholder(tf.float32, [config['dmodel']], name = 'encoded_placeholder')\n",
    "predicted_placeholder = tf.placeholder(tf.int32, None, name = 'predicted_placeholder')\n",
    "t = transducer_model.predict_net.get_initial_state().shape\n",
    "states_placeholder = tf.placeholder(tf.float32, [int(i) for i in t], name = 'states_placeholder')\n",
    "\n",
    "ytu, new_states = transducer_model.decoder_inference(\n",
    "    encoded=encoded_placeholder,\n",
    "    predicted=predicted_placeholder,\n",
    "    states=states_placeholder,\n",
    "    training = training\n",
    ")\n",
    "\n",
    "ytu = tf.identity(ytu, name = 'ytu')\n",
    "new_states = tf.identity(new_states, name = 'new_states')\n",
    "ytu, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = transducer_model.predict_net.get_initial_state()\n",
    "initial_states = tf.identity(initial_states, name = 'initial_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "# saver = tf.train.Saver(var_list = var_list)\n",
    "# saver.restore(sess, 'asr-small-conformer-transducer/model.ckpt-325000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'speech/record/savewav_2020-11-26_22-36-06_294832.wav',\n",
    "    'speech/record/savewav_2020-11-26_22-40-56_929661.wav',\n",
    "    'speech/record/675.wav',\n",
    "    'speech/record/664.wav',\n",
    "    'speech/example-speaker/husein-zolkepli.wav',\n",
    "    'speech/example-speaker/mas-aisyah.wav',\n",
    "    'speech/example-speaker/khalil-nooh.wav',\n",
    "    'speech/example-speaker/shafiqah-idayu.wav',\n",
    "    'speech/khutbah/wadi-annuar.wav',\n",
    "    'singlish0.wav',\n",
    "    'singlish1.wav',\n",
    "    'singlish2.wav',\n",
    "    'singlish3.wav',\n",
    "    'singlish4.wav'\n",
    "]\n",
    "\n",
    "front_pad = 200\n",
    "back_pad = 2000\n",
    "inputs = [malaya_speech.load(f)[0] for f in files]\n",
    "padded, lens = malaya_speech.padding.sequence_1d(inputs, return_len = True)\n",
    "back = np.zeros(shape = (len(inputs), back_pad))\n",
    "front = np.zeros(shape = (len(inputs), front_pad))\n",
    "padded = np.concatenate([front, padded, back], axis = -1)\n",
    "lens = [l + front_pad + back_pad for l in lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BeamHypothesis = collections.namedtuple(\n",
    "    'BeamHypothesis', ('score', 'prediction', 'states')\n",
    ")\n",
    "\n",
    "\n",
    "def transducer(\n",
    "    enc,\n",
    "    total,\n",
    "    initial_states,\n",
    "    encoded_placeholder,\n",
    "    predicted_placeholder,\n",
    "    states_placeholder,\n",
    "    ytu,\n",
    "    new_states,\n",
    "    sess,\n",
    "    beam_width = 10,\n",
    "    norm_score = True,\n",
    "):\n",
    "    kept_hyps = [\n",
    "        BeamHypothesis(score = 0.0, prediction = [0], states = initial_states)\n",
    "    ]\n",
    "    B = kept_hyps\n",
    "    for i in range(total):\n",
    "        A = B\n",
    "        B = []\n",
    "        while True:\n",
    "            y_hat = max(A, key = lambda x: x.score)\n",
    "            A.remove(y_hat)\n",
    "            ytu_, new_states_ = sess.run(\n",
    "                [ytu, new_states],\n",
    "                feed_dict = {\n",
    "                    encoded_placeholder: enc[i],\n",
    "                    predicted_placeholder: y_hat.prediction[-1],\n",
    "                    states_placeholder: y_hat.states,\n",
    "                },\n",
    "            )\n",
    "            for k in range(ytu_.shape[0]):\n",
    "                beam_hyp = BeamHypothesis(\n",
    "                    score = (y_hat.score + float(ytu_[k])),\n",
    "                    prediction = y_hat.prediction,\n",
    "                    states = y_hat.states,\n",
    "                )\n",
    "                if k == 0:\n",
    "                    B.append(beam_hyp)\n",
    "                else:\n",
    "                    beam_hyp = BeamHypothesis(\n",
    "                        score = beam_hyp.score,\n",
    "                        prediction = (beam_hyp.prediction + [int(k)]),\n",
    "                        states = new_states_,\n",
    "                    )\n",
    "                    A.append(beam_hyp)\n",
    "            if len(B) > beam_width:\n",
    "                break\n",
    "    if norm_score:\n",
    "        kept_hyps = sorted(\n",
    "            B, key = lambda x: x.score / len(x.prediction), reverse = True\n",
    "        )[:beam_width]\n",
    "    else:\n",
    "        kept_hyps = sorted(B, key = lambda x: x.score, reverse = True)[\n",
    "            :beam_width\n",
    "        ]\n",
    "    return kept_hyps[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helo nama saya saya tak suka mandi ke tak saya masang\n",
      "helo nama saya hussein saya suka mandi saya mandi titik hari\n",
      "ini dan melalui kenyataan mesej itu mestura menegaskan\n",
      "pilihan tepat apabila dia kini lebih berani dan\n",
      "testing nama saya hussein bin zulkifli\n",
      "sebut perkataan uncle\n",
      "tolong sebut adik kata\n",
      "nama saya syafikah idayu\n",
      "jadi dalam perjalanan ini dunia yang susah ini ketika nabi mengajar muadz bin jabal tadi ni allah mak\n",
      "and then see how they road in film okay actually\n",
      "then you tell to your eyes\n",
      "send person him out\n",
      "international shipping dollar\n",
      "then after that humans later they read someone then\n",
      "CPU times: user 1min, sys: 9.03 s, total: 1min 9s\n",
      "Wall time: 7.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = sess.run(decoded, feed_dict = {X: padded, X_len: lens})\n",
    "for row in r:\n",
    "    print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helo nama saya saya tak suka mandi ke tak saya masang\n",
      "helo nama saya hussein saya suka mandi saya mandi titik hari\n",
      "ini dan melalui kenyataan mesej itu mastura menegaskan\n",
      "pilihan tepat apabila dia kini lebih berani dan\n",
      "testing nama saya hussein pleae\n",
      "sebut perkataan uncle\n",
      "tolong sebut adik kata\n",
      "nama saya syafikah idayu\n",
      "jadi dalam perjalanan ini dunia yang susah ini ketika nabi mengajar muadz bin jabal tadi ni allah mak\n",
      "and then see how they road in film okay actual\n",
      "then you tell to your eyes\n",
      "send person him out\n",
      "international shipping trade dollar\n",
      "then after a few months they read someone then\n",
      "CPU times: user 1min 25s, sys: 7.06 s, total: 1min 32s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "encoded_, padded_lens_  = sess.run([encoded, padded_lens], feed_dict = {X: padded, X_len: lens})\n",
    "padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor\n",
    "s = sess.run(initial_states)\n",
    "\n",
    "for i in range(len(encoded_)):\n",
    "    r = transducer(\n",
    "        enc = encoded_[i],\n",
    "        total = padded_lens_[i],\n",
    "        initial_states = s,\n",
    "        encoded_placeholder = encoded_placeholder,\n",
    "        predicted_placeholder = predicted_placeholder,\n",
    "        states_placeholder = states_placeholder,\n",
    "        ytu = ytu,\n",
    "        new_states = new_states,\n",
    "        sess = sess,\n",
    "        beam_width = 1,\n",
    "    )\n",
    "\n",
    "    print(malaya_speech.subword.decode(subwords, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypothesis(index=<tf.Tensor 'while_3/Exit_1:0' shape=() dtype=int32>, prediction=<tf.Tensor 'TensorArrayStack_3/TensorArrayGatherV3:0' shape=(?,) dtype=int32>, states=<tf.Tensor 'while_3/Exit_3:0' shape=(1, 2, 1, 640) dtype=float32>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = padded_lens // transducer_model.encoder.conv_subsampling.time_reduction_factor\n",
    "encoded = transducer_model.encoder(padded_features, training = training)\n",
    "g = transducer_model._perform_greedy(encoded[0], l[0],\n",
    "                                tf.constant(0, dtype = tf.int32),\n",
    "                                transducer_model.predict_net.get_initial_state())\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = g.prediction\n",
    "minus_one = -1 * tf.ones_like(indices, dtype=tf.int32)\n",
    "blank_like = 0 * tf.ones_like(indices, dtype=tf.int32)\n",
    "indices = tf.where(indices == minus_one, blank_like, indices)\n",
    "num_samples = tf.cast(X_len[0], dtype=tf.float32)\n",
    "total_time_reduction_factor = featurizer.frame_step\n",
    "stime = tf.range(0, num_samples, delta=total_time_reduction_factor, dtype=tf.float32)\n",
    "stime /= tf.cast(featurizer.sample_rate, dtype=tf.float32)\n",
    "stime = stime[::tf.shape(stime)[0] // tf.shape(indices)[0]]\n",
    "stime.set_shape((None,))\n",
    "non_blank = tf.where(tf.not_equal(indices, 0))\n",
    "non_blank_transcript = tf.gather_nd(indices, non_blank)\n",
    "non_blank_stime = tf.gather_nd(stime, non_blank)\n",
    "non_blank_transcript = tf.identity(non_blank_transcript, name = 'non_blank_transcript')\n",
    "non_blank_stime = tf.identity(non_blank_stime, name = 'non_blank_stime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.2 s, sys: 2.76 s, total: 44 s\n",
      "Wall time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = sess.run([non_blank_transcript, non_blank_stime], feed_dict = {X: padded, X_len: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, indices = [], []\n",
    "for no, ids in enumerate(r[0]):\n",
    "    w = subwords._id_to_subword(ids - 1)\n",
    "    if type(w) == bytes:\n",
    "        w = w.decode()\n",
    "    words.extend([w, None])\n",
    "    indices.extend([no, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import six\n",
    "from malaya_speech.utils import text_encoder\n",
    "\n",
    "def _trim_underscore_and_tell(token):\n",
    "    if token.endswith('_'):\n",
    "        return token[:-1], True\n",
    "    return token, False\n",
    "\n",
    "def decode(ids):\n",
    "    ids = text_encoder.pad_decr(ids)\n",
    "    subword_ids = ids\n",
    "    del ids\n",
    "\n",
    "    subwords_ = []\n",
    "    prev_bytes = []\n",
    "    prev_ids = []\n",
    "    ids = []\n",
    "\n",
    "    def consume_prev_bytes():\n",
    "        if prev_bytes:\n",
    "            subwords_.extend(prev_bytes)\n",
    "            ids.extend(prev_ids)\n",
    "        return [], []\n",
    "\n",
    "    for no, subword_id in enumerate(subword_ids):\n",
    "        subword = subwords._id_to_subword(subword_id)\n",
    "        if isinstance(subword, six.binary_type):\n",
    "            # Byte-encoded\n",
    "            prev_bytes.append(subword.decode('utf-8', 'replace'))\n",
    "            if subword == b' ':\n",
    "                prev_ids.append(None)\n",
    "            else:\n",
    "                prev_ids.append(no)\n",
    "        else:\n",
    "            # If there were bytes previously, convert to unicode.\n",
    "            prev_bytes, prev_ids = consume_prev_bytes()\n",
    "            trimmed, add_space = _trim_underscore_and_tell(subword)\n",
    "            ids.append(no)\n",
    "            subwords_.append(trimmed)\n",
    "            if add_space:\n",
    "                subwords_.append(' ')\n",
    "                ids.append(None)\n",
    "    prev_bytes = consume_prev_bytes()\n",
    "\n",
    "    return subwords_, ids\n",
    "\n",
    "words, indices = decode(r[0])\n",
    "len(words), len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_indices(subwords, ids, l, reduction_factor = 160, sample_rate = 16000):\n",
    "    result, temp_l, temp_r = [], [], []\n",
    "    for i in range(len(subwords)):\n",
    "        if ids[i] is not None:\n",
    "            temp_l.append(subwords[i])\n",
    "            temp_r.append(l[ids[i]])\n",
    "        else:\n",
    "            data = {'text': ''.join(temp_l), \n",
    "                    'start': round(temp_r[0],4), \n",
    "                    'end': round(temp_r[-1] + (reduction_factor / sample_rate), 4)}\n",
    "            result.append(data)\n",
    "            temp_l, temp_r = [], []\n",
    "    \n",
    "    if len(temp_l):\n",
    "        data = {'text': ''.join(temp_l), \n",
    "                'start': round(temp_r[0],4), \n",
    "                'end': round(temp_r[-1] + (reduction_factor / sample_rate), 4)}\n",
    "        result.append(data)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'helo', 'start': 0.0, 'end': 0.21},\n",
       " {'text': 'nama', 'start': 0.76, 'end': 0.97},\n",
       " {'text': 'saya', 'start': 1.0, 'end': 1.25},\n",
       " {'text': 'saya', 'start': 2.64, 'end': 2.73},\n",
       " {'text': 'tak', 'start': 2.8, 'end': 2.81},\n",
       " {'text': 'suka', 'start': 2.96, 'end': 3.01},\n",
       " {'text': 'mandi', 'start': 3.16, 'end': 3.33},\n",
       " {'text': 'ke', 'start': 4.56, 'end': 4.57},\n",
       " {'text': 'tak', 'start': 4.64, 'end': 4.65},\n",
       " {'text': 'saya', 'start': 4.8, 'end': 5.01},\n",
       " {'text': 'masang', 'start': 5.24, 'end': 5.53}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_indices(words, indices, r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output-large-mixed-conformer/model.ckpt'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'output-large-mixed-conformer/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_placeholder',\n",
       " 'X_len_placeholder',\n",
       " 'padded_features',\n",
       " 'padded_lens',\n",
       " 'transducer/transducer_prediction/transducer_prediction_embedding/embeddings',\n",
       " 'greedy_decoder',\n",
       " 'encoded',\n",
       " 'encoded_placeholder',\n",
       " 'predicted_placeholder',\n",
       " 'states_placeholder',\n",
       " 'ytu',\n",
       " 'new_states',\n",
       " 'initial_states',\n",
       " 'non_blank_transcript',\n",
       " 'non_blank_stime']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'gather' in n.op.lower()\n",
    "        or 'placeholder' in n.name\n",
    "        or 'encoded' in n.name\n",
    "        or 'decoder' in n.name\n",
    "        or 'ytu' in n.name\n",
    "        or 'new_states' in n.name\n",
    "        or 'padded_' in n.name\n",
    "        or 'initial_states' in n.name\n",
    "        or 'non_blank' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "        and 'ReadVariableOp' not in n.name\n",
    "        and 'Gather' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-large-mixed-conformer/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-32-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 561 variables.\n",
      "INFO:tensorflow:Converted 561 variables to const ops.\n",
      "27400 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('output-large-mixed-conformer', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "                \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-large-mixed-conformer/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "    'encoded_placeholder',\n",
    "    'predicted_placeholder',\n",
    "    'states_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'greedy_decoder',\n",
    "    'encoded',\n",
    "    'ytu',\n",
    "    'new_states',\n",
    "    'padded_features',\n",
    "    'padded_lens',\n",
    "    'initial_states',\n",
    "    'non_blank_transcript',\n",
    "    'non_blank_stime'\n",
    "]\n",
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run(outputs['greedy_decoder'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                          inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helo nama saya sin saya tak suka mandi ketik saya masam\n",
      "helo nama saya hussein saya suka mandi saya mandi titik hari\n",
      "ini dan melalui kenyataan mesej itu mastura menegaskan\n",
      "pilihan tepat apabila dia kini lebih berani dan\n",
      "testing nama saya hussein bin zulkifli\n",
      "sebut perkataan uncle\n",
      "tolong sebut anti kata\n",
      "nama saya syafiqah you\n",
      "jadi dalam perjalanan ini dunia yang susah ini ketika nabi mengajar muaz bin jabal tadi ni allahumma in\n",
      "and then see how they roll it and film okay actually\n",
      "then you back to your eyes\n",
      "samsung emo\n",
      "international ship and long\n",
      "then after that humour standard leave it someone then\n"
     ]
    }
   ],
   "source": [
    "for row in r:\n",
    "    print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_, padded_lens_, s  = test_sess.run([outputs['encoded'], outputs['padded_lens'], outputs['initial_states']], \n",
    "                                        feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                     inputs['X_len_placeholder']: lens})\n",
    "\n",
    "padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'helo nama saya sin saya tak suka mandi ketik saya masang'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "r = transducer(\n",
    "    enc = encoded_[i],\n",
    "    total = padded_lens_[i],\n",
    "    initial_states = s,\n",
    "    encoded_placeholder = inputs['encoded_placeholder'],\n",
    "    predicted_placeholder = inputs['predicted_placeholder'],\n",
    "    states_placeholder = inputs['states_placeholder'],\n",
    "    ytu = outputs['ytu'],\n",
    "    new_states = outputs['new_states'],\n",
    "    sess = test_sess,\n",
    "    beam_width = 1,\n",
    ")\n",
    "\n",
    "malaya_speech.subword.decode(subwords, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-37-650a8a05e947>:31: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "    'encoded_placeholder',\n",
    "    'predicted_placeholder',\n",
    "    'states_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'greedy_decoder',\n",
    "    'encoded',\n",
    "    'ytu',\n",
    "    'new_states',\n",
    "    'padded_features',\n",
    "    'padded_lens',\n",
    "    'initial_states',\n",
    "    'non_blank_transcript',\n",
    "    'non_blank_stime'\n",
    "]\n",
    "\n",
    "pb = 'output-large-mixed-conformer/frozen_model.pb'\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.FastGFile(pb, 'rb') as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                           input_nodes,\n",
    "                                           output_nodes, transforms)\n",
    "    \n",
    "with tf.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "    f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-large-mixed-conformer/frozen_model.pb.quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}\n",
    "test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run(outputs['greedy_decoder'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                          inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in r:\n",
    "    print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_, padded_lens_, s  = test_sess.run([outputs['encoded'], outputs['padded_lens'], outputs['initial_states']], \n",
    "                                        feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                     inputs['X_len_placeholder']: lens})\n",
    "\n",
    "padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "r = transducer(\n",
    "    enc = encoded_[i],\n",
    "    total = padded_lens_[i],\n",
    "    initial_states = s,\n",
    "    encoded_placeholder = inputs['encoded_placeholder'],\n",
    "    predicted_placeholder = inputs['predicted_placeholder'],\n",
    "    states_placeholder = inputs['states_placeholder'],\n",
    "    ytu = outputs['ytu'],\n",
    "    new_states = outputs['new_states'],\n",
    "    sess = test_sess,\n",
    "    beam_width = 1,\n",
    ")\n",
    "\n",
    "malaya_speech.subword.decode(subwords, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_application_key_id = os.environ['b2_application_key_id']\n",
    "b2_application_key = os.environ['b2_application_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from b2sdk.v1 import *\n",
    "info = InMemoryAccountInfo()\n",
    "b2_api = B2Api(info)\n",
    "application_key_id = b2_application_key_id\n",
    "application_key = b2_application_key\n",
    "b2_api.authorize_account(\"production\", application_key_id, application_key)\n",
    "file_info = {'how': 'good-file'}\n",
    "b2_bucket = b2_api.get_bucket_by_name('malaya-speech-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'output-large-mixed-conformer'\n",
    "tar = 'output-large-mixed-conformer-v3.tar.gz'\n",
    "os.system(f'tar -czvf {tar} {directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outPutname = f'pretrained/{tar}'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=tar,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {tar}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'output-large-mixed-conformer/frozen_model.pb'\n",
    "outPutname = 'speech-to-text-transducer/large-conformer-mixed/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'output-large-mixed-conformer/frozen_model.pb.quantized'\n",
    "outPutname = 'speech-to-text-transducer/large-conformer-mixed-quantized/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
