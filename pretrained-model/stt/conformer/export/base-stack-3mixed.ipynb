{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords_malay = malaya_speech.subword.load('bahasa-512.subword')\n",
    "subwords_singlish = malaya_speech.subword.load('singlish-512.subword')\n",
    "subwords_mandarin = malaya_speech.subword.load('mandarin-512.subword')\n",
    "langs = [subwords_malay, subwords_singlish, subwords_mandarin]\n",
    "len_vocab = [l.vocab_size for l in langs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ExpandDims:0' shape=(?, ?, 80, 1) dtype=float32>,\n",
       " <tf.Tensor 'TensorArrayStack_2/TensorArrayGatherV3:0' shape=(?,) dtype=int32>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = tf.shape(X)[0]\n",
    "features = tf.TensorArray(dtype = tf.float32, size = batch_size, dynamic_size = True, infer_shape = False)\n",
    "features_len = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "\n",
    "init_state = (0, features, features_len)\n",
    "\n",
    "def condition(i, features, features_len):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, features, features_len):\n",
    "    f = featurizer(X[i, :X_len[i]])\n",
    "    f_len = tf.shape(f)[0]\n",
    "    return i + 1, features.write(i, f), features_len.write(i, f_len)\n",
    "\n",
    "_, features, features_len = tf.while_loop(condition, body, init_state)\n",
    "features_len = features_len.stack()\n",
    "padded_features = tf.TensorArray(dtype = tf.float32, size = batch_size)\n",
    "padded_lens = tf.TensorArray(dtype = tf.int32, size = batch_size)\n",
    "maxlen = tf.reduce_max(features_len)\n",
    "\n",
    "init_state = (0, padded_features, padded_lens)\n",
    "\n",
    "def condition(i, padded_features, padded_lens):\n",
    "    return i < batch_size\n",
    "\n",
    "def body(i, padded_features, padded_lens):\n",
    "    f = features.read(i)\n",
    "    len_f = tf.shape(f)[0]\n",
    "    f = tf.pad(f, [[0, maxlen - tf.shape(f)[0]], [0,0]])\n",
    "    return i + 1, padded_features.write(i, f), padded_lens.write(i, len_f)\n",
    "\n",
    "_, padded_features, padded_lens = tf.while_loop(condition, body, init_state)\n",
    "padded_features = padded_features.stack()\n",
    "padded_lens = padded_lens.stack()\n",
    "padded_lens.set_shape((None,))\n",
    "padded_features.set_shape((None, None, 80))\n",
    "padded_features = tf.expand_dims(padded_features, -1)\n",
    "padded_features, padded_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_features = tf.identity(padded_features, name = 'padded_features')\n",
    "padded_lens = tf.identity(padded_lens, name = 'padded_lens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.conformer_base_encoder_config\n",
    "config['dropout'] = 0.0\n",
    "conformer_model = conformer.Model(**config)\n",
    "decoder_config = malaya_speech.config.conformer_base_decoder_config\n",
    "decoder_config['embed_dropout'] = 0.0\n",
    "transducer_model = transducer.rnn.Model(\n",
    "    conformer_model, vocabulary_size = sum(len_vocab), **decoder_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = tf.compat.v1.placeholder(tf.int32, [None, None])\n",
    "z = tf.zeros((tf.shape(p)[0], 1),dtype=tf.int32)\n",
    "c = tf.concat([z, p], axis = 1)\n",
    "p_len = tf.compat.v1.placeholder(tf.int32, [None])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/transducer/layer.py:37: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transducer/transducer_joint/transducer_joint_vocab/BiasAdd:0' shape=(?, ?, ?, 1543) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = transducer_model([padded_features, c, p_len], training = training)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from asr-base-conformer-transducer-3mixed/model.ckpt-1625000\n"
     ]
    }
   ],
   "source": [
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'asr-base-conformer-transducer-3mixed/model.ckpt-1625000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'greedy_decoder:0' shape=(?, ?) dtype=int32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = transducer_model.greedy_decoder(padded_features, padded_lens, training = training)\n",
    "decoded = tf.identity(decoded[0], name = 'greedy_decoder')\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ytu:0' shape=(1543,) dtype=float32>,\n",
       " <tf.Tensor 'new_states:0' shape=(1, 2, 1, 640) dtype=float32>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = transducer_model.encoder(padded_features, training = training)\n",
    "encoded = tf.identity(encoded, name = 'encoded')\n",
    "encoded_placeholder = tf.placeholder(tf.float32, [config['dmodel']], name = 'encoded_placeholder')\n",
    "predicted_placeholder = tf.placeholder(tf.int32, None, name = 'predicted_placeholder')\n",
    "t = transducer_model.predict_net.get_initial_state().shape\n",
    "states_placeholder = tf.placeholder(tf.float32, [int(i) for i in t], name = 'states_placeholder')\n",
    "\n",
    "ytu, new_states = transducer_model.decoder_inference(\n",
    "    encoded=encoded_placeholder,\n",
    "    predicted=predicted_placeholder,\n",
    "    states=states_placeholder,\n",
    "    training = training\n",
    ")\n",
    "\n",
    "ytu = tf.identity(ytu, name = 'ytu')\n",
    "new_states = tf.identity(new_states, name = 'new_states')\n",
    "ytu, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = transducer_model.predict_net.get_initial_state()\n",
    "initial_states = tf.identity(initial_states, name = 'initial_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "# saver = tf.train.Saver(var_list = var_list)\n",
    "# saver.restore(sess, 'asr-small-conformer-transducer/model.ckpt-325000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'speech/record/savewav_2020-11-26_22-36-06_294832.wav',\n",
    "    'speech/record/savewav_2020-11-26_22-40-56_929661.wav',\n",
    "    'speech/record/675.wav',\n",
    "    'speech/record/664.wav',\n",
    "    'mandarin-test/597.wav',\n",
    "    'mandarin-test/584.wav',\n",
    "    'speech/example-speaker/husein-zolkepli.wav',\n",
    "    'speech/example-speaker/mas-aisyah.wav',\n",
    "    'speech/example-speaker/khalil-nooh.wav',\n",
    "    'speech/example-speaker/shafiqah-idayu.wav',\n",
    "    'speech/khutbah/wadi-annuar.wav',\n",
    "    'singlish0.wav',\n",
    "    'singlish1.wav',\n",
    "    'singlish2.wav',\n",
    "    'singlish3.wav',\n",
    "    'singlish4.wav'\n",
    "]\n",
    "\n",
    "front_pad = 200\n",
    "back_pad = 2000\n",
    "inputs = [malaya_speech.load(f)[0] for f in files]\n",
    "padded, lens = malaya_speech.padding.sequence_1d(inputs, return_len = True)\n",
    "back = np.zeros(shape = (len(inputs), back_pad))\n",
    "front = np.zeros(shape = (len(inputs), front_pad))\n",
    "padded = np.concatenate([front, padded, back], axis = -1)\n",
    "lens = [l + front_pad + back_pad for l in lens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import collections\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# BeamHypothesis = collections.namedtuple(\n",
    "#     'BeamHypothesis', ('score', 'prediction', 'states')\n",
    "# )\n",
    "\n",
    "\n",
    "# def transducer(\n",
    "#     enc,\n",
    "#     total,\n",
    "#     initial_states,\n",
    "#     encoded_placeholder,\n",
    "#     predicted_placeholder,\n",
    "#     states_placeholder,\n",
    "#     ytu,\n",
    "#     new_states,\n",
    "#     sess,\n",
    "#     beam_width = 10,\n",
    "#     norm_score = True,\n",
    "# ):\n",
    "#     kept_hyps = [\n",
    "#         BeamHypothesis(score = 0.0, prediction = [0], states = initial_states)\n",
    "#     ]\n",
    "#     B = kept_hyps\n",
    "#     for i in range(total):\n",
    "#         A = B\n",
    "#         B = []\n",
    "#         while True:\n",
    "#             y_hat = max(A, key = lambda x: x.score)\n",
    "#             A.remove(y_hat)\n",
    "#             ytu_, new_states_ = sess.run(\n",
    "#                 [ytu, new_states],\n",
    "#                 feed_dict = {\n",
    "#                     encoded_placeholder: enc[i],\n",
    "#                     predicted_placeholder: y_hat.prediction[-1],\n",
    "#                     states_placeholder: y_hat.states,\n",
    "#                 },\n",
    "#             )\n",
    "#             for k in range(ytu_.shape[0]):\n",
    "#                 beam_hyp = BeamHypothesis(\n",
    "#                     score = (y_hat.score + float(ytu_[k])),\n",
    "#                     prediction = y_hat.prediction,\n",
    "#                     states = y_hat.states,\n",
    "#                 )\n",
    "#                 if k == 0:\n",
    "#                     B.append(beam_hyp)\n",
    "#                 else:\n",
    "#                     beam_hyp = BeamHypothesis(\n",
    "#                         score = beam_hyp.score,\n",
    "#                         prediction = (beam_hyp.prediction + [int(k)]),\n",
    "#                         states = new_states_,\n",
    "#                     )\n",
    "#                     A.append(beam_hyp)\n",
    "#             if len(B) > beam_width:\n",
    "#                 break\n",
    "#     if norm_score:\n",
    "#         kept_hyps = sorted(\n",
    "#             B, key = lambda x: x.score / len(x.prediction), reverse = True\n",
    "#         )[:beam_width]\n",
    "#     else:\n",
    "#         kept_hyps = sorted(B, key = lambda x: x.score, reverse = True)[\n",
    "#             :beam_width\n",
    "#         ]\n",
    "#     return kept_hyps[0].prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from malaya_speech.utils.subword import decode\n",
    "\n",
    "def decode_multilanguage(row, langs):\n",
    "    \n",
    "    if not len(row):\n",
    "        return ''\n",
    "\n",
    "    len_vocab = [l.vocab_size for l in langs]\n",
    "\n",
    "    def get_index_multilanguage(r):\n",
    "        for i in range(len(langs)):\n",
    "            sum_v = sum(len_vocab[:i + 1])\n",
    "            if r < sum(len_vocab[:i + 1]):\n",
    "                return i, r - sum(len_vocab[:i])\n",
    "\n",
    "    last_index, v = get_index_multilanguage(row[0])\n",
    "    d, q = [], [v]\n",
    "    for r in row[1:]:\n",
    "        index, v = get_index_multilanguage(r)\n",
    "        if index != last_index:\n",
    "            d.append(decode(langs[last_index], q))\n",
    "            q = [v]\n",
    "            last_index = index\n",
    "        else:\n",
    "            q.append(v)\n",
    "    if len(q):\n",
    "        d.append(decode(langs[last_index], q))\n",
    "    d = re.sub(r'[ ]+', ' ', ' '.join(d)).strip()\n",
    "    d = d.replace(' lah', 'lah')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kalau nama saya musim saya tak suka mandi kata saya masak\n",
      "hello sorry sorry so\n",
      "ini melalui kementerian mesin itu struktu\n",
      "pilihan tepat apabila dia kini lebih berani dan\n",
      "gei wo lai ge zhang jie zui xin de ge\n",
      "wo xiang ting su bing dao de jie mu\n",
      "testing number would say being a caply\n",
      "uncle\n",
      "dollar anti\n",
      "nama saya tak hidaya\n",
      "jadi dalam perjalanan ini ini yang susah ini ketika nabi mengajar muaz bin jabal tadi ni allah\n",
      "and then see how they bring and film okay actually\n",
      "later to your s\n",
      "seven seven more\n",
      "\n",
      "then after that she brought the living some month\n",
      "CPU times: user 44.9 s, sys: 11.1 s, total: 56 s\n",
      "Wall time: 6.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = sess.run(decoded, feed_dict = {X: padded, X_len: lens})\n",
    "for row in r:\n",
    "    print(decode_multilanguage(row[row > 0], langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# encoded_, padded_lens_  = sess.run([encoded, padded_lens], feed_dict = {X: padded, X_len: lens})\n",
    "# padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor\n",
    "# s = sess.run(initial_states)\n",
    "\n",
    "# for i in range(len(encoded_)):\n",
    "#     r = transducer(\n",
    "#         enc = encoded_[i],\n",
    "#         total = padded_lens_[i],\n",
    "#         initial_states = s,\n",
    "#         encoded_placeholder = encoded_placeholder,\n",
    "#         predicted_placeholder = predicted_placeholder,\n",
    "#         states_placeholder = states_placeholder,\n",
    "#         ytu = ytu,\n",
    "#         new_states = new_states,\n",
    "#         sess = sess,\n",
    "#         beam_width = 1,\n",
    "#     )\n",
    "    \n",
    "#     print(decode_multilanguage(r, langs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hypothesis(index=<tf.Tensor 'while_3/Exit_1:0' shape=() dtype=int32>, prediction=<tf.Tensor 'TensorArrayStack_3/TensorArrayGatherV3:0' shape=(?,) dtype=int32>, states=<tf.Tensor 'while_3/Exit_3:0' shape=(1, 2, 1, 640) dtype=float32>, alignment=<tf.Tensor 'TensorArrayStack_4/TensorArrayGatherV3:0' shape=(?, 1543) dtype=float32>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = padded_lens // transducer_model.encoder.conv_subsampling.time_reduction_factor\n",
    "encoded = transducer_model.encoder(padded_features, training = training)\n",
    "g = transducer_model._perform_greedy(encoded[0], l[0],\n",
    "                                tf.constant(0, dtype = tf.int32),\n",
    "                                transducer_model.predict_net.get_initial_state())\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = g.prediction\n",
    "minus_one = -1 * tf.ones_like(indices, dtype=tf.int32)\n",
    "blank_like = 0 * tf.ones_like(indices, dtype=tf.int32)\n",
    "indices = tf.where(indices == minus_one, blank_like, indices)\n",
    "num_samples = tf.cast(X_len[0], dtype=tf.float32)\n",
    "total_time_reduction_factor = featurizer.frame_step\n",
    "stime = tf.range(0, num_samples, delta=total_time_reduction_factor, dtype=tf.float32)\n",
    "stime /= tf.cast(featurizer.sample_rate, dtype=tf.float32)\n",
    "stime = stime[::tf.shape(stime)[0] // tf.shape(indices)[0]]\n",
    "stime.set_shape((None,))\n",
    "non_blank = tf.where(tf.not_equal(indices, 0))\n",
    "non_blank_transcript = tf.gather_nd(indices, non_blank)\n",
    "non_blank_stime = tf.gather_nd(stime, non_blank)\n",
    "non_blank_transcript = tf.identity(non_blank_transcript, name = 'non_blank_transcript')\n",
    "non_blank_stime = tf.identity(non_blank_stime, name = 'non_blank_stime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 s, sys: 2 s, total: 24.9 s\n",
      "Wall time: 5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "r = sess.run([non_blank_transcript, non_blank_stime], feed_dict = {X: padded, X_len: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 74, 139, 230,   1,  65,   1,  54,  42, 123,  65,   1,  10, 290,\n",
       "         32,  17, 290,  58,  52,  41,   1,  65,   1,  78, 355, 365],\n",
       "       dtype=int32),\n",
       " array([0.56     , 0.68     , 1.2800001, 1.4000001, 1.5200001, 1.7600001,\n",
       "        1.96     , 2.0400002, 2.2800002, 3.1200001, 3.2400002, 3.3200002,\n",
       "        3.44     , 3.5200002, 3.6000001, 3.68     , 3.7200003, 3.88     ,\n",
       "        5.1200004, 5.1600003, 5.32     , 5.5200005, 5.7200003, 5.92     ,\n",
       "        5.9600005], dtype=float32)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_multilanguage_subwords(tokenizers, ids):\n",
    "    \"\"\"\n",
    "    Decode integer representation to string using list of tokenizer objects.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    tokenizers: List[object]\n",
    "        List of tokenizer objects.\n",
    "    ids: List[int]\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    result: str\n",
    "    \"\"\"\n",
    "\n",
    "    if not len(ids):\n",
    "        return ''\n",
    "\n",
    "    len_vocab = [l.vocab_size for l in tokenizers]\n",
    "\n",
    "    def get_index_multilanguage(r):\n",
    "        for i in range(len(tokenizers)):\n",
    "            sum_v = sum(len_vocab[:i + 1])\n",
    "            if r < sum(len_vocab[:i + 1]):\n",
    "                return i, r - sum(len_vocab[:i])\n",
    "\n",
    "    last_index, v = get_index_multilanguage(ids[0])\n",
    "    d, q = [], [v]\n",
    "    for r in ids[1:]:\n",
    "        index, v = get_index_multilanguage(r)\n",
    "        if index != last_index:\n",
    "            d.append(tokenizers[last_index]._id_to_subword(q - 1))\n",
    "            q = [v]\n",
    "            last_index = index\n",
    "        else:\n",
    "            q.append(v)\n",
    "    if len(q):\n",
    "        d.append(tokenizers[last_index]._id_to_subword(q - 1))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_multilanguage(r, tokenizers, len_vocab):\n",
    "    for i in range(len(tokenizers)):\n",
    "        sum_v = sum(len_vocab[:i + 1])\n",
    "        if r < sum(len_vocab[:i + 1]):\n",
    "            return i, r - sum(len_vocab[:i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 23)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index_multilanguage(1050, langs, len_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, indices = [], []\n",
    "for no, ids in enumerate(r[0]):\n",
    "    last_index, v = get_index_multilanguage(ids, langs, len_vocab)\n",
    "    w = langs[last_index]._id_to_subword(v - 1)\n",
    "    if type(w) == bytes:\n",
    "        w = w.decode()\n",
    "    words.extend([w, None])\n",
    "    indices.extend([no, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['kal',\n",
       "  None,\n",
       "  'au_',\n",
       "  None,\n",
       "  'nam',\n",
       "  None,\n",
       "  'a_',\n",
       "  None,\n",
       "  'say',\n",
       "  None,\n",
       "  'a_',\n",
       "  None,\n",
       "  'mu',\n",
       "  None,\n",
       "  'si',\n",
       "  None,\n",
       "  'm_',\n",
       "  None,\n",
       "  'say',\n",
       "  None,\n",
       "  'a_',\n",
       "  None,\n",
       "  'tak',\n",
       "  None,\n",
       "  ' ',\n",
       "  None,\n",
       "  'su',\n",
       "  None,\n",
       "  'ka',\n",
       "  None,\n",
       "  ' ',\n",
       "  None,\n",
       "  'man',\n",
       "  None,\n",
       "  'di_',\n",
       "  None,\n",
       "  'kat',\n",
       "  None,\n",
       "  'a_',\n",
       "  None,\n",
       "  'say',\n",
       "  None,\n",
       "  'a_',\n",
       "  None,\n",
       "  'mas',\n",
       "  None,\n",
       "  'a',\n",
       "  None,\n",
       "  'k',\n",
       "  None],\n",
       " [0,\n",
       "  None,\n",
       "  1,\n",
       "  None,\n",
       "  2,\n",
       "  None,\n",
       "  3,\n",
       "  None,\n",
       "  4,\n",
       "  None,\n",
       "  5,\n",
       "  None,\n",
       "  6,\n",
       "  None,\n",
       "  7,\n",
       "  None,\n",
       "  8,\n",
       "  None,\n",
       "  9,\n",
       "  None,\n",
       "  10,\n",
       "  None,\n",
       "  11,\n",
       "  None,\n",
       "  12,\n",
       "  None,\n",
       "  13,\n",
       "  None,\n",
       "  14,\n",
       "  None,\n",
       "  15,\n",
       "  None,\n",
       "  16,\n",
       "  None,\n",
       "  17,\n",
       "  None,\n",
       "  18,\n",
       "  None,\n",
       "  19,\n",
       "  None,\n",
       "  20,\n",
       "  None,\n",
       "  21,\n",
       "  None,\n",
       "  22,\n",
       "  None,\n",
       "  23,\n",
       "  None,\n",
       "  24,\n",
       "  None])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 33)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import six\n",
    "from malaya_speech.utils import text_encoder\n",
    "\n",
    "def _trim_underscore_and_tell(token):\n",
    "    if token.endswith('_'):\n",
    "        return token[:-1], True\n",
    "    return token, False\n",
    "\n",
    "def decode(ids):\n",
    "    ids = text_encoder.pad_decr(ids)\n",
    "    subword_ids = ids\n",
    "    del ids\n",
    "\n",
    "    subwords_ = []\n",
    "    prev_bytes = []\n",
    "    prev_ids = []\n",
    "    ids = []\n",
    "\n",
    "    def consume_prev_bytes():\n",
    "        if prev_bytes:\n",
    "            subwords_.extend(prev_bytes)\n",
    "            ids.extend(prev_ids)\n",
    "        return [], []\n",
    "\n",
    "    for no, subword_id in enumerate(subword_ids):\n",
    "        last_index, v = get_index_multilanguage(subword_id, langs, len_vocab)\n",
    "        subword = langs[last_index]._id_to_subword(v)\n",
    "        if isinstance(subword, six.binary_type):\n",
    "            # Byte-encoded\n",
    "            prev_bytes.append(subword.decode('utf-8', 'replace'))\n",
    "            if subword == b' ':\n",
    "                prev_ids.append(None)\n",
    "            else:\n",
    "                prev_ids.append(no)\n",
    "        else:\n",
    "            # If there were bytes previously, convert to unicode.\n",
    "            prev_bytes, prev_ids = consume_prev_bytes()\n",
    "            trimmed, add_space = _trim_underscore_and_tell(subword)\n",
    "            ids.append(no)\n",
    "            subwords_.append(trimmed)\n",
    "            if add_space:\n",
    "                subwords_.append(' ')\n",
    "                ids.append(None)\n",
    "    prev_bytes = consume_prev_bytes()\n",
    "\n",
    "    return subwords_, ids\n",
    "\n",
    "words, indices = decode(r[0])\n",
    "len(words), len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_indices(subwords, ids, l, reduction_factor = 160, sample_rate = 16000):\n",
    "    result, temp_l, temp_r = [], [], []\n",
    "    for i in range(len(subwords)):\n",
    "        if ids[i] is not None:\n",
    "            temp_l.append(subwords[i])\n",
    "            temp_r.append(l[ids[i]])\n",
    "        else:\n",
    "            data = {'text': ''.join(temp_l), \n",
    "                    'start': round(temp_r[0],4), \n",
    "                    'end': round(temp_r[-1] + (reduction_factor / sample_rate), 4)}\n",
    "            result.append(data)\n",
    "            temp_l, temp_r = [], []\n",
    "    \n",
    "    if len(temp_l):\n",
    "        data = {'text': ''.join(temp_l), \n",
    "                'start': round(temp_r[0],4), \n",
    "                'end': round(temp_r[-1] + (reduction_factor / sample_rate), 4)}\n",
    "        result.append(data)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'kalau', 'start': 0.56, 'end': 0.69},\n",
       " {'text': 'nama', 'start': 1.28, 'end': 1.41},\n",
       " {'text': 'saya', 'start': 1.52, 'end': 1.77},\n",
       " {'text': 'musim', 'start': 1.96, 'end': 2.29},\n",
       " {'text': 'saya', 'start': 3.12, 'end': 3.25},\n",
       " {'text': 'tak', 'start': 3.32, 'end': 3.33},\n",
       " {'text': 'suka', 'start': 3.52, 'end': 3.61},\n",
       " {'text': 'mandi', 'start': 3.72, 'end': 3.89},\n",
       " {'text': 'kata', 'start': 5.12, 'end': 5.17},\n",
       " {'text': 'saya', 'start': 5.32, 'end': 5.53},\n",
       " {'text': 'masak', 'start': 5.72, 'end': 5.97}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_indices(words, indices, r[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output-base-stack-3mixed-conformer/model.ckpt'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'output-base-stack-3mixed-conformer/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_placeholder',\n",
       " 'X_len_placeholder',\n",
       " 'padded_features',\n",
       " 'padded_lens',\n",
       " 'transducer/transducer_prediction/transducer_prediction_embedding/embeddings',\n",
       " 'greedy_decoder',\n",
       " 'encoded',\n",
       " 'encoded_placeholder',\n",
       " 'predicted_placeholder',\n",
       " 'states_placeholder',\n",
       " 'ytu',\n",
       " 'new_states',\n",
       " 'initial_states',\n",
       " 'non_blank_transcript',\n",
       " 'non_blank_stime']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'gather' in n.op.lower()\n",
    "        or 'placeholder' in n.name\n",
    "        or 'encoded' in n.name\n",
    "        or 'decoder' in n.name\n",
    "        or 'ytu' in n.name\n",
    "        or 'new_states' in n.name\n",
    "        or 'padded_' in n.name\n",
    "        or 'initial_states' in n.name\n",
    "        or 'non_blank' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "        and 'ReadVariableOp' not in n.name\n",
    "        and 'Gather' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-base-stack-3mixed-conformer/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-38-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 561 variables.\n",
      "INFO:tensorflow:Converted 561 variables to const ops.\n",
      "27392 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('output-base-stack-3mixed-conformer', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "                \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-base-stack-3mixed-conformer/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "    'encoded_placeholder',\n",
    "    'predicted_placeholder',\n",
    "    'states_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'greedy_decoder',\n",
    "    'encoded',\n",
    "    'ytu',\n",
    "    'new_states',\n",
    "    'padded_features',\n",
    "    'padded_lens',\n",
    "    'initial_states',\n",
    "    'non_blank_transcript',\n",
    "    'non_blank_stime'\n",
    "]\n",
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = test_sess.run(outputs['greedy_decoder'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "#                                                           inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in r:\n",
    "#     print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_, padded_lens_, s  = test_sess.run([outputs['encoded'], outputs['padded_lens'], outputs['initial_states']], \n",
    "#                                         feed_dict = {inputs['X_placeholder']: padded, \n",
    "#                                                      inputs['X_len_placeholder']: lens})\n",
    "\n",
    "# padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# r = transducer(\n",
    "#     enc = encoded_[i],\n",
    "#     total = padded_lens_[i],\n",
    "#     initial_states = s,\n",
    "#     encoded_placeholder = inputs['encoded_placeholder'],\n",
    "#     predicted_placeholder = inputs['predicted_placeholder'],\n",
    "#     states_placeholder = inputs['states_placeholder'],\n",
    "#     ytu = outputs['ytu'],\n",
    "#     new_states = outputs['new_states'],\n",
    "#     sess = test_sess,\n",
    "#     beam_width = 1,\n",
    "# )\n",
    "\n",
    "# malaya_speech.subword.decode(subwords, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-49-052e765d8104>:31: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "    'encoded_placeholder',\n",
    "    'predicted_placeholder',\n",
    "    'states_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'greedy_decoder',\n",
    "    'encoded',\n",
    "    'ytu',\n",
    "    'new_states',\n",
    "    'padded_features',\n",
    "    'padded_lens',\n",
    "    'initial_states',\n",
    "    'non_blank_transcript',\n",
    "    'non_blank_stime'\n",
    "]\n",
    "\n",
    "pb = 'output-base-stack-3mixed-conformer/frozen_model.pb'\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.FastGFile(pb, 'rb') as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                           input_nodes,\n",
    "                                           output_nodes, transforms)\n",
    "    \n",
    "with tf.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "    f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = load_graph('output-base-stack-mixed-conformer/frozen_model.pb.quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "# outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}\n",
    "# test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = test_sess.run(outputs['greedy_decoder'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "#                                                           inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in r:\n",
    "#     print(malaya_speech.subword.decode(subwords, row[row > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_, padded_lens_, s  = test_sess.run([outputs['encoded'], outputs['padded_lens'], outputs['initial_states']], \n",
    "#                                         feed_dict = {inputs['X_placeholder']: padded, \n",
    "#                                                      inputs['X_len_placeholder']: lens})\n",
    "\n",
    "# padded_lens_ = padded_lens_ // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# r = transducer(\n",
    "#     enc = encoded_[i],\n",
    "#     total = padded_lens_[i],\n",
    "#     initial_states = s,\n",
    "#     encoded_placeholder = inputs['encoded_placeholder'],\n",
    "#     predicted_placeholder = inputs['predicted_placeholder'],\n",
    "#     states_placeholder = inputs['states_placeholder'],\n",
    "#     ytu = outputs['ytu'],\n",
    "#     new_states = outputs['new_states'],\n",
    "#     sess = test_sess,\n",
    "#     beam_width = 1,\n",
    "# )\n",
    "\n",
    "# malaya_speech.subword.decode(subwords, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_application_key_id = os.environ['b2_application_key_id']\n",
    "b2_application_key = os.environ['b2_application_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from b2sdk.v1 import *\n",
    "info = InMemoryAccountInfo()\n",
    "b2_api = B2Api(info)\n",
    "application_key_id = b2_application_key_id\n",
    "application_key = b2_application_key\n",
    "b2_api.authorize_account(\"production\", application_key_id, application_key)\n",
    "file_info = {'how': 'good-file'}\n",
    "b2_bucket = b2_api.get_bucket_by_name('malaya-speech-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = 'output-base-stack-3mixed-conformer'\n",
    "tar = 'output-base-stack-3mixed-conformer.tar.gz'\n",
    "os.system(f'tar -czvf {tar} {directory}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7fdbfc14e828>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outPutname = f'pretrained/{tar}'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=tar,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm {tar}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7fdbfc377080>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'output-base-stack-3mixed-conformer/frozen_model.pb'\n",
    "outPutname = 'speech-to-text-transducer/conformer-stack-3mixed/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7fdc787a8f98>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'output-base-stack-3mixed-conformer/frozen_model.pb.quantized'\n",
    "outPutname = 'speech-to-text-transducer/conformer-stack-3mixed-quantized/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output-base-stack-3mixed-conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
