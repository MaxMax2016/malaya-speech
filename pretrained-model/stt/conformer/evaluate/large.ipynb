{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:38: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:42: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords = malaya_speech.subword.load('transducer.subword')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "sr = 16000\n",
    "maxlen = 18\n",
    "minlen_text = 1\n",
    "\n",
    "def mp3_to_wav(file, sr = sr):\n",
    "    audio = AudioSegment.from_file(file)\n",
    "    audio = audio.set_frame_rate(sr).set_channels(1)\n",
    "    sample = np.array(audio.get_array_of_samples())\n",
    "    return malaya_speech.astype.int_to_float(sample), sr\n",
    "\n",
    "\n",
    "def generate(file):\n",
    "    with open(file) as fopen:\n",
    "        dataset = json.load(fopen)\n",
    "    audios, cleaned_texts = dataset['X'], dataset['Y']\n",
    "    for i in range(len(audios)):\n",
    "        try:\n",
    "            if audios[i].endswith('.mp3'):\n",
    "                # print('found mp3', audios[i])\n",
    "                wav_data, _ = mp3_to_wav(audios[i])\n",
    "            else:\n",
    "                wav_data, _ = malaya_speech.load(audios[i], sr = sr)\n",
    "\n",
    "            if (len(wav_data) / sr) > maxlen:\n",
    "                # print(f'skipped audio too long {audios[i]}')\n",
    "                continue\n",
    "\n",
    "            if len(cleaned_texts[i]) < minlen_text:\n",
    "                # print(f'skipped text too short {audios[i]}')\n",
    "                continue\n",
    "\n",
    "            t = malaya_speech.subword.encode(\n",
    "                subwords, cleaned_texts[i], add_blank = False\n",
    "            )\n",
    "            back = np.zeros(shape=(2000,))\n",
    "            front = np.zeros(shape=(200,))\n",
    "            wav_data = np.concatenate([front, wav_data, back], axis=-1)\n",
    "\n",
    "            yield {\n",
    "                'waveforms': wav_data,\n",
    "                'targets': t,\n",
    "                'targets_length': [len(t)],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def preprocess_inputs(example):\n",
    "    s = featurizer.vectorize(example['waveforms'])\n",
    "    mel_fbanks = tf.reshape(s, (-1, n_mels))\n",
    "    length = tf.cast(tf.shape(mel_fbanks)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['inputs'] = mel_fbanks\n",
    "    example['inputs_length'] = length\n",
    "    example.pop('waveforms', None)\n",
    "    return example\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    file,\n",
    "    batch_size = 3,\n",
    "    shuffle_size = 20,\n",
    "    thread_count = 24,\n",
    "    maxlen_feature = 1800,\n",
    "):\n",
    "    def get():\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generate,\n",
    "            {\n",
    "                'waveforms': tf.float32,\n",
    "                'targets': tf.int32,\n",
    "                'targets_length': tf.int32,\n",
    "            },\n",
    "            output_shapes = {\n",
    "                'waveforms': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "                'targets_length': tf.TensorShape([None]),\n",
    "            },\n",
    "            args = (file,),\n",
    "        )\n",
    "        dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
    "        dataset = dataset.map(\n",
    "            preprocess_inputs, num_parallel_calls = thread_count\n",
    "        )\n",
    "        dataset = dataset.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes = {\n",
    "                'inputs': tf.TensorShape([None, n_mels]),\n",
    "                'inputs_length': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "                'targets_length': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values = {\n",
    "                'inputs': tf.constant(0, dtype = tf.float32),\n",
    "                'inputs_length': tf.constant(0, dtype = tf.int32),\n",
    "                'targets': tf.constant(0, dtype = tf.int32),\n",
    "                'targets_length': tf.constant(0, dtype = tf.int32),\n",
    "            },\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = get_dataset('bahasa-asr-test.json')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-41f3b56a7581>:1: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int32>,\n",
       " 'targets_length': <tf.Tensor 'IteratorGetNext:3' shape=(?, ?) dtype=int32>,\n",
       " 'inputs': <tf.Tensor 'IteratorGetNext:0' shape=(?, ?, 80) dtype=float32>,\n",
       " 'inputs_length': <tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dev_dataset.make_one_shot_iterator().get_next()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/transducer/layer.py:37: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "config = malaya_speech.config.conformer_large_encoder_config\n",
    "config['dropout'] = 0.0\n",
    "conformer_model = conformer.Model(\n",
    "    kernel_regularizer = None, bias_regularizer = None, **config\n",
    ")\n",
    "decoder_config = malaya_speech.config.conformer_large_decoder_config\n",
    "decoder_config['embed_dropout'] = 0.0\n",
    "transducer_model = transducer.rnn.Model(\n",
    "    conformer_model, vocabulary_size = subwords.vocab_size, **decoder_config\n",
    ")\n",
    "targets_length = features['targets_length'][:, 0]\n",
    "v = tf.expand_dims(features['inputs'], -1)\n",
    "z = tf.zeros((tf.shape(features['targets'])[0], 1), dtype = tf.int32)\n",
    "c = tf.concat([z, features['targets']], axis = 1)\n",
    "\n",
    "logits = transducer_model([v, c, targets_length + 1], training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = transducer_model.greedy_decoder(v, features['inputs_length'][:, 0], training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from asr-large-conformer-transducer-v2/model.ckpt-800000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'asr-large-conformer-transducer-v2/model.ckpt-800000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer, cer = [], []\n",
    "index = 0\n",
    "while True:\n",
    "    try:\n",
    "        r = sess.run([decoded, features['targets']])\n",
    "        for no, row in enumerate(r[0]):\n",
    "            d = malaya_speech.subword.decode(subwords, row[row > 0])\n",
    "            t = malaya_speech.subword.decode(subwords, r[1][no])\n",
    "            wer.append(malaya_speech.metrics.calculate_wer(t, d))\n",
    "            cer.append(malaya_speech.metrics.calculate_cer(t, d))\n",
    "            break\n",
    "        index += 1\n",
    "    except Exception as e:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15954776269300172, 0.05939583926324828)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)\n",
    "# (0.24665871358025013, 0.11013793851962718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 mempunyai kadar jenayah di bangla meningkat kerana bharis\n",
      "mempunyai kadar jenayah di bangalore meningkat kerana biharis\n",
      "\n",
      "1 semenjak ianya ditubuhkan lebih 20 tahun yang lalu\n",
      "semenjak ianya ditubuhkan lebih 20 tahun yang lalu\n",
      "\n",
      "2 saja tempat bandik menaruh tumis buatannya itu piring saji yang isinya\n",
      "saji tempat bangdik menaruh tumis tahu buatannya itu piring saji yang isinya\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for no, row in enumerate(r[0]):\n",
    "    d = malaya_speech.subword.decode(subwords, row[row > 0])\n",
    "    t = malaya_speech.subword.decode(subwords, r[1][no])\n",
    "    print(no, d)\n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
