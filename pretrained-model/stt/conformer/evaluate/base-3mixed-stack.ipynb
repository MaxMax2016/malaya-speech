{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/husein/t5/prepare/mesolitica-tpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "char_vocabs = [''] + list(string.ascii_lowercase + string.digits) + [' ']\n",
    "subwords_malay = malaya_speech.subword.load('bahasa-512.subword')\n",
    "subwords_singlish = malaya_speech.subword.load('singlish-512.subword')\n",
    "subwords_mandarin = malaya_speech.subword.load('mandarin-512.subword')\n",
    "langs = [subwords_malay, subwords_singlish, subwords_mandarin]\n",
    "len_vocab = [l.vocab_size for l in langs]\n",
    "config = malaya_speech.config.conformer_base_encoder_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subwords(ids, lang):\n",
    "    lang = lang[0]\n",
    "    text = ''.join([char_vocabs[c] for c in ids])\n",
    "    t = malaya_speech.subword.encode(\n",
    "        langs[lang], text, add_blank=False\n",
    "    )\n",
    "    t = np.array(t) + sum(len_vocab[:lang])\n",
    "    return t.astype(np.int32)\n",
    "\n",
    "\n",
    "def preprocess_inputs(example):\n",
    "    s = featurizer.vectorize(example['waveforms'])\n",
    "    mel_fbanks = tf.reshape(s, (-1, n_mels))\n",
    "    length = tf.cast(tf.shape(mel_fbanks)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['inputs'] = mel_fbanks\n",
    "    example['inputs_length'] = length\n",
    "\n",
    "    t = tf.compat.v1.numpy_function(get_subwords, [example['targets'], example['lang']], tf.int32)\n",
    "    t = tf.reshape(t, (-1,))\n",
    "    example['targets'] = t\n",
    "    length = tf.cast(tf.shape(t)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['targets_length'] = length\n",
    "\n",
    "    return example\n",
    "\n",
    "def parse(serialized_example):\n",
    "\n",
    "    data_fields = {\n",
    "        'waveforms': tf.compat.v1.VarLenFeature(tf.float32),\n",
    "        'targets': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'targets_length': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "        'lang': tf.compat.v1.VarLenFeature(tf.int64),\n",
    "    }\n",
    "    features = tf.compat.v1.parse_single_example(\n",
    "        serialized_example, features=data_fields\n",
    "    )\n",
    "    for k in features.keys():\n",
    "        features[k] = features[k].values\n",
    "\n",
    "    features = preprocess_inputs(features)\n",
    "\n",
    "    keys = list(features.keys())\n",
    "    for k in keys:\n",
    "        if k not in ['waveforms', 'inputs', 'inputs_length', 'targets', 'targets_length']:\n",
    "            features.pop(k, None)\n",
    "\n",
    "    return features\n",
    "\n",
    "def pop(features):\n",
    "    features.pop('waveforms', None)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "sr = 16000\n",
    "maxlen = 18\n",
    "minlen_text = 1\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    files,\n",
    "    batch_size = 3,\n",
    "    shuffle_size = 20,\n",
    "    thread_count = 24,\n",
    "    maxlen_feature = 1800,\n",
    "    num_cpu_threads=6,\n",
    "):\n",
    "    def get():\n",
    "        d = tf.data.Dataset.from_tensor_slices(tf.constant(files))\n",
    "        cycle_length = min(num_cpu_threads, len(files))\n",
    "        d = d.interleave(\n",
    "            tf.data.TFRecordDataset,\n",
    "            cycle_length=cycle_length,\n",
    "            block_length=thread_count)\n",
    "        d = d.map(parse, num_parallel_calls=thread_count)\n",
    "        d = d.map(pop, num_parallel_calls=thread_count)\n",
    "        d = d.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes={\n",
    "                'inputs': tf.TensorShape([None, n_mels]),\n",
    "                'inputs_length': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "                'targets_length': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values={\n",
    "                'inputs': tf.constant(0, dtype=tf.float32),\n",
    "                'inputs_length': tf.constant(0, dtype=tf.int32),\n",
    "                'targets': tf.constant(0, dtype=tf.int32),\n",
    "                'targets_length': tf.constant(0, dtype=tf.int32),\n",
    "            },\n",
    "        )\n",
    "        return d\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('3mixed-train-test.json') as fopen:\n",
    "    dataset = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = get_dataset(dataset['test'])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-41f3b56a7581>:1: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int32>,\n",
       " 'targets_length': <tf.Tensor 'IteratorGetNext:3' shape=(?, ?) dtype=int32>,\n",
       " 'inputs': <tf.Tensor 'IteratorGetNext:0' shape=(?, ?, 80) dtype=float32>,\n",
       " 'inputs_length': <tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dev_dataset.make_one_shot_iterator().get_next()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/transducer/layer.py:37: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "config = malaya_speech.config.conformer_base_encoder_config\n",
    "config['dropout'] = 0.0\n",
    "conformer_model = conformer.Model(\n",
    "    kernel_regularizer = None, bias_regularizer = None, **config\n",
    ")\n",
    "decoder_config = malaya_speech.config.conformer_base_decoder_config\n",
    "decoder_config['embed_dropout'] = 0.0\n",
    "transducer_model = transducer.rnn.Model(\n",
    "    conformer_model, vocabulary_size = sum(len_vocab), **decoder_config\n",
    ")\n",
    "targets_length = features['targets_length'][:, 0]\n",
    "v = tf.expand_dims(features['inputs'], -1)\n",
    "z = tf.zeros((tf.shape(features['targets'])[0], 1), dtype = tf.int32)\n",
    "c = tf.concat([z, features['targets']], axis = 1)\n",
    "\n",
    "logits = transducer_model([v, c, targets_length + 1], training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = transducer_model.greedy_decoder(v, features['inputs_length'][:, 0], training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from asr-base-conformer-transducer-3mixed/model.ckpt-1500000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'asr-base-conformer-transducer-3mixed/model.ckpt-1625000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from malaya_speech.utils.subword import decode\n",
    "\n",
    "def decode_multilanguage(row, langs):\n",
    "    \n",
    "    if not len(row):\n",
    "        return ''\n",
    "\n",
    "    len_vocab = [l.vocab_size for l in langs]\n",
    "\n",
    "    def get_index_multilanguage(r):\n",
    "        for i in range(len(langs)):\n",
    "            sum_v = sum(len_vocab[:i + 1])\n",
    "            if r < sum(len_vocab[:i + 1]):\n",
    "                return i, r - sum(len_vocab[:i])\n",
    "\n",
    "    last_index, v = get_index_multilanguage(row[0])\n",
    "    d, q = [], [v]\n",
    "    for r in row[1:]:\n",
    "        index, v = get_index_multilanguage(r)\n",
    "        if index != last_index:\n",
    "            d.append(decode(langs[last_index], q))\n",
    "            q = [v]\n",
    "            last_index = index\n",
    "        else:\n",
    "            q.append(v)\n",
    "    if len(q):\n",
    "        d.append(decode(langs[last_index], q))\n",
    "    d = re.sub(r'[ ]+', ' ', ' '.join(d)).strip()\n",
    "    d = d.replace(' lah', 'lah')\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of sequence\n",
      "\t [[node IteratorGetNext (defined at /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "\n",
      "Original stack trace for 'IteratorGetNext':\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 563, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 438, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.6/asyncio/base_events.py\", line 1451, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 272, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 542, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-41f3b56a7581>\", line 1, in <module>\n",
      "    features = dev_dataset.make_one_shot_iterator().get_next()\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\n",
      "    name=name)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\n",
      "    output_shapes=output_shapes, name=name)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "pairs = []\n",
    "index = 0\n",
    "while True:\n",
    "    try:\n",
    "        r = sess.run([decoded, features['targets']])\n",
    "        for no, row in enumerate(r[0]):\n",
    "            try:\n",
    "                d = decode_multilanguage(row[row > 0], langs)\n",
    "                t = decode_multilanguage(r[1][no], langs)\n",
    "                wer.append(malaya_speech.metrics.calculate_wer(t, d))\n",
    "                cer.append(malaya_speech.metrics.calculate_cer(t, d))\n",
    "                pairs.append((d, t))\n",
    "            except Exception as e:\n",
    "                print('inside', e)\n",
    "        index += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2775877387974494, 0.16312050753168209)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gei wo bo yi ge wu bai de ge qu\n",
      "gei wo bo yi ge wu bai de ge qu\n",
      "\n",
      "leng dong shi wen du diao dao ling xia er shi yi she shi du\n",
      "leng dong shi wen du diao dao ling xia er shi yi she shi du\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for no, row in enumerate(r[0]):\n",
    "    try:\n",
    "        d = decode_multilanguage(row[row > 0], langs)\n",
    "        t = decode_multilanguage(r[1][no], langs)\n",
    "        print(d)\n",
    "        print(t)\n",
    "        print()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('technician told them boat', 'tangan aku disentuh lembut'),\n",
       " ('sampaikan ada orang yang menegur aku dengan bahasa inggeris toncy izin tv',\n",
       "  'sampai kan ada orang yang menegur aku dengan bahasa kasarnya don t you know it is a sin to be pessimistic'),\n",
       " ('kenapa tidak kita menus', 'kenapa tidak kita mengusir obummer'),\n",
       " ('sama kalau kokasi kau ikut jantan lain kan sering hantaran 2',\n",
       "  'sama kalau kekasih kau ikut jantan lain kan saving duit hantaran 20k kau tu'),\n",
       " ('laki laki bernama anda itu segera mengalirkan pandangannya keliberan kemudian',\n",
       "  'laki laki bernama andra itu segera mengalihkan pandangannya ke libra kemudian'),\n",
       " ('kenapa saya berurusan dengan aktif internet biasanya meninggalkan keputusan yang tidak baik',\n",
       "  'kenapa saya berurusan dengan atheis internet biasanya meninggalkan keputusan yang tidak baik'),\n",
       " ('dan perlukan duit untuk operation dalam kadar segera',\n",
       "  'dan perlukan duit untuk operation dalam kadar segera'),\n",
       " ('tokoh adalah bukti bahawa umno tidak ada belas kasihan',\n",
       "  'tokong adalah bukti bahawa umno tidak ada belas kasihan'),\n",
       " ('di tengah tengah nikmatnya aku menyantak makanan bandik tiba tiba sija',\n",
       "  'ditengah tengah nikmatnya aku menyantap makanan bangdik tiba tiba si chef'),\n",
       " ('pendek sangat menangguh kehidupan syariat aku kalau kadang bila nak makan pun aku jadi saya nak takut',\n",
       "  'benda ni sangat menganggu kehidupan seharian aku kadang kadang bila nak makan pun aku jadi sangat takut'),\n",
       " ('kenapa lelaki lebih bijak daripada gadis dalam setiap aspek',\n",
       "  'kenapa lelaki lebih bijak daripada gadis dalam setiap aspek'),\n",
       " ('waktu siang buka siaran yang anak kau suka',\n",
       "  'waktu siang buka siaran yang anak kau suka'),\n",
       " ('kenapa doktor esok alaihisdap membunuh seseorang dan berjalan kaki',\n",
       "  'kenapa doktor ezor alaris dapat membunuh seseorang dan berjalan kaki'),\n",
       " ('weh masing aku tahu gap', 'gue eh sorry maksudnya aku boleh ketawa gak'),\n",
       " ('sekiranya saya memanggil polis pada anak di saya',\n",
       "  'sekiranya saya memanggil polis pada anak gay saya'),\n",
       " ('boleh diubah dengan menambah', 'boleh diubah dengan menambah'),\n",
       " ('menunggu persetugal lain yang belum tiba serta proses',\n",
       "  'menunggu peserta negara lain yang belum tiba serta proses'),\n",
       " ('sebutkan taat acuan', 'sebut perkataan acuan'),\n",
       " ('adakah untuk menyediakan rokok untuk bertaubat walaupun aktif anda',\n",
       "  'adakah untuk menyedut rokok untuk bertaubat walaupun ateis anda'),\n",
       " ('to do runway some spior', 'c tudung rambut sama seperti di sektor swasta'),\n",
       " ('sebelum ini ekonomi da ha ria',\n",
       "  'sebelum ini menteri hal ehwal ekonomi datuk seri mohamed azmin ali'),\n",
       " ('bagaimana orang yahudi cuba mengiklankan akal komuniti mereka',\n",
       "  'bagaimana orang yahudi cuba mengiklankan akal komuniti mereka'),\n",
       " ('akan dimukrab membuat kita menjadi rajin komunis',\n",
       "  'akan demokrat membuat kita menjadi rejim komunis'),\n",
       " ('kenapa benda isbejat daripada kumpulan lain',\n",
       "  'kenapa bengalis begitu bijak daripada kumpulan lain'),\n",
       " ('kenapa tidak akan membatalkan rekodnya terutamanya pulangan cukai',\n",
       "  'kenapa tidak akan membatalkan rekodnya terutamanya pulangan cukai'),\n",
       " ('kenapa orang di utasar dan sumbu dan mementingkan diri sendiri',\n",
       "  'kenapa orang di utah kasar dan sombong dan mementingkan diri sendiri'),\n",
       " ('ketiga negara eropah kita geli', 'kategori negara eropah kategori'),\n",
       " ('telur subo', 'tolong sebut dermaga'),\n",
       " ('serta menafikan menjadikannya sebagai asas bagi filem terbitan mereka',\n",
       "  'serta menafikan menjadikannya sebagai asas bagi filem terbitan mereka'),\n",
       " ('kota kinabalu naik presiden warisan jun wang berkata tidak',\n",
       "  'kota kinabalu naib presiden warisan junz wong berkata tidak'),\n",
       " ('mengapa orang mereka afrika sama ada mangsa atau penjenayah',\n",
       "  'mengapa orang amerika afrika sama ada mangsa atau penjenayah'),\n",
       " ('katanya kementerian juga sudah melakukan siasatan berhubung perkara',\n",
       "  'katanya kementeriannya juga sudah melakukan siasatan berhubung perkara'),\n",
       " ('saya cerita sekolah menenga', 'ayah saya cikgu sekolah menengah'),\n",
       " ('ia menundukkan kepala menjadi di bawah main asli melihat sebuah gantungan',\n",
       "  'dia menundukkan kepala mencari dibawah meja yasmin melihat sebuah gantungan'),\n",
       " ('aku call tanya ustaz ustaz tanya sampai pat ayah mana anak menangis sekuat',\n",
       "  'aku call tanya ustaz ustaz tanya sampai part ayat mana anak menangis kuat'),\n",
       " ('dan kajian mendalam oleh pasukan teknikal akan berterusan',\n",
       "  'dan kajian mendalam oleh pasukan teknikal akan berterusan'),\n",
       " ('asmi sampai dikelas lalu membuka pintu dengan kecam segera dia berlari',\n",
       "  'yasmin sampai dikelas lalu membuka pintu dengan kencang segera dia berlari'),\n",
       " ('dan usaha', 'dan mesti naik atas'),\n",
       " ('kerana juga bekerja sama dengan dia hisap tingg',\n",
       "  'prada juga bekerja sama dengan the humane society'),\n",
       " ('yang jenis ni serta tenang', 'yang jernih serta tenang'),\n",
       " ('dalam kenyataan yang dikeluarkan pejabat menteri pelancongan seni dan budaya hari',\n",
       "  'dalam kenyataan yang dikeluarkan pejabat menteri pelancongan seni dan budaya hari'),\n",
       " ('yasenku di belah berteriak segencang mungkin tapi asing minta meninggal',\n",
       "  'yas tunggu libra berteriak sekencang mungkin tapi yasmin tak mendengar'),\n",
       " ('adakah orang bertemu sehingga kehilangan keperaan mereka di sini',\n",
       "  'adakah orang bertemu sehingga kehilangan keperawanan mereka di sini'),\n",
       " ('sudah setengah habis dimakan oleh membuat banding menggelengkan kepala',\n",
       "  'sudah setengah habis dimakan olehku membuat bangdik menggelengkan kepala'),\n",
       " ('melihat gambar keseluruhannya adakah orang kulit hitam yang paling tidak terkawal',\n",
       "  'melihat gambar keseluruhannya adakah orang kulit hitam yang paling tidak terkawal'),\n",
       " ('membuat rambutnya kadang terlihat perwarna kemirahan',\n",
       "  'membuat rambutnya kadang terlihat berwarna kemerahan'),\n",
       " ('sebut kedai aktif tetapi', 'sebut perkataan aktinoterapi'),\n",
       " ('president updasis boutiga',\n",
       "  'peletakan jawatan presiden abdelaziz bouteflika'),\n",
       " ('bagaimana saya boleh merayu dengan ibu balu saya',\n",
       "  'bagaimana saya boleh merayu dengan ibu balu saya'),\n",
       " ('mengikuti dua jam pelajaran sama pak dadi senget livering cepat cepat',\n",
       "  'mengikuti 2 jam pelajaran bersama pak dadi rasanya libra ingin cepat cepat'),\n",
       " ('adakah orang kulit putih mempunyai rasa iddan budaya yang paling rendah',\n",
       "  'adakah orang kulit putih mempunyai rasa identiti dan budaya yang paling rendah'),\n",
       " ('kenapa lgbt orang perlu tentang lebar begitu banyak',\n",
       "  'kenapa lgbt orang peduli tentang label begitu banyak'),\n",
       " ('keadaan kini terkawal dan semua pihak berkuasa berkaitan telah dimaklumkan',\n",
       "  'keadaan kini terkawal dan semua pihak berkuasa berkaitan telah dimaklumkan'),\n",
       " ('sweet dia melihat sekeliling sambil mengingat ingat kembali ke pan',\n",
       "  'yasmin terdiam melihat sekeliling sambil mengingat ingat kembali kapan'),\n",
       " ('mak bagi tahu lagi masa mengandungkan yang tempat maka tiba rasa macam sakit di bahagian atas proses sakit menteri cucuk',\n",
       "  'mak bagitahu lagi masa mengandungkan yang keempat mak tetiba rasa macam sakit di bahagian atas perut sakit mencucuk cucuk'),\n",
       " ('manakala saya dapat rabiu', 'manakala china terdapat radio'),\n",
       " ('bayangkan sudah lain ibu tunggal anak dua laki pula makin bermasalah ketu',\n",
       "  'bayangkan sudahlah ibu tunggal anak2 lelaki pulak makin bermasalah ketika itu'),\n",
       " ('sayangnya suruh pagi', 'sayangnya rasulullah pada kita'),\n",
       " ('tiba langit yang berdatang dengan fasmu sana menetap',\n",
       "  'libra dan gisel yang baru datang dengan nafas ngos ngosan menatap'),\n",
       " ('hari jumaat lepas kerja siap siap untuk nak naik bas kes alam',\n",
       "  'hari jumaat lepas kerja siap siap untuk nak naik bas ke shah alam'),\n",
       " ('afrisia merupakan jino sejenis', 'rafflesia merupakan genus sejenis'),\n",
       " ('adakah orang orang kulit putih di amerika menanggap mereka istimewa',\n",
       "  'adakah orang orang kulit putih di amerika menganggap mereka istimewa'),\n",
       " ('apa kurang dan kulit', 'apa yang aku kurang dan kawan aku lebih'),\n",
       " ('kehilangan saya mengayuh ayam tempoh motor',\n",
       "  'kegirangan seraya mengayun ayunkan kunci motornya'),\n",
       " ('pelajaran fizikal dan daftar sudah mewajar hari ini liberal sudah melayu resah',\n",
       "  'pelajaran fisika dan daffa sudah mewajari hal ini libra sudah mulai resah'),\n",
       " ('adalah china indonesia atau seluruh kan',\n",
       "  'adalah cina indonesian atau slogan'),\n",
       " ('baru baru ini kesatuan perkhidmatan perguan kebangsaan semenanjung malaysia anu tv',\n",
       "  'baru baru ini kesatuan perkhidmatan perguruan kebangsaan semenanjung malaysia nutp'),\n",
       " ('mengapa bahasa sepanjang lemas tidak baik di bahasa inggeris',\n",
       "  'mengapa bahasa sepanyol masih tidak baik di bahasa inggeris'),\n",
       " ('bagaimana anda bengkok dan mengisap asho anda sendiri',\n",
       "  'bagaimana anda bengkok dan mengisap asshole anda sendiri'),\n",
       " ('assalamualaikum siapa pernah kena tinggi',\n",
       "  'assalamualaikum sapa pernah kena tindih'),\n",
       " ('tolong sebut penyakitan', 'tolong sebut pengertian'),\n",
       " ('hujannya dengan nafas yang masih mohon',\n",
       "  'ujarnya dengan nafas yang masih ngos ngosan'),\n",
       " ('malangnya adil mendakwa pihak pengurusan tempat itu tidak persetuju dan berikan',\n",
       "  'malangnya adrian mendakwa pihak pengurusan tempat itu tidak bersetuju dan berikan'),\n",
       " ('librars p o v', 'libra s pov'),\n",
       " ('kenapa gadis gadis putih membenci lelaki india',\n",
       "  'kenapa gadis gadis putih membenci lelaki india'),\n",
       " ('bagaimana program di india adalah muslim',\n",
       "  'bagaimana perogol di india adalah muslim'),\n",
       " ('dan memasukkan ke dalam tempatnya lalu segera menemasi barangnya ke dalam tas',\n",
       "  'dan memasukkan ke dalam tempatnya lalu segera mengemasi barangnya kedalam tas'),\n",
       " ('terus membenarkan kemasukan perkataan',\n",
       "  'terus membenarkan kemasukan perkataan'),\n",
       " ('ya kawan juga hari ini dong kamu dah makan berapa kali makannya abang',\n",
       "  'ya kamu juga harusnya ngaca dong kamu udah makan berapa kali makanya abang'),\n",
       " ('paha', 'paham dah'),\n",
       " ('telok subo kerman', 'tolong sebut kemaluan'),\n",
       " ('mempunyai tuhan meletakkan juri sebagai penguasa dunia moden',\n",
       "  'mempunyai tuhan meletakkan jeweh sebagai penguasa dunia moden'),\n",
       " ('kambing and dulu', 'kembali andraku yang dulu'),\n",
       " ('mengapa menang di kerestor di pokemon',\n",
       "  'mengapa manaphy pergi ke restoran di pokemon'),\n",
       " ('dan dokumen perjalanan s', 'dan dokumen perjalanan bangladesh'),\n",
       " ('adakah baik untuk seorang wanita berumur 2',\n",
       "  'adakah ia baik untuk seorang wanita berumur 12 tahun'),\n",
       " ('adakah anda menggunakan sos pasta untuk cabar anda',\n",
       "  'adakah anda menggunakan sos pasta untuk cabai anda'),\n",
       " ('dakwah juga tu tanpa tiket', 'dakwah jugak tu tanpa kita sedar'),\n",
       " ('perkara memangnya', 'perut karet gumamnya'),\n",
       " ('lipat yes sebab banyak barang dia saya duduk di sebuah kerusi sambil mengatur',\n",
       "  'lipat yas cepet banget parah gisel duduk di sebuah kursi sambil mengatur'),\n",
       " ('sekiranya saya menolak tawaran tersebut saya masih boleh kekal berkematian situ tetapi sekiranya saya menerima maka saya perlu berpindah keluar dari situ dan bertugas di tempat lain',\n",
       "  'sekiranya saya menolak tawaran tersebut saya masih boleh kekal berkhidmat disitu tetapi sekiranya saya menerima maka saya perlu berpindah keluar dari situ dan bertugas di tempat lain'),\n",
       " ('kenapa ada orang yang bertanya soalan mengenai orang bodoh seperti itu',\n",
       "  'kenapa ada orang yang bertanya soalan mengenai orang bodoh seperti itu'),\n",
       " ('bank degre', 'bank yang terletak negara'),\n",
       " ('kuno asia tenggara masih', 'kuno asia tenggara masih'),\n",
       " ('adakah sebanyak orang yang paling indah di dunia',\n",
       "  'adakah serbaneka orang yang paling indah di dunia'),\n",
       " ('antara foto adik ia perada putra', 'antara foto aditya pradana putra'),\n",
       " ('only rudolf you do done', 'oleh huruf iaitu dan'),\n",
       " ('all mala malaysia is it bad', 'malah malaysia juga terlibat'),\n",
       " ('itu mahkamah', 'ah itu mah kamunya aja yang emang rakus'),\n",
       " ('the fight', 'the fight')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('motorcycle premium was the only section',\n",
       "  'motorcycle premium was the only exception'),\n",
       " ('he has said they was likely to harmful fisheries subsidies of keen interest to developing countries',\n",
       "  'she has said a deal was likely to end harmful fisheries subsidies of keen interest to developing countries'),\n",
       " ('but he has five years less experience that he otherwise would have had',\n",
       "  'but he has five years less experience that he otherwise would have had'),\n",
       " ('but received so back if positively valuate the top behind them',\n",
       "  'but receivers of bad gifts positively evaluated the thought behind them'),\n",
       " ('he also mentioned that doctor lee proposed to build a memorial garden in the university',\n",
       "  'he also mentioned that doctor lee proposed to build a memorial garden in the university'),\n",
       " ('h funds and others packaging is who a record level of police bats on brands on expectations of the the price rises',\n",
       "  'hedge funds and other speculators hold a record level of bullish bets on brent on expectations of further price rises'),\n",
       " ('alternative door opens were you shared and live with someone from your blood',\n",
       "  'hold the lift door open so youll share a lift with someone from your block'),\n",
       " ('just dont be fit news though', 'just dont be fake news though'),\n",
       " ('private hospital should relate systems and relationship to positives',\n",
       "  'private hospitals should develop the systems and relationships to facilitate this'),\n",
       " ('another matters such consultation is optional',\n",
       "  'in other matters such consultation is optional')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1000:1010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
