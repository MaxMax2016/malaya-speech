{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8a780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install malaya-speech -U --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928fac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4987606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/tensorflow_addons/utils/resource_loader.py:72: UserWarning: You are currently using TensorFlow 2.6.0 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
      "TensorFlow Addons has compiled its custom ops against TensorFlow 2.4.0, and there are no compatibility guarantees between the two versions. \n",
      "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
      " If you do, do not file an issue on Github. This is a known limitation.\n",
      "\n",
      "It might help you to fallback to pure Python ops with TF_ADDONS_PY_OPS . To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
      "\n",
      "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.4.0 and strictly below 2.5.0.\n",
      " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
      "\n",
      "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/malaya_boilerplate/frozen_graph.py:28: UserWarning: Cannot import beam_search_ops from Tensorflow Addons, `deep_model` for stemmer will not available to use, make sure Tensorflow Addons version >= 0.12.0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.2.6.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import json\n",
    "\n",
    "malaya_speech.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7187367f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 3579, 614)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "malay = sorted(glob('/home/ubuntu/wav2vec2/malay-test/*.wav'), key = lambda x: int(x.split('/')[-1].replace('.wav', '')))\n",
    "singlish = sorted(glob('/home/ubuntu/wav2vec2/singlish-test/*.wav'), key = lambda x: int(x.split('/')[-1].replace('.wav', '')))\n",
    "mandarin = sorted(glob('/home/ubuntu/wav2vec2/mandarin-test/*.wav'), key = lambda x: int(x.split('/')[-1].replace('.wav', '')))\n",
    "len(malay), len(singlish), len(mandarin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f3da4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(765, 3579, 614)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/ubuntu/wav2vec2/malay-test.json') as fopen:\n",
    "    malay_label = json.load(fopen)\n",
    "with open('/home/ubuntu/wav2vec2/singlish-test.json') as fopen:\n",
    "    singlish_label = json.load(fopen)\n",
    "with open('/home/ubuntu/wav2vec2/mandarin-test.json') as fopen:\n",
    "    mandarin_label = json.load(fopen)\n",
    "    \n",
    "len(malay_label), len(singlish_label), len(mandarin_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38707301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/home/ubuntu/wav2vec2/singlish-test/2502.wav',\n",
       "  'force to smile a forced smile'),\n",
       " ('/home/ubuntu/wav2vec2/malay-test/610.wav',\n",
       "  'kenapa tidak ada masalah dengan ucapan bebas'),\n",
       " ('/home/ubuntu/wav2vec2/malay-test/425.wav',\n",
       "  'aku whatsapp isteri aku yang aku nak bunuh diri'),\n",
       " ('/home/ubuntu/wav2vec2/singlish-test/2662.wav',\n",
       "  'the villagers pray for plentiful harvest at the start of every year'),\n",
       " ('/home/ubuntu/wav2vec2/malay-test/247.wav',\n",
       "  'agar bisa segera keluar dari ruangan maut pak dadi mulai keluar kelas'),\n",
       " ('/home/ubuntu/wav2vec2/singlish-test/3274.wav',\n",
       "  'if you cant settle my request you can always proceed to hearing'),\n",
       " ('/home/ubuntu/wav2vec2/singlish-test/2757.wav',\n",
       "  'and that was the start of something special'),\n",
       " ('/home/ubuntu/wav2vec2/singlish-test/1540.wav',\n",
       "  'singapore has grown beyond our wildest dreams'),\n",
       " ('/home/ubuntu/wav2vec2/singlish-test/1479.wav',\n",
       "  'they tried to keep it a secret but he was able to figure everything out'),\n",
       " ('/home/ubuntu/wav2vec2/singlish-test/3478.wav',\n",
       "  'as singapore ages their ranks can only grow')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "audio = malay + singlish + mandarin\n",
    "labels = malay_label + singlish_label + mandarin_label\n",
    "audio, labels = shuffle(audio, labels)\n",
    "test_set = list(zip(audio, labels))\n",
    "test_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1f2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "from pyctcdecode.language_model import LanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc63748",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = malaya_speech.stt.language_model(model = 'bahasa-manglish-combined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb4936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kenlm_model = kenlm.Model(lm)\n",
    "language_model = LanguageModel(kenlm_model, alpha = 0.01, beta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100e5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, _ = malaya_speech.load(test_set[0][0])\n",
    "y1, _ = malaya_speech.load(test_set[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d39d610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e5d6535b034537bcc3e6b138e852a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/127M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b9d7c857b3b497c8b52247cbfea2cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-11 22:41:46.048608: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-11 22:41:46.052470: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-06-11 22:41:46.052488: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: huseincomel-desktop\n",
      "2022-06-11 22:41:46.052492: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: huseincomel-desktop\n",
      "2022-06-11 22:41:46.052556: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program\n",
      "2022-06-11 22:41:46.052579: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 470.129.6\n"
     ]
    }
   ],
   "source": [
    "model = malaya_speech.stt.deep_transducer(model = 'conformer-stack-3mixed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e2b4ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.97 s, sys: 256 ms, total: 9.23 s\n",
      "Wall time: 6.22 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['force the small afford small',\n",
       " 'kenapa tidak ada masalah dengan ucapan bebas']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.beam_decoder_lm([y, y1], language_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51aab95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bd3929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 61/1240 [11:39<4:01:44, 12.30s/it]2022-06-11 22:53:56.722653: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 37785600 exceeds 10% of free system memory.\n",
      "2022-06-11 22:54:00.909883: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 37785600 exceeds 10% of free system memory.\n",
      "  6%|▋         | 78/1240 [15:10<4:17:00, 13.27s/it]2022-06-11 22:57:27.787498: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45711360 exceeds 10% of free system memory.\n",
      "2022-06-11 22:57:32.224188: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 45711360 exceeds 10% of free system memory.\n",
      "  7%|▋         | 86/1240 [16:48<3:50:11, 11.97s/it]2022-06-11 22:59:05.893360: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 39260160 exceeds 10% of free system memory.\n",
      "100%|██████████| 1240/1240 [3:44:53<00:00, 10.88s/it] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "wer, cer = [], []\n",
    "wer_lm, cer_lm = [], []\n",
    "\n",
    "batch_size = 4\n",
    "for i in tqdm(range(0, len(audio), batch_size)):\n",
    "    \n",
    "    batch_x = audio[i: i + batch_size]\n",
    "    batch_y = labels[i: i + batch_size]\n",
    "    \n",
    "    ys = [malaya_speech.load(b)[0] for b in batch_x]\n",
    "    pred = model.beam_decoder(ys)\n",
    "    pred_lm = model.beam_decoder_lm(ys, language_model)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        \n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))\n",
    "        \n",
    "        wer_lm.append(calculate_wer(batch_y[k], pred_lm[k]))\n",
    "        cer_lm.append(calculate_cer(batch_y[k], pred_lm[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "419bb86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23476848812196416,\n",
       " 0.13394483674348717,\n",
       " 0.22924182213367433,\n",
       " 0.13070185396400735)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(wer), np.mean(cer), np.mean(wer_lm), np.mean(cer_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dd4b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_malay = [no for no, i in enumerate(audio[: len(wer)]) if 'malay-test/' in i]\n",
    "index_singlish = [no for no, i in enumerate(audio[: len(wer)]) if 'singlish-test/' in i]\n",
    "index_mandarin = [no for no, i in enumerate(audio[: len(wer)]) if 'mandarin-test/' in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "374f6b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4818578988186831,\n",
       " 0.26272383033777974,\n",
       " 0.4732879865232807,\n",
       " 0.2588061061370562)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(wer)[index_malay]), np.mean(np.array(cer)[index_malay]), np.mean(np.array(wer_lm)[index_malay]), np.mean(np.array(cer_lm)[index_malay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3047aa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19609774671596963,\n",
       " 0.11304379568019195,\n",
       " 0.19033112424535406,\n",
       " 0.10952327667125457)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(wer)[index_singlish]), np.mean(np.array(cer)[index_singlish]), np.mean(np.array(wer_lm)[index_singlish]), np.mean(np.array(cer_lm)[index_singlish])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4cce4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1523241628924268,\n",
       " 0.09532740330032738,\n",
       " 0.15198786771062786,\n",
       " 0.09454285594833946)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(wer)[index_mandarin]), np.mean(np.array(cer)[index_mandarin]), np.mean(np.array(wer_lm)[index_mandarin]), np.mean(np.array(cer_lm)[index_mandarin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adac12e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
