{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech.train.model.conformer as conformer\n",
    "import malaya_speech.train.model.transducer as transducer\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subwords = malaya_speech.subword.load('transducer.subword')\n",
    "vocabs = {i: subwords._id_to_subword(i) for i in range(subwords.vocab_size - 1)}\n",
    "vocabs[-1] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = malaya_speech.tf_featurization.STTFeaturizer(\n",
    "    normalize_per_feature = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80\n",
    "sr = 16000\n",
    "maxlen = 18\n",
    "minlen_text = 1\n",
    "\n",
    "def mp3_to_wav(file, sr = sr):\n",
    "    audio = AudioSegment.from_file(file)\n",
    "    audio = audio.set_frame_rate(sr).set_channels(1)\n",
    "    sample = np.array(audio.get_array_of_samples())\n",
    "    return malaya_speech.astype.int_to_float(sample), sr\n",
    "\n",
    "\n",
    "def generate(file):\n",
    "    with open(file) as fopen:\n",
    "        dataset = json.load(fopen)\n",
    "    audios, cleaned_texts = dataset['X'], dataset['Y']\n",
    "    for i in range(len(audios)):\n",
    "        try:\n",
    "            if audios[i].endswith('.mp3'):\n",
    "                # print('found mp3', audios[i])\n",
    "                wav_data, _ = mp3_to_wav(audios[i])\n",
    "            else:\n",
    "                wav_data, _ = malaya_speech.load(audios[i], sr = sr)\n",
    "\n",
    "            if (len(wav_data) / sr) > maxlen:\n",
    "                # print(f'skipped audio too long {audios[i]}')\n",
    "                continue\n",
    "\n",
    "            if len(cleaned_texts[i]) < minlen_text:\n",
    "                # print(f'skipped text too short {audios[i]}')\n",
    "                continue\n",
    "\n",
    "            t = malaya_speech.subword.encode(\n",
    "                subwords, cleaned_texts[i], add_blank = False\n",
    "            )\n",
    "            back = np.zeros(shape=(2000,))\n",
    "            front = np.zeros(shape=(200,))\n",
    "            wav_data = np.concatenate([front, wav_data, back], axis=-1)\n",
    "\n",
    "            yield {\n",
    "                'waveforms': wav_data,\n",
    "                'targets': t,\n",
    "                'targets_length': [len(t)],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "\n",
    "def preprocess_inputs(example):\n",
    "    s = featurizer.vectorize(example['waveforms'])\n",
    "    mel_fbanks = tf.reshape(s, (-1, n_mels))\n",
    "    length = tf.cast(tf.shape(mel_fbanks)[0], tf.int32)\n",
    "    length = tf.expand_dims(length, 0)\n",
    "    example['inputs'] = mel_fbanks\n",
    "    example['inputs_length'] = length\n",
    "    example.pop('waveforms', None)\n",
    "    return example\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    file,\n",
    "    batch_size = 3,\n",
    "    shuffle_size = 20,\n",
    "    thread_count = 24,\n",
    "    maxlen_feature = 1800,\n",
    "):\n",
    "    def get():\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generate,\n",
    "            {\n",
    "                'waveforms': tf.float32,\n",
    "                'targets': tf.int32,\n",
    "                'targets_length': tf.int32,\n",
    "            },\n",
    "            output_shapes = {\n",
    "                'waveforms': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "                'targets_length': tf.TensorShape([None]),\n",
    "            },\n",
    "            args = (file,),\n",
    "        )\n",
    "        dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
    "        dataset = dataset.map(\n",
    "            preprocess_inputs, num_parallel_calls = thread_count\n",
    "        )\n",
    "        dataset = dataset.padded_batch(\n",
    "            batch_size,\n",
    "            padded_shapes = {\n",
    "                'inputs': tf.TensorShape([None, n_mels]),\n",
    "                'inputs_length': tf.TensorShape([None]),\n",
    "                'targets': tf.TensorShape([None]),\n",
    "                'targets_length': tf.TensorShape([None]),\n",
    "            },\n",
    "            padding_values = {\n",
    "                'inputs': tf.constant(0, dtype = tf.float32),\n",
    "                'inputs_length': tf.constant(0, dtype = tf.int32),\n",
    "                'targets': tf.constant(0, dtype = tf.int32),\n",
    "                'targets_length': tf.constant(0, dtype = tf.int32),\n",
    "            },\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    return get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = get_dataset('bahasa-asr-test.json')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-41f3b56a7581>:1: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'targets': <tf.Tensor 'IteratorGetNext:2' shape=(?, ?) dtype=int32>,\n",
       " 'targets_length': <tf.Tensor 'IteratorGetNext:3' shape=(?, ?) dtype=int32>,\n",
       " 'inputs': <tf.Tensor 'IteratorGetNext:0' shape=(?, ?, 80) dtype=float32>,\n",
       " 'inputs_length': <tf.Tensor 'IteratorGetNext:1' shape=(?, ?) dtype=int32>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = dev_dataset.make_one_shot_iterator().get_next()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/transducer/layer.py:37: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "config = malaya_speech.config.conformer_tiny_encoder_config\n",
    "config['dropout'] = 0.0\n",
    "conformer_model = conformer.Model(\n",
    "    kernel_regularizer = None, bias_regularizer = None, **config\n",
    ")\n",
    "decoder_config = malaya_speech.config.conformer_tiny_decoder_config\n",
    "decoder_config['embed_dropout'] = 0.0\n",
    "transducer_model = transducer.rnn.Model(\n",
    "    conformer_model, vocabulary_size = subwords.vocab_size, **decoder_config\n",
    ")\n",
    "targets_length = features['targets_length'][:, 0]\n",
    "v = tf.expand_dims(features['inputs'], -1)\n",
    "z = tf.zeros((tf.shape(features['targets'])[0], 1), dtype = tf.int32)\n",
    "c = tf.concat([z, features['targets']], axis = 1)\n",
    "\n",
    "logits = transducer_model([v, c, targets_length + 1], training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'while/Exit_1:0' shape=(?, ?) dtype=int32>,\n",
       " <tf.Tensor 'while/Exit_2:0' shape=(?, ?, 1030) dtype=float32>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded = transducer_model.greedy_decoder(v, features['inputs_length'][:, 0], training = training)\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = decoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ytu:0' shape=(1030,) dtype=float32>,\n",
       " <tf.Tensor 'new_states:0' shape=(1, 2, 1, 128) dtype=float32>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = transducer_model.encoder(v, training = training)\n",
    "encoded = tf.identity(encoded, name = 'encoded')\n",
    "encoded_placeholder = tf.placeholder(tf.float32, [config['dmodel']], name = 'encoded_placeholder')\n",
    "predicted_placeholder = tf.placeholder(tf.int32, None, name = 'predicted_placeholder')\n",
    "t = transducer_model.predict_net.get_initial_state().shape\n",
    "states_placeholder = tf.placeholder(tf.float32, [int(i) for i in t], name = 'states_placeholder')\n",
    "\n",
    "ytu, new_states = transducer_model.decoder_inference(\n",
    "    encoded=encoded_placeholder,\n",
    "    predicted=predicted_placeholder,\n",
    "    states=states_placeholder,\n",
    "    training = training,\n",
    "    use_softmax = True\n",
    ")\n",
    "\n",
    "ytu = tf.identity(ytu, name = 'ytu')\n",
    "new_states = tf.identity(new_states, name = 'new_states')\n",
    "ytu, new_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_states = transducer_model.predict_net.get_initial_state()\n",
    "initial_states = tf.identity(initial_states, name = 'initial_states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode.language_model import LanguageModel\n",
    "import kenlm\n",
    "\n",
    "kenlm_model = kenlm.Model('model.trie.klm')\n",
    "language_model = LanguageModel(kenlm_model, alpha = 0.05, beta = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from asr-tiny-conformer-transducer-v3/model.ckpt-575000\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list = tf.trainable_variables())\n",
    "saver.restore(sess, 'asr-tiny-conformer-transducer-v3/model.ckpt-575000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import heapq\n",
    "from typing import Any, Collection, Dict, Iterable, List, Optional, Tuple, Union\n",
    "np.set_printoptions(threshold=3)\n",
    "\n",
    "LMState = Optional[Union[kenlm.State, List[kenlm.State]]]\n",
    "\n",
    "BeamHypothesis_LM = collections.namedtuple(\n",
    "    'BeamHypothesis_LM', ('score', 'score_lm', 'prediction', 'states', 'text', 'next_word', 'word_part')\n",
    ")\n",
    "\n",
    "def apply_temp(logits_BxN, temperature):\n",
    "    uniform_noise_BxN = np.random.uniform(size = logits_BxN.shape)\n",
    "    logits_BxN += -np.log(-np.log(uniform_noise_BxN)) * temperature\n",
    "    return logits_BxN\n",
    "\n",
    "def _sort_and_trim_beams(beams: list, beam_width: int) -> list:\n",
    "    return heapq.nlargest(beam_width, beams, key=lambda x: x.score_lm)\n",
    "\n",
    "def prune_space(string):\n",
    "    return re.sub(r'[ ]+', ' ', string).strip()\n",
    "\n",
    "def _merge_tokens(token_1, token_2) -> str:\n",
    "    if len(token_2) == 0:\n",
    "        text = token_1\n",
    "    elif len(token_1) == 0:\n",
    "        text = token_2\n",
    "    else:\n",
    "        text = token_1 + \" \" + token_2\n",
    "    return prune_space(text)\n",
    "\n",
    "def _prune_history(beams, lm_order: int):\n",
    "    \"\"\"Filter out beams that are the same over max_ngram history.\n",
    "    Since n-gram language models have a finite history when scoring a new token, we can use that\n",
    "    fact to prune beams that only differ early on (more than n tokens in the past) and keep only the\n",
    "    higher scoring ones. Note that this helps speed up the decoding process but comes at the cost of\n",
    "    some amount of beam diversity. If more than the top beam is used in the output it should\n",
    "    potentially be disabled.\n",
    "    \"\"\"\n",
    "    # let's keep at least 1 word of history\n",
    "    min_n_history = max(1, lm_order - 1)\n",
    "    seen_hashes = set()\n",
    "    filtered_beams = []\n",
    "    # for each beam after this, check if we need to add it\n",
    "    for beam in beams:\n",
    "        text = beam.text\n",
    "        next_word = beam.next_word\n",
    "        word_part = beam.word_part\n",
    "        last_char = beam.prediction[-1]\n",
    "        logit_score = beam.score\n",
    "        hash_idx = (tuple(text.split()[-min_n_history:]), word_part, last_char)\n",
    "        if hash_idx not in seen_hashes:\n",
    "            beam_hyp = BeamHypothesis_LM(\n",
    "                score = logit_score,\n",
    "                score_lm = 0.0,\n",
    "                prediction = beam.prediction,\n",
    "                states = beam.states,\n",
    "                text = text,\n",
    "                next_word = next_word,\n",
    "                word_part = word_part\n",
    "            )\n",
    "            filtered_beams.append(beam_hyp)\n",
    "            seen_hashes.add(hash_idx)\n",
    "    return filtered_beams\n",
    "\n",
    "def get_lm_beams(beams, cached_lm_scores,\n",
    "        cached_partial_token_scores,\n",
    "        is_eos: bool = False):\n",
    "    \n",
    "    new_beams = []\n",
    "    for beam in beams:\n",
    "        text = beam.text\n",
    "        next_word = beam.next_word\n",
    "        word_part = beam.word_part\n",
    "        last_char = beam.prediction[-1]\n",
    "        logit_score = beam.score\n",
    "        new_text = _merge_tokens(text, next_word)\n",
    "        if new_text not in cached_lm_scores:\n",
    "            _, prev_raw_lm_score, start_state = cached_lm_scores[text]\n",
    "            score, end_state = language_model.score(start_state, next_word, is_last_word=is_eos)\n",
    "            raw_lm_score = prev_raw_lm_score + score\n",
    "            lm_hw_score = raw_lm_score\n",
    "            cached_lm_scores[new_text] = (lm_hw_score, raw_lm_score, end_state)\n",
    "        lm_score, _, _ = cached_lm_scores[new_text]\n",
    "        if len(word_part) > 0:\n",
    "            if word_part not in cached_partial_token_scores:\n",
    "                cached_partial_token_scores[word_part] = language_model.score_partial_token(\n",
    "                    word_part\n",
    "                )\n",
    "            lm_score += cached_partial_token_scores[word_part]\n",
    "        beam_hyp = BeamHypothesis_LM(\n",
    "            score = logit_score,\n",
    "            score_lm = logit_score + lm_score,\n",
    "            prediction = beam.prediction,\n",
    "            states = beam.states,\n",
    "            text = new_text,\n",
    "            next_word = '',\n",
    "            word_part = word_part\n",
    "        )\n",
    "        new_beams.append(beam_hyp)\n",
    "\n",
    "    return new_beams\n",
    "            \n",
    "        \n",
    "def transducer_lm(\n",
    "    enc,\n",
    "    total,\n",
    "    initial_states,\n",
    "    encoded_placeholder,\n",
    "    predicted_placeholder,\n",
    "    states_placeholder,\n",
    "    ytu,\n",
    "    new_states,\n",
    "    sess,\n",
    "    beam_width = 10,\n",
    "    token_min_logp = -20.0,\n",
    "    beam_prune_logp = -5.0,\n",
    "    temperature = 0.0,\n",
    "    score_norm = True,\n",
    "):\n",
    "    kept_hyps = [\n",
    "        BeamHypothesis_LM(score = 0.0, score_lm = 0.0,\n",
    "                          prediction = [0], states = initial_states, \n",
    "                          text = '', next_word = '', word_part = '')\n",
    "    ]\n",
    "    start_state = kenlm.State()\n",
    "    cached_lm_scores: Dict[str, Tuple[float, float, LMState]] = {\n",
    "        '': (0.0, 0.0, language_model.get_start_state())\n",
    "    }\n",
    "    cached_p_lm_scores: Dict[str, float] = {}\n",
    "    B = kept_hyps\n",
    "    for i in range(total):\n",
    "        A = B\n",
    "        B = []\n",
    "        while True:\n",
    "            y_hat = max(A, key = lambda x: x.score)\n",
    "            A.remove(y_hat)\n",
    "            ytu_, new_states_ = sess.run(\n",
    "                [ytu, new_states],\n",
    "                feed_dict = {\n",
    "                    encoded_placeholder: enc[i],\n",
    "                    predicted_placeholder: y_hat.prediction[-1],\n",
    "                    states_placeholder: y_hat.states,\n",
    "                },\n",
    "            )\n",
    "            ytu_ = np.log(ytu_)\n",
    "            if temperature > 0:\n",
    "                ytu_ = apply_temp(ytu_, temperature=temperature)\n",
    "            # ytu_ = np.clip(ytu_, np.log(1e-15), 0)\n",
    "            B.append(BeamHypothesis_LM(\n",
    "                score=y_hat.score + ytu_[0],\n",
    "                score_lm = 0.0,\n",
    "                prediction=y_hat.prediction,\n",
    "                states=y_hat.states,\n",
    "                text=y_hat.text,\n",
    "                next_word=y_hat.next_word,\n",
    "                word_part=y_hat.word_part,\n",
    "            ))\n",
    "            ytu_ = ytu_[1:]\n",
    "            max_idx = ytu_.argmax()\n",
    "            idx_list = set(np.where(ytu_ >= token_min_logp)[0]) | {max_idx}\n",
    "            for k in idx_list:\n",
    "                w = vocabs[k]\n",
    "                if isinstance(w, bytes):\n",
    "                    w = w.decode(encoding = 'ISO-8859-1')\n",
    "                w = w.replace('_', ' ')\n",
    "                s = y_hat.score + ytu_[k]\n",
    "                p = y_hat.prediction + [k + 1]\n",
    "            \n",
    "                if w[-1] == ' ':\n",
    "                    beam_hyp = BeamHypothesis_LM(\n",
    "                        score = s,\n",
    "                        score_lm = 0.0,\n",
    "                        prediction = p,\n",
    "                        states = new_states_,\n",
    "                        text = y_hat.text,\n",
    "                        next_word = y_hat.word_part + w,\n",
    "                        word_part = ''\n",
    "                    )\n",
    "                else:\n",
    "                    beam_hyp = BeamHypothesis_LM(\n",
    "                        score = s,\n",
    "                        score_lm = 0.0,\n",
    "                        prediction = p,\n",
    "                        states = new_states_,\n",
    "                        text = y_hat.text,\n",
    "                        next_word = y_hat.next_word,\n",
    "                        word_part = y_hat.word_part + w\n",
    "                    )\n",
    "                A.append(beam_hyp)\n",
    "            \n",
    "            scored_beams = get_lm_beams(A, cached_lm_scores, cached_p_lm_scores)\n",
    "            max_beam = max(scored_beams, key = lambda x: x.score_lm)\n",
    "            max_score = max_beam.score_lm\n",
    "            scored_beams = [b for b in scored_beams if b.score_lm >= max_score + beam_prune_logp]\n",
    "            trimmed_beams = _sort_and_trim_beams(scored_beams, beam_width = beam_width)\n",
    "            A = _prune_history(trimmed_beams, lm_order=language_model.order)\n",
    "        \n",
    "            max_A = max(A, key=lambda x: x.score)\n",
    "            hyps_max = max_A.score\n",
    "            kept_most_prob = [hyp for hyp in B if hyp.score > hyps_max]\n",
    "            if len(kept_most_prob) >= beam_width:\n",
    "                B = kept_most_prob\n",
    "                break\n",
    "            \n",
    "    new_beams = []\n",
    "    for beam in B:\n",
    "        text = beam.text\n",
    "        next_word = beam.next_word\n",
    "        word_part = beam.word_part\n",
    "        last_char = beam.prediction[-1]\n",
    "        logit_score = beam.score\n",
    "        beam_hyp = BeamHypothesis_LM(\n",
    "            score = logit_score,\n",
    "            score_lm = 0.0,\n",
    "            prediction = beam.prediction,\n",
    "            states = beam.states,\n",
    "            text = text,\n",
    "            next_word = word_part,\n",
    "            word_part = ''\n",
    "        )\n",
    "        new_beams.append(beam_hyp)\n",
    "    scored_beams = get_lm_beams(new_beams, cached_lm_scores, cached_p_lm_scores,is_eos=True)\n",
    "    max_beam = max(scored_beams, key = lambda x: x.score_lm)\n",
    "    max_score = max_beam.score_lm\n",
    "    scored_beams = [b for b in scored_beams if b.score_lm >= max_score + beam_prune_logp]\n",
    "    trimmed_beams = _sort_and_trim_beams(scored_beams, beam_width)\n",
    "\n",
    "    if score_norm:\n",
    "        trimmed_beams.sort(key=lambda x: x.score_lm / len(x.prediction), reverse=True)\n",
    "    else:\n",
    "        trimmed_beams.sort(key=lambda x: x.score_lm, reverse=True)\n",
    "    return trimmed_beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = sess.run([decoded, features['targets'], encoded, features['inputs_length'][:,0], initial_states])\n",
    "# l = r[3] // conformer_model.conv_subsampling.time_reduction_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for no, row in enumerate(r[0]):\n",
    "#     d = malaya_speech.subword.decode(subwords, row[row > 0])\n",
    "#     t = malaya_speech.subword.decode(subwords, r[1][no])\n",
    "#     print(no, t)\n",
    "#     print(no, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language_model = LanguageModel(kenlm_model, alpha = 0.05, beta = 1.0)\n",
    "\n",
    "# o = transducer_lm(\n",
    "#     enc = r[2][0],\n",
    "#     total = l[0],\n",
    "#     initial_states = r[4],\n",
    "#     encoded_placeholder = encoded_placeholder,\n",
    "#     predicted_placeholder = predicted_placeholder,\n",
    "#     states_placeholder = states_placeholder,\n",
    "#     ytu = ytu, \n",
    "#     new_states = new_states,\n",
    "#     sess = sess,\n",
    "#     beam_width = 5,\n",
    "# )\n",
    "# # malaya_speech.subword.decode(subwords, o[0])\n",
    "# [(malaya_speech.subword.decode(subwords, i.prediction), i.score_lm) for i in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "wer_lm, cer_lm = [], []\n",
    "index = 0\n",
    "while True:\n",
    "    try:\n",
    "        r = sess.run([decoded, features['targets'], encoded, features['inputs_length'][:,0], initial_states])\n",
    "        l = r[3] // conformer_model.conv_subsampling.time_reduction_factor\n",
    "        for no, row in enumerate(r[0]):\n",
    "            d = malaya_speech.subword.decode(subwords, row[row > 0])\n",
    "            t = malaya_speech.subword.decode(subwords, r[1][no])\n",
    "            \n",
    "            wer.append(malaya_speech.metrics.calculate_wer(t, d))\n",
    "            cer.append(malaya_speech.metrics.calculate_cer(t, d))\n",
    "            \n",
    "            o = transducer_lm(\n",
    "                enc = r[2][no],\n",
    "                total = l[no],\n",
    "                initial_states = r[4],\n",
    "                encoded_placeholder = encoded_placeholder,\n",
    "                predicted_placeholder = predicted_placeholder,\n",
    "                states_placeholder = states_placeholder,\n",
    "                ytu = ytu,\n",
    "                new_states = new_states,\n",
    "                sess = sess,\n",
    "                beam_width = 3,\n",
    "            )[0].prediction\n",
    "            d_lm = malaya_speech.subword.decode(subwords, o)\n",
    "\n",
    "            wer_lm.append(malaya_speech.metrics.calculate_wer(t, d_lm))\n",
    "            cer_lm.append(malaya_speech.metrics.calculate_cer(t, d_lm))\n",
    "        index += 1\n",
    "        print(index)\n",
    "    except Exception as e:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('saja tempat banding menaragis buatannya itu pilih saja yang isinya',\n",
       " 'saji tempat bangdik menaruh tumis tahu buatannya itu piring saji yang isinya',\n",
       " 'saja tempat banding menaramis buatannya itu pilih saja yang isinya')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d, t, d_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21284191174535216,\n",
       " 0.08140905442040013,\n",
       " 0.19968285285321455,\n",
       " 0.07700373888679218)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer), np.mean(wer_lm), np.mean(cer_lm)\n",
    "# (0.24665871358025013, 0.11013793851962718)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
