{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:39: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:40: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:41: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:43: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/optimizer/__init__.py:44: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import malaya_speech\n",
    "import malaya_speech.config\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "import random\n",
    "from malaya_speech.train.model import hubert\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = malaya_speech.config.transducer_featurizer_config\n",
    "config['feature_type'] = 'mfcc'\n",
    "config['num_feature_bins'] = 30\n",
    "config['stride_ms'] = 20\n",
    "featurizer = malaya_speech.utils.tf_featurization.STTFeaturizer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('bahasa-asr-train.json') as fopen:\n",
    "    dataset = json.load(fopen)\n",
    "    \n",
    "audios, cleaned_texts = dataset['X'], dataset['Y']\n",
    "audios = random.sample(audios, 400000)\n",
    "len(audios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(?, 90) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.placeholder(tf.float32, [None])\n",
    "v = featurizer.vectorize(i)\n",
    "deltas = malaya_speech.utils.tf_featurization.deltas(v)\n",
    "ddeltas = malaya_speech.utils.tf_featurization.deltas(deltas)\n",
    "concated = tf.concat([v, deltas, ddeltas], axis = 1)\n",
    "concated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=10000, compute_labels=False, init='k-means++',\n",
       "                init_size=None, max_iter=100, max_no_improvement=100,\n",
       "                n_clusters=100, n_init=20, random_state=None,\n",
       "                reassignment_ratio=0.0, tol=0.0, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km_model = hubert.kmeans.get_km_model()\n",
    "km_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [5:21:22<00:00,  2.07it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 10\n",
    "for n in tqdm(range(0, len(audios), batch_size)):\n",
    "    x = audios[n: n + batch_size]\n",
    "    b = []\n",
    "    for k in range(len(x)):\n",
    "        if not os.path.exists(x[k]):\n",
    "            continue\n",
    "        if x[k].endswith('.mp3'):\n",
    "            continue\n",
    "        y, _ = malaya_speech.load(x[k], sr = 16000)\n",
    "        v1 = sess.run(concated, feed_dict = {i: y})\n",
    "        b.append(v1)\n",
    "    if len(b):\n",
    "        b = np.concatenate(b)\n",
    "        km_model = km_model.partial_fit(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmean.km']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(km_model, 'kmean.km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean = hubert.kmeans.ApplyKmeans_TF('kmean.km')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58, 62, 51, 19, 11, 29, 75, 82, 27, 27, 27, 27, 27, 53, 45, 45, 54,\n",
       "        7, 77, 77, 58, 58, 58, 46, 55, 27, 52, 39, 51, 51, 19, 40, 61, 79,\n",
       "       66, 66,  5,  5,  5,  5,  5, 15,  5,  5,  5,  5, 30, 85, 90,  7, 25,\n",
       "       52, 11, 37, 82, 77, 46, 63,  2,  2, 96, 96, 16, 58, 17, 39, 37, 82,\n",
       "       57, 57, 35, 64, 64, 39, 51, 51, 19, 74, 67, 61, 61, 61, 79, 79, 66,\n",
       "        5,  5, 66,  5, 79, 79,  5,  5, 15,  5, 15,  5, 15, 43, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean(b[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/hubert/kmeans.py:18: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMin:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmean_tf = kmean(concated)\n",
    "kmean_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 74, 45, 74, 50, 78, 78, 78, 78, 37, 37, 89, 95, 40, 99, 86, 10,\n",
       "       92, 30, 90, 90, 52, 52, 38, 28, 28, 38, 36, 36, 29, 97, 39, 97, 67,\n",
       "       89, 89, 50, 43, 30, 90, 27, 52, 50, 10, 92, 97, 97, 89, 67, 38, 38,\n",
       "       38, 36, 36,  1,  1,  1,  1,  1, 21, 73, 73, 44, 18, 46, 25, 25, 95,\n",
       "       50, 99, 15, 66, 15,  9,  5, 10, 29, 97, 19, 99, 86, 30, 73, 37, 39,\n",
       "       39, 39, 52, 40, 99, 86, 92, 85, 37, 11, 40, 67, 11, 11, 11, 11, 39,\n",
       "       37, 37, 37, 37, 37, 26, 26, 37, 37, 37, 37, 37, 37, 37, 37, 26, 26,\n",
       "       37, 37, 37,  2,  2, 26, 26, 26, 26, 51, 74, 21, 21, 50, 38, 38, 38,\n",
       "       30, 60, 90, 58, 58, 25, 39, 39, 27, 27, 52, 52, 37, 37, 37, 39, 52,\n",
       "       52, 22, 50, 78, 81, 81, 81, 81, 30, 54, 90, 52, 95, 78, 78, 34, 78,\n",
       "       95, 43, 30, 31, 90, 58, 64, 51, 19, 74, 89, 50, 15, 78, 78, 78, 78,\n",
       "       78, 60, 27, 52, 50, 38, 21, 37, 61, 66, 28, 28, 28, 50, 99, 99, 43,\n",
       "       30,  1, 21, 38, 43, 86, 36, 67, 50, 99, 86, 92, 85,  1, 28, 28, 50,\n",
       "       99,  1,  1,  1, 28, 28, 99, 86, 92,  1, 73, 28, 74, 74, 50, 38,  3,\n",
       "        3, 73, 73,  9, 89, 97, 67, 67, 11, 27, 52, 40, 40, 50,  3, 30])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(kmean_tf, feed_dict = {i: y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
