{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.train.model import hubert, ctc\n",
    "from malaya_speech.train.model.conformer.model import Model as ConformerModel\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vocab = [''] + list(\n",
    "    string.ascii_lowercase + string.digits\n",
    ") + [' ']\n",
    "len(unique_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.encoder = ConformerModel(**self.config)\n",
    "\n",
    "    def __call__(self, x, input_mask, training = True):\n",
    "        return self.encoder(x, training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/hubert/model.py:59: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-6-aa51afee35a7>:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "config_conformer = malaya_speech.config.conformer_tiny_encoder_config\n",
    "config_conformer['subsampling']['type'] = 'none'\n",
    "config_conformer['dropout'] = 0.0\n",
    "encoder = Encoder(config_conformer)\n",
    "cfg = hubert.HuBERTConfig(\n",
    "    extractor_mode='layer_norm',\n",
    "    dropout=0.0,\n",
    "    attention_dropout=0.0,\n",
    "    encoder_layerdrop=0.0,\n",
    "    dropout_input=0.0,\n",
    "    dropout_features=0.0,\n",
    "    final_dim=128,\n",
    ")\n",
    "model = hubert.Model(cfg, encoder, ['pad', 'eos', 'unk'] + [str(i) for i in range(100)])\n",
    "r = model(X, padding_mask = X_len, features_only = True, mask = False)\n",
    "logits = tf.layers.dense(r['x'], len(unique_vocab) + 1)\n",
    "seq_lens = tf.reduce_sum(\n",
    "    tf.cast(tf.logical_not(r['padding_mask']), tf.int32), axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.transpose(logits, [1, 0, 2])\n",
    "logits = tf.identity(logits, name = 'logits')\n",
    "seq_lens = tf.identity(seq_lens, name = 'seq_lens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyctcdecode import build_ctcdecoder\n",
    "import kenlm\n",
    "\n",
    "kenlm_model = kenlm.Model('out.trie.klm')\n",
    "decoder = build_ctcdecoder(\n",
    "    unique_vocab + ['_'],\n",
    "    kenlm_model,\n",
    "    alpha=0.2,\n",
    "    beta=1.0,\n",
    "    ctc_token_idx=len(unique_vocab)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_t = tf.nn.softmax(tf.transpose(logits, [1, 0, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'speech/record/savewav_2020-11-26_22-36-06_294832.wav',\n",
    "    'speech/record/savewav_2020-11-26_22-40-56_929661.wav',\n",
    "    'speech/record/675.wav',\n",
    "    'speech/record/664.wav',\n",
    "    'speech/example-speaker/husein-zolkepli.wav',\n",
    "    'speech/example-speaker/mas-aisyah.wav',\n",
    "    'speech/example-speaker/khalil-nooh.wav',\n",
    "    'speech/example-speaker/shafiqah-idayu.wav',\n",
    "    'speech/khutbah/wadi-annuar.wav',\n",
    "]\n",
    "\n",
    "ys = [malaya_speech.load(f)[0] for f in files]\n",
    "padded, lens = malaya_speech.padding.sequence_1d(ys, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sess.run([logits_t, seq_lens], feed_dict = {X: padded, X_len: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 499, 39),\n",
       " array([299, 250, 279, 200, 281, 143, 196, 175, 499], dtype=int32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].shape, r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.04469749e-11, 9.53841954e-05, 1.79659619e-04, ...,\n",
       "        4.99524366e-10, 7.41766598e-06, 9.97852087e-01],\n",
       "       [1.78250800e-11, 3.19799554e-04, 3.49451111e-05, ...,\n",
       "        9.40413747e-10, 7.24381389e-05, 9.96281087e-01],\n",
       "       [2.35856970e-08, 1.06788284e-04, 1.74917616e-02, ...,\n",
       "        2.54488441e-06, 9.51646070e-05, 2.51933992e-01],\n",
       "       ...,\n",
       "       [1.77272070e-13, 7.85718748e-06, 3.84613941e-07, ...,\n",
       "        1.65338210e-09, 1.56802955e-07, 9.99935985e-01],\n",
       "       [1.58478008e-13, 1.04536739e-05, 2.63559798e-07, ...,\n",
       "        1.10291642e-09, 1.71716664e-07, 9.99942064e-01],\n",
       "       [1.27815510e-13, 1.04950568e-05, 1.85754615e-07, ...,\n",
       "        6.03708306e-10, 4.97670612e-07, 9.99933362e-01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0][0,:r[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pilihan tepat apabila dia kini lebih berani dan',\n",
       "  <kenlm.State at 0x7f1db04272b0>,\n",
       "  [('pilihan', (13, 28)),\n",
       "   ('tepat', (33, 47)),\n",
       "   ('apabila', (55, 73)),\n",
       "   ('dia', (104, 109)),\n",
       "   ('kini', (118, 126)),\n",
       "   ('lebih', (130, 140)),\n",
       "   ('berani', (144, 162)),\n",
       "   ('dan', (175, 186))],\n",
       "  -0.7227686417719876,\n",
       "  -1.4217007573524127)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = decoder.decode_beams(r[0][3,:r[1][3]], prune_history=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hubert-conformer-tiny-ctc-char/model.ckpt-1080000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'hubert-conformer-tiny-ctc-char/model.ckpt-1080000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output-hubert-conformer-tiny-ctc/model.ckpt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'output-hubert-conformer-tiny-ctc/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_placeholder',\n",
       " 'X_len_placeholder',\n",
       " 'mask_emb',\n",
       " 'label_embs_concat',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'logits',\n",
       " 'seq_lens']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'gather' in n.op.lower()\n",
    "        or 'placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'seq_lens' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "        and 'ReadVariableOp' not in n.name\n",
    "        and 'Gather' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-hubert-conformer-tiny-ctc/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-11-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 303 variables.\n",
      "INFO:tensorflow:Converted 303 variables to const ops.\n",
      "4971 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('output-hubert-conformer-tiny-ctc', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "                \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-hubert-conformer-tiny-ctc/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'logits',\n",
    "    'seq_lens',\n",
    "]\n",
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run(outputs['logits'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                          inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-1d79bd9b5404>:12: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "pb = 'output-hubert-conformer-tiny-ctc/frozen_model.pb'\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.FastGFile(pb, 'rb') as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                           input_nodes,\n",
    "                                           output_nodes, transforms)\n",
    "    \n",
    "with tf.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "    f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-hubert-conformer-large-ctc/frozen_model.pb.quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm output-hubert-conformer-tiny-ctc.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-hubert-conformer-tiny-ctc/\n",
      "output-hubert-conformer-tiny-ctc/model.ckpt.index\n",
      "output-hubert-conformer-tiny-ctc/model.ckpt.data-00000-of-00001\n",
      "output-hubert-conformer-tiny-ctc/frozen_model.pb.quantized\n",
      "output-hubert-conformer-tiny-ctc/checkpoint\n",
      "output-hubert-conformer-tiny-ctc/model.ckpt.meta\n",
      "output-hubert-conformer-tiny-ctc/frozen_model.pb\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf output-hubert-conformer-tiny-ctc-v2.tar.gz output-hubert-conformer-tiny-ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "b2_application_key_id = os.environ['b2_application_key_id']\n",
    "b2_application_key = os.environ['b2_application_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from b2sdk.v1 import *\n",
    "info = InMemoryAccountInfo()\n",
    "b2_api = B2Api(info)\n",
    "application_key_id = b2_application_key_id\n",
    "application_key = b2_application_key\n",
    "b2_api.authorize_account(\"production\", application_key_id, application_key)\n",
    "file_info = {'how': 'good-file'}\n",
    "b2_bucket = b2_api.get_bucket_by_name('malaya-speech-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7f682de10e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = 'output-hubert-conformer-tiny-ctc-v2.tar.gz'\n",
    "outPutname = \"pretrained/output-hubert-conformer-tiny-ctc-v2.tar.gz\"\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=key,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7f6819b3f160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'output-hubert-conformer-tiny-ctc/frozen_model.pb'\n",
    "outPutname = 'speech-to-text-ctc/hubert-conformer-tiny/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7f6819bf1358>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'output-hubert-conformer-tiny-ctc/frozen_model.pb.quantized'\n",
    "outPutname = 'speech-to-text-ctc/hubert-conformer-tiny-quantized/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output-hubert-conformer-tiny-ctc output-hubert-conformer-tiny-ctc-v2.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
