{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_speech.train.model import hubert, ctc\n",
    "from malaya_speech.train.model.conformer.model import Model as ConformerModel\n",
    "import malaya_speech\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_vocab = [''] + list(\n",
    "    string.ascii_lowercase + string.digits\n",
    ") + [' ']\n",
    "len(unique_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.compat.v1.placeholder(tf.float32, [None, None], name = 'X_placeholder')\n",
    "X_len = tf.compat.v1.placeholder(tf.int32, [None], name = 'X_len_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.encoder = ConformerModel(**self.config)\n",
    "\n",
    "    def __call__(self, x, input_mask, training = True):\n",
    "        return self.encoder(x, training = training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/hubert/model.py:59: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-6-c8d249235ff2>:16: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "config_conformer = malaya_speech.config.conformer_large_encoder_config\n",
    "config_conformer['subsampling']['type'] = 'none'\n",
    "config_conformer['dropout'] = 0.0\n",
    "encoder = Encoder(config_conformer)\n",
    "cfg = hubert.HuBERTConfig(\n",
    "    extractor_mode='layer_norm',\n",
    "    dropout=0.0,\n",
    "    attention_dropout=0.0,\n",
    "    encoder_layerdrop=0.0,\n",
    "    dropout_input=0.0,\n",
    "    dropout_features=0.0,\n",
    "    final_dim=768,\n",
    ")\n",
    "model = hubert.Model(cfg, encoder, ['pad', 'eos', 'unk'] + [str(i) for i in range(100)])\n",
    "r = model(X, padding_mask = X_len, features_only = True, mask = False)\n",
    "logits = tf.layers.dense(r['x'], len(unique_vocab) + 1)\n",
    "seq_lens = tf.reduce_sum(\n",
    "    tf.cast(tf.logical_not(r['padding_mask']), tf.int32), axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.transpose(logits, [1, 0, 2])\n",
    "logits = tf.identity(logits, name = 'logits')\n",
    "seq_lens = tf.identity(seq_lens, name = 'seq_lens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hubert-conformer-large-3mixed-ctc/model.ckpt-1800000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "var_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_list)\n",
    "saver.restore(sess, 'hubert-conformer-large-3mixed-ctc/model.ckpt-1800000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output-hubert-conformer-large-3mixed-ctc/model.ckpt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'output-hubert-conformer-large-3mixed-ctc/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X_placeholder',\n",
       " 'X_len_placeholder',\n",
       " 'mask_emb',\n",
       " 'label_embs_concat',\n",
       " 'dense/kernel',\n",
       " 'dense/bias',\n",
       " 'logits',\n",
       " 'seq_lens']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'gather' in n.op.lower()\n",
    "        or 'placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'seq_lens' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "        and 'ReadVariableOp' not in n.name\n",
    "        and 'Gather' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-hubert-conformer-large-3mixed-ctc/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-12-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 575 variables.\n",
      "INFO:tensorflow:Converted 575 variables to const ops.\n",
      "9451 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('output-hubert-conformer-large-3mixed-ctc', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "                \n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "        \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    'speech/record/savewav_2020-11-26_22-36-06_294832.wav',\n",
    "    'speech/record/savewav_2020-11-26_22-40-56_929661.wav',\n",
    "    'speech/record/675.wav',\n",
    "    'speech/record/664.wav',\n",
    "    'mandarin-test/597.wav',\n",
    "    'mandarin-test/584.wav',\n",
    "    'speech/example-speaker/husein-zolkepli.wav',\n",
    "    'speech/example-speaker/mas-aisyah.wav',\n",
    "    'speech/example-speaker/khalil-nooh.wav',\n",
    "    'speech/example-speaker/shafiqah-idayu.wav',\n",
    "    'speech/khutbah/wadi-annuar.wav',\n",
    "    'singlish0.wav',\n",
    "    'singlish1.wav',\n",
    "    'singlish2.wav',\n",
    "    'singlish3.wav',\n",
    "    'singlish4.wav'\n",
    "]\n",
    "\n",
    "ys = [malaya_speech.load(f)[0] for f in files]\n",
    "padded, lens = malaya_speech.padding.sequence_1d(ys, return_len = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-hubert-conformer-large-3mixed-ctc/frozen_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = [\n",
    "    'X_placeholder',\n",
    "    'X_len_placeholder',\n",
    "]\n",
    "output_nodes = [\n",
    "    'logits',\n",
    "    'seq_lens',\n",
    "]\n",
    "inputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in input_nodes}\n",
    "outputs = {n: g.get_tensor_by_name(f'import/{n}:0') for n in output_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sess = tf.Session(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test_sess.run(outputs['logits'], feed_dict = {inputs['X_placeholder']: padded, \n",
    "                                                          inputs['X_len_placeholder']: lens})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.74796791e+01,  2.22706008e+00, -2.28309345e+00, ...,\n",
       "         -1.39269934e+01,  4.40964985e+00,  1.51709175e+01],\n",
       "        [-1.48394098e+01,  6.53269887e-01,  1.36876714e+00, ...,\n",
       "         -1.23634958e+01, -4.26429844e+00,  1.14488792e+01],\n",
       "        [-1.73578930e+01, -7.59971961e-02,  2.17342234e+00, ...,\n",
       "         -1.26250257e+01, -1.66954195e+00,  1.41015282e+01],\n",
       "        ...,\n",
       "        [-1.39627028e+01, -6.12434089e-01,  2.01688170e+00, ...,\n",
       "         -9.78253078e+00, -3.94086266e+00,  8.97707462e+00],\n",
       "        [-1.36591835e+01, -2.63311386e-01,  1.81870794e+00, ...,\n",
       "         -9.38347626e+00, -4.68216276e+00,  8.15526581e+00],\n",
       "        [-1.55976276e+01,  5.69279566e-02,  1.64571798e+00, ...,\n",
       "         -1.20707617e+01, -3.19104433e+00,  1.07102451e+01]],\n",
       "\n",
       "       [[-1.58719206e+01,  1.98721373e+00, -3.52281380e+00, ...,\n",
       "         -1.22139034e+01,  7.32882404e+00,  1.50353127e+01],\n",
       "        [-1.54291716e+01,  1.92501259e+00,  9.40426350e-01, ...,\n",
       "         -1.36616240e+01, -4.27194500e+00,  1.13539562e+01],\n",
       "        [-1.78797398e+01,  1.97131467e+00,  8.90905023e-01, ...,\n",
       "         -1.30719995e+01, -2.11565232e+00,  1.45716562e+01],\n",
       "        ...,\n",
       "        [-1.43001375e+01,  8.80140603e-01,  5.00414550e-01, ...,\n",
       "         -1.06196346e+01, -4.22823334e+00,  9.44809341e+00],\n",
       "        [-1.39119425e+01,  9.85099792e-01,  4.37068403e-01, ...,\n",
       "         -1.00563784e+01, -4.80862904e+00,  8.48269844e+00],\n",
       "        [-1.55869131e+01,  1.65985096e+00,  6.11696184e-01, ...,\n",
       "         -1.25433559e+01, -4.02166224e+00,  1.05466290e+01]],\n",
       "\n",
       "       [[-1.00943031e+01, -1.32239115e+00, -7.34586596e-01, ...,\n",
       "         -6.04068565e+00,  2.00423455e+00,  6.58915854e+00],\n",
       "        [-1.70897217e+01,  2.55564046e+00, -1.06049907e+00, ...,\n",
       "         -1.44853230e+01, -4.10199434e-01,  1.27002926e+01],\n",
       "        [-1.76981983e+01,  2.58555627e+00,  7.42076159e-01, ...,\n",
       "         -1.27099466e+01, -2.73837423e+00,  1.43908539e+01],\n",
       "        ...,\n",
       "        [-1.53338223e+01,  2.49373388e+00, -1.66520989e+00, ...,\n",
       "         -1.05544119e+01, -2.31337333e+00,  1.03472729e+01],\n",
       "        [-1.39770308e+01,  8.08155179e-01,  4.48613241e-02, ...,\n",
       "         -1.04156046e+01, -4.74940014e+00,  8.41199875e+00],\n",
       "        [-1.57421370e+01,  2.10553169e+00,  1.46787819e-02, ...,\n",
       "         -1.32292185e+01, -4.27867842e+00,  1.04025574e+01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.47661695e+01,  2.79380012e+00, -2.60774350e+00, ...,\n",
       "         -8.66752529e+00, -3.83111477e+00,  9.71401215e+00],\n",
       "        [-1.45578737e+01,  2.75544047e+00, -2.08305693e+00, ...,\n",
       "         -8.44402599e+00, -5.29704380e+00,  9.28408146e+00],\n",
       "        [-1.51994677e+01,  2.91082382e+00, -1.45415568e+00, ...,\n",
       "         -9.34847736e+00, -4.30651283e+00,  1.05497437e+01],\n",
       "        ...,\n",
       "        [-1.56023951e+01,  2.85705709e+00, -8.89245272e-01, ...,\n",
       "         -9.43931484e+00, -4.25654030e+00,  1.02041359e+01],\n",
       "        [-1.55044260e+01,  2.57429719e+00, -1.41461933e+00, ...,\n",
       "         -9.47346210e+00, -4.32102585e+00,  1.02529221e+01],\n",
       "        [-1.46126051e+01,  2.77410650e+00, -1.35551775e+00, ...,\n",
       "         -9.10505199e+00, -5.45129299e+00,  9.30177402e+00]],\n",
       "\n",
       "       [[-1.55868044e+01,  3.83680153e+00, -4.05489969e+00, ...,\n",
       "         -8.95182228e+00, -3.29431629e+00,  1.05788193e+01],\n",
       "        [-1.54213734e+01,  3.78712320e+00, -3.49966669e+00, ...,\n",
       "         -8.84159184e+00, -3.93008184e+00,  1.02960596e+01],\n",
       "        [-1.61716366e+01,  3.99606895e+00, -3.30509281e+00, ...,\n",
       "         -9.72338295e+00, -3.13358784e+00,  1.14963646e+01],\n",
       "        ...,\n",
       "        [-1.62139587e+01,  3.48994350e+00, -3.00323510e+00, ...,\n",
       "         -9.69863796e+00, -3.57965326e+00,  1.06807280e+01],\n",
       "        [-1.63783607e+01,  3.37919044e+00, -3.52862930e+00, ...,\n",
       "         -9.93885708e+00, -3.38941956e+00,  1.09906607e+01],\n",
       "        [-1.55325327e+01,  3.92054319e+00, -3.27364850e+00, ...,\n",
       "         -9.73996735e+00, -4.43802071e+00,  1.01175709e+01]],\n",
       "\n",
       "       [[-1.57777548e+01,  1.73406497e-01, -2.34396243e+00, ...,\n",
       "         -8.58921719e+00, -1.97434556e+00,  9.93628883e+00],\n",
       "        [-1.56889849e+01,  7.56966099e-02, -2.00757384e+00, ...,\n",
       "         -8.59029865e+00, -1.56410325e+00,  9.91970825e+00],\n",
       "        [-1.60379314e+01, -2.12392136e-01, -1.47143650e+00, ...,\n",
       "         -8.83734417e+00, -1.24966085e+00,  1.04817677e+01],\n",
       "        ...,\n",
       "        [-1.57077417e+01, -6.98710084e-01, -1.37162006e+00, ...,\n",
       "         -8.84020805e+00, -1.61450875e+00,  9.26728249e+00],\n",
       "        [-1.58895702e+01, -7.47503161e-01, -1.81692052e+00, ...,\n",
       "         -8.98040867e+00, -1.48967767e+00,  9.51249504e+00],\n",
       "        [-1.59941959e+01,  6.15396723e-02, -1.96084177e+00, ...,\n",
       "         -9.40454769e+00, -1.47421825e+00,  9.84638405e+00]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-22-edcb14b1ea43>:12: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "pb = 'output-hubert-conformer-large-3mixed-ctc/frozen_model.pb'\n",
    "\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.FastGFile(pb, 'rb') as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                           input_nodes,\n",
    "                                           output_nodes, transforms)\n",
    "    \n",
    "with tf.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "    f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('output-hubert-conformer-large-3mixed-ctc/frozen_model.pb.quantized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-hubert-conformer-large-3mixed-ctc/\n",
      "output-hubert-conformer-large-3mixed-ctc/model.ckpt.index\n",
      "output-hubert-conformer-large-3mixed-ctc/model.ckpt.data-00000-of-00001\n",
      "output-hubert-conformer-large-3mixed-ctc/frozen_model.pb.quantized\n",
      "output-hubert-conformer-large-3mixed-ctc/checkpoint\n",
      "output-hubert-conformer-large-3mixed-ctc/model.ckpt.meta\n",
      "output-hubert-conformer-large-3mixed-ctc/frozen_model.pb\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf output-hubert-conformer-large-3mixed-ctc.tar.gz output-hubert-conformer-large-3mixed-ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b2_application_key_id = os.environ['b2_application_key_id']\n",
    "b2_application_key = os.environ['b2_application_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from b2sdk.v1 import *\n",
    "info = InMemoryAccountInfo()\n",
    "b2_api = B2Api(info)\n",
    "application_key_id = b2_application_key_id\n",
    "application_key = b2_application_key\n",
    "b2_api.authorize_account(\"production\", application_key_id, application_key)\n",
    "file_info = {'how': 'good-file'}\n",
    "b2_bucket = b2_api.get_bucket_by_name('malaya-speech-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7f0558689c88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = 'output-hubert-conformer-large-3mixed-ctc.tar.gz'\n",
    "outPutname = \"pretrained/output-hubert-conformer-large-3mixed-ctc.tar.gz\"\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=key,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7f0570096b38>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'output-hubert-conformer-large-3mixed-ctc/frozen_model.pb'\n",
    "outPutname = 'speech-to-text-ctc-v2/hubert-conformer-large-3mixed/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b2sdk.file_version.FileVersionInfo at 0x7f0558689320>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'output-hubert-conformer-large-3mixed-ctc/frozen_model.pb.quantized'\n",
    "outPutname = 'speech-to-text-ctc-v2/hubert-conformer-large-3mixed-quantized/model.pb'\n",
    "b2_bucket.upload_local_file(\n",
    "    local_file=file,\n",
    "    file_name=outPutname,\n",
    "    file_infos=file_info,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output-hubert-conformer-large-3mixed-ctc output-hubert-conformer-large-3mixed-ctc.tar.gz"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
