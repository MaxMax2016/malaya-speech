{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Config, Wav2Vec2ForPreTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:368: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = Wav2Vec2Config.from_pretrained('facebook/wav2vec2-base')\n",
    "config.save_pretrained('./wav2vec2-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_7_1000000.pt\t\tcheckpoint.best_loss_3.0450.pt\r\n",
      "checkpoint.best_loss_3.0372.pt\tcheckpoint_best.pt\r\n",
      "checkpoint.best_loss_3.0422.pt\tcheckpoint_last.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/husein/outputs/2022-10-08/02-41-28/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = '/home/husein/outputs/2022-10-08/02-41-28/checkpoints/checkpoint_7_1000000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file wav2vec2-base/config.json\n",
      "/home/husein/.local/lib/python3.8/site-packages/transformers/configuration_utils.py:368: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Model config Wav2Vec2Config {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForPreTraining\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 256,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"freeze_feat_extract_train\": true,\n",
      "  \"gradient_checkpointing\": true,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"no_mask_channel_overlap\": false,\n",
      "  \"no_mask_time_overlap\": false,\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 768,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 256,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "2022-10-08 21:58:36 | INFO | __main__ |  was initialized from mask_emb.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 0 was initialized from feature_extractor.conv_layers.0.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract layer norm weight of layer 0 was initialized from feature_extractor.conv_layers.0.2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract layer norm weight of layer 0 was initialized from feature_extractor.conv_layers.0.2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 1 was initialized from feature_extractor.conv_layers.1.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 2 was initialized from feature_extractor.conv_layers.2.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 3 was initialized from feature_extractor.conv_layers.3.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 4 was initialized from feature_extractor.conv_layers.4.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 5 was initialized from feature_extractor.conv_layers.5.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | Feat extract conv layer 6 was initialized from feature_extractor.conv_layers.6.0.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.feature_projection.projection.weight was initialized from post_extract_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.feature_projection.projection.bias was initialized from post_extract_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ |  was initialized from quantizer.vars.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | quantizer.weight_proj.weight was initialized from quantizer.weight_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | quantizer.weight_proj.bias was initialized from quantizer.weight_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | project_q.weight was initialized from project_q.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | project_q.bias was initialized from project_q.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.pos_conv_embed.conv.bias was initialized from encoder.pos_conv.0.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.pos_conv_embed.conv.weight_g was initialized from encoder.pos_conv.0.weight_g.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.pos_conv_embed.conv.weight_v was initialized from encoder.pos_conv.0.weight_v.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.k_proj.weight was initialized from encoder.layers.0.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.k_proj.bias was initialized from encoder.layers.0.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.v_proj.weight was initialized from encoder.layers.0.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.v_proj.bias was initialized from encoder.layers.0.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.q_proj.weight was initialized from encoder.layers.0.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.q_proj.bias was initialized from encoder.layers.0.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.out_proj.weight was initialized from encoder.layers.0.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.attention.out_proj.bias was initialized from encoder.layers.0.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.layer_norm.weight was initialized from encoder.layers.0.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.layer_norm.bias was initialized from encoder.layers.0.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.feed_forward.intermediate_dense.weight was initialized from encoder.layers.0.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.feed_forward.intermediate_dense.bias was initialized from encoder.layers.0.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.feed_forward.output_dense.weight was initialized from encoder.layers.0.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.feed_forward.output_dense.bias was initialized from encoder.layers.0.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.final_layer_norm.weight was initialized from encoder.layers.0.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.0.final_layer_norm.bias was initialized from encoder.layers.0.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.k_proj.weight was initialized from encoder.layers.1.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.k_proj.bias was initialized from encoder.layers.1.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.v_proj.weight was initialized from encoder.layers.1.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.v_proj.bias was initialized from encoder.layers.1.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.q_proj.weight was initialized from encoder.layers.1.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.q_proj.bias was initialized from encoder.layers.1.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.out_proj.weight was initialized from encoder.layers.1.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.attention.out_proj.bias was initialized from encoder.layers.1.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.layer_norm.weight was initialized from encoder.layers.1.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.layer_norm.bias was initialized from encoder.layers.1.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.feed_forward.intermediate_dense.weight was initialized from encoder.layers.1.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.feed_forward.intermediate_dense.bias was initialized from encoder.layers.1.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.feed_forward.output_dense.weight was initialized from encoder.layers.1.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.feed_forward.output_dense.bias was initialized from encoder.layers.1.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.final_layer_norm.weight was initialized from encoder.layers.1.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.1.final_layer_norm.bias was initialized from encoder.layers.1.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.k_proj.weight was initialized from encoder.layers.2.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.k_proj.bias was initialized from encoder.layers.2.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.v_proj.weight was initialized from encoder.layers.2.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.v_proj.bias was initialized from encoder.layers.2.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.q_proj.weight was initialized from encoder.layers.2.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.q_proj.bias was initialized from encoder.layers.2.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.out_proj.weight was initialized from encoder.layers.2.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.attention.out_proj.bias was initialized from encoder.layers.2.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.layer_norm.weight was initialized from encoder.layers.2.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.layer_norm.bias was initialized from encoder.layers.2.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.feed_forward.intermediate_dense.weight was initialized from encoder.layers.2.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.feed_forward.intermediate_dense.bias was initialized from encoder.layers.2.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.feed_forward.output_dense.weight was initialized from encoder.layers.2.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.feed_forward.output_dense.bias was initialized from encoder.layers.2.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.final_layer_norm.weight was initialized from encoder.layers.2.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.2.final_layer_norm.bias was initialized from encoder.layers.2.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.k_proj.weight was initialized from encoder.layers.3.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.k_proj.bias was initialized from encoder.layers.3.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.v_proj.weight was initialized from encoder.layers.3.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.v_proj.bias was initialized from encoder.layers.3.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.q_proj.weight was initialized from encoder.layers.3.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.q_proj.bias was initialized from encoder.layers.3.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.out_proj.weight was initialized from encoder.layers.3.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.attention.out_proj.bias was initialized from encoder.layers.3.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.layer_norm.weight was initialized from encoder.layers.3.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.layer_norm.bias was initialized from encoder.layers.3.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.feed_forward.intermediate_dense.weight was initialized from encoder.layers.3.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.feed_forward.intermediate_dense.bias was initialized from encoder.layers.3.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.feed_forward.output_dense.weight was initialized from encoder.layers.3.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.feed_forward.output_dense.bias was initialized from encoder.layers.3.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.final_layer_norm.weight was initialized from encoder.layers.3.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.3.final_layer_norm.bias was initialized from encoder.layers.3.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.k_proj.weight was initialized from encoder.layers.4.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.k_proj.bias was initialized from encoder.layers.4.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.v_proj.weight was initialized from encoder.layers.4.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.v_proj.bias was initialized from encoder.layers.4.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.q_proj.weight was initialized from encoder.layers.4.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.q_proj.bias was initialized from encoder.layers.4.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.out_proj.weight was initialized from encoder.layers.4.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.attention.out_proj.bias was initialized from encoder.layers.4.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.layer_norm.weight was initialized from encoder.layers.4.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.layer_norm.bias was initialized from encoder.layers.4.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.feed_forward.intermediate_dense.weight was initialized from encoder.layers.4.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.feed_forward.intermediate_dense.bias was initialized from encoder.layers.4.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.feed_forward.output_dense.weight was initialized from encoder.layers.4.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.feed_forward.output_dense.bias was initialized from encoder.layers.4.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.final_layer_norm.weight was initialized from encoder.layers.4.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.4.final_layer_norm.bias was initialized from encoder.layers.4.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.k_proj.weight was initialized from encoder.layers.5.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.k_proj.bias was initialized from encoder.layers.5.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.v_proj.weight was initialized from encoder.layers.5.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.v_proj.bias was initialized from encoder.layers.5.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.q_proj.weight was initialized from encoder.layers.5.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.q_proj.bias was initialized from encoder.layers.5.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.out_proj.weight was initialized from encoder.layers.5.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.attention.out_proj.bias was initialized from encoder.layers.5.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.layer_norm.weight was initialized from encoder.layers.5.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.layer_norm.bias was initialized from encoder.layers.5.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.feed_forward.intermediate_dense.weight was initialized from encoder.layers.5.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.feed_forward.intermediate_dense.bias was initialized from encoder.layers.5.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.feed_forward.output_dense.weight was initialized from encoder.layers.5.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.feed_forward.output_dense.bias was initialized from encoder.layers.5.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.final_layer_norm.weight was initialized from encoder.layers.5.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.5.final_layer_norm.bias was initialized from encoder.layers.5.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.k_proj.weight was initialized from encoder.layers.6.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.k_proj.bias was initialized from encoder.layers.6.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.v_proj.weight was initialized from encoder.layers.6.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.v_proj.bias was initialized from encoder.layers.6.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.q_proj.weight was initialized from encoder.layers.6.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.q_proj.bias was initialized from encoder.layers.6.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.out_proj.weight was initialized from encoder.layers.6.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.attention.out_proj.bias was initialized from encoder.layers.6.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.layer_norm.weight was initialized from encoder.layers.6.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.layer_norm.bias was initialized from encoder.layers.6.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.feed_forward.intermediate_dense.weight was initialized from encoder.layers.6.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.feed_forward.intermediate_dense.bias was initialized from encoder.layers.6.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.feed_forward.output_dense.weight was initialized from encoder.layers.6.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.feed_forward.output_dense.bias was initialized from encoder.layers.6.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.final_layer_norm.weight was initialized from encoder.layers.6.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.6.final_layer_norm.bias was initialized from encoder.layers.6.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.k_proj.weight was initialized from encoder.layers.7.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.k_proj.bias was initialized from encoder.layers.7.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.v_proj.weight was initialized from encoder.layers.7.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.v_proj.bias was initialized from encoder.layers.7.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.q_proj.weight was initialized from encoder.layers.7.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.q_proj.bias was initialized from encoder.layers.7.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.out_proj.weight was initialized from encoder.layers.7.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.attention.out_proj.bias was initialized from encoder.layers.7.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.layer_norm.weight was initialized from encoder.layers.7.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.layer_norm.bias was initialized from encoder.layers.7.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.feed_forward.intermediate_dense.weight was initialized from encoder.layers.7.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.feed_forward.intermediate_dense.bias was initialized from encoder.layers.7.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.feed_forward.output_dense.weight was initialized from encoder.layers.7.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.feed_forward.output_dense.bias was initialized from encoder.layers.7.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.final_layer_norm.weight was initialized from encoder.layers.7.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.7.final_layer_norm.bias was initialized from encoder.layers.7.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.k_proj.weight was initialized from encoder.layers.8.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.k_proj.bias was initialized from encoder.layers.8.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.v_proj.weight was initialized from encoder.layers.8.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.v_proj.bias was initialized from encoder.layers.8.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.q_proj.weight was initialized from encoder.layers.8.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.q_proj.bias was initialized from encoder.layers.8.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.out_proj.weight was initialized from encoder.layers.8.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.attention.out_proj.bias was initialized from encoder.layers.8.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.layer_norm.weight was initialized from encoder.layers.8.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.layer_norm.bias was initialized from encoder.layers.8.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.feed_forward.intermediate_dense.weight was initialized from encoder.layers.8.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.feed_forward.intermediate_dense.bias was initialized from encoder.layers.8.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.feed_forward.output_dense.weight was initialized from encoder.layers.8.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.feed_forward.output_dense.bias was initialized from encoder.layers.8.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.final_layer_norm.weight was initialized from encoder.layers.8.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.8.final_layer_norm.bias was initialized from encoder.layers.8.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.k_proj.weight was initialized from encoder.layers.9.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.k_proj.bias was initialized from encoder.layers.9.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.v_proj.weight was initialized from encoder.layers.9.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.v_proj.bias was initialized from encoder.layers.9.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.q_proj.weight was initialized from encoder.layers.9.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.q_proj.bias was initialized from encoder.layers.9.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.out_proj.weight was initialized from encoder.layers.9.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.attention.out_proj.bias was initialized from encoder.layers.9.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.layer_norm.weight was initialized from encoder.layers.9.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.layer_norm.bias was initialized from encoder.layers.9.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.feed_forward.intermediate_dense.weight was initialized from encoder.layers.9.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.feed_forward.intermediate_dense.bias was initialized from encoder.layers.9.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.feed_forward.output_dense.weight was initialized from encoder.layers.9.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.feed_forward.output_dense.bias was initialized from encoder.layers.9.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.final_layer_norm.weight was initialized from encoder.layers.9.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.9.final_layer_norm.bias was initialized from encoder.layers.9.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.k_proj.weight was initialized from encoder.layers.10.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.k_proj.bias was initialized from encoder.layers.10.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.v_proj.weight was initialized from encoder.layers.10.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.v_proj.bias was initialized from encoder.layers.10.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.q_proj.weight was initialized from encoder.layers.10.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.q_proj.bias was initialized from encoder.layers.10.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.out_proj.weight was initialized from encoder.layers.10.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.attention.out_proj.bias was initialized from encoder.layers.10.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.layer_norm.weight was initialized from encoder.layers.10.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.layer_norm.bias was initialized from encoder.layers.10.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.feed_forward.intermediate_dense.weight was initialized from encoder.layers.10.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.feed_forward.intermediate_dense.bias was initialized from encoder.layers.10.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.feed_forward.output_dense.weight was initialized from encoder.layers.10.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.feed_forward.output_dense.bias was initialized from encoder.layers.10.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.final_layer_norm.weight was initialized from encoder.layers.10.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.10.final_layer_norm.bias was initialized from encoder.layers.10.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.k_proj.weight was initialized from encoder.layers.11.self_attn.k_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.k_proj.bias was initialized from encoder.layers.11.self_attn.k_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.v_proj.weight was initialized from encoder.layers.11.self_attn.v_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.v_proj.bias was initialized from encoder.layers.11.self_attn.v_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.q_proj.weight was initialized from encoder.layers.11.self_attn.q_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.q_proj.bias was initialized from encoder.layers.11.self_attn.q_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.out_proj.weight was initialized from encoder.layers.11.self_attn.out_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.attention.out_proj.bias was initialized from encoder.layers.11.self_attn.out_proj.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.layer_norm.weight was initialized from encoder.layers.11.self_attn_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.layer_norm.bias was initialized from encoder.layers.11.self_attn_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.feed_forward.intermediate_dense.weight was initialized from encoder.layers.11.fc1.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.feed_forward.intermediate_dense.bias was initialized from encoder.layers.11.fc1.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.feed_forward.output_dense.weight was initialized from encoder.layers.11.fc2.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.feed_forward.output_dense.bias was initialized from encoder.layers.11.fc2.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.final_layer_norm.weight was initialized from encoder.layers.11.final_layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layers.11.final_layer_norm.bias was initialized from encoder.layers.11.final_layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layer_norm.weight was initialized from encoder.layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.encoder.layer_norm.bias was initialized from encoder.layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.feature_projection.layer_norm.weight was initialized from layer_norm.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | wav2vec2.feature_projection.layer_norm.bias was initialized from layer_norm.bias.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | project_hid.weight was initialized from final_proj.weight.\n",
      "2022-10-08 21:58:36 | INFO | __main__ | project_hid.bias was initialized from final_proj.bias.\n",
      "2022-10-08 21:58:36 | WARNING | __main__ | Unused weights: []\n",
      "Configuration saved in wav2vec2-base/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved in wav2vec2-base/pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m transformers.models.wav2vec2.convert_wav2vec2_original_pytorch_checkpoint_to_pytorch --pytorch_dump_folder wav2vec2-base --checkpoint_path {ckpt} --config_path wav2vec2-base/config.json --not_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wav2Vec2ForPreTraining.from_pretrained('./wav2vec2-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e873a05fbd23450295c3be601b507ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/363M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/mesolitica/wav2vec2-base-ms\n",
      "   96263fe..a8f9924  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/mesolitica/wav2vec2-base-ms/commit/a8f99248aad3e3a342c55b76d5fb0f937dbbf76b'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('wav2vec2-base-ms', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!cd wav2vec2-base-ms && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 323ef86] add tensorboard\n",
      " 3 files changed, 9 insertions(+)\n",
      " create mode 100644 tensorboard/train/events.out.tfevents.1665175692.husein-MS-7D31.248350.2\n",
      " create mode 100644 tensorboard/train_inner/events.out.tfevents.1665168112.husein-MS-7D31.248350.0\n",
      " create mode 100644 tensorboard/valid/events.out.tfevents.1665169409.husein-MS-7D31.248350.1\n",
      "Uploading LFS objects: 100% (3/3), 3.2 MB | 327 KB/s, done.                     \n",
      "Enumerating objects: 14, done.\n",
      "Counting objects: 100% (14/14), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (9/9), done.\n",
      "Writing objects: 100% (9/9), 1.07 KiB | 1.07 MiB/s, done.\n",
      "Total 9 (delta 1), reused 0 (delta 0)\n",
      "remote: Scanning LFS files for validity, may be slow...\u001b[K\n",
      "remote: LFS file scan complete.\u001b[K\n",
      "To https://huggingface.co/mesolitica/wav2vec2-base-ms\n",
      "   a8f9924..323ef86  main -> main\n"
     ]
    }
   ],
   "source": [
    "!cp -r /home/husein/outputs/2022-10-08/02-41-28/tensorboard wav2vec2-base-ms\n",
    "!cd wav2vec2-base-ms && git add . && git commit -m 'add tensorboard' && git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
