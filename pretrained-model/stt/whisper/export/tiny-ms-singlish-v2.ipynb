{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !~/huggingface/bin/pip3 install torch torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "# !~/huggingface/bin/pip3 install pytorch-lightning\n",
    "# !~/huggingface/bin/pip3 install soundfile librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoFeatureExtractor,\n",
    "    AutoModelForSpeechSeq2Seq,\n",
    "    AutoProcessor,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'openai/whisper-tiny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "\n",
    "class Model(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        learning_rate: float = 2e-5,\n",
    "        adam_epsilon: float = 1e-8,\n",
    "        warmup_steps: int = 1000,\n",
    "        weight_decay: float = 0.0,\n",
    "        eval_splits=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, config=self.config)\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model-epoch=05-step=465000.ckpt'  'model-epoch=05-step=480000.ckpt'\r\n",
      "'model-epoch=05-step=470000.ckpt'  'model-epoch=05-step=485000.ckpt'\r\n",
      "'model-epoch=05-step=475000.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls openai-whisper-tiny-16-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load_from_checkpoint(\"openai-whisper-tiny-16-v2/model-epoch=05-step=485000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save_pretrained('./ms-tiny-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.save_pretrained('./ms-tiny-v2')\n",
    "tokenizer.save_pretrained('./ms-tiny-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained('./ms-tiny-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.push_to_hub('finetune-whisper-tiny-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/transformers/utils/hub.py:651: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/finetune-whisper-tiny-ms-singlish-v2/commit/3917e8f4f704b751197569d942bfb18f8fe17d4f', commit_message='Upload WhisperForConditionalGeneration', commit_description='', oid='3917e8f4f704b751197569d942bfb18f8fe17d4f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.push_to_hub('finetune-whisper-tiny-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.push_to_hub('finetune-whisper-tiny-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub('finetune-whisper-tiny-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, WhisperProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = AutoModelForSpeechSeq2Seq.from_pretrained('ms-tiny-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained('ms-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import json\n",
    "\n",
    "with open('/home/husein/ssd1/speech-bahasa/malay-asr-test.json') as fopen:\n",
    "    test_set = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [librosa.load(f, sr = 16000, mono = True)[0] for f in test_set['X'][:3] + ['singlish0.wav', 'husein-zolkepli.wav']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 80, 3000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = processor(ys, return_tensors=\"pt\").input_features\n",
    "input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = new_model.generate(input_features, max_length = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'ms ialah penyakit yang mempengaruhi sistem saraposan yang dibentuk daripada otak sarah puncang dan sarap optik',\n",
       " 'jimnastik a s dan joas mempunyai matlamat yang sama menjadikan sukan jimnastik dan lain lain selamat pagi para atlet untuk mengejar impian mereka dalam persekitaran yang selamat positif dan berdaya maju',\n",
       " 'and then see how they grow it in film okay actually',\n",
       " 'testing nama saya hussein bin zulkifli']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer.batch_decode(o, skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'gimnastik as dan joas mempunyai matlamat yang sama menjadikan sukan gimnastik dan lain lain selamat bagi para atlet untuk mengejar impian mereka dalam persekitaran yang selamat positif dan berdaya maju']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Y'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nama saya syafiqah aida you',\n",
       " 'sebut perkataan uncle',\n",
       " 'testing nama saya hussein bin zulkifli',\n",
       " 'takkan orang yang seperti abang fakar itu mahu juga dia menjaganya baik baik orang yang tidak bertimbang rasa tu',\n",
       " 'sebagai pembangkang yang matang dan sejahtera pas akan menghadapi pilihan raya umum dan tidak menumbang kerajaan dari pintu belakang',\n",
       " 'pengaturcaraan adalah suatu kaedah memberi arahan atau perintah kepada komputer untuk menjalankan sesuatu juga atau mana mana mesin elektronik',\n",
       " 'tolong sebut and theukata',\n",
       " 'apa khabar semua saya doakan saudara dan saudari sihat walafiat hari ini saya sekali lagi menemui saudara']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "import malaya_speech\n",
    "\n",
    "files = glob('speech/example-speaker/*.wav')\n",
    "ys = [malaya_speech.load(f)[0] for f in files]\n",
    "input_features = processor(ys, sampling_rate = 16000, return_tensors=\"pt\").input_features\n",
    "o = new_model.generate(input_features, max_length = 256)\n",
    "processor.tokenizer.batch_decode(o, skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 206 ms, sys: 0 ns, total: 206 ms\n",
      "Wall time: 19.1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.7919e-02,  3.7591e-01,  6.7061e-01,  ..., -4.9661e-01,\n",
       "          -4.9661e-01, -4.9661e-01],\n",
       "         [ 1.4865e-01,  5.2505e-01,  7.3631e-01,  ..., -4.9661e-01,\n",
       "          -4.9661e-01, -4.9661e-01],\n",
       "         [ 3.0252e-01,  5.7934e-01,  7.0872e-01,  ..., -4.9661e-01,\n",
       "          -4.9661e-01, -4.9661e-01],\n",
       "         ...,\n",
       "         [-1.0308e-01, -3.9721e-02,  4.8087e-02,  ..., -4.9661e-01,\n",
       "          -4.9661e-01, -4.9661e-01],\n",
       "         [-1.2300e-01, -3.3460e-02,  4.4005e-02,  ..., -4.9661e-01,\n",
       "          -4.9661e-01, -4.9661e-01],\n",
       "         [-1.4860e-01, -2.4000e-02,  7.9799e-04,  ..., -4.9661e-01,\n",
       "          -4.9661e-01, -4.9661e-01]],\n",
       "\n",
       "        [[ 9.5621e-01,  9.2088e-01,  9.8969e-01,  ..., -4.8367e-01,\n",
       "          -4.8367e-01, -4.8367e-01],\n",
       "         [ 7.0786e-01,  9.7993e-01,  9.7543e-01,  ..., -4.8367e-01,\n",
       "          -4.8367e-01, -4.8367e-01],\n",
       "         [ 8.1467e-01,  8.3065e-01,  7.8870e-01,  ..., -4.8367e-01,\n",
       "          -4.8367e-01, -4.8367e-01],\n",
       "         ...,\n",
       "         [-3.9725e-02, -6.7097e-02, -1.3501e-01,  ..., -4.8367e-01,\n",
       "          -4.8367e-01, -4.8367e-01],\n",
       "         [ 4.1101e-02,  3.1993e-02,  1.7885e-02,  ..., -4.8367e-01,\n",
       "          -4.8367e-01, -4.8367e-01],\n",
       "         [ 1.6128e-03,  1.9813e-02, -5.0588e-02,  ..., -4.8367e-01,\n",
       "          -4.8367e-01, -4.8367e-01]],\n",
       "\n",
       "        [[-5.4417e-01, -2.3037e-01,  1.8659e-01,  ..., -5.4417e-01,\n",
       "          -5.4417e-01, -5.4417e-01],\n",
       "         [-3.9115e-01,  3.7812e-02,  2.6878e-01,  ..., -5.4417e-01,\n",
       "          -5.4417e-01, -5.4417e-01],\n",
       "         [-1.2523e-01,  1.8266e-01,  3.9105e-01,  ..., -5.4417e-01,\n",
       "          -5.4417e-01, -5.4417e-01],\n",
       "         ...,\n",
       "         [-2.9860e-01, -2.7390e-01, -3.4831e-01,  ..., -5.4417e-01,\n",
       "          -5.4417e-01, -5.4417e-01],\n",
       "         [-3.2355e-01, -3.5818e-01, -4.3552e-01,  ..., -5.4417e-01,\n",
       "          -5.4417e-01, -5.4417e-01],\n",
       "         [-2.8144e-01, -2.8397e-01, -3.2560e-01,  ..., -5.4417e-01,\n",
       "          -5.4417e-01, -5.4417e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.8524e-01, -6.0959e-01, -3.1738e-01,  ..., -6.0959e-01,\n",
       "          -6.0959e-01, -6.0959e-01],\n",
       "         [-6.2001e-02, -2.2092e-01, -1.4226e-01,  ..., -6.0959e-01,\n",
       "          -6.0959e-01, -6.0959e-01],\n",
       "         [-1.0096e-01, -1.8467e-01, -5.2040e-02,  ..., -6.0959e-01,\n",
       "          -6.0959e-01, -6.0959e-01],\n",
       "         ...,\n",
       "         [-6.0959e-01, -6.0959e-01, -6.0959e-01,  ..., -6.0959e-01,\n",
       "          -6.0959e-01, -6.0959e-01],\n",
       "         [-6.0959e-01, -6.0959e-01, -6.0959e-01,  ..., -6.0959e-01,\n",
       "          -6.0959e-01, -6.0959e-01],\n",
       "         [-6.0959e-01, -6.0959e-01, -6.0959e-01,  ..., -6.0959e-01,\n",
       "          -6.0959e-01, -6.0959e-01]],\n",
       "\n",
       "        [[ 7.0911e-01,  4.7957e-01,  6.6427e-01,  ..., -6.2609e-01,\n",
       "          -6.2609e-01, -6.2609e-01],\n",
       "         [ 6.3448e-01,  5.5664e-01,  5.5310e-01,  ..., -6.2609e-01,\n",
       "          -6.2609e-01, -6.2609e-01],\n",
       "         [ 4.2659e-01,  4.0321e-01,  3.7969e-01,  ..., -6.2609e-01,\n",
       "          -6.2609e-01, -6.2609e-01],\n",
       "         ...,\n",
       "         [-2.2363e-01, -2.8742e-01, -2.7254e-01,  ..., -6.2609e-01,\n",
       "          -6.2609e-01, -6.2609e-01],\n",
       "         [-2.3387e-01, -3.0162e-01, -2.6535e-01,  ..., -6.2609e-01,\n",
       "          -6.2609e-01, -6.2609e-01],\n",
       "         [-3.2731e-01, -3.2658e-01, -2.9667e-01,  ..., -6.2609e-01,\n",
       "          -6.2609e-01, -6.2609e-01]],\n",
       "\n",
       "        [[-6.2273e-01, -3.6755e-01,  4.6767e-01,  ..., -6.2273e-01,\n",
       "          -6.2273e-01, -6.2273e-01],\n",
       "         [-6.2273e-01, -3.8772e-01,  4.9812e-01,  ..., -6.2273e-01,\n",
       "          -6.2273e-01, -6.2273e-01],\n",
       "         [-6.2273e-01, -4.2007e-01,  4.0704e-01,  ..., -6.2273e-01,\n",
       "          -6.2273e-01, -6.2273e-01],\n",
       "         ...,\n",
       "         [-6.2273e-01, -6.2273e-01, -6.2055e-01,  ..., -6.2273e-01,\n",
       "          -6.2273e-01, -6.2273e-01],\n",
       "         [-6.2273e-01, -6.2273e-01, -6.2273e-01,  ..., -6.2273e-01,\n",
       "          -6.2273e-01, -6.2273e-01],\n",
       "         [-6.2273e-01, -6.2273e-01, -6.2273e-01,  ..., -6.2273e-01,\n",
       "          -6.2273e-01, -6.2273e-01]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mels = []\n",
    "inputs = ys\n",
    "for k in range(len(inputs)):\n",
    "    audio = whisper.pad_or_trim(inputs[k].astype(np.float32).flatten())\n",
    "    mel = whisper.log_mel_spectrogram(audio)\n",
    "    mels.append({'input_features': mel})\n",
    "    \n",
    "batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "batch.input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = new_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 370/370 [00:34<00:00, 10.81it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "wer, cer = [], []\n",
    "\n",
    "batch_size = 2\n",
    "for i in tqdm(range(0, len(test_set['X']), batch_size)):\n",
    "    batch_y = test_set['Y'][i: i + batch_size]\n",
    "    ys = [malaya_speech.load(f)[0] for f in test_set['X'][i: i + batch_size]]\n",
    "    mels = []\n",
    "    for k in range(len(ys)):\n",
    "        audio = whisper.pad_or_trim(ys[k].astype(np.float32))\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        mels.append({'input_features': mel})\n",
    "\n",
    "    batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "    input_features = batch.input_features\n",
    "    o = new_model.generate(input_features.cuda(), max_length = 256)\n",
    "    pred = processor.tokenizer.batch_decode(o, skip_special_tokens = True)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22459602785237057, 0.08940646925178528)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('postprocess-malaya-malay-test-set.json') as fopen:\n",
    "    malaya_malay = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 765/765 [00:26<00:00, 28.70it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(malaya_malay))):\n",
    "    if not malaya_malay[i]['accept']:\n",
    "        continue\n",
    "    \n",
    "    batch_y = [malaya_malay[i]['cleaned']]\n",
    "    ys = [malaya_speech.load(f)[0] for f in [f'malay-test/{i}.wav']]\n",
    "    mels = []\n",
    "    for k in range(len(ys)):\n",
    "        audio = whisper.pad_or_trim(ys[k].astype(np.float32))\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        mels.append({'input_features': mel})\n",
    "\n",
    "    batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "    input_features = batch.input_features\n",
    "    o = new_model.generate(input_features.cuda(), max_length = 256)\n",
    "    pred = processor.tokenizer.batch_decode(o, skip_special_tokens = True)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2030751600909704, 0.07452196517713668)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('singlish-test.json') as fopen:\n",
    "    singlish = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3579/3579 [02:05<00:00, 28.61it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(singlish))):\n",
    "    \n",
    "    batch_y = [singlish[i]]\n",
    "    ys = [malaya_speech.load(f)[0] for f in [f'singlish-test/{i}.wav']]\n",
    "    mels = []\n",
    "    for k in range(len(ys)):\n",
    "        audio = whisper.pad_or_trim(ys[k].astype(np.float32))\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        mels.append({'input_features': mel})\n",
    "\n",
    "    batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "    input_features = batch.input_features\n",
    "    o = new_model.generate(input_features.cuda(), max_length = 256)\n",
    "    pred = processor.tokenizer.batch_decode(o, skip_special_tokens = True)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1388829716298684, 0.07492980731417179)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
