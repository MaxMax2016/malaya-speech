{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoFeatureExtractor,\n",
    "    AutoModelForSpeechSeq2Seq,\n",
    "    AutoProcessor,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    set_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'openai/whisper-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.1.36ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/pkg_resources/__init__.py:116: PkgResourcesDeprecationWarning: 0.23ubuntu1 is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
    "\n",
    "class Model(LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        learning_rate: float = 2e-5,\n",
    "        adam_epsilon: float = 1e-8,\n",
    "        warmup_steps: int = 1000,\n",
    "        weight_decay: float = 0.0,\n",
    "        eval_splits=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.config = AutoConfig.from_pretrained(model_name_or_path)\n",
    "        self.model = AutoModelForSpeechSeq2Seq.from_pretrained(model_name_or_path, config=self.config)\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'model-epoch=02-step=345000.ckpt'  'model-epoch=02-step=355000.ckpt'\r\n",
      "'model-epoch=02-step=350000.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls openai-whisper-base-16-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load_from_checkpoint(\"openai-whisper-base-16-v2/model-epoch=02-step=355000.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save_pretrained('./ms-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./ms-base-v2/tokenizer_config.json',\n",
       " './ms-base-v2/special_tokens_map.json',\n",
       " './ms-base-v2/vocab.json',\n",
       " './ms-base-v2/merges.txt',\n",
       " './ms-base-v2/normalizer.json',\n",
       " './ms-base-v2/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.save_pretrained('./ms-base-v2')\n",
    "tokenizer.save_pretrained('./ms-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained('./ms-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/transformers/utils/hub.py:651: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/finetune-whisper-base-ms-singlish-v2/commit/746c0bb942b30a23ccb5ebb4d663b8203cbc7aa4', commit_message='Upload processor', commit_description='', oid='746c0bb942b30a23ccb5ebb4d663b8203cbc7aa4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.push_to_hub('finetune-whisper-base-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/finetune-whisper-base-ms-singlish-v2/commit/ca430c0f0429e8cbc8a4f5ac89e6b91a726a09d2', commit_message='Upload WhisperForConditionalGeneration', commit_description='', oid='ca430c0f0429e8cbc8a4f5ac89e6b91a726a09d2', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.push_to_hub('finetune-whisper-base-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/finetune-whisper-base-ms-singlish-v2/commit/4b42864d5296e10a5045e701e05df9c20e841272', commit_message='Upload feature extractor', commit_description='', oid='4b42864d5296e10a5045e701e05df9c20e841272', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor.push_to_hub('finetune-whisper-base-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/finetune-whisper-base-ms-singlish-v2/commit/305c61c30c713677c060c3cafef0ad65219a6372', commit_message='Upload tokenizer', commit_description='', oid='305c61c30c713677c060c3cafef0ad65219a6372', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('finetune-whisper-base-ms-singlish-v2', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq, WhisperProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = AutoModelForSpeechSeq2Seq.from_pretrained('ms-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained('ms-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import malaya_speech\n",
    "import json\n",
    "\n",
    "with open('/home/husein/ssd1/speech-bahasa/malay-asr-test.json') as fopen:\n",
    "    test_set = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = [malaya_speech.load(f)[0] for f in test_set['X'][:3] + ['singlish0.wav', 'husein-zolkepli.wav']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 80, 3000])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_features = processor(ys, return_tensors=\"pt\").input_features\n",
    "input_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibantu daripada otak saraf puncang dan saraf optik',\n",
       " 'jimnas tik as dan joash mempunyai matlamat yang sama menjadikan sukan jimnas tik dan lain lain selamat pagi para atlet untuk mengejar impian mereka dalam persekitaran yang selamat positif dan berdaya maju',\n",
       " 'and then see how they roll it and film okay actually',\n",
       " 'testing nama saya hussein bin also kipli']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = new_model.generate(input_features, max_length = 256)\n",
    "processor.tokenizer.batch_decode(o, skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'ms ialah penyakit yang mempengaruhi sistem saraf pusat yang dibentuk daripada otak saraf tunjang dan saraf optik',\n",
       " 'gimnastik as dan joas mempunyai matlamat yang sama menjadikan sukan gimnastik dan lain lain selamat bagi para atlet untuk mengejar impian mereka dalam persekitaran yang selamat positif dan berdaya maju']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Y'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saya syafiqah hidayu',\n",
       " 'sebut perkataan uncle',\n",
       " 'testing nama saya hussein bin also kipli',\n",
       " 'takkan orang yang seperti abang pakar itu mahu juga dia menjaganya baik baik orang yang tidak bertimbang rasa tu',\n",
       " 'sebagai pembangkang yang matang dan sejahtera pas akan menghadapi pilihan raya umum dan tidak menumbang kerajaan dari pintu belakang',\n",
       " 'pengadu caraan adalah suatu kaedah memberi arahan atau perintah kepada komputer untuk menjalankan sesuatu juga atau mana mana mesin elektronik',\n",
       " 'tolong sebut antikata',\n",
       " 'apa khabar semua saya doakan saudara dan saudari sihat walafiat hari ini saya sekali lagi menemui saudara']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "files = glob('speech/example-speaker/*.wav')\n",
    "ys = [malaya_speech.load(f)[0] for f in files]\n",
    "input_features = processor(ys, sampling_rate = 16000, return_tensors=\"pt\").input_features\n",
    "o = new_model.generate(input_features, max_length = 256)\n",
    "processor.tokenizer.batch_decode(o, skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# mels = []\n",
    "# inputs = ys\n",
    "# for k in range(len(inputs)):\n",
    "#     audio = whisper.pad_or_trim(inputs[k].astype(np.float32).flatten())\n",
    "#     mel = whisper.log_mel_spectrogram(audio)\n",
    "#     mels.append({'input_features': mel})\n",
    "    \n",
    "# batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "# batch.input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = new_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 370/370 [01:02<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "wer, cer = [], []\n",
    "\n",
    "batch_size = 2\n",
    "for i in tqdm(range(0, len(test_set['X']), batch_size)):\n",
    "    batch_y = test_set['Y'][i: i + batch_size]\n",
    "    ys = [malaya_speech.load(f)[0] for f in test_set['X'][i: i + batch_size]]\n",
    "    mels = []\n",
    "    for k in range(len(ys)):\n",
    "        audio = whisper.pad_or_trim(ys[k].astype(np.float32))\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        mels.append({'input_features': mel})\n",
    "\n",
    "    batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "    input_features = batch.input_features\n",
    "    o = new_model.generate(input_features.cuda(), max_length = 256)\n",
    "    pred = processor.tokenizer.batch_decode(o, skip_special_tokens = True)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1892628902256146, 0.07414237301735345)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('postprocess-malaya-malay-test-set.json') as fopen:\n",
    "    malaya_malay = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 765/765 [00:33<00:00, 23.02it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(malaya_malay))):\n",
    "    if not malaya_malay[i]['accept']:\n",
    "        continue\n",
    "    \n",
    "    batch_y = [malaya_malay[i]['cleaned']]\n",
    "    ys = [malaya_speech.load(f)[0] for f in [f'malay-test/{i}.wav']]\n",
    "    mels = []\n",
    "    for k in range(len(ys)):\n",
    "        audio = whisper.pad_or_trim(ys[k].astype(np.float32))\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        mels.append({'input_features': mel})\n",
    "\n",
    "    batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "    input_features = batch.input_features\n",
    "    o = new_model.generate(input_features.cuda(), max_length = 256)\n",
    "    pred = processor.tokenizer.batch_decode(o, skip_special_tokens = True)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1789545288557146, 0.06458568742050953)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('singlish-test.json') as fopen:\n",
    "    singlish = json.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3579/3579 [02:33<00:00, 23.30it/s]\n"
     ]
    }
   ],
   "source": [
    "wer, cer = [], []\n",
    "\n",
    "for i in tqdm(range(len(singlish))):\n",
    "    \n",
    "    batch_y = [singlish[i]]\n",
    "    ys = [malaya_speech.load(f)[0] for f in [f'singlish-test/{i}.wav']]\n",
    "    mels = []\n",
    "    for k in range(len(ys)):\n",
    "        audio = whisper.pad_or_trim(ys[k].astype(np.float32))\n",
    "        mel = whisper.log_mel_spectrogram(audio)\n",
    "        mels.append({'input_features': mel})\n",
    "\n",
    "    batch = processor.feature_extractor.pad(mels, return_tensors=\"pt\")\n",
    "    input_features = batch.input_features\n",
    "    o = new_model.generate(input_features.cuda(), max_length = 256)\n",
    "    pred = processor.tokenizer.batch_decode(o, skip_special_tokens = True)\n",
    "    \n",
    "    for k in range(len(pred)):\n",
    "        wer.append(calculate_wer(batch_y[k], pred[k]))\n",
    "        cer.append(calculate_cer(batch_y[k], pred[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11699458363762497, 0.06190362020536486)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wer), np.mean(cer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
