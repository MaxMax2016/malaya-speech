{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import HubertConfig, HubertPreTrainedModel, HubertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'Adafactor',\n",
       " 'AdamW',\n",
       " 'AdamWeightDecay',\n",
       " 'AdaptiveEmbedding',\n",
       " 'AddedToken',\n",
       " 'AlbertConfig',\n",
       " 'AlbertForMaskedLM',\n",
       " 'AlbertForMultipleChoice',\n",
       " 'AlbertForPreTraining',\n",
       " 'AlbertForQuestionAnswering',\n",
       " 'AlbertForSequenceClassification',\n",
       " 'AlbertForTokenClassification',\n",
       " 'AlbertModel',\n",
       " 'AlbertPreTrainedModel',\n",
       " 'AlbertTokenizer',\n",
       " 'AlbertTokenizerFast',\n",
       " 'AudioClassificationPipeline',\n",
       " 'AutoConfig',\n",
       " 'AutoFeatureExtractor',\n",
       " 'AutoModel',\n",
       " 'AutoModelForAudioClassification',\n",
       " 'AutoModelForAudioFrameClassification',\n",
       " 'AutoModelForAudioXVector',\n",
       " 'AutoModelForCTC',\n",
       " 'AutoModelForCausalLM',\n",
       " 'AutoModelForImageClassification',\n",
       " 'AutoModelForImageSegmentation',\n",
       " 'AutoModelForInstanceSegmentation',\n",
       " 'AutoModelForMaskedImageModeling',\n",
       " 'AutoModelForMaskedLM',\n",
       " 'AutoModelForMultipleChoice',\n",
       " 'AutoModelForNextSentencePrediction',\n",
       " 'AutoModelForObjectDetection',\n",
       " 'AutoModelForPreTraining',\n",
       " 'AutoModelForQuestionAnswering',\n",
       " 'AutoModelForSemanticSegmentation',\n",
       " 'AutoModelForSeq2SeqLM',\n",
       " 'AutoModelForSequenceClassification',\n",
       " 'AutoModelForSpeechSeq2Seq',\n",
       " 'AutoModelForTableQuestionAnswering',\n",
       " 'AutoModelForTokenClassification',\n",
       " 'AutoModelForVision2Seq',\n",
       " 'AutoModelForVisualQuestionAnswering',\n",
       " 'AutoModelWithLMHead',\n",
       " 'AutoProcessor',\n",
       " 'AutoTokenizer',\n",
       " 'AutomaticSpeechRecognitionPipeline',\n",
       " 'BART_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIGBIRD_PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLENDERBOT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLENDERBOT_SMALL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLOOM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BartConfig',\n",
       " 'BartForCausalLM',\n",
       " 'BartForConditionalGeneration',\n",
       " 'BartForQuestionAnswering',\n",
       " 'BartForSequenceClassification',\n",
       " 'BartModel',\n",
       " 'BartPretrainedModel',\n",
       " 'BartTokenizer',\n",
       " 'BartTokenizerFast',\n",
       " 'BarthezTokenizer',\n",
       " 'BarthezTokenizerFast',\n",
       " 'BartphoTokenizer',\n",
       " 'BasicTokenizer',\n",
       " 'BatchEncoding',\n",
       " 'BatchFeature',\n",
       " 'BeamScorer',\n",
       " 'BeamSearchScorer',\n",
       " 'BeitConfig',\n",
       " 'BeitFeatureExtractor',\n",
       " 'BeitForImageClassification',\n",
       " 'BeitForMaskedImageModeling',\n",
       " 'BeitForSemanticSegmentation',\n",
       " 'BeitModel',\n",
       " 'BeitPreTrainedModel',\n",
       " 'BertConfig',\n",
       " 'BertForMaskedLM',\n",
       " 'BertForMultipleChoice',\n",
       " 'BertForNextSentencePrediction',\n",
       " 'BertForPreTraining',\n",
       " 'BertForQuestionAnswering',\n",
       " 'BertForSequenceClassification',\n",
       " 'BertForTokenClassification',\n",
       " 'BertGenerationConfig',\n",
       " 'BertGenerationDecoder',\n",
       " 'BertGenerationEncoder',\n",
       " 'BertGenerationPreTrainedModel',\n",
       " 'BertGenerationTokenizer',\n",
       " 'BertJapaneseTokenizer',\n",
       " 'BertLMHeadModel',\n",
       " 'BertLayer',\n",
       " 'BertModel',\n",
       " 'BertPreTrainedModel',\n",
       " 'BertTokenizer',\n",
       " 'BertTokenizerFast',\n",
       " 'BertweetTokenizer',\n",
       " 'BigBirdConfig',\n",
       " 'BigBirdForCausalLM',\n",
       " 'BigBirdForMaskedLM',\n",
       " 'BigBirdForMultipleChoice',\n",
       " 'BigBirdForPreTraining',\n",
       " 'BigBirdForQuestionAnswering',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdForTokenClassification',\n",
       " 'BigBirdLayer',\n",
       " 'BigBirdModel',\n",
       " 'BigBirdPegasusConfig',\n",
       " 'BigBirdPegasusForCausalLM',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BigBirdPegasusForQuestionAnswering',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'BigBirdPegasusModel',\n",
       " 'BigBirdPegasusPreTrainedModel',\n",
       " 'BigBirdPreTrainedModel',\n",
       " 'BigBirdTokenizer',\n",
       " 'BigBirdTokenizerFast',\n",
       " 'BlenderbotConfig',\n",
       " 'BlenderbotForCausalLM',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotModel',\n",
       " 'BlenderbotPreTrainedModel',\n",
       " 'BlenderbotSmallConfig',\n",
       " 'BlenderbotSmallForCausalLM',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'BlenderbotSmallModel',\n",
       " 'BlenderbotSmallPreTrainedModel',\n",
       " 'BlenderbotSmallTokenizer',\n",
       " 'BlenderbotSmallTokenizerFast',\n",
       " 'BlenderbotTokenizer',\n",
       " 'BlenderbotTokenizerFast',\n",
       " 'BloomConfig',\n",
       " 'BloomForCausalLM',\n",
       " 'BloomForSequenceClassification',\n",
       " 'BloomForTokenClassification',\n",
       " 'BloomModel',\n",
       " 'BloomPreTrainedModel',\n",
       " 'BloomTokenizerFast',\n",
       " 'ByT5Tokenizer',\n",
       " 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CANINE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CANINE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPConfig',\n",
       " 'CLIPFeatureExtractor',\n",
       " 'CLIPModel',\n",
       " 'CLIPPreTrainedModel',\n",
       " 'CLIPProcessor',\n",
       " 'CLIPTextConfig',\n",
       " 'CLIPTextModel',\n",
       " 'CLIPTokenizer',\n",
       " 'CLIPTokenizerFast',\n",
       " 'CLIPVisionConfig',\n",
       " 'CLIPVisionModel',\n",
       " 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CODEGEN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONFIG_MAPPING',\n",
       " 'CONFIG_NAME',\n",
       " 'CONVBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONVNEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVNEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CTRLConfig',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CTRLLMHeadModel',\n",
       " 'CTRLModel',\n",
       " 'CTRLPreTrainedModel',\n",
       " 'CTRLTokenizer',\n",
       " 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CVT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CVT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CamembertConfig',\n",
       " 'CamembertForCausalLM',\n",
       " 'CamembertForMaskedLM',\n",
       " 'CamembertForMultipleChoice',\n",
       " 'CamembertForQuestionAnswering',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CamembertForTokenClassification',\n",
       " 'CamembertModel',\n",
       " 'CamembertTokenizer',\n",
       " 'CamembertTokenizerFast',\n",
       " 'CanineConfig',\n",
       " 'CanineForMultipleChoice',\n",
       " 'CanineForQuestionAnswering',\n",
       " 'CanineForSequenceClassification',\n",
       " 'CanineForTokenClassification',\n",
       " 'CanineLayer',\n",
       " 'CanineModel',\n",
       " 'CaninePreTrainedModel',\n",
       " 'CanineTokenizer',\n",
       " 'CharSpan',\n",
       " 'CharacterTokenizer',\n",
       " 'CodeGenConfig',\n",
       " 'CodeGenForCausalLM',\n",
       " 'CodeGenModel',\n",
       " 'CodeGenPreTrainedModel',\n",
       " 'CodeGenTokenizer',\n",
       " 'CodeGenTokenizerFast',\n",
       " 'ConstrainedBeamSearchScorer',\n",
       " 'Constraint',\n",
       " 'ConstraintListState',\n",
       " 'Conv1D',\n",
       " 'ConvBertConfig',\n",
       " 'ConvBertForMaskedLM',\n",
       " 'ConvBertForMultipleChoice',\n",
       " 'ConvBertForQuestionAnswering',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'ConvBertForTokenClassification',\n",
       " 'ConvBertLayer',\n",
       " 'ConvBertModel',\n",
       " 'ConvBertPreTrainedModel',\n",
       " 'ConvBertTokenizer',\n",
       " 'ConvBertTokenizerFast',\n",
       " 'ConvNextConfig',\n",
       " 'ConvNextFeatureExtractor',\n",
       " 'ConvNextForImageClassification',\n",
       " 'ConvNextModel',\n",
       " 'ConvNextPreTrainedModel',\n",
       " 'Conversation',\n",
       " 'ConversationalPipeline',\n",
       " 'CpmTokenizer',\n",
       " 'CpmTokenizerFast',\n",
       " 'CsvPipelineDataFormat',\n",
       " 'CvtConfig',\n",
       " 'CvtForImageClassification',\n",
       " 'CvtModel',\n",
       " 'CvtPreTrainedModel',\n",
       " 'DATA2VEC_AUDIO_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DATA2VEC_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DATA2VEC_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DATA2VEC_VISION_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DATA2VEC_VISION_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEBERTA_V2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DECISION_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DECISION_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPRConfig',\n",
       " 'DPRContextEncoder',\n",
       " 'DPRContextEncoderTokenizer',\n",
       " 'DPRContextEncoderTokenizerFast',\n",
       " 'DPRPreTrainedModel',\n",
       " 'DPRPretrainedContextEncoder',\n",
       " 'DPRPretrainedQuestionEncoder',\n",
       " 'DPRPretrainedReader',\n",
       " 'DPRQuestionEncoder',\n",
       " 'DPRQuestionEncoderTokenizer',\n",
       " 'DPRQuestionEncoderTokenizerFast',\n",
       " 'DPRReader',\n",
       " 'DPRReaderOutput',\n",
       " 'DPRReaderTokenizer',\n",
       " 'DPRReaderTokenizerFast',\n",
       " 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPTConfig',\n",
       " 'DPTFeatureExtractor',\n",
       " 'DPTForDepthEstimation',\n",
       " 'DPTForSemanticSegmentation',\n",
       " 'DPTModel',\n",
       " 'DPTPreTrainedModel',\n",
       " 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'Data2VecAudioConfig',\n",
       " 'Data2VecAudioForAudioFrameClassification',\n",
       " 'Data2VecAudioForCTC',\n",
       " 'Data2VecAudioForSequenceClassification',\n",
       " 'Data2VecAudioForXVector',\n",
       " 'Data2VecAudioModel',\n",
       " 'Data2VecAudioPreTrainedModel',\n",
       " 'Data2VecTextConfig',\n",
       " 'Data2VecTextForCausalLM',\n",
       " 'Data2VecTextForMaskedLM',\n",
       " 'Data2VecTextForMultipleChoice',\n",
       " 'Data2VecTextForQuestionAnswering',\n",
       " 'Data2VecTextForSequenceClassification',\n",
       " 'Data2VecTextForTokenClassification',\n",
       " 'Data2VecTextModel',\n",
       " 'Data2VecTextPreTrainedModel',\n",
       " 'Data2VecVisionConfig',\n",
       " 'Data2VecVisionForImageClassification',\n",
       " 'Data2VecVisionForSemanticSegmentation',\n",
       " 'Data2VecVisionModel',\n",
       " 'Data2VecVisionPreTrainedModel',\n",
       " 'DataCollator',\n",
       " 'DataCollatorForLanguageModeling',\n",
       " 'DataCollatorForPermutationLanguageModeling',\n",
       " 'DataCollatorForSOP',\n",
       " 'DataCollatorForSeq2Seq',\n",
       " 'DataCollatorForTokenClassification',\n",
       " 'DataCollatorForWholeWordMask',\n",
       " 'DataCollatorWithPadding',\n",
       " 'DataProcessor',\n",
       " 'DebertaConfig',\n",
       " 'DebertaForMaskedLM',\n",
       " 'DebertaForQuestionAnswering',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaForTokenClassification',\n",
       " 'DebertaModel',\n",
       " 'DebertaPreTrainedModel',\n",
       " 'DebertaTokenizer',\n",
       " 'DebertaTokenizerFast',\n",
       " 'DebertaV2Config',\n",
       " 'DebertaV2ForMaskedLM',\n",
       " 'DebertaV2ForMultipleChoice',\n",
       " 'DebertaV2ForQuestionAnswering',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DebertaV2Model',\n",
       " 'DebertaV2PreTrainedModel',\n",
       " 'DebertaV2Tokenizer',\n",
       " 'DebertaV2TokenizerFast',\n",
       " 'DecisionTransformerConfig',\n",
       " 'DecisionTransformerGPT2Model',\n",
       " 'DecisionTransformerGPT2PreTrainedModel',\n",
       " 'DecisionTransformerModel',\n",
       " 'DecisionTransformerPreTrainedModel',\n",
       " 'DefaultDataCollator',\n",
       " 'DefaultFlowCallback',\n",
       " 'DeiTConfig',\n",
       " 'DeiTFeatureExtractor',\n",
       " 'DeiTForImageClassification',\n",
       " 'DeiTForImageClassificationWithTeacher',\n",
       " 'DeiTForMaskedImageModeling',\n",
       " 'DeiTModel',\n",
       " 'DeiTPreTrainedModel',\n",
       " 'DetrConfig',\n",
       " 'DetrFeatureExtractor',\n",
       " 'DetrForObjectDetection',\n",
       " 'DetrForSegmentation',\n",
       " 'DetrModel',\n",
       " 'DisjunctiveConstraint',\n",
       " 'DistilBertConfig',\n",
       " 'DistilBertForMaskedLM',\n",
       " 'DistilBertForMultipleChoice',\n",
       " 'DistilBertForQuestionAnswering',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'DistilBertForTokenClassification',\n",
       " 'DistilBertModel',\n",
       " 'DistilBertPreTrainedModel',\n",
       " 'DistilBertTokenizer',\n",
       " 'DistilBertTokenizerFast',\n",
       " 'DummyObject',\n",
       " 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'EarlyStoppingCallback',\n",
       " 'ElectraConfig',\n",
       " 'ElectraForCausalLM',\n",
       " 'ElectraForMaskedLM',\n",
       " 'ElectraForMultipleChoice',\n",
       " 'ElectraForPreTraining',\n",
       " 'ElectraForQuestionAnswering',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'ElectraForTokenClassification',\n",
       " 'ElectraModel',\n",
       " 'ElectraPreTrainedModel',\n",
       " 'ElectraTokenizer',\n",
       " 'ElectraTokenizerFast',\n",
       " 'EncoderDecoderConfig',\n",
       " 'EncoderDecoderModel',\n",
       " 'EvalPrediction',\n",
       " 'FEATURE_EXTRACTOR_MAPPING',\n",
       " 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FLAVA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MASKED_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING',\n",
       " 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_PRETRAINING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_MAPPING',\n",
       " 'FNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FNetConfig',\n",
       " 'FNetForMaskedLM',\n",
       " 'FNetForMultipleChoice',\n",
       " 'FNetForNextSentencePrediction',\n",
       " 'FNetForPreTraining',\n",
       " 'FNetForQuestionAnswering',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FNetForTokenClassification',\n",
       " 'FNetLayer',\n",
       " 'FNetModel',\n",
       " 'FNetPreTrainedModel',\n",
       " 'FNetTokenizer',\n",
       " 'FNetTokenizerFast',\n",
       " 'FSMTConfig',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'FSMTModel',\n",
       " 'FSMTTokenizer',\n",
       " 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FUNNEL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FeatureExtractionMixin',\n",
       " 'FeatureExtractionPipeline',\n",
       " 'FillMaskPipeline',\n",
       " 'FlaubertConfig',\n",
       " 'FlaubertForMultipleChoice',\n",
       " 'FlaubertForQuestionAnswering',\n",
       " 'FlaubertForQuestionAnsweringSimple',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FlaubertForTokenClassification',\n",
       " 'FlaubertModel',\n",
       " 'FlaubertTokenizer',\n",
       " 'FlaubertWithLMHeadModel',\n",
       " 'FlavaConfig',\n",
       " 'FlavaFeatureExtractor',\n",
       " 'FlavaForPreTraining',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageConfig',\n",
       " 'FlavaImageModel',\n",
       " 'FlavaModel',\n",
       " 'FlavaMultimodalConfig',\n",
       " 'FlavaMultimodalModel',\n",
       " 'FlavaPreTrainedModel',\n",
       " 'FlavaProcessor',\n",
       " 'FlavaTextConfig',\n",
       " 'FlavaTextModel',\n",
       " 'FlaxAlbertForMaskedLM',\n",
       " 'FlaxAlbertForMultipleChoice',\n",
       " 'FlaxAlbertForPreTraining',\n",
       " 'FlaxAlbertForQuestionAnswering',\n",
       " 'FlaxAlbertForSequenceClassification',\n",
       " 'FlaxAlbertForTokenClassification',\n",
       " 'FlaxAlbertModel',\n",
       " 'FlaxAlbertPreTrainedModel',\n",
       " 'FlaxAutoModel',\n",
       " 'FlaxAutoModelForCausalLM',\n",
       " 'FlaxAutoModelForImageClassification',\n",
       " 'FlaxAutoModelForMaskedLM',\n",
       " 'FlaxAutoModelForMultipleChoice',\n",
       " 'FlaxAutoModelForNextSentencePrediction',\n",
       " 'FlaxAutoModelForPreTraining',\n",
       " 'FlaxAutoModelForQuestionAnswering',\n",
       " 'FlaxAutoModelForSeq2SeqLM',\n",
       " 'FlaxAutoModelForSequenceClassification',\n",
       " 'FlaxAutoModelForTokenClassification',\n",
       " 'FlaxAutoModelForVision2Seq',\n",
       " 'FlaxBartDecoderPreTrainedModel',\n",
       " 'FlaxBartForCausalLM',\n",
       " 'FlaxBartForConditionalGeneration',\n",
       " 'FlaxBartForQuestionAnswering',\n",
       " 'FlaxBartForSequenceClassification',\n",
       " 'FlaxBartModel',\n",
       " 'FlaxBartPreTrainedModel',\n",
       " 'FlaxBeitForImageClassification',\n",
       " 'FlaxBeitForMaskedImageModeling',\n",
       " 'FlaxBeitModel',\n",
       " 'FlaxBeitPreTrainedModel',\n",
       " 'FlaxBertForCausalLM',\n",
       " 'FlaxBertForMaskedLM',\n",
       " 'FlaxBertForMultipleChoice',\n",
       " 'FlaxBertForNextSentencePrediction',\n",
       " 'FlaxBertForPreTraining',\n",
       " 'FlaxBertForQuestionAnswering',\n",
       " 'FlaxBertForSequenceClassification',\n",
       " 'FlaxBertForTokenClassification',\n",
       " 'FlaxBertModel',\n",
       " 'FlaxBertPreTrainedModel',\n",
       " 'FlaxBigBirdForCausalLM',\n",
       " 'FlaxBigBirdForMaskedLM',\n",
       " 'FlaxBigBirdForMultipleChoice',\n",
       " 'FlaxBigBirdForPreTraining',\n",
       " 'FlaxBigBirdForQuestionAnswering',\n",
       " 'FlaxBigBirdForSequenceClassification',\n",
       " 'FlaxBigBirdForTokenClassification',\n",
       " 'FlaxBigBirdModel',\n",
       " 'FlaxBigBirdPreTrainedModel',\n",
       " 'FlaxBlenderbotForConditionalGeneration',\n",
       " 'FlaxBlenderbotModel',\n",
       " 'FlaxBlenderbotPreTrainedModel',\n",
       " 'FlaxBlenderbotSmallForConditionalGeneration',\n",
       " 'FlaxBlenderbotSmallModel',\n",
       " 'FlaxBlenderbotSmallPreTrainedModel',\n",
       " 'FlaxCLIPModel',\n",
       " 'FlaxCLIPPreTrainedModel',\n",
       " 'FlaxCLIPTextModel',\n",
       " 'FlaxCLIPTextPreTrainedModel',\n",
       " 'FlaxCLIPVisionModel',\n",
       " 'FlaxCLIPVisionPreTrainedModel',\n",
       " 'FlaxDistilBertForMaskedLM',\n",
       " 'FlaxDistilBertForMultipleChoice',\n",
       " 'FlaxDistilBertForQuestionAnswering',\n",
       " 'FlaxDistilBertForSequenceClassification',\n",
       " 'FlaxDistilBertForTokenClassification',\n",
       " 'FlaxDistilBertModel',\n",
       " 'FlaxDistilBertPreTrainedModel',\n",
       " 'FlaxElectraForCausalLM',\n",
       " 'FlaxElectraForMaskedLM',\n",
       " 'FlaxElectraForMultipleChoice',\n",
       " 'FlaxElectraForPreTraining',\n",
       " 'FlaxElectraForQuestionAnswering',\n",
       " 'FlaxElectraForSequenceClassification',\n",
       " 'FlaxElectraForTokenClassification',\n",
       " 'FlaxElectraModel',\n",
       " 'FlaxElectraPreTrainedModel',\n",
       " 'FlaxEncoderDecoderModel',\n",
       " 'FlaxForcedBOSTokenLogitsProcessor',\n",
       " 'FlaxForcedEOSTokenLogitsProcessor',\n",
       " 'FlaxGPT2LMHeadModel',\n",
       " 'FlaxGPT2Model',\n",
       " 'FlaxGPT2PreTrainedModel',\n",
       " 'FlaxGPTJForCausalLM',\n",
       " 'FlaxGPTJModel',\n",
       " 'FlaxGPTJPreTrainedModel',\n",
       " 'FlaxGPTNeoForCausalLM',\n",
       " 'FlaxGPTNeoModel',\n",
       " 'FlaxGPTNeoPreTrainedModel',\n",
       " 'FlaxLogitsProcessor',\n",
       " 'FlaxLogitsProcessorList',\n",
       " 'FlaxLogitsWarper',\n",
       " 'FlaxLongT5ForConditionalGeneration',\n",
       " 'FlaxLongT5Model',\n",
       " 'FlaxLongT5PreTrainedModel',\n",
       " 'FlaxMBartForConditionalGeneration',\n",
       " 'FlaxMBartForQuestionAnswering',\n",
       " 'FlaxMBartForSequenceClassification',\n",
       " 'FlaxMBartModel',\n",
       " 'FlaxMBartPreTrainedModel',\n",
       " 'FlaxMT5EncoderModel',\n",
       " 'FlaxMT5ForConditionalGeneration',\n",
       " 'FlaxMT5Model',\n",
       " 'FlaxMarianMTModel',\n",
       " 'FlaxMarianModel',\n",
       " 'FlaxMarianPreTrainedModel',\n",
       " 'FlaxMinLengthLogitsProcessor',\n",
       " 'FlaxOPTForCausalLM',\n",
       " 'FlaxOPTModel',\n",
       " 'FlaxOPTPreTrainedModel',\n",
       " 'FlaxPegasusForConditionalGeneration',\n",
       " 'FlaxPegasusModel',\n",
       " 'FlaxPegasusPreTrainedModel',\n",
       " 'FlaxPreTrainedModel',\n",
       " 'FlaxRoFormerForMaskedLM',\n",
       " 'FlaxRoFormerForMultipleChoice',\n",
       " 'FlaxRoFormerForQuestionAnswering',\n",
       " 'FlaxRoFormerForSequenceClassification',\n",
       " 'FlaxRoFormerForTokenClassification',\n",
       " 'FlaxRoFormerModel',\n",
       " 'FlaxRoFormerPreTrainedModel',\n",
       " 'FlaxRobertaForCausalLM',\n",
       " 'FlaxRobertaForMaskedLM',\n",
       " 'FlaxRobertaForMultipleChoice',\n",
       " 'FlaxRobertaForQuestionAnswering',\n",
       " 'FlaxRobertaForSequenceClassification',\n",
       " 'FlaxRobertaForTokenClassification',\n",
       " 'FlaxRobertaModel',\n",
       " 'FlaxRobertaPreTrainedModel',\n",
       " 'FlaxSpeechEncoderDecoderModel',\n",
       " 'FlaxT5EncoderModel',\n",
       " 'FlaxT5ForConditionalGeneration',\n",
       " 'FlaxT5Model',\n",
       " 'FlaxT5PreTrainedModel',\n",
       " 'FlaxTemperatureLogitsWarper',\n",
       " 'FlaxTopKLogitsWarper',\n",
       " 'FlaxTopPLogitsWarper',\n",
       " 'FlaxViTForImageClassification',\n",
       " 'FlaxViTModel',\n",
       " 'FlaxViTPreTrainedModel',\n",
       " 'FlaxVisionEncoderDecoderModel',\n",
       " 'FlaxVisionTextDualEncoderModel',\n",
       " 'FlaxWav2Vec2ForCTC',\n",
       " 'FlaxWav2Vec2ForPreTraining',\n",
       " 'FlaxWav2Vec2Model',\n",
       " 'FlaxWav2Vec2PreTrainedModel',\n",
       " 'FlaxXGLMForCausalLM',\n",
       " 'FlaxXGLMModel',\n",
       " 'FlaxXGLMPreTrainedModel',\n",
       " 'FlaxXLMRobertaForMaskedLM',\n",
       " 'FlaxXLMRobertaForMultipleChoice',\n",
       " 'FlaxXLMRobertaForQuestionAnswering',\n",
       " 'FlaxXLMRobertaForSequenceClassification',\n",
       " 'FlaxXLMRobertaForTokenClassification',\n",
       " 'FlaxXLMRobertaModel',\n",
       " 'ForcedBOSTokenLogitsProcessor',\n",
       " 'ForcedEOSTokenLogitsProcessor',\n",
       " 'FunnelBaseModel',\n",
       " 'FunnelConfig',\n",
       " 'FunnelForMaskedLM',\n",
       " 'FunnelForMultipleChoice',\n",
       " 'FunnelForPreTraining',\n",
       " 'FunnelForQuestionAnswering',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'FunnelForTokenClassification',\n",
       " 'FunnelModel',\n",
       " 'FunnelPreTrainedModel',\n",
       " 'FunnelTokenizer',\n",
       " 'FunnelTokenizerFast',\n",
       " 'GLPNConfig',\n",
       " 'GLPNFeatureExtractor',\n",
       " 'GLPNForDepthEstimation',\n",
       " 'GLPNModel',\n",
       " 'GLPNPreTrainedModel',\n",
       " 'GLPN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GLPN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT2Config',\n",
       " 'GPT2DoubleHeadsModel',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPT2ForTokenClassification',\n",
       " 'GPT2LMHeadModel',\n",
       " 'GPT2Model',\n",
       " 'GPT2PreTrainedModel',\n",
       " 'GPT2Tokenizer',\n",
       " 'GPT2TokenizerFast',\n",
       " 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTJConfig',\n",
       " 'GPTJForCausalLM',\n",
       " 'GPTJForQuestionAnswering',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTJModel',\n",
       " 'GPTJPreTrainedModel',\n",
       " 'GPTJ_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPTJ_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTNeoConfig',\n",
       " 'GPTNeoForCausalLM',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'GPTNeoModel',\n",
       " 'GPTNeoPreTrainedModel',\n",
       " 'GPTNeoXConfig',\n",
       " 'GPTNeoXForCausalLM',\n",
       " 'GPTNeoXLayer',\n",
       " 'GPTNeoXModel',\n",
       " 'GPTNeoXPreTrainedModel',\n",
       " 'GPTNeoXTokenizerFast',\n",
       " 'GPT_NEOX_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT_NEOX_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT_NEO_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT_NEO_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GROUPVIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GlueDataTrainingArguments',\n",
       " 'GlueDataset',\n",
       " 'GradientAccumulator',\n",
       " 'GroupViTConfig',\n",
       " 'GroupViTModel',\n",
       " 'GroupViTPreTrainedModel',\n",
       " 'GroupViTTextConfig',\n",
       " 'GroupViTTextModel',\n",
       " 'GroupViTVisionConfig',\n",
       " 'GroupViTVisionModel',\n",
       " 'HUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'HUBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'HammingDiversityLogitsProcessor',\n",
       " 'HerbertTokenizer',\n",
       " 'HerbertTokenizerFast',\n",
       " 'HfArgumentParser',\n",
       " 'HubertConfig',\n",
       " 'HubertForCTC',\n",
       " 'HubertForSequenceClassification',\n",
       " 'HubertModel',\n",
       " 'HubertPreTrainedModel',\n",
       " 'IBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'IBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'IBertConfig',\n",
       " 'IBertForMaskedLM',\n",
       " 'IBertForMultipleChoice',\n",
       " 'IBertForQuestionAnswering',\n",
       " 'IBertForSequenceClassification',\n",
       " 'IBertForTokenClassification',\n",
       " 'IBertModel',\n",
       " 'IBertPreTrainedModel',\n",
       " 'IMAGEGPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'IMAGEGPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ImageClassificationPipeline',\n",
       " 'ImageFeatureExtractionMixin',\n",
       " 'ImageGPTConfig',\n",
       " 'ImageGPTFeatureExtractor',\n",
       " 'ImageGPTForCausalImageModeling',\n",
       " 'ImageGPTForImageClassification',\n",
       " 'ImageGPTModel',\n",
       " 'ImageGPTPreTrainedModel',\n",
       " 'ImageSegmentationPipeline',\n",
       " 'InfNanRemoveLogitsProcessor',\n",
       " 'InputExample',\n",
       " 'InputFeatures',\n",
       " 'IntervalStrategy',\n",
       " 'JsonPipelineDataFormat',\n",
       " 'KerasMetricCallback',\n",
       " 'LAYOUTLMV2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LAYOUTLMV2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LAYOUTLMV3_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LAYOUTLMV3_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LAYOUTLM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LAYOUTLM_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LEDConfig',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'LEDForQuestionAnswering',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LEDModel',\n",
       " 'LEDPreTrainedModel',\n",
       " 'LEDTokenizer',\n",
       " 'LEDTokenizerFast',\n",
       " 'LED_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LED_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LEVIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LEVIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LONGFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LONGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LONGT5_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LONGT5_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LUKE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LUKE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LXMERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LayoutLMConfig',\n",
       " 'LayoutLMForMaskedLM',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMForTokenClassification',\n",
       " 'LayoutLMModel',\n",
       " 'LayoutLMPreTrainedModel',\n",
       " 'LayoutLMTokenizer',\n",
       " 'LayoutLMTokenizerFast',\n",
       " 'LayoutLMv2Config',\n",
       " 'LayoutLMv2FeatureExtractor',\n",
       " 'LayoutLMv2ForQuestionAnswering',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LayoutLMv2ForTokenClassification',\n",
       " 'LayoutLMv2Model',\n",
       " 'LayoutLMv2PreTrainedModel',\n",
       " 'LayoutLMv2Processor',\n",
       " 'LayoutLMv2Tokenizer',\n",
       " 'LayoutLMv2TokenizerFast',\n",
       " 'LayoutLMv3Config',\n",
       " 'LayoutLMv3FeatureExtractor',\n",
       " 'LayoutLMv3ForQuestionAnswering',\n",
       " 'LayoutLMv3ForSequenceClassification',\n",
       " 'LayoutLMv3ForTokenClassification',\n",
       " 'LayoutLMv3Model',\n",
       " 'LayoutLMv3PreTrainedModel',\n",
       " 'LayoutLMv3Processor',\n",
       " 'LayoutLMv3Tokenizer',\n",
       " 'LayoutLMv3TokenizerFast',\n",
       " 'LayoutXLMProcessor',\n",
       " 'LayoutXLMTokenizer',\n",
       " 'LayoutXLMTokenizerFast',\n",
       " 'LevitConfig',\n",
       " 'LevitFeatureExtractor',\n",
       " 'LevitForImageClassification',\n",
       " 'LevitForImageClassificationWithTeacher',\n",
       " 'LevitModel',\n",
       " 'LevitPreTrainedModel',\n",
       " 'LineByLineTextDataset',\n",
       " 'LineByLineWithRefDataset',\n",
       " 'LineByLineWithSOPTextDataset',\n",
       " 'LogitsProcessor',\n",
       " 'LogitsProcessorList',\n",
       " 'LogitsWarper',\n",
       " 'LongT5Config',\n",
       " 'LongT5EncoderModel',\n",
       " 'LongT5ForConditionalGeneration',\n",
       " 'LongT5Model',\n",
       " 'LongT5PreTrainedModel',\n",
       " 'LongformerConfig',\n",
       " 'LongformerForMaskedLM',\n",
       " 'LongformerForMultipleChoice',\n",
       " 'LongformerForQuestionAnswering',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'LongformerForTokenClassification',\n",
       " 'LongformerModel',\n",
       " 'LongformerPreTrainedModel',\n",
       " 'LongformerSelfAttention',\n",
       " 'LongformerTokenizer',\n",
       " 'LongformerTokenizerFast',\n",
       " 'LukeConfig',\n",
       " 'LukeForEntityClassification',\n",
       " 'LukeForEntityPairClassification',\n",
       " 'LukeForEntitySpanClassification',\n",
       " 'LukeForMaskedLM',\n",
       " 'LukeModel',\n",
       " 'LukePreTrainedModel',\n",
       " 'LukeTokenizer',\n",
       " 'LxmertConfig',\n",
       " 'LxmertEncoder',\n",
       " 'LxmertForPreTraining',\n",
       " 'LxmertForQuestionAnswering',\n",
       " 'LxmertModel',\n",
       " 'LxmertPreTrainedModel',\n",
       " 'LxmertTokenizer',\n",
       " 'LxmertTokenizerFast',\n",
       " 'LxmertVisualFeatureEncoder',\n",
       " 'LxmertXLayer',\n",
       " 'M2M100Config',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'M2M100Model',\n",
       " 'M2M100PreTrainedModel',\n",
       " 'M2M100Tokenizer',\n",
       " 'M2M_100_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'M2M_100_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MASKFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MASKFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MBart50Tokenizer',\n",
       " 'MBart50TokenizerFast',\n",
       " 'MBartConfig',\n",
       " 'MBartForCausalLM',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MBartForQuestionAnswering',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MBartModel',\n",
       " 'MBartPreTrainedModel',\n",
       " 'MBartTokenizer',\n",
       " 'MBartTokenizerFast',\n",
       " 'MCTCTConfig',\n",
       " 'MCTCTFeatureExtractor',\n",
       " 'MCTCTForCTC',\n",
       " 'MCTCTModel',\n",
       " 'MCTCTPreTrainedModel',\n",
       " 'MCTCTProcessor',\n",
       " 'MCTCT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MCTCT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MEGATRON_BERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MEGATRON_BERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MLukeTokenizer',\n",
       " 'MMBTConfig',\n",
       " 'MMBTForClassification',\n",
       " 'MMBTModel',\n",
       " 'MOBILEBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MOBILEBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MOBILEVIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MOBILEVIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MODEL_CARD_NAME',\n",
       " 'MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING',\n",
       " 'MODEL_FOR_AUDIO_XVECTOR_MAPPING',\n",
       " 'MODEL_FOR_CAUSAL_IMAGE_MODELING_MAPPING',\n",
       " 'MODEL_FOR_CAUSAL_LM_MAPPING',\n",
       " 'MODEL_FOR_CTC_MAPPING',\n",
       " 'MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING',\n",
       " 'MODEL_FOR_IMAGE_SEGMENTATION_MAPPING',\n",
       " 'MODEL_FOR_INSTANCE_SEGMENTATION_MAPPING',\n",
       " 'MODEL_FOR_MASKED_IMAGE_MODELING_MAPPING',\n",
       " 'MODEL_FOR_MASKED_LM_MAPPING',\n",
       " 'MODEL_FOR_MULTIPLE_CHOICE_MAPPING',\n",
       " 'MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING',\n",
       " 'MODEL_FOR_OBJECT_DETECTION_MAPPING',\n",
       " 'MODEL_FOR_PRETRAINING_MAPPING',\n",
       " 'MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
       " 'MODEL_FOR_SEMANTIC_SEGMENTATION_MAPPING',\n",
       " 'MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
       " 'MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING',\n",
       " 'MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING',\n",
       " 'MODEL_FOR_TABLE_QUESTION_ANSWERING_MAPPING',\n",
       " 'MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
       " 'MODEL_FOR_VISION_2_SEQ_MAPPING',\n",
       " 'MODEL_FOR_VISUAL_QUESTION_ANSWERING_MAPPING',\n",
       " 'MODEL_MAPPING',\n",
       " 'MODEL_NAMES_MAPPING',\n",
       " 'MODEL_WITH_LM_HEAD_MAPPING',\n",
       " 'MPNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MPNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MPNetConfig',\n",
       " 'MPNetForMaskedLM',\n",
       " 'MPNetForMultipleChoice',\n",
       " 'MPNetForQuestionAnswering',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MPNetForTokenClassification',\n",
       " 'MPNetLayer',\n",
       " 'MPNetModel',\n",
       " 'MPNetPreTrainedModel',\n",
       " 'MPNetTokenizer',\n",
       " 'MPNetTokenizerFast',\n",
       " 'MT5Config',\n",
       " 'MT5EncoderModel',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'MT5Model',\n",
       " 'MT5Tokenizer',\n",
       " 'MT5TokenizerFast',\n",
       " 'MVP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MarianConfig',\n",
       " 'MarianForCausalLM',\n",
       " 'MarianMTModel',\n",
       " 'MarianModel',\n",
       " 'MarianTokenizer',\n",
       " 'MaskFormerConfig',\n",
       " 'MaskFormerFeatureExtractor',\n",
       " 'MaskFormerForInstanceSegmentation',\n",
       " 'MaskFormerModel',\n",
       " 'MaskFormerPreTrainedModel',\n",
       " 'MaxLengthCriteria',\n",
       " 'MaxTimeCriteria',\n",
       " 'MecabTokenizer',\n",
       " 'MegatronBertConfig',\n",
       " 'MegatronBertForCausalLM',\n",
       " 'MegatronBertForMaskedLM',\n",
       " 'MegatronBertForMultipleChoice',\n",
       " 'MegatronBertForNextSentencePrediction',\n",
       " 'MegatronBertForPreTraining',\n",
       " 'MegatronBertForQuestionAnswering',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MegatronBertForTokenClassification',\n",
       " 'MegatronBertModel',\n",
       " 'MegatronBertPreTrainedModel',\n",
       " 'MinLengthLogitsProcessor',\n",
       " 'MobileBertConfig',\n",
       " 'MobileBertForMaskedLM',\n",
       " 'MobileBertForMultipleChoice',\n",
       " 'MobileBertForNextSentencePrediction',\n",
       " 'MobileBertForPreTraining',\n",
       " 'MobileBertForQuestionAnswering',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'MobileBertForTokenClassification',\n",
       " 'MobileBertLayer',\n",
       " 'MobileBertModel',\n",
       " 'MobileBertPreTrainedModel',\n",
       " 'MobileBertTokenizer',\n",
       " 'MobileBertTokenizerFast',\n",
       " 'MobileViTConfig',\n",
       " 'MobileViTFeatureExtractor',\n",
       " 'MobileViTForImageClassification',\n",
       " 'MobileViTForSemanticSegmentation',\n",
       " 'MobileViTModel',\n",
       " 'MobileViTPreTrainedModel',\n",
       " 'ModalEmbeddings',\n",
       " 'ModelCard',\n",
       " 'MvpConfig',\n",
       " 'MvpForCausalLM',\n",
       " 'MvpForConditionalGeneration',\n",
       " 'MvpForQuestionAnswering',\n",
       " 'MvpForSequenceClassification',\n",
       " 'MvpModel',\n",
       " 'MvpPreTrainedModel',\n",
       " 'MvpTokenizer',\n",
       " 'MvpTokenizerFast',\n",
       " 'NEZHA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'NEZHA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'NYSTROMFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'NYSTROMFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'NerPipeline',\n",
       " 'NezhaConfig',\n",
       " 'NezhaForMaskedLM',\n",
       " 'NezhaForMultipleChoice',\n",
       " 'NezhaForNextSentencePrediction',\n",
       " 'NezhaForPreTraining',\n",
       " 'NezhaForQuestionAnswering',\n",
       " 'NezhaForSequenceClassification',\n",
       " 'NezhaForTokenClassification',\n",
       " 'NezhaModel',\n",
       " 'NezhaPreTrainedModel',\n",
       " 'NllbTokenizer',\n",
       " 'NllbTokenizerFast',\n",
       " 'NoBadWordsLogitsProcessor',\n",
       " 'NoRepeatNGramLogitsProcessor',\n",
       " 'NystromformerConfig',\n",
       " 'NystromformerForMaskedLM',\n",
       " 'NystromformerForMultipleChoice',\n",
       " 'NystromformerForQuestionAnswering',\n",
       " 'NystromformerForSequenceClassification',\n",
       " 'NystromformerForTokenClassification',\n",
       " 'NystromformerLayer',\n",
       " 'NystromformerModel',\n",
       " 'NystromformerPreTrainedModel',\n",
       " 'OPENAI_GPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'OPTConfig',\n",
       " 'OPTForCausalLM',\n",
       " 'OPTForSequenceClassification',\n",
       " 'OPTModel',\n",
       " 'OPTPreTrainedModel',\n",
       " 'OPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'OWLVIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'OWLVIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ObjectDetectionPipeline',\n",
       " 'OpenAIGPTConfig',\n",
       " 'OpenAIGPTDoubleHeadsModel',\n",
       " 'OpenAIGPTForSequenceClassification',\n",
       " 'OpenAIGPTLMHeadModel',\n",
       " 'OpenAIGPTModel',\n",
       " 'OpenAIGPTPreTrainedModel',\n",
       " 'OpenAIGPTTokenizer',\n",
       " 'OpenAIGPTTokenizerFast',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "dir(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95d9e15d5f9460bb7d77975a8c31745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = HubertConfig.from_pretrained('facebook/hubert-base-ls960')\n",
    "config.save_pretrained('./hubert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_6_720000.pt\t\tcheckpoint_best.pt\r\n",
      "checkpoint.best_loss_7.0482.pt\tcheckpoint_last.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/husein/None/checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = '/home/husein/None/checkpoints/checkpoint_6_720000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading configuration file hubert-base/config.json\n",
      "Model config HubertConfig {\n",
      "  \"_name_or_path\": \"facebook/hubert-base-ls960\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"HubertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"conv_bias\": false,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"sum\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"do_stable_layer_norm\": false,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"group\",\n",
      "  \"feat_proj_dropout\": 0.1,\n",
      "  \"feat_proj_layer_norm\": true,\n",
      "  \"final_dropout\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"model_type\": \"hubert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"tokenizer_class\": \"Wav2Vec2CTCTokenizer\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 32\n",
      "}\n",
      "\n",
      "2022-11-01 15:59:23 | INFO | fairseq.tasks.hubert_pretraining | current directory is /home/husein/dev/malaya-speech\n",
      "2022-11-01 15:59:23 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/home/husein/ssd1/speech-bahasa/wav2vec2-malay', 'fine_tuning': False, 'labels': ['km'], 'label_dir': '/home/husein/ssd1/mfcc-label', 'label_rate': 100.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "2022-11-01 15:59:23 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 100.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\n",
      "2022-11-01 15:59:24 | INFO | __main__ |  was initialized from mask_emb.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 0 was initialized from feature_extractor.conv_layers.0.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract layer norm weight of layer 0 was initialized from feature_extractor.conv_layers.0.2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract layer norm weight of layer 0 was initialized from feature_extractor.conv_layers.0.2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 1 was initialized from feature_extractor.conv_layers.1.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 2 was initialized from feature_extractor.conv_layers.2.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 3 was initialized from feature_extractor.conv_layers.3.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 4 was initialized from feature_extractor.conv_layers.4.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 5 was initialized from feature_extractor.conv_layers.5.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | Feat extract conv layer 6 was initialized from feature_extractor.conv_layers.6.0.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | feature_projection.projection.weight was initialized from post_extract_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | feature_projection.projection.bias was initialized from post_extract_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.pos_conv_embed.conv.bias was initialized from encoder.pos_conv.0.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.pos_conv_embed.conv.weight_g was initialized from encoder.pos_conv.0.weight_g.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.pos_conv_embed.conv.weight_v was initialized from encoder.pos_conv.0.weight_v.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.k_proj.weight was initialized from encoder.layers.0.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.k_proj.bias was initialized from encoder.layers.0.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.v_proj.weight was initialized from encoder.layers.0.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.v_proj.bias was initialized from encoder.layers.0.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.q_proj.weight was initialized from encoder.layers.0.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.q_proj.bias was initialized from encoder.layers.0.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.out_proj.weight was initialized from encoder.layers.0.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.attention.out_proj.bias was initialized from encoder.layers.0.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.layer_norm.weight was initialized from encoder.layers.0.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.layer_norm.bias was initialized from encoder.layers.0.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.feed_forward.intermediate_dense.weight was initialized from encoder.layers.0.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.feed_forward.intermediate_dense.bias was initialized from encoder.layers.0.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.feed_forward.output_dense.weight was initialized from encoder.layers.0.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.feed_forward.output_dense.bias was initialized from encoder.layers.0.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.final_layer_norm.weight was initialized from encoder.layers.0.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.0.final_layer_norm.bias was initialized from encoder.layers.0.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.k_proj.weight was initialized from encoder.layers.1.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.k_proj.bias was initialized from encoder.layers.1.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.v_proj.weight was initialized from encoder.layers.1.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.v_proj.bias was initialized from encoder.layers.1.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.q_proj.weight was initialized from encoder.layers.1.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.q_proj.bias was initialized from encoder.layers.1.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.out_proj.weight was initialized from encoder.layers.1.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.attention.out_proj.bias was initialized from encoder.layers.1.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.layer_norm.weight was initialized from encoder.layers.1.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.layer_norm.bias was initialized from encoder.layers.1.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.feed_forward.intermediate_dense.weight was initialized from encoder.layers.1.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.feed_forward.intermediate_dense.bias was initialized from encoder.layers.1.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.feed_forward.output_dense.weight was initialized from encoder.layers.1.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.feed_forward.output_dense.bias was initialized from encoder.layers.1.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.final_layer_norm.weight was initialized from encoder.layers.1.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.1.final_layer_norm.bias was initialized from encoder.layers.1.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.k_proj.weight was initialized from encoder.layers.2.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.k_proj.bias was initialized from encoder.layers.2.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.v_proj.weight was initialized from encoder.layers.2.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.v_proj.bias was initialized from encoder.layers.2.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.q_proj.weight was initialized from encoder.layers.2.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.q_proj.bias was initialized from encoder.layers.2.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.out_proj.weight was initialized from encoder.layers.2.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.attention.out_proj.bias was initialized from encoder.layers.2.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.layer_norm.weight was initialized from encoder.layers.2.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.layer_norm.bias was initialized from encoder.layers.2.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.feed_forward.intermediate_dense.weight was initialized from encoder.layers.2.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.feed_forward.intermediate_dense.bias was initialized from encoder.layers.2.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.feed_forward.output_dense.weight was initialized from encoder.layers.2.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.feed_forward.output_dense.bias was initialized from encoder.layers.2.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.final_layer_norm.weight was initialized from encoder.layers.2.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.2.final_layer_norm.bias was initialized from encoder.layers.2.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.k_proj.weight was initialized from encoder.layers.3.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.k_proj.bias was initialized from encoder.layers.3.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.v_proj.weight was initialized from encoder.layers.3.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.v_proj.bias was initialized from encoder.layers.3.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.q_proj.weight was initialized from encoder.layers.3.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.q_proj.bias was initialized from encoder.layers.3.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.out_proj.weight was initialized from encoder.layers.3.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.attention.out_proj.bias was initialized from encoder.layers.3.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.layer_norm.weight was initialized from encoder.layers.3.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.layer_norm.bias was initialized from encoder.layers.3.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.feed_forward.intermediate_dense.weight was initialized from encoder.layers.3.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.feed_forward.intermediate_dense.bias was initialized from encoder.layers.3.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.feed_forward.output_dense.weight was initialized from encoder.layers.3.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.feed_forward.output_dense.bias was initialized from encoder.layers.3.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.final_layer_norm.weight was initialized from encoder.layers.3.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.3.final_layer_norm.bias was initialized from encoder.layers.3.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.k_proj.weight was initialized from encoder.layers.4.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.k_proj.bias was initialized from encoder.layers.4.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.v_proj.weight was initialized from encoder.layers.4.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.v_proj.bias was initialized from encoder.layers.4.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.q_proj.weight was initialized from encoder.layers.4.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.q_proj.bias was initialized from encoder.layers.4.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.out_proj.weight was initialized from encoder.layers.4.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.attention.out_proj.bias was initialized from encoder.layers.4.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.layer_norm.weight was initialized from encoder.layers.4.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.layer_norm.bias was initialized from encoder.layers.4.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.feed_forward.intermediate_dense.weight was initialized from encoder.layers.4.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.feed_forward.intermediate_dense.bias was initialized from encoder.layers.4.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.feed_forward.output_dense.weight was initialized from encoder.layers.4.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.feed_forward.output_dense.bias was initialized from encoder.layers.4.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.final_layer_norm.weight was initialized from encoder.layers.4.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.4.final_layer_norm.bias was initialized from encoder.layers.4.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.k_proj.weight was initialized from encoder.layers.5.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.k_proj.bias was initialized from encoder.layers.5.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.v_proj.weight was initialized from encoder.layers.5.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.v_proj.bias was initialized from encoder.layers.5.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.q_proj.weight was initialized from encoder.layers.5.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.q_proj.bias was initialized from encoder.layers.5.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.out_proj.weight was initialized from encoder.layers.5.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.attention.out_proj.bias was initialized from encoder.layers.5.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.layer_norm.weight was initialized from encoder.layers.5.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.layer_norm.bias was initialized from encoder.layers.5.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.feed_forward.intermediate_dense.weight was initialized from encoder.layers.5.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.feed_forward.intermediate_dense.bias was initialized from encoder.layers.5.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.feed_forward.output_dense.weight was initialized from encoder.layers.5.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.feed_forward.output_dense.bias was initialized from encoder.layers.5.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.final_layer_norm.weight was initialized from encoder.layers.5.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.5.final_layer_norm.bias was initialized from encoder.layers.5.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.k_proj.weight was initialized from encoder.layers.6.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.k_proj.bias was initialized from encoder.layers.6.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.v_proj.weight was initialized from encoder.layers.6.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.v_proj.bias was initialized from encoder.layers.6.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.q_proj.weight was initialized from encoder.layers.6.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.q_proj.bias was initialized from encoder.layers.6.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.out_proj.weight was initialized from encoder.layers.6.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.attention.out_proj.bias was initialized from encoder.layers.6.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.layer_norm.weight was initialized from encoder.layers.6.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.layer_norm.bias was initialized from encoder.layers.6.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.feed_forward.intermediate_dense.weight was initialized from encoder.layers.6.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.feed_forward.intermediate_dense.bias was initialized from encoder.layers.6.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.feed_forward.output_dense.weight was initialized from encoder.layers.6.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.feed_forward.output_dense.bias was initialized from encoder.layers.6.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.final_layer_norm.weight was initialized from encoder.layers.6.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.6.final_layer_norm.bias was initialized from encoder.layers.6.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.k_proj.weight was initialized from encoder.layers.7.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.k_proj.bias was initialized from encoder.layers.7.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.v_proj.weight was initialized from encoder.layers.7.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.v_proj.bias was initialized from encoder.layers.7.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.q_proj.weight was initialized from encoder.layers.7.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.q_proj.bias was initialized from encoder.layers.7.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.out_proj.weight was initialized from encoder.layers.7.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.attention.out_proj.bias was initialized from encoder.layers.7.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.layer_norm.weight was initialized from encoder.layers.7.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.layer_norm.bias was initialized from encoder.layers.7.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.feed_forward.intermediate_dense.weight was initialized from encoder.layers.7.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.feed_forward.intermediate_dense.bias was initialized from encoder.layers.7.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.feed_forward.output_dense.weight was initialized from encoder.layers.7.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.feed_forward.output_dense.bias was initialized from encoder.layers.7.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.final_layer_norm.weight was initialized from encoder.layers.7.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.7.final_layer_norm.bias was initialized from encoder.layers.7.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.k_proj.weight was initialized from encoder.layers.8.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.k_proj.bias was initialized from encoder.layers.8.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.v_proj.weight was initialized from encoder.layers.8.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.v_proj.bias was initialized from encoder.layers.8.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.q_proj.weight was initialized from encoder.layers.8.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.q_proj.bias was initialized from encoder.layers.8.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.out_proj.weight was initialized from encoder.layers.8.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.attention.out_proj.bias was initialized from encoder.layers.8.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.layer_norm.weight was initialized from encoder.layers.8.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.layer_norm.bias was initialized from encoder.layers.8.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.feed_forward.intermediate_dense.weight was initialized from encoder.layers.8.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.feed_forward.intermediate_dense.bias was initialized from encoder.layers.8.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.feed_forward.output_dense.weight was initialized from encoder.layers.8.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.feed_forward.output_dense.bias was initialized from encoder.layers.8.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.final_layer_norm.weight was initialized from encoder.layers.8.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.8.final_layer_norm.bias was initialized from encoder.layers.8.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.k_proj.weight was initialized from encoder.layers.9.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.k_proj.bias was initialized from encoder.layers.9.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.v_proj.weight was initialized from encoder.layers.9.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.v_proj.bias was initialized from encoder.layers.9.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.q_proj.weight was initialized from encoder.layers.9.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.q_proj.bias was initialized from encoder.layers.9.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.out_proj.weight was initialized from encoder.layers.9.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.attention.out_proj.bias was initialized from encoder.layers.9.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.layer_norm.weight was initialized from encoder.layers.9.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.layer_norm.bias was initialized from encoder.layers.9.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.feed_forward.intermediate_dense.weight was initialized from encoder.layers.9.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.feed_forward.intermediate_dense.bias was initialized from encoder.layers.9.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.feed_forward.output_dense.weight was initialized from encoder.layers.9.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.feed_forward.output_dense.bias was initialized from encoder.layers.9.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.final_layer_norm.weight was initialized from encoder.layers.9.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.9.final_layer_norm.bias was initialized from encoder.layers.9.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.k_proj.weight was initialized from encoder.layers.10.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.k_proj.bias was initialized from encoder.layers.10.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.v_proj.weight was initialized from encoder.layers.10.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.v_proj.bias was initialized from encoder.layers.10.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.q_proj.weight was initialized from encoder.layers.10.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.q_proj.bias was initialized from encoder.layers.10.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.out_proj.weight was initialized from encoder.layers.10.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.attention.out_proj.bias was initialized from encoder.layers.10.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.layer_norm.weight was initialized from encoder.layers.10.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.layer_norm.bias was initialized from encoder.layers.10.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.feed_forward.intermediate_dense.weight was initialized from encoder.layers.10.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.feed_forward.intermediate_dense.bias was initialized from encoder.layers.10.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.feed_forward.output_dense.weight was initialized from encoder.layers.10.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.feed_forward.output_dense.bias was initialized from encoder.layers.10.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.final_layer_norm.weight was initialized from encoder.layers.10.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.10.final_layer_norm.bias was initialized from encoder.layers.10.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.k_proj.weight was initialized from encoder.layers.11.self_attn.k_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.k_proj.bias was initialized from encoder.layers.11.self_attn.k_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.v_proj.weight was initialized from encoder.layers.11.self_attn.v_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.v_proj.bias was initialized from encoder.layers.11.self_attn.v_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.q_proj.weight was initialized from encoder.layers.11.self_attn.q_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.q_proj.bias was initialized from encoder.layers.11.self_attn.q_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.out_proj.weight was initialized from encoder.layers.11.self_attn.out_proj.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.attention.out_proj.bias was initialized from encoder.layers.11.self_attn.out_proj.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.layer_norm.weight was initialized from encoder.layers.11.self_attn_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.layer_norm.bias was initialized from encoder.layers.11.self_attn_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.feed_forward.intermediate_dense.weight was initialized from encoder.layers.11.fc1.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.feed_forward.intermediate_dense.bias was initialized from encoder.layers.11.fc1.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.feed_forward.output_dense.weight was initialized from encoder.layers.11.fc2.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.feed_forward.output_dense.bias was initialized from encoder.layers.11.fc2.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.final_layer_norm.weight was initialized from encoder.layers.11.final_layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layers.11.final_layer_norm.bias was initialized from encoder.layers.11.final_layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layer_norm.weight was initialized from encoder.layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | encoder.layer_norm.bias was initialized from encoder.layer_norm.bias.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | feature_projection.layer_norm.weight was initialized from layer_norm.weight.\n",
      "2022-11-01 15:59:24 | INFO | __main__ | feature_projection.layer_norm.bias was initialized from layer_norm.bias.\n",
      "2022-11-01 15:59:24 | WARNING | __main__ | Unused weights: ['label_embs_concat', 'final_proj.weight', 'final_proj.bias']\n",
      "Configuration saved in hubert-base/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved in hubert-base/pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m transformers.models.hubert.convert_hubert_original_pytorch_checkpoint_to_pytorch --pytorch_dump_folder hubert-base --checkpoint_path {ckpt} --config_path hubert-base/config.json --not_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HubertModel.from_pretrained('./hubert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.8/site-packages/huggingface_hub/utils/_deprecation.py:38: FutureWarning: Deprecated positional argument(s) used in 'create_repo': pass token='hubert-base-ms' as keyword args. From version 0.12 passing these as positional arguments will result in an error,\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/huggingface_hub/hf_api.py:102: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.10. Pass `repo_id` instead.\n",
      "  warnings.warn(\n",
      "/home/husein/.local/lib/python3.8/site-packages/huggingface_hub/hf_api.py:681: FutureWarning: `create_repo` now takes `token` as an optional positional argument. Be sure to adapt your code!\n",
      "  warnings.warn(\n",
      "Cloning https://huggingface.co/mesolitica/hubert-base-ms into local empty directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d786f0ff4a4271ac7acc8950f1d377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 32.0k/360M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "remote: Scanning LFS files for validity, may be slow...        \n",
      "remote: LFS file scan complete.        \n",
      "To https://huggingface.co/mesolitica/hubert-base-ms\n",
      "   eb23bfb..103ac20  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/mesolitica/hubert-base-ms/commit/103ac2018828bbc052a0b626766b1d80b00d616a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('hubert-base-ms', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!cd hubert-base-ms && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 98b2fe3] add tensorboard\n",
      " 3 files changed, 9 insertions(+)\n",
      " create mode 100644 tensorboard/train/events.out.tfevents.1667199380.husein-MS-7D31.3942440.2\n",
      " create mode 100644 tensorboard/train_inner/events.out.tfevents.1667147588.husein-MS-7D31.3942440.0\n",
      " create mode 100644 tensorboard/valid/events.out.tfevents.1667152286.husein-MS-7D31.3942440.1\n",
      "Enumerating objects: 10, done./3), 6.9 MB | 1.4 MB/s                            \n",
      "Counting objects: 100% (10/10), done.\n",
      "Delta compression using up to 20 threads\n",
      "Compressing objects: 100% (9/9), done.\n",
      "Writing objects: 100% (9/9), 986 bytes | 986.00 KiB/s, done.\n",
      "Total 9 (delta 1), reused 0 (delta 0)\n",
      "remote: Scanning LFS files for validity, may be slow...\u001b[K\n",
      "remote: LFS file scan complete.\u001b[K\n",
      "To https://huggingface.co/mesolitica/hubert-base-ms\n",
      "   103ac20..98b2fe3  main -> main\n"
     ]
    }
   ],
   "source": [
    "!cp -r /home/husein/None/tensorboard hubert-base-ms\n",
    "!cd hubert-base-ms && git add . && git commit -m 'add tensorboard' && git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
