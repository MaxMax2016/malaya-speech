{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation, Conv1D, Conv2D, Input, Lambda\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Dense, Reshape\n",
    "from tensorflow.keras.layers import (\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "weight_decay = 1e-4\n",
    "\n",
    "\n",
    "def identity_block_2D(\n",
    "    input_tensor, kernel_size, filters, stage, block, trainable = True\n",
    "):\n",
    "    \"\"\"The identity block is the block that has no conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "\n",
    "    conv_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce'\n",
    "    bn_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce/bn'\n",
    "    x = Conv2D(\n",
    "        filters1,\n",
    "        (1, 1),\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_1,\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_1\n",
    "    )(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3'\n",
    "    bn_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3/bn'\n",
    "    x = Conv2D(\n",
    "        filters2,\n",
    "        kernel_size,\n",
    "        padding = 'same',\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_2,\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_2\n",
    "    )(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase'\n",
    "    bn_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase/bn'\n",
    "    x = Conv2D(\n",
    "        filters3,\n",
    "        (1, 1),\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_3,\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_3\n",
    "    )(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_2D(\n",
    "    input_tensor,\n",
    "    kernel_size,\n",
    "    filters,\n",
    "    stage,\n",
    "    block,\n",
    "    strides = (2, 2),\n",
    "    trainable = True,\n",
    "):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "    # Arguments\n",
    "        input_tensor: input tensor\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filterss of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "    # Returns\n",
    "        Output tensor for the block.\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2,2)\n",
    "    And the shortcut should have strides=(2,2) as well\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "    bn_axis = 3\n",
    "\n",
    "    conv_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce'\n",
    "    bn_name_1 = 'conv' + str(stage) + '_' + str(block) + '_1x1_reduce/bn'\n",
    "    x = Conv2D(\n",
    "        filters1,\n",
    "        (1, 1),\n",
    "        strides = strides,\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_1,\n",
    "    )(input_tensor)\n",
    "    x = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_1\n",
    "    )(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3'\n",
    "    bn_name_2 = 'conv' + str(stage) + '_' + str(block) + '_3x3/bn'\n",
    "    x = Conv2D(\n",
    "        filters2,\n",
    "        kernel_size,\n",
    "        padding = 'same',\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_2,\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_2\n",
    "    )(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    conv_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase'\n",
    "    bn_name_3 = 'conv' + str(stage) + '_' + str(block) + '_1x1_increase/bn'\n",
    "    x = Conv2D(\n",
    "        filters3,\n",
    "        (1, 1),\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_3,\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_3\n",
    "    )(x)\n",
    "\n",
    "    conv_name_4 = 'conv' + str(stage) + '_' + str(block) + '_1x1_proj'\n",
    "    bn_name_4 = 'conv' + str(stage) + '_' + str(block) + '_1x1_proj/bn'\n",
    "    shortcut = Conv2D(\n",
    "        filters3,\n",
    "        (1, 1),\n",
    "        strides = strides,\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = trainable,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        name = conv_name_4,\n",
    "    )(input_tensor)\n",
    "    shortcut = BatchNormalization(\n",
    "        axis = bn_axis, trainable = trainable, name = bn_name_4\n",
    "    )(shortcut)\n",
    "\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_2D_v1(inputs, mode = 'train'):\n",
    "    bn_axis = 3\n",
    "    #     if mode == 'train':\n",
    "    #         inputs = Input(shape=input_dim, name='input')\n",
    "    #     else:\n",
    "    #         inputs = Input(shape=(input_dim[0], None, input_dim[-1]), name='input')\n",
    "    # ===============================================\n",
    "    #            Convolution Block 1\n",
    "    # ===============================================\n",
    "    x1 = Conv2D(\n",
    "        64,\n",
    "        (7, 7),\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = True,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        padding = 'same',\n",
    "        name = 'conv1_1/3x3_s1',\n",
    "    )(inputs)\n",
    "\n",
    "    x1 = BatchNormalization(\n",
    "        axis = bn_axis, name = 'conv1_1/3x3_s1/bn', trainable = True\n",
    "    )(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2), strides = (2, 2))(x1)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 2\n",
    "    # ===============================================\n",
    "    x2 = conv_block_2D(\n",
    "        x1,\n",
    "        3,\n",
    "        [48, 48, 96],\n",
    "        stage = 2,\n",
    "        block = 'a',\n",
    "        strides = (1, 1),\n",
    "        trainable = True,\n",
    "    )\n",
    "    x2 = identity_block_2D(\n",
    "        x2, 3, [48, 48, 96], stage = 2, block = 'b', trainable = True\n",
    "    )\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 3\n",
    "    # ===============================================\n",
    "    x3 = conv_block_2D(\n",
    "        x2, 3, [96, 96, 128], stage = 3, block = 'a', trainable = True\n",
    "    )\n",
    "    x3 = identity_block_2D(\n",
    "        x3, 3, [96, 96, 128], stage = 3, block = 'b', trainable = True\n",
    "    )\n",
    "    x3 = identity_block_2D(\n",
    "        x3, 3, [96, 96, 128], stage = 3, block = 'c', trainable = True\n",
    "    )\n",
    "    # ===============================================\n",
    "    #            Convolution Section 4\n",
    "    # ===============================================\n",
    "    x4 = conv_block_2D(\n",
    "        x3, 3, [128, 128, 256], stage = 4, block = 'a', trainable = True\n",
    "    )\n",
    "    x4 = identity_block_2D(\n",
    "        x4, 3, [128, 128, 256], stage = 4, block = 'b', trainable = True\n",
    "    )\n",
    "    x4 = identity_block_2D(\n",
    "        x4, 3, [128, 128, 256], stage = 4, block = 'c', trainable = True\n",
    "    )\n",
    "    # ===============================================\n",
    "    #            Convolution Section 5\n",
    "    # ===============================================\n",
    "    x5 = conv_block_2D(\n",
    "        x4, 3, [256, 256, 512], stage = 5, block = 'a', trainable = True\n",
    "    )\n",
    "    x5 = identity_block_2D(\n",
    "        x5, 3, [256, 256, 512], stage = 5, block = 'b', trainable = True\n",
    "    )\n",
    "    x5 = identity_block_2D(\n",
    "        x5, 3, [256, 256, 512], stage = 5, block = 'c', trainable = True\n",
    "    )\n",
    "    y = MaxPooling2D((3, 1), strides = (2, 1), name = 'mpool2')(x5)\n",
    "    return inputs, y\n",
    "\n",
    "\n",
    "def resnet_2D_v2(inputs, mode = 'train'):\n",
    "    bn_axis = 3\n",
    "    #     if mode == 'train':\n",
    "    #         inputs = Input(shape=input_dim, name='input')\n",
    "    #     else:\n",
    "    #         inputs = Input(shape=(input_dim[0], None, input_dim[-1]), name='input')\n",
    "    # ===============================================\n",
    "    #            Convolution Block 1\n",
    "    # ===============================================\n",
    "    x1 = Conv2D(\n",
    "        64,\n",
    "        (7, 7),\n",
    "        strides = (2, 2),\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = False,\n",
    "        trainable = True,\n",
    "        kernel_regularizer = l2(weight_decay),\n",
    "        padding = 'same',\n",
    "        name = 'conv1_1/3x3_s1',\n",
    "    )(inputs)\n",
    "\n",
    "    x1 = BatchNormalization(\n",
    "        axis = bn_axis, name = 'conv1_1/3x3_s1/bn', trainable = True\n",
    "    )(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = MaxPooling2D((2, 2), strides = (2, 2))(x1)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Convolution Section 2\n",
    "    # ===============================================\n",
    "    x2 = conv_block_2D(\n",
    "        x1,\n",
    "        3,\n",
    "        [64, 64, 256],\n",
    "        stage = 2,\n",
    "        block = 'a',\n",
    "        strides = (1, 1),\n",
    "        trainable = True,\n",
    "    )\n",
    "    x2 = identity_block_2D(\n",
    "        x2, 3, [64, 64, 256], stage = 2, block = 'b', trainable = True\n",
    "    )\n",
    "    x2 = identity_block_2D(\n",
    "        x2, 3, [64, 64, 256], stage = 2, block = 'c', trainable = True\n",
    "    )\n",
    "    # ===============================================\n",
    "    #            Convolution Section 3\n",
    "    # ===============================================\n",
    "    x3 = conv_block_2D(\n",
    "        x2, 3, [128, 128, 512], stage = 3, block = 'a', trainable = True\n",
    "    )\n",
    "    x3 = identity_block_2D(\n",
    "        x3, 3, [128, 128, 512], stage = 3, block = 'b', trainable = True\n",
    "    )\n",
    "    x3 = identity_block_2D(\n",
    "        x3, 3, [128, 128, 512], stage = 3, block = 'c', trainable = True\n",
    "    )\n",
    "    # ===============================================\n",
    "    #            Convolution Section 4\n",
    "    # ===============================================\n",
    "    x4 = conv_block_2D(\n",
    "        x3,\n",
    "        3,\n",
    "        [256, 256, 1024],\n",
    "        stage = 4,\n",
    "        block = 'a',\n",
    "        strides = (1, 1),\n",
    "        trainable = True,\n",
    "    )\n",
    "    x4 = identity_block_2D(\n",
    "        x4, 3, [256, 256, 1024], stage = 4, block = 'b', trainable = True\n",
    "    )\n",
    "    x4 = identity_block_2D(\n",
    "        x4, 3, [256, 256, 1024], stage = 4, block = 'c', trainable = True\n",
    "    )\n",
    "    # ===============================================\n",
    "    #            Convolution Section 5\n",
    "    # ===============================================\n",
    "    x5 = conv_block_2D(\n",
    "        x4, 3, [512, 512, 2048], stage = 5, block = 'a', trainable = True\n",
    "    )\n",
    "    x5 = identity_block_2D(\n",
    "        x5, 3, [512, 512, 2048], stage = 5, block = 'b', trainable = True\n",
    "    )\n",
    "    x5 = identity_block_2D(\n",
    "        x5, 3, [512, 512, 2048], stage = 5, block = 'c', trainable = True\n",
    "    )\n",
    "    y = MaxPooling2D((3, 1), strides = (2, 1), name = 'mpool2')(x5)\n",
    "    return inputs, y\n",
    "\n",
    "\n",
    "class VladPooling(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    This layer follows the NetVlad, GhostVlad\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode, k_centers, g_centers = 0, **kwargs):\n",
    "        self.k_centers = k_centers\n",
    "        self.g_centers = g_centers\n",
    "        self.mode = mode\n",
    "        super(VladPooling, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.cluster = self.add_weight(\n",
    "            shape = [self.k_centers + self.g_centers, input_shape[0][-1]],\n",
    "            name = 'centers',\n",
    "            initializer = 'orthogonal',\n",
    "        )\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape\n",
    "        return (input_shape[0][0], self.k_centers * input_shape[0][-1])\n",
    "\n",
    "    def call(self, x):\n",
    "        # feat : bz x W x H x D, cluster_score: bz X W x H x clusters.\n",
    "        feat, cluster_score = x\n",
    "        num_features = feat.shape[-1]\n",
    "\n",
    "        # softmax normalization to get soft-assignment.\n",
    "        # A : bz x W x H x clusters\n",
    "        max_cluster_score = K.max(cluster_score, -1, keepdims = True)\n",
    "        exp_cluster_score = K.exp(cluster_score - max_cluster_score)\n",
    "        A = exp_cluster_score / K.sum(\n",
    "            exp_cluster_score, axis = -1, keepdims = True\n",
    "        )\n",
    "\n",
    "        # Now, need to compute the residual, self.cluster: clusters x D\n",
    "        A = K.expand_dims(A, -1)  # A : bz x W x H x clusters x 1\n",
    "        feat_broadcast = K.expand_dims(\n",
    "            feat, -2\n",
    "        )  # feat_broadcast : bz x W x H x 1 x D\n",
    "        feat_res = (\n",
    "            feat_broadcast - self.cluster\n",
    "        )  # feat_res : bz x W x H x clusters x D\n",
    "        weighted_res = tf.multiply(\n",
    "            A, feat_res\n",
    "        )  # weighted_res : bz x W x H x clusters x D\n",
    "        cluster_res = K.sum(weighted_res, [1, 2])\n",
    "\n",
    "        if self.mode == 'gvlad':\n",
    "            cluster_res = cluster_res[:, : self.k_centers, :]\n",
    "\n",
    "        cluster_l2 = K.l2_normalize(cluster_res, -1)\n",
    "        outputs = K.reshape(\n",
    "            cluster_l2, [-1, int(self.k_centers) * int(num_features)]\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def amsoftmax_loss(y_true, y_pred, scale = 30, margin = 0.35):\n",
    "    y_pred = y_true * (y_pred - margin) + (1 - y_true) * y_pred\n",
    "    y_pred *= scale\n",
    "    return K.categorical_crossentropy(y_true, y_pred, from_logits = True)\n",
    "\n",
    "\n",
    "def vggvox_resnet2d_icassp(\n",
    "    inputs, num_class = 8631, mode = 'train', args = None\n",
    "):\n",
    "\n",
    "    net = 'resnet34s'\n",
    "    loss = 'softmax'\n",
    "    vlad_clusters = 8\n",
    "    ghost_clusters = 2\n",
    "    bottleneck_dim = 512\n",
    "    aggregation = 'gvlad'\n",
    "    mgpu = 0\n",
    "\n",
    "    if net == 'resnet34s':\n",
    "        inputs, x = resnet_2D_v1(inputs, mode = mode)\n",
    "    else:\n",
    "        inputs, x = resnet_2D_v2(inputs, mode = mode)\n",
    "\n",
    "    x_fc = keras.layers.Conv2D(\n",
    "        bottleneck_dim,\n",
    "        (7, 1),\n",
    "        strides = (1, 1),\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = True,\n",
    "        trainable = True,\n",
    "        kernel_regularizer = keras.regularizers.l2(weight_decay),\n",
    "        bias_regularizer = keras.regularizers.l2(weight_decay),\n",
    "        name = 'x_fc',\n",
    "    )(x)\n",
    "\n",
    "    # ===============================================\n",
    "    #            Feature Aggregation\n",
    "    # ===============================================\n",
    "    if aggregation == 'avg':\n",
    "        if mode == 'train':\n",
    "            x = keras.layers.AveragePooling2D(\n",
    "                (1, 5), strides = (1, 1), name = 'avg_pool'\n",
    "            )(x)\n",
    "            x = keras.layers.Reshape((-1, bottleneck_dim))(x)\n",
    "        else:\n",
    "            x = keras.layers.GlobalAveragePooling2D(name = 'avg_pool')(x)\n",
    "            x = keras.layers.Reshape((1, bottleneck_dim))(x)\n",
    "\n",
    "    elif aggregation == 'vlad':\n",
    "        x_k_center = keras.layers.Conv2D(\n",
    "            vlad_clusters,\n",
    "            (7, 1),\n",
    "            strides = (1, 1),\n",
    "            kernel_initializer = 'orthogonal',\n",
    "            use_bias = True,\n",
    "            trainable = True,\n",
    "            kernel_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            bias_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            name = 'vlad_center_assignment',\n",
    "        )(x)\n",
    "        x = VladPooling(\n",
    "            k_centers = vlad_clusters, mode = 'vlad', name = 'vlad_pool'\n",
    "        )([x_fc, x_k_center])\n",
    "\n",
    "    elif aggregation == 'gvlad':\n",
    "        x_k_center = keras.layers.Conv2D(\n",
    "            vlad_clusters + ghost_clusters,\n",
    "            (7, 1),\n",
    "            strides = (1, 1),\n",
    "            kernel_initializer = 'orthogonal',\n",
    "            use_bias = True,\n",
    "            trainable = True,\n",
    "            kernel_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            bias_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            name = 'gvlad_center_assignment',\n",
    "        )(x)\n",
    "        x = VladPooling(\n",
    "            k_centers = vlad_clusters,\n",
    "            g_centers = ghost_clusters,\n",
    "            mode = 'gvlad',\n",
    "            name = 'gvlad_pool',\n",
    "        )([x_fc, x_k_center])\n",
    "\n",
    "    else:\n",
    "        raise IOError('==> unknown aggregation mode')\n",
    "    x = keras.layers.Dense(\n",
    "        bottleneck_dim,\n",
    "        activation = 'relu',\n",
    "        kernel_initializer = 'orthogonal',\n",
    "        use_bias = True,\n",
    "        trainable = True,\n",
    "        kernel_regularizer = keras.regularizers.l2(weight_decay),\n",
    "        bias_regularizer = keras.regularizers.l2(weight_decay),\n",
    "        name = 'fc6',\n",
    "    )(x)\n",
    "    if loss == 'softmax':\n",
    "        y = keras.layers.Dense(\n",
    "            num_class,\n",
    "            activation = 'softmax',\n",
    "            kernel_initializer = 'orthogonal',\n",
    "            use_bias = False,\n",
    "            trainable = True,\n",
    "            kernel_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            bias_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            name = 'prediction',\n",
    "        )(x)\n",
    "        trnloss = 'categorical_crossentropy'\n",
    "\n",
    "    elif loss == 'amsoftmax':\n",
    "        x_l2 = keras.layers.Lambda(lambda x: K.l2_normalize(x, 1))(x)\n",
    "        y = keras.layers.Dense(\n",
    "            num_class,\n",
    "            kernel_initializer = 'orthogonal',\n",
    "            use_bias = False,\n",
    "            trainable = True,\n",
    "            kernel_constraint = keras.constraints.unit_norm(),\n",
    "            kernel_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            bias_regularizer = keras.regularizers.l2(weight_decay),\n",
    "            name = 'prediction',\n",
    "        )(x_l2)\n",
    "        trnloss = amsoftmax_loss\n",
    "\n",
    "    else:\n",
    "        raise IOError('==> unknown loss.')\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 257, None, 1])\n",
    "        \n",
    "        params = {'dim': (257, None, 1),\n",
    "            'nfft': 512,\n",
    "            'spec_len': 250,\n",
    "            'win_length': 400,\n",
    "            'hop_length': 160,\n",
    "            'n_classes': 5994,\n",
    "            'sampling_rate': 16000,\n",
    "            'normalize': True,\n",
    "        }\n",
    "        self.logits = vggvox_resnet2d_icassp(self.X, num_class=8, mode='eval')\n",
    "        self.logits = tf.identity(self.logits, name = 'logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'output-vggvox-v2-emotion/model.ckpt-100000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-vggvox-v2-emotion/model.ckpt-100000\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vggvox-v2-emotion-detection/model.ckpt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'vggvox-v2-emotion-detection/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name\n",
    "        or 'self/Softmax' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggvox-v2-emotion-detection/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-9-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 198 variables.\n",
      "INFO:tensorflow:Converted 198 variables to const ops.\n",
      "1367 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('vggvox-v2-emotion-detection', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename, **kwargs):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # https://github.com/onnx/tensorflow-onnx/issues/77#issuecomment-445066091\n",
    "    # to fix import T5\n",
    "    for node in graph_def.node:\n",
    "        if node.op == 'RefSwitch':\n",
    "            node.op = 'Switch'\n",
    "            for index in xrange(len(node.input)):\n",
    "                if 'moving_' in node.input[index]:\n",
    "                    node.input[index] = node.input[index] + '/read'\n",
    "        elif node.op == 'AssignSub':\n",
    "            node.op = 'Sub'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'AssignAdd':\n",
    "            node.op = 'Add'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'Assign':\n",
    "            node.op = 'Identity'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "            if 'validate_shape' in node.attr:\n",
    "                del node.attr['validate_shape']\n",
    "            if len(node.input) == 2:\n",
    "                node.input[0] = node.input[1]\n",
    "                del node.input[1]\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('vggvox-v2-emotion-detection/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vggvox-v2-emotion-detection/\n",
      "vggvox-v2-emotion-detection/model.ckpt.index\n",
      "vggvox-v2-emotion-detection/model.ckpt.data-00000-of-00001\n",
      "vggvox-v2-emotion-detection/checkpoint\n",
      "vggvox-v2-emotion-detection/model.ckpt.meta\n",
      "vggvox-v2-emotion-detection/frozen_model.pb\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf vggvox-v2-emotion-detection-100k.tar.gz vggvox-v2-emotion-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
