{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/malaya-speech/malaya_speech/train/model/quartznet/layer.py:6: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import malaya_speech\n",
    "import malaya_speech.train\n",
    "from malaya_speech.train.model import unet\n",
    "from malaya_speech.utils import tf_featurization\n",
    "import malaya_speech.augmentation.waveform as augmentation\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "from malaya_speech.utils.tf_featurization import separation_exponent, EPSILON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, size = 2):\n",
    "        self.X = tf.placeholder(tf.float32, (None))\n",
    "        self.Y = tf.placeholder(tf.float32, (size, None))\n",
    "        \n",
    "        stft_X, D_X = tf_featurization.get_stft(self.X)\n",
    "        \n",
    "        self.stft = []\n",
    "        for i in range(size):\n",
    "            self.stft.append(tf_featurization.get_stft(self.Y[i]))\n",
    "        \n",
    "        self.outputs = []\n",
    "        for i in range(size):\n",
    "            with tf.variable_scope(f'model_{i}'):\n",
    "                self.outputs.append(unet.Model(D_X).logits)\n",
    "        \n",
    "        self.loss = []\n",
    "        for i in range(size):\n",
    "            self.loss.append(\n",
    "                tf.reduce_mean(tf.abs(self.outputs[i] - self.stft[i][1]))\n",
    "            )\n",
    "\n",
    "        self.cost = tf.reduce_sum(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "model = Model()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from noise-reduction-unet/model.ckpt-500000\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, 'noise-reduction-unet/model.ckpt-500000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('test-set-noise-reduction.pkl', 'rb') as fopen:\n",
    "    results = pickle.load(fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.04715744,  0.03726677,  0.0389775 , ..., -0.06868765,\n",
       "        -0.06979144, -0.05400571]),\n",
       " array([ 0.02517777,  0.02410962,  0.02356029, ..., -0.09015168,\n",
       "        -0.08832057, -0.0868862 ]),\n",
       " array([ 2.79740543e-02,  1.88972249e-02,  2.10265001e-02, ...,\n",
       "         4.84924156e-07, -2.49846227e-03,  1.21944008e-02]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.76937425, [0.57742643, 0.19194783]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([model.cost, model.loss], feed_dict = {model.X: results[0][0],\n",
    "                                               model.Y: results[0][1:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:08<00:00, 11.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total, voice, noise = [], [], []\n",
    "\n",
    "for i in tqdm(range(len(results))):\n",
    "    c, l = sess.run([model.cost, model.loss], feed_dict = {model.X: results[i][0],\n",
    "                                               model.Y: results[i][1:]})\n",
    "    total.append(c)\n",
    "    voice.append(l[0])\n",
    "    noise.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0017848"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70453936"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29724538"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
