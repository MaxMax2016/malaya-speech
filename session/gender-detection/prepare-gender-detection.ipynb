{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33862"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librispeech = glob('LibriSpeech/*/*/*/*.flac')\n",
    "len(librispeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "librispeech_speakers = {}\n",
    "\n",
    "with open('LibriSpeech/SPEAKERS.TXT') as fopen:\n",
    "    speakers = fopen.read()\n",
    "speakers = speakers.split(';')[-1].split('\\n')[1:]\n",
    "for s in speakers:\n",
    "    splitted = s.split('|')\n",
    "    if len(splitted) > 2:\n",
    "        i, g = splitted[:2]\n",
    "        librispeech_speakers[i.strip()] = g.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_librispeech(file):\n",
    "    return file.split('/')[-1].split('-')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librispeech_speakers.get(get_speaker_librispeech(librispeech[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://www.robots.ox.ac.uk/~vgg/data/voxceleb/meta/vox2_meta.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092009"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('vox2_meta.csv')\n",
    "voxceleb = glob('voxceleb-wav/*.wav', recursive = True)\n",
    "len(voxceleb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_voxceleb(file):\n",
    "    return file.split('/')[-1].split('-')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxceleb_speakers = {}\n",
    "for i in range(len(df)):\n",
    "    voxceleb_speakers[df.iloc[i,0].strip()] = df.iloc[i,-2].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id03556'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_speaker_voxceleb(voxceleb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxceleb_speakers.get(get_speaker_voxceleb(voxceleb[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def resample(data, old_samplerate, new_samplerate):\n",
    "    old_audio = data\n",
    "    duration = data.shape[0] / old_samplerate\n",
    "    time_old = np.linspace(0, duration, old_audio.shape[0])\n",
    "    time_new = np.linspace(\n",
    "        0, duration, int(old_audio.shape[0] * new_samplerate / old_samplerate)\n",
    "    )\n",
    "\n",
    "    interpolator = interpolate.interp1d(time_old, old_audio.T)\n",
    "    data = interpolator(time_new).T\n",
    "    return data\n",
    "\n",
    "def read_wav(file, sample_rate = 16000):\n",
    "    y, sr = sf.read(file)\n",
    "    if sr != sample_rate:\n",
    "        y = resample(y, sr, sample_rate)\n",
    "    return y, sample_rate\n",
    "\n",
    "def sampling(combined, frame_duration_ms = 700, sample_rate = 16000):\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0))\n",
    "    offset = 0\n",
    "    while offset + n <= len(combined):\n",
    "        yield combined[offset : offset + n]\n",
    "        offset += n\n",
    "    if offset < len(combined):\n",
    "        yield combined[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "def sox_reverb(\n",
    "    y, reverberance = 1, hf_damping = 1, room_scale = 1, stereo_depth = 1\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    apply_audio_effects = AudioEffectsChain().reverb(\n",
    "        reverberance = reverberance,\n",
    "        hf_damping = hf_damping,\n",
    "        room_scale = room_scale,\n",
    "        stereo_depth = stereo_depth,\n",
    "        pre_delay = 20,\n",
    "        wet_gain = 0,\n",
    "        wet_only = False,\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def sox_augment_low(\n",
    "    y,\n",
    "    min_bass_gain = 5,\n",
    "    reverberance = 1,\n",
    "    hf_damping = 1,\n",
    "    room_scale = 1,\n",
    "    stereo_depth = 1,\n",
    "    negate = 1,\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    if negate:\n",
    "        min_bass_gain = -min_bass_gain\n",
    "    apply_audio_effects = (\n",
    "        AudioEffectsChain()\n",
    "        .lowshelf(gain = min_bass_gain, frequency = 300, slope = 0.1)\n",
    "        .reverb(\n",
    "            reverberance = reverberance,\n",
    "            hf_damping = hf_damping,\n",
    "            room_scale = room_scale,\n",
    "            stereo_depth = stereo_depth,\n",
    "            pre_delay = 20,\n",
    "            wet_gain = 0,\n",
    "            wet_only = False,\n",
    "        )\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def sox_augment_high(\n",
    "    y,\n",
    "    min_bass_gain = 5,\n",
    "    reverberance = 1,\n",
    "    hf_damping = 1,\n",
    "    room_scale = 1,\n",
    "    stereo_depth = 1,\n",
    "    negate = 1,\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    if negate:\n",
    "        min_bass_gain = -min_bass_gain\n",
    "\n",
    "    apply_audio_effects = (\n",
    "        AudioEffectsChain()\n",
    "        .highshelf(\n",
    "            gain = -min_bass_gain * (1 - expit(np.max(y))),\n",
    "            frequency = 300,\n",
    "            slope = 0.1,\n",
    "        )\n",
    "        .reverb(\n",
    "            reverberance = reverberance,\n",
    "            hf_damping = hf_damping,\n",
    "            room_scale = room_scale,\n",
    "            stereo_depth = stereo_depth,\n",
    "            pre_delay = 20,\n",
    "            wet_gain = 0,\n",
    "            wet_only = False,\n",
    "        )\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def sox_augment_combine(\n",
    "    y,\n",
    "    min_bass_gain_low = 5,\n",
    "    min_bass_gain_high = 5,\n",
    "    reverberance = 1,\n",
    "    hf_damping = 1,\n",
    "    room_scale = 1,\n",
    "    stereo_depth = 1,\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    apply_audio_effects = (\n",
    "        AudioEffectsChain()\n",
    "        .lowshelf(gain = min_bass_gain_low, frequency = 300, slope = 0.1)\n",
    "        .highshelf(gain = -min_bass_gain_high, frequency = 300, slope = 0.1)\n",
    "        .reverb(\n",
    "            reverberance = reverberance,\n",
    "            hf_damping = hf_damping,\n",
    "            room_scale = room_scale,\n",
    "            stereo_depth = stereo_depth,\n",
    "            pre_delay = 20,\n",
    "            wet_gain = 0,\n",
    "            wet_only = False,\n",
    "        )\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def random_pitch(sample, low = 0.5, high = 1.0):\n",
    "    y_pitch_speed = sample.copy()\n",
    "    length_change = np.random.uniform(low = low, high = high)\n",
    "    speed_fac = 1.0 / length_change\n",
    "    tmp = np.interp(\n",
    "        np.arange(0, len(y_pitch_speed), speed_fac),\n",
    "        np.arange(0, len(y_pitch_speed)),\n",
    "        y_pitch_speed,\n",
    "    )\n",
    "    minlen = min(y_pitch_speed.shape[0], tmp.shape[0])\n",
    "    y_pitch_speed *= 0\n",
    "    y_pitch_speed[:minlen] = tmp[:minlen]\n",
    "    return y_pitch_speed\n",
    "\n",
    "\n",
    "def random_amplitude(sample, low = 1.5, high = 3):\n",
    "    y_aug = sample.copy()\n",
    "    dyn_change = np.random.uniform(low = low, high = high)\n",
    "    return y_aug * dyn_change\n",
    "\n",
    "\n",
    "def random_stretch(sample, low = 0.5, high = 1.3):\n",
    "    input_length = len(sample)\n",
    "    stretching = sample.copy()\n",
    "    random_stretch = np.random.uniform(low = low, high = high)\n",
    "    stretching = librosa.effects.time_stretch(\n",
    "        stretching.astype('float'), random_stretch\n",
    "    )\n",
    "    return stretching\n",
    "\n",
    "def add_uniform_noise(sample, power = 0.01):\n",
    "    y_noise = sample.copy()\n",
    "    noise_amp = power * np.random.uniform() * np.amax(y_noise)\n",
    "    return y_noise.astype('float64') + noise_amp * np.random.normal(\n",
    "        size = y_noise.shape[0]\n",
    "    )\n",
    "\n",
    "\n",
    "def add_noise(sample, noise, random_sample = True, factor = 0.1):\n",
    "    y_noise = sample.copy()\n",
    "    if len(y_noise) > len(noise):\n",
    "        noise = np.tile(noise, int(np.ceil(len(y_noise) / len(noise))))\n",
    "    else:\n",
    "        if random_sample:\n",
    "            noise = noise[np.random.randint(0, len(noise) - len(y_noise) + 1) :]\n",
    "    return y_noise + noise[: len(y_noise)] * factor\n",
    "\n",
    "def sampling(combined, frame_duration_ms = 700, sample_rate = 16000):\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0))\n",
    "    offset = 0\n",
    "    while offset + n <= len(combined):\n",
    "        yield combined[offset : offset + n]\n",
    "        offset += n\n",
    "    if offset < len(combined):\n",
    "        yield combined[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(signal):\n",
    "\n",
    "    choice = random.randint(0, 4)\n",
    "    if choice == 0:\n",
    "\n",
    "        x = sox_augment_high(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(25, 50),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 50),\n",
    "            negate = 1,\n",
    "        )\n",
    "    if choice == 1:\n",
    "        x = sox_augment_high(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(25, 70),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 50),\n",
    "            negate = 0,\n",
    "        )\n",
    "    if choice == 2:\n",
    "        x = sox_augment_low(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(5, 30),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 50),\n",
    "            negate = random.randint(0, 1),\n",
    "        )\n",
    "    if choice == 3:\n",
    "        x = sox_augment_combine(\n",
    "            signal,\n",
    "            min_bass_gain_high = random.randint(25, 70),\n",
    "            min_bass_gain_low = random.randint(5, 30),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 90),\n",
    "        )\n",
    "    if choice == 4:\n",
    "        x = sox_reverb(\n",
    "            signal,\n",
    "            reverberance = random.randint(10, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(10, 90),\n",
    "        )\n",
    "\n",
    "    if random.randint(0, 1):\n",
    "        x = add_uniform_noise(\n",
    "            x, power = random.uniform(0.005, 0.015)\n",
    "        )\n",
    "        \n",
    "    if random.random() > 0.75:\n",
    "        r = random.choice(not_music)\n",
    "        n = read_wav(r)[0]\n",
    "        x = add_noise(x, n, factor = random.uniform(0.005, 0.01))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = ['female', 'male', 'not a gender']\n",
    "mapping = {'f': 'female', 'm': 'male'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110000, 110000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "files, labels = [], []\n",
    "\n",
    "for f in random.sample(librispeech, 10000):\n",
    "    l = librispeech_speakers.get(get_speaker_librispeech(f))\n",
    "    if l:\n",
    "        labels.append(mapping[l])\n",
    "        files.append(f)\n",
    "        \n",
    "for f in random.sample(voxceleb, 100000):\n",
    "    l = voxceleb_speakers.get(get_speaker_voxceleb(f))\n",
    "    if l:\n",
    "        labels.append(mapping[l])\n",
    "        files.append(f)\n",
    "        \n",
    "len(files), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_music = glob('not-music/clean-wav/*.wav') + glob('musan/music/**/*.wav', recursive = True) \\\n",
    "+ glob('musan/noise/**/*.wav', recursive = True)\n",
    "files = files + not_music\n",
    "labels = labels + ['not a gender'] * len(not_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "files, labels = shuffle(files, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0184021 ,  0.07171631,  0.16143799, ..., -0.02212524,\n",
       "        -0.01934814, -0.01745605]),\n",
       " 16000,\n",
       " 'female')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, sr = read_wav(files[-2])\n",
    "y = y[:sr * 10]\n",
    "y, sr, labels[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10992366,  0.44814456,  0.90128332, ..., -0.01737537,\n",
       "        0.01271827,  0.03356281])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.system('rm gender/data/*')\n",
    "DATA_DIR = os.path.expanduser('gender/data')\n",
    "tf.gfile.MakeDirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from malaya_speech.train import prepare_data\n",
    "from collections import defaultdict\n",
    "\n",
    "def loop(files, dupe_factor = 1):\n",
    "    files, no = files\n",
    "    fname = f'{DATA_DIR}/part-{no}.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(fname)\n",
    "    counts = defaultdict(int)\n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            wav = read_wav(file[0])[0]\n",
    "            if file[1] != 'not a gender':\n",
    "                d = dupe_factor\n",
    "            else:\n",
    "                d = 1\n",
    "            for _ in range(d):\n",
    "                if file[1] != 'not a gender':\n",
    "                    minimum = 1000\n",
    "                else:\n",
    "                    minimum = 200\n",
    "                fs = sampling(wav, random.randint(minimum, 2000))\n",
    "                for s in fs:\n",
    "                    try:\n",
    "                        if file[1] != 'not a gender':\n",
    "                            for _ in range(dupe_factor):\n",
    "                                n = calc(s)\n",
    "                                if len(n) > 50:\n",
    "                                    example = prepare_data.to_example({'inputs': n.tolist(), \n",
    "                                                                       'targets': [actual_labels.index(file[1])]})\n",
    "                                    writer.write(example.SerializeToString())\n",
    "                                    counts[file[1]] += 1\n",
    "                            n = s\n",
    "                        else:\n",
    "                            n = s\n",
    "                        if len(n) > 50:\n",
    "                            example = prepare_data.to_example({'inputs': n.tolist(), \n",
    "                                                               'targets': [actual_labels.index(file[1])]})\n",
    "                            writer.write(example.SerializeToString())\n",
    "                            counts[file[1]] += 1\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        pass\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    writer.close()\n",
    "    return [counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all = list(zip(files, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11202/11202 [1:44:11<00:00,  1.79it/s] \n",
      "100%|██████████| 6/6 [00:04<00:00,  1.37it/s] 2.23it/s]\n",
      "100%|██████████| 11202/11202 [1:45:13<00:00,  1.77it/s]\n",
      "100%|██████████| 11202/11202 [1:45:31<00:00,  1.77it/s]\n",
      "100%|██████████| 11202/11202 [1:45:38<00:00,  1.77it/s]\n",
      "100%|██████████| 11202/11202 [1:46:02<00:00,  1.76it/s]\n",
      "100%|██████████| 11202/11202 [1:46:05<00:00,  1.76it/s]\n",
      "100%|██████████| 11202/11202 [1:46:11<00:00,  1.76it/s]\n",
      "100%|██████████| 11202/11202 [1:46:13<00:00,  1.76it/s]\n",
      "100%|██████████| 11202/11202 [1:46:19<00:00,  1.76it/s]\n",
      "100%|██████████| 11202/11202 [1:46:21<00:00,  1.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import mp\n",
    "returned = mp.multiprocessing(combined_all, loop, cores = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'male': 831810, 'not a gender': 503997, 'female': 525766})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_d = defaultdict(int)\n",
    "for d in returned:\n",
    "    for k, v in d.items():\n",
    "        combined_d[k] += v\n",
    "combined_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
