{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33862"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librispeech = glob('LibriSpeech/*/*/*/*.flac')\n",
    "len(librispeech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_speaker_librispeech(file):\n",
    "    return file.split('/')[-1].split('-')[0]\n",
    "\n",
    "speakers = defaultdict(list)\n",
    "for f in librispeech:\n",
    "    speakers[get_speaker_librispeech(f)].append(f)\n",
    "    \n",
    "len(speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1092009"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voxceleb = glob('voxceleb-wav/*.wav', recursive = True)\n",
    "len(voxceleb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_speaker_voxceleb(file):\n",
    "    return file.split('/')[-1].split('-')[2]\n",
    "\n",
    "voxceleb_speakers = defaultdict(list)\n",
    "for f in voxceleb:\n",
    "    voxceleb_speakers[get_speaker_voxceleb(f)].append(f)\n",
    "    \n",
    "len(voxceleb_speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def combine_speakers(files, n = 5, sr = 16000):\n",
    "    w_samples = random.sample(files, n)\n",
    "    w_samples = [\n",
    "        random_sampling(\n",
    "            read_wav(f)[0],\n",
    "            length = min(random.randint(20000 // n, 240_000 // n), 100_000 // n),\n",
    "        )\n",
    "        for f in w_samples\n",
    "    ]\n",
    "    y = [w_samples[0]]\n",
    "    left = w_samples[0].copy() * random.uniform(0.5, 1.0)\n",
    "    timestamps = [(0 / sr, len(left) / sr)]\n",
    "    for i in range(1, n):\n",
    "        right = w_samples[i].copy() * random.uniform(0.5, 1.0)\n",
    "\n",
    "        overlap = random.uniform(0.01, 1.25)\n",
    "        left_len = int(overlap * len(left))\n",
    "        \n",
    "        padded_right = np.pad(right, (left_len, 0))\n",
    "        timestamps.append((left_len / sr, (left_len + len(right)) / sr))\n",
    "\n",
    "        if len(left) > len(padded_right):\n",
    "            padded_right = np.pad(\n",
    "                padded_right, (0, len(left) - len(padded_right))\n",
    "            )\n",
    "        else:\n",
    "            left = np.pad(left, (0, len(padded_right) - len(left)))\n",
    "\n",
    "        y.append(padded_right)\n",
    "        left = left + padded_right\n",
    "    return left, y, np.array(timestamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.special import expit\n",
    "\n",
    "np.seterr(all='raise')\n",
    "\n",
    "def resample(data, old_samplerate, new_samplerate):\n",
    "    old_audio = data\n",
    "    duration = data.shape[0] / old_samplerate\n",
    "    time_old = np.linspace(0, duration, old_audio.shape[0])\n",
    "    time_new = np.linspace(\n",
    "        0, duration, int(old_audio.shape[0] * new_samplerate / old_samplerate)\n",
    "    )\n",
    "\n",
    "    interpolator = interpolate.interp1d(time_old, old_audio.T)\n",
    "    data = interpolator(time_new).T\n",
    "    return data\n",
    "\n",
    "def read_wav(file, sample_rate = 16000):\n",
    "    y, sr = sf.read(file)\n",
    "    if sr != sample_rate:\n",
    "        y = resample(y, sr, sample_rate)\n",
    "    return y, sample_rate\n",
    "\n",
    "def random_sampling(sample, sr = 16000, length = 500):\n",
    "    sr = int(sr / 1000)\n",
    "    up = len(sample) - (sr * length)\n",
    "    if up < 1:\n",
    "        r = 0\n",
    "    else:\n",
    "        r = np.random.randint(0, up)\n",
    "    return sample[r : r + sr * length]\n",
    "\n",
    "def sox_reverb(\n",
    "    y, reverberance = 1, hf_damping = 1, room_scale = 1, stereo_depth = 1\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    apply_audio_effects = AudioEffectsChain().reverb(\n",
    "        reverberance = reverberance,\n",
    "        hf_damping = hf_damping,\n",
    "        room_scale = room_scale,\n",
    "        stereo_depth = stereo_depth,\n",
    "        pre_delay = 20,\n",
    "        wet_gain = 0,\n",
    "        wet_only = False,\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def sox_augment_low(\n",
    "    y,\n",
    "    min_bass_gain = 5,\n",
    "    reverberance = 1,\n",
    "    hf_damping = 1,\n",
    "    room_scale = 1,\n",
    "    stereo_depth = 1,\n",
    "    negate = 1,\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    if negate:\n",
    "        min_bass_gain = -min_bass_gain\n",
    "    apply_audio_effects = (\n",
    "        AudioEffectsChain()\n",
    "        .lowshelf(gain = min_bass_gain, frequency = 300, slope = 0.1)\n",
    "        .reverb(\n",
    "            reverberance = reverberance,\n",
    "            hf_damping = hf_damping,\n",
    "            room_scale = room_scale,\n",
    "            stereo_depth = stereo_depth,\n",
    "            pre_delay = 20,\n",
    "            wet_gain = 0,\n",
    "            wet_only = False,\n",
    "        )\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def sox_augment_high(\n",
    "    y,\n",
    "    min_bass_gain = 5,\n",
    "    reverberance = 1,\n",
    "    hf_damping = 1,\n",
    "    room_scale = 1,\n",
    "    stereo_depth = 1,\n",
    "    negate = 1,\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    if negate:\n",
    "        min_bass_gain = -min_bass_gain\n",
    "\n",
    "    apply_audio_effects = (\n",
    "        AudioEffectsChain()\n",
    "        .highshelf(\n",
    "            gain = -min_bass_gain * (1 - expit(np.max(y))),\n",
    "            frequency = 300,\n",
    "            slope = 0.1,\n",
    "        )\n",
    "        .reverb(\n",
    "            reverberance = reverberance,\n",
    "            hf_damping = hf_damping,\n",
    "            room_scale = room_scale,\n",
    "            stereo_depth = stereo_depth,\n",
    "            pre_delay = 20,\n",
    "            wet_gain = 0,\n",
    "            wet_only = False,\n",
    "        )\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def sox_augment_combine(\n",
    "    y,\n",
    "    min_bass_gain_low = 5,\n",
    "    min_bass_gain_high = 5,\n",
    "    reverberance = 1,\n",
    "    hf_damping = 1,\n",
    "    room_scale = 1,\n",
    "    stereo_depth = 1,\n",
    "):\n",
    "    from pysndfx import AudioEffectsChain\n",
    "\n",
    "    apply_audio_effects = (\n",
    "        AudioEffectsChain()\n",
    "        .lowshelf(gain = min_bass_gain_low, frequency = 300, slope = 0.1)\n",
    "        .highshelf(gain = -min_bass_gain_high, frequency = 300, slope = 0.1)\n",
    "        .reverb(\n",
    "            reverberance = reverberance,\n",
    "            hf_damping = hf_damping,\n",
    "            room_scale = room_scale,\n",
    "            stereo_depth = stereo_depth,\n",
    "            pre_delay = 20,\n",
    "            wet_gain = 0,\n",
    "            wet_only = False,\n",
    "        )\n",
    "    )\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced\n",
    "\n",
    "\n",
    "def random_pitch(sample, low = 0.5, high = 1.0):\n",
    "    y_pitch_speed = sample.copy()\n",
    "    length_change = np.random.uniform(low = low, high = high)\n",
    "    speed_fac = 1.0 / length_change\n",
    "    tmp = np.interp(\n",
    "        np.arange(0, len(y_pitch_speed), speed_fac),\n",
    "        np.arange(0, len(y_pitch_speed)),\n",
    "        y_pitch_speed,\n",
    "    )\n",
    "    minlen = min(y_pitch_speed.shape[0], tmp.shape[0])\n",
    "    y_pitch_speed *= 0\n",
    "    y_pitch_speed[:minlen] = tmp[:minlen]\n",
    "    return y_pitch_speed\n",
    "\n",
    "\n",
    "def random_amplitude(sample, low = 1.5, high = 3):\n",
    "    y_aug = sample.copy()\n",
    "    dyn_change = np.random.uniform(low = low, high = high)\n",
    "    return y_aug * dyn_change\n",
    "\n",
    "\n",
    "def random_stretch(sample, low = 0.5, high = 1.3):\n",
    "    input_length = len(sample)\n",
    "    stretching = sample.copy()\n",
    "    random_stretch = np.random.uniform(low = low, high = high)\n",
    "    stretching = librosa.effects.time_stretch(\n",
    "        stretching.astype('float'), random_stretch\n",
    "    )\n",
    "    return stretching\n",
    "\n",
    "def add_uniform_noise(sample, power = 0.01):\n",
    "    y_noise = sample.copy()\n",
    "    noise_amp = power * np.random.uniform() * np.amax(y_noise)\n",
    "    return y_noise.astype('float64') + noise_amp * np.random.normal(\n",
    "        size = y_noise.shape[0]\n",
    "    )\n",
    "\n",
    "def add_noise(sample, noise, random_sample = True, factor = 0.1):\n",
    "    y_noise = sample.copy()\n",
    "    if len(y_noise) > len(noise):\n",
    "        noise = np.tile(noise, int(np.ceil(len(y_noise) / len(noise))))\n",
    "    else:\n",
    "        if random_sample:\n",
    "            noise = noise[np.random.randint(0, len(noise) - len(y_noise) + 1) :]\n",
    "    return y_noise + noise[: len(y_noise)] * factor\n",
    "\n",
    "def sampling(combined, frame_duration_ms = 700, sample_rate = 16000):\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0))\n",
    "    offset = 0\n",
    "    while offset + n <= len(combined):\n",
    "        yield combined[offset : offset + n]\n",
    "        offset += n\n",
    "    if offset < len(combined):\n",
    "        yield combined[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FRAME:\n",
    "    def __init__(self, array, timestamp, duration):\n",
    "        self.array = array\n",
    "        self.timestamp = timestamp\n",
    "        self.duration = duration\n",
    "        \n",
    "def generate_frames(\n",
    "    audio,\n",
    "    frame_duration_ms: int = 30,\n",
    "    sample_rate: int = 16000,\n",
    "    append_ending_trail: bool = True,\n",
    "):\n",
    "    n = int(sample_rate * (frame_duration_ms / 1000.0))\n",
    "    offset = 0\n",
    "    timestamp = 0.0\n",
    "    duration = float(n) / sample_rate\n",
    "    results = []\n",
    "    while offset + n <= len(audio):\n",
    "        results.append(FRAME(audio[offset : offset + n], timestamp, duration))\n",
    "        timestamp += duration\n",
    "        offset += n\n",
    "    if append_ending_trail and offset < len(audio):\n",
    "        results.append(\n",
    "            FRAME(\n",
    "                audio[offset:], timestamp, len(audio) / sample_rate - timestamp\n",
    "            )\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(signal):\n",
    "\n",
    "    choice = random.randint(0, 4)\n",
    "    if choice == 0:\n",
    "\n",
    "        x = sox_augment_high(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(25, 50),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 50),\n",
    "            negate = 1,\n",
    "        )\n",
    "    if choice == 1:\n",
    "        x = sox_augment_high(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(25, 70),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 50),\n",
    "            negate = 0,\n",
    "        )\n",
    "    if choice == 2:\n",
    "        x = sox_augment_low(\n",
    "            signal,\n",
    "            min_bass_gain = random.randint(5, 30),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 50),\n",
    "            negate = random.randint(0, 1),\n",
    "        )\n",
    "    if choice == 3:\n",
    "        x = sox_augment_combine(\n",
    "            signal,\n",
    "            min_bass_gain_high = random.randint(25, 70),\n",
    "            min_bass_gain_low = random.randint(5, 30),\n",
    "            reverberance = random.randint(0, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(0, 90),\n",
    "        )\n",
    "    if choice == 4:\n",
    "        x = sox_reverb(\n",
    "            signal,\n",
    "            reverberance = random.randint(10, 80),\n",
    "            hf_damping = 10,\n",
    "            room_scale = random.randint(10, 90),\n",
    "        )\n",
    "\n",
    "    if random.randint(0, 1):\n",
    "        x = add_uniform_noise(\n",
    "            x, power = random.uniform(0.005, 0.015)\n",
    "        )\n",
    "        \n",
    "    if random.random() > 0.75:\n",
    "        r = random.choice(not_music)\n",
    "        n = read_wav(r)[0]\n",
    "        x = add_noise(x, n, factor = random.uniform(0.005, 0.01))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_music = glob('not-music/clean-wav/*.wav') + glob('musan/music/**/*.wav', recursive = True) \\\n",
    "+ glob('musan/noise/**/*.wav', recursive = True)\n",
    "len(not_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, _, _ = combine_speakers(not_music, 1)\n",
    "len(y) / 16000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise():\n",
    "    n = np.random.normal(-random.uniform(0,0.5),random.uniform(0,0.5),random.randint(16000 * 10, 16000 * 120))\n",
    "    n = n * random.uniform(0.0001, 0.8)\n",
    "    n[random.randint(0, len(n) -1)] = 1\n",
    "    n[random.randint(0, len(n) -1)] = -1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython.display as ipd\n",
    "\n",
    "# ipd.Audio(generate_noise(), rate = 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {**voxceleb_speakers, **speakers}\n",
    "keys = list(s.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_speakers(n):\n",
    "    ks = random.sample(keys, n)\n",
    "    r = []\n",
    "    for k in ks:\n",
    "        r.append(random.choice(s[k]))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 20\n",
    "y, _, timestamps = combine_speakers(random_speakers(count), count)\n",
    "frames = generate_frames(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "for no, frame in enumerate(frames):\n",
    "    speakers = np.where((frame.timestamp >= timestamps[:,0]) & (frame.timestamp <= timestamps[:,1]))[0]\n",
    "    Y.append(len(speakers))\n",
    "    \n",
    "Y = np.expand_dims(np.array(Y), -1)\n",
    "Y = np.sum(np.abs(np.diff(Y, axis=0)), axis=1, keepdims=True)\n",
    "Y = np.vstack(([[0]], Y > 0))\n",
    "Y = Y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712, 1712)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frames), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.system('rm speaker-change/data/*')\n",
    "DATA_DIR = os.path.expanduser('speaker-change/data')\n",
    "tf.gfile.MakeDirs(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from malaya_speech.train import prepare_data\n",
    "from collections import defaultdict\n",
    "import traceback\n",
    "\n",
    "selected_frames = [30, 90]\n",
    "\n",
    "def loop(files, dupe_factor = 5000):\n",
    "    _, no = files\n",
    "    fname = f'{DATA_DIR}/part-{no}.tfrecords'\n",
    "    writer = tf.python_io.TFRecordWriter(fname)\n",
    "    counts = defaultdict(int)\n",
    "    for _ in tqdm(range(dupe_factor)):\n",
    "        if random.random() > 0.3:\n",
    "            count = random.randint(1, 20)\n",
    "        else:\n",
    "            count = 0\n",
    "        try:\n",
    "            if count == 0:\n",
    "                if random.random() > 0.2:\n",
    "                    y, _, _ = combine_speakers(not_music, random.randint(1, 20))\n",
    "                    y = calc(y)\n",
    "                else:\n",
    "                    y = generate_noise()\n",
    "                \n",
    "            else:\n",
    "                y, _, timestamps = combine_speakers(random_speakers(count), count)\n",
    "                if random.random() > 0.7:\n",
    "                    y = calc(y)\n",
    "                if random.random() > 0.7:\n",
    "                    s_, _, _ = combine_speakers(not_music, random.randint(1, 20))\n",
    "                    y = add_noise(y, s_, factor = random.uniform(0.2, 0.8))\n",
    "                \n",
    "            for f in selected_frames:\n",
    "                frames = generate_frames(y, f)\n",
    "                if count == 0:\n",
    "                    Y = [0] * len(frames)\n",
    "                else:\n",
    "                    Y = []\n",
    "                    for no, frame in enumerate(frames):\n",
    "                        speakers = np.where((frame.timestamp >= timestamps[:,0]) & (frame.timestamp <= timestamps[:,1]))[0]\n",
    "                        Y.append(len(speakers))\n",
    "\n",
    "                    Y = np.expand_dims(np.array(Y), -1)\n",
    "                    Y = np.sum(np.abs(np.diff(Y, axis=0)), axis=1, keepdims=True)\n",
    "                    Y = np.vstack(([[0]], Y > 0))\n",
    "                    Y = Y[:,0]\n",
    "                    \n",
    "                for no, frame in enumerate(frames):\n",
    "                    example = prepare_data.to_example({'inputs': frame.array.tolist(), \n",
    "                                                       'targets': [Y[no]]})\n",
    "                    writer.write(example.SerializeToString())\n",
    "                    counts[Y[no]] += 1\n",
    "        except Exception as e:\n",
    "            print(traceback.format_exc())\n",
    "            \n",
    "    writer.close()\n",
    "    return [counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4143/5000 [1:28:18<20:22,  1.43s/it]  IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 94%|█████████▍| 4698/5000 [1:38:44<05:21,  1.07s/it]"
     ]
    }
   ],
   "source": [
    "import mp\n",
    "returned = mp.multiprocessing([10] * 12, loop, cores = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {0: 92074635, 1: 1537795})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_d = defaultdict(int)\n",
    "for d in returned:\n",
    "    for k, v in d.items():\n",
    "        combined_d[k] += v\n",
    "combined_d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
