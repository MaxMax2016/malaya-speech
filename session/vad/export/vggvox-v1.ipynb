{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from scipy.signal import lfilter, butter\n",
    "import decimal\n",
    "import math\n",
    "\n",
    "dimension = 512\n",
    "\n",
    "# for VGGVox v1\n",
    "def round_half_up(number):\n",
    "    return int(\n",
    "        decimal.Decimal(number).quantize(\n",
    "            decimal.Decimal('1'), rounding = decimal.ROUND_HALF_UP\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# for VGGVox v1\n",
    "def remove_dc_and_dither(sin, sample_rate):\n",
    "    if sample_rate == 16e3:\n",
    "        alpha = 0.99\n",
    "    elif sample_rate == 8e3:\n",
    "        alpha = 0.999\n",
    "    else:\n",
    "        print('Sample rate must be 16kHz or 8kHz only')\n",
    "        exit(1)\n",
    "    sin = lfilter([1, -1], [1, -alpha], sin)\n",
    "    dither = (\n",
    "        np.random.random_sample(len(sin))\n",
    "        + np.random.random_sample(len(sin))\n",
    "        - 1\n",
    "    )\n",
    "    spow = np.std(dither)\n",
    "    sout = sin + 1e-6 * spow * dither\n",
    "    return sout\n",
    "\n",
    "\n",
    "# for VGGVox v1\n",
    "def preemphasis(signal, coeff = 0.95):\n",
    "    return np.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "\n",
    "# for VGGVox v1\n",
    "def rolling_window(a, window, step = 1):\n",
    "    # http://ellisvalentiner.com/post/2017-03-21-np-strides-trick\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape = shape, strides = strides)[\n",
    "        ::step\n",
    "    ]\n",
    "\n",
    "\n",
    "# for VGGVox v1\n",
    "def framesig(\n",
    "    sig,\n",
    "    frame_len,\n",
    "    frame_step,\n",
    "    winfunc = lambda x: numpy.ones((x,)),\n",
    "    stride_trick = True,\n",
    "):\n",
    "    slen = len(sig)\n",
    "    frame_len = int(round_half_up(frame_len))\n",
    "    frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(\n",
    "            math.ceil((1.0 * slen - frame_len) / frame_step)\n",
    "        )  # LV\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "    zeros = np.zeros((padlen - slen,))\n",
    "    padsignal = np.concatenate((sig, zeros))\n",
    "    if stride_trick:\n",
    "        win = winfunc(frame_len)\n",
    "        frames = rolling_window(\n",
    "            padsignal, window = frame_len, step = frame_step\n",
    "        )\n",
    "    else:\n",
    "        indices = (\n",
    "            numpy.tile(numpy.arange(0, frame_len), (numframes, 1))\n",
    "            + numpy.tile(\n",
    "                numpy.arange(0, numframes * frame_step, frame_step),\n",
    "                (frame_len, 1),\n",
    "            ).T\n",
    "        )\n",
    "        indices = numpy.array(indices, dtype = numpy.int32)\n",
    "        frames = padsignal[indices]\n",
    "        win = numpy.tile(winfunc(frame_len), (numframes, 1))\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "\n",
    "# for VGGVox v1\n",
    "def normalize_frames(m, epsilon = 1e-12):\n",
    "    return np.array([(v - np.mean(v)) / max(np.std(v), epsilon) for v in m])\n",
    "\n",
    "\n",
    "# for VGGVox v1\n",
    "def vggvox_v1(\n",
    "    signal,\n",
    "    sample_rate = 16000,\n",
    "    preemphasis_alpha = 0.97,\n",
    "    frame_len = 0.005,\n",
    "    frame_step = 0.0005,\n",
    "    num_fft = 512,\n",
    "    buckets = None,\n",
    "    **kwargs\n",
    "):\n",
    "    signal = signal.copy()\n",
    "    signal *= 2 ** 15\n",
    "    signal = remove_dc_and_dither(signal, sample_rate)\n",
    "    signal = preemphasis(signal, coeff = preemphasis_alpha)\n",
    "    frames = framesig(\n",
    "        signal,\n",
    "        frame_len = frame_len * sample_rate,\n",
    "        frame_step = frame_step * sample_rate,\n",
    "        winfunc = np.hamming,\n",
    "    )\n",
    "    fft = abs(np.fft.fft(frames, n = num_fft))\n",
    "    fft_norm = normalize_frames(fft.T)\n",
    "\n",
    "    if buckets:\n",
    "        rsize = max(k for k in buckets if k <= fft_norm.shape[1])\n",
    "        rstart = int((fft_norm.shape[1] - rsize) / 2)\n",
    "        out = fft_norm[:, rstart : rstart + rsize]\n",
    "        return out\n",
    "\n",
    "    else:\n",
    "        if fft_norm.shape[1] < 100:\n",
    "            fft_norm = np.pad(\n",
    "                fft_norm, ((0, 0), (0, 100 - fft_norm.shape[1])), 'constant'\n",
    "            )\n",
    "        return fft_norm.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Reshape\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    ZeroPadding2D,\n",
    "    MaxPooling2D,\n",
    "    AveragePooling2D,\n",
    ")\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Lambda, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def conv_bn_pool(\n",
    "    inp_tensor,\n",
    "    layer_idx,\n",
    "    conv_filters,\n",
    "    conv_kernel_size,\n",
    "    conv_strides,\n",
    "    conv_pad,\n",
    "    pool = '',\n",
    "    pool_size = (2, 2),\n",
    "    pool_strides = None,\n",
    "    conv_layer_prefix = 'conv',\n",
    "):\n",
    "    x = ZeroPadding2D(padding = conv_pad, name = 'pad{}'.format(layer_idx))(\n",
    "        inp_tensor\n",
    "    )\n",
    "    x = Conv2D(\n",
    "        filters = conv_filters,\n",
    "        kernel_size = conv_kernel_size,\n",
    "        strides = conv_strides,\n",
    "        padding = 'valid',\n",
    "        name = '{}{}'.format(conv_layer_prefix, layer_idx),\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        epsilon = 1e-5, momentum = 1.0, name = 'bn{}'.format(layer_idx)\n",
    "    )(x)\n",
    "    x = Activation('relu', name = 'relu{}'.format(layer_idx))(x)\n",
    "    if pool == 'max':\n",
    "        x = MaxPooling2D(\n",
    "            pool_size = pool_size,\n",
    "            strides = pool_strides,\n",
    "            name = 'mpool{}'.format(layer_idx),\n",
    "        )(x)\n",
    "    elif pool == 'avg':\n",
    "        x = AveragePooling2D(\n",
    "            pool_size = pool_size,\n",
    "            strides = pool_strides,\n",
    "            name = 'apool{}'.format(layer_idx),\n",
    "        )(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "# Block of layers: Conv --> BatchNorm --> ReLU --> Dynamic average pool (fc6 -> apool6 only)\n",
    "def conv_bn_dynamic_apool(\n",
    "    inp_tensor,\n",
    "    layer_idx,\n",
    "    conv_filters,\n",
    "    conv_kernel_size,\n",
    "    conv_strides,\n",
    "    conv_pad,\n",
    "    conv_layer_prefix = 'conv',\n",
    "):\n",
    "    x = ZeroPadding2D(padding = conv_pad, name = 'pad{}'.format(layer_idx))(\n",
    "        inp_tensor\n",
    "    )\n",
    "    x = Conv2D(\n",
    "        filters = conv_filters,\n",
    "        kernel_size = conv_kernel_size,\n",
    "        strides = conv_strides,\n",
    "        padding = 'valid',\n",
    "        name = '{}{}'.format(conv_layer_prefix, layer_idx),\n",
    "    )(x)\n",
    "    x = BatchNormalization(\n",
    "        epsilon = 1e-5, momentum = 1.0, name = 'bn{}'.format(layer_idx)\n",
    "    )(x)\n",
    "    x = Activation('relu', name = 'relu{}'.format(layer_idx))(x)\n",
    "    x = GlobalAveragePooling2D(name = 'gapool{}'.format(layer_idx))(x)\n",
    "    x = Reshape((1, 1, conv_filters), name = 'reshape{}'.format(layer_idx))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "class Resnet1D(Model):\n",
    "    def __init__(self, params = None, is_training = False):\n",
    "        super(Resnet1D, self).__init__()\n",
    "\n",
    "    def call(self, inputs, training = None, mask = None):\n",
    "        inp = inputs['features_input']\n",
    "        x = conv_bn_pool(\n",
    "            inp,\n",
    "            layer_idx = 1,\n",
    "            conv_filters = 96,\n",
    "            conv_kernel_size = (7, 7),\n",
    "            conv_strides = (2, 2),\n",
    "            conv_pad = (1, 1),\n",
    "            pool = 'max',\n",
    "            pool_size = (3, 3),\n",
    "            pool_strides = (2, 2),\n",
    "        )\n",
    "        x = conv_bn_pool(\n",
    "            x,\n",
    "            layer_idx = 2,\n",
    "            conv_filters = 256,\n",
    "            conv_kernel_size = (5, 5),\n",
    "            conv_strides = (2, 2),\n",
    "            conv_pad = (1, 1),\n",
    "            pool = 'max',\n",
    "            pool_size = (3, 3),\n",
    "            pool_strides = (2, 2),\n",
    "        )\n",
    "        x = conv_bn_pool(\n",
    "            x,\n",
    "            layer_idx = 3,\n",
    "            conv_filters = 384,\n",
    "            conv_kernel_size = (3, 3),\n",
    "            conv_strides = (1, 1),\n",
    "            conv_pad = (1, 1),\n",
    "        )\n",
    "        x = conv_bn_pool(\n",
    "            x,\n",
    "            layer_idx = 4,\n",
    "            conv_filters = 256,\n",
    "            conv_kernel_size = (3, 3),\n",
    "            conv_strides = (1, 1),\n",
    "            conv_pad = (1, 1),\n",
    "        )\n",
    "        x = conv_bn_pool(\n",
    "            x,\n",
    "            layer_idx = 5,\n",
    "            conv_filters = 256,\n",
    "            conv_kernel_size = (3, 3),\n",
    "            conv_strides = (1, 1),\n",
    "            conv_pad = (1, 1),\n",
    "            pool = 'max',\n",
    "            pool_size = (5, 3),\n",
    "            pool_strides = (3, 2),\n",
    "        )\n",
    "        x = conv_bn_dynamic_apool(\n",
    "            x,\n",
    "            layer_idx = 6,\n",
    "            conv_filters = 4096,\n",
    "            conv_kernel_size = (9, 1),\n",
    "            conv_strides = (1, 1),\n",
    "            conv_pad = (0, 0),\n",
    "            conv_layer_prefix = 'fc',\n",
    "        )\n",
    "        x = conv_bn_pool(\n",
    "            x,\n",
    "            layer_idx = 7,\n",
    "            conv_filters = 1024,\n",
    "            conv_kernel_size = (1, 1),\n",
    "            conv_strides = (1, 1),\n",
    "            conv_pad = (0, 0),\n",
    "            conv_layer_prefix = 'fc',\n",
    "        )\n",
    "        x = Lambda(lambda y: K.l2_normalize(y, axis = 3), name = 'norm')(x)\n",
    "        x = Conv2D(\n",
    "            filters = 1024,\n",
    "            kernel_size = (1, 1),\n",
    "            strides = (1, 1),\n",
    "            padding = 'valid',\n",
    "            name = 'fc8',\n",
    "        )(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 512, None, 1])\n",
    "        inputs = {'features_input': self.X}\n",
    "        model = Resnet1D(is_training = True)\n",
    "        \n",
    "        logits = model.call(inputs)\n",
    "        logits = logits[:, 0, 0, :]\n",
    "        logits = tf.layers.dense(logits, 2)\n",
    "        self.logits = tf.identity(logits, name = 'logits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = 'output-vggvox-v1-vad/model.ckpt-170000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-4-ee5fe9908b35>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from output-vggvox-v1-vad/model.ckpt-170000\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vggvox-v1/model.ckpt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, 'vggvox-v1/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'logits' in n.name\n",
    "        or 'alphas' in n.name\n",
    "        or 'self/Softmax' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vggvox-v1/model.ckpt\n",
      "WARNING:tensorflow:From <ipython-input-11-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 46 variables.\n",
      "INFO:tensorflow:Converted 46 variables to const ops.\n",
      "324 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('vggvox-v1', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_graph(frozen_graph_filename):\n",
    "#     with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "#         graph_def = tf.GraphDef()\n",
    "#         graph_def.ParseFromString(f.read())\n",
    "#     with tf.Graph().as_default() as graph:\n",
    "#         tf.import_graph_def(graph_def)\n",
    "#     return graph\n",
    "\n",
    "def load_graph(frozen_graph_filename, **kwargs):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "\n",
    "    # https://github.com/onnx/tensorflow-onnx/issues/77#issuecomment-445066091\n",
    "    # to fix import T5\n",
    "    for node in graph_def.node:\n",
    "        if node.op == 'RefSwitch':\n",
    "            node.op = 'Switch'\n",
    "            for index in xrange(len(node.input)):\n",
    "                if 'moving_' in node.input[index]:\n",
    "                    node.input[index] = node.input[index] + '/read'\n",
    "        elif node.op == 'AssignSub':\n",
    "            node.op = 'Sub'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'AssignAdd':\n",
    "            node.op = 'Add'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "        elif node.op == 'Assign':\n",
    "            node.op = 'Identity'\n",
    "            if 'use_locking' in node.attr:\n",
    "                del node.attr['use_locking']\n",
    "            if 'validate_shape' in node.attr:\n",
    "                del node.attr['validate_shape']\n",
    "            if len(node.input) == 2:\n",
    "                node.input[0] = node.input[1]\n",
    "                del node.input[1]\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = load_graph('vggvox-v1/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "logits = g.get_tensor_by_name('import/logits:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
